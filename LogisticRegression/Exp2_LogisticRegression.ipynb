{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 逻辑回归\n",
    "### Logistic函数 (Sigmoid)\n",
    "### 为什么Sigmoid函数可以表示二分类概率？详见伯努利分布和指数分布族\n",
    "g 代表一个常用的逻辑函数（logistic function）为S形函数（Sigmoid function），公式为： $$g\\left( z \\right)=\\frac{1}{1+{{e}^{-z}}}$$\n",
    "合起来，我们得到逻辑回归模型的假设函数：\n",
    "$${{h}_{\\theta }}\\left( x \\right)=\\frac{1}{1+{{e}^{-{{\\theta}^{T}}X}}}$$\n",
    "### 损失函数\n",
    "### 关于交叉熵详见Liu II\n",
    "Binary Cross Entropy\n",
    "$$loss=-(y\\log{\\hat{y}}+(1-y)\\log{(1-\\hat{y})})$$\n",
    "$$J(\\theta)=-\\frac{1}{m}\\sum_{i=1}^{m}{(y\\log{h_{\\theta}(x)}-(1-y)\\log{(1-h_{\\theta}(x))})}$$\n",
    "### 梯度下降\n",
    "$$\\theta_{j}=\\theta_{j}-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}{(h_{\\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}}$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from LogisticRegression import sigmoid\n",
    "\n",
    "nums = np.arange(-5, 5, step=0.1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(nums, sigmoid(nums), 'r')\n",
    "ax.set_title(\"Sigmoid Function\")\n",
    "ax.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "加载数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[34.62365962, 78.02469282,  0.        ],\n       [30.28671077, 43.89499752,  0.        ],\n       [35.84740877, 72.90219803,  0.        ],\n       [60.18259939, 86.3085521 ,  1.        ],\n       [79.03273605, 75.34437644,  1.        ],\n       [45.08327748, 56.31637178,  0.        ],\n       [61.10666454, 96.51142588,  1.        ],\n       [75.02474557, 46.55401354,  1.        ],\n       [76.0987867 , 87.42056972,  1.        ],\n       [84.43281996, 43.53339331,  1.        ],\n       [95.86155507, 38.22527806,  0.        ],\n       [75.01365839, 30.60326323,  0.        ],\n       [82.30705337, 76.4819633 ,  1.        ],\n       [69.36458876, 97.71869196,  1.        ],\n       [39.53833914, 76.03681085,  0.        ],\n       [53.97105215, 89.20735014,  1.        ],\n       [69.07014406, 52.74046973,  1.        ],\n       [67.94685548, 46.67857411,  0.        ],\n       [70.66150955, 92.92713789,  1.        ],\n       [76.97878373, 47.57596365,  1.        ],\n       [67.37202755, 42.83843832,  0.        ],\n       [89.67677575, 65.79936593,  1.        ],\n       [50.53478829, 48.85581153,  0.        ],\n       [34.21206098, 44.2095286 ,  0.        ],\n       [77.92409145, 68.97235999,  1.        ],\n       [62.27101367, 69.95445795,  1.        ],\n       [80.19018075, 44.82162893,  1.        ],\n       [93.1143888 , 38.80067034,  0.        ],\n       [61.83020602, 50.25610789,  0.        ],\n       [38.7858038 , 64.99568096,  0.        ],\n       [61.37928945, 72.80788731,  1.        ],\n       [85.40451939, 57.05198398,  1.        ],\n       [52.10797973, 63.12762377,  0.        ],\n       [52.04540477, 69.43286012,  1.        ],\n       [40.23689374, 71.16774802,  0.        ],\n       [54.63510555, 52.21388588,  0.        ],\n       [33.91550011, 98.86943574,  0.        ],\n       [64.17698887, 80.90806059,  1.        ],\n       [74.78925296, 41.57341523,  0.        ],\n       [34.18364003, 75.23772034,  0.        ],\n       [83.90239366, 56.30804622,  1.        ],\n       [51.54772027, 46.85629026,  0.        ],\n       [94.44336777, 65.56892161,  1.        ],\n       [82.36875376, 40.61825516,  0.        ],\n       [51.04775177, 45.82270146,  0.        ],\n       [62.22267576, 52.06099195,  0.        ],\n       [77.19303493, 70.4582    ,  1.        ],\n       [97.77159928, 86.72782233,  1.        ],\n       [62.0730638 , 96.76882412,  1.        ],\n       [91.5649745 , 88.69629255,  1.        ],\n       [79.94481794, 74.16311935,  1.        ],\n       [99.27252693, 60.999031  ,  1.        ],\n       [90.54671411, 43.39060181,  1.        ],\n       [34.52451385, 60.39634246,  0.        ],\n       [50.28649612, 49.80453881,  0.        ],\n       [49.58667722, 59.80895099,  0.        ],\n       [97.64563396, 68.86157272,  1.        ],\n       [32.57720017, 95.59854761,  0.        ],\n       [74.24869137, 69.82457123,  1.        ],\n       [71.79646206, 78.45356225,  1.        ],\n       [75.39561147, 85.75993667,  1.        ],\n       [35.28611282, 47.02051395,  0.        ],\n       [56.2538175 , 39.26147251,  0.        ],\n       [30.05882245, 49.59297387,  0.        ],\n       [44.66826172, 66.45008615,  0.        ],\n       [66.56089447, 41.09209808,  0.        ],\n       [40.45755098, 97.53518549,  1.        ],\n       [49.07256322, 51.88321182,  0.        ],\n       [80.27957401, 92.11606081,  1.        ],\n       [66.74671857, 60.99139403,  1.        ],\n       [32.72283304, 43.30717306,  0.        ],\n       [64.03932042, 78.03168802,  1.        ],\n       [72.34649423, 96.22759297,  1.        ],\n       [60.45788574, 73.0949981 ,  1.        ],\n       [58.84095622, 75.85844831,  1.        ],\n       [99.8278578 , 72.36925193,  1.        ],\n       [47.26426911, 88.475865  ,  1.        ],\n       [50.4581598 , 75.80985953,  1.        ],\n       [60.45555629, 42.50840944,  0.        ],\n       [82.22666158, 42.71987854,  0.        ],\n       [88.91389642, 69.8037889 ,  1.        ],\n       [94.83450672, 45.6943068 ,  1.        ],\n       [67.31925747, 66.58935318,  1.        ],\n       [57.23870632, 59.51428198,  1.        ],\n       [80.366756  , 90.9601479 ,  1.        ],\n       [68.46852179, 85.5943071 ,  1.        ],\n       [42.07545454, 78.844786  ,  0.        ],\n       [75.47770201, 90.424539  ,  1.        ],\n       [78.63542435, 96.64742717,  1.        ],\n       [52.34800399, 60.76950526,  0.        ],\n       [94.09433113, 77.15910509,  1.        ],\n       [90.44855097, 87.50879176,  1.        ],\n       [55.48216114, 35.57070347,  0.        ],\n       [74.49269242, 84.84513685,  1.        ],\n       [89.84580671, 45.35828361,  1.        ],\n       [83.48916274, 48.3802858 ,  1.        ],\n       [42.26170081, 87.10385094,  1.        ],\n       [99.31500881, 68.77540947,  1.        ],\n       [55.34001756, 64.93193801,  1.        ],\n       [74.775893  , 89.5298129 ,  1.        ]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(fname='ex2data1.txt',delimiter=\",\")\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看数据集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "positive_data_idx= np.where(data[:,2]==1)\n",
    "positive_data = data[positive_data_idx]\n",
    "negative_data_idx= np.where(data[:, 2] == 0)\n",
    "negative_data = data[negative_data_idx]\n",
    "ax.scatter(x=positive_data[:, 0], y=positive_data[:, 1], s=10, color=\"red\",label=\"positive\")\n",
    "ax.scatter(x=negative_data[:, 0], y=negative_data[:, 1], s=10, label=\"negative\")\n",
    "ax.set_title(\"Dataset\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "划分训练集、验证集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9oAAAKqCAYAAADFQiYyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAABirUlEQVR4nO3de1yUdf7//+coggiCqMhAioGHJDaLrEWsjTI3opOJ28Gl8tSaZgdtXcHKyqw8tFtmrbK1fbQsa7PVynbNNTO2UllTrDbdtCRHU/BrAqOYqHD9/vDn5MhBRq/hmsPjfrtxq3nPcM1LLgZ4zvv9fl02wzAMAQAAAAAAU7SwugAAAAAAAAIJQRsAAAAAABMRtAEAAAAAMBFBGwAAAAAAExG0AQAAAAAwEUEbAAAAAAATEbQBAAAAADARQRsAAAAAABMRtAEAAAAAMBFBGwAASQcOHNCdd94pu90um82mcePGWV3SGfn+++9ls9k0f/58q0vx2McffyybzaaPP/64WZ+3vq/ZY489JpvN1qTPt9lseuyxx0yt6fLLL9fll19u6jEBAN5H0AaAIDJ//nzZbDbXR+vWrZWQkKCsrCzNnj1b+/fvP+1jr169Wo899pgqKirMK/gMzJkzx6OQ+dRTT2n+/PkaM2aMFixYoNtvv90rdR0Pbqf6IFw17oYbblCbNm0a/Z7Nzc1VaGiofvzxx2aszHObNm3SY489pu+//97qUgAAJgmxugAAQPN7/PHHlZSUpCNHjqi0tFQff/yxxo0bp2eeeUbvvfeeevfu7fExV69erSlTpmjYsGFq166d+UV7aM6cOerYsaOGDRvWpMd/9NFH6tu3rx599FGv1pWTk6Pu3bu7bh84cEBjxozRoEGDlJOT4xqPi4s7o+fp2rWrfvrpJ7Vq1eqMjuOrcnNztXTpUi1ZskR33HFHnfsPHjyod999V1dffbU6dOhw2s/z8MMPKz8//0xKPaVNmzZpypQpuvzyy3X22We73fevf/3Lq88NAPAOgjYABKHs7GxddNFFrtuTJk3SRx99pOuuu0433HCDNm/erPDwcAsrbH579uzRueeea9rxjh49qtraWoWGhrqN9+7d2+2NjL1792rMmDHq3bu3brvttgaPd+jQIYWGhqpFi6YtRju+YiFQ3XDDDWrbtq0WLlxYb9B+9913VVVVpdzc3DN6npCQEIWEWPfn0snfPwAA/8DScQCAJKl///6aPHmytm/frtdee801/uWXX2rYsGFKTk5W69atZbfbNWLECLfluI899pj+8Ic/SJKSkpJcy5+PL4WdN2+e+vfvr06dOiksLEznnnuu5s6dW6eGzz//XFlZWerYsaPCw8OVlJSkESNGuD2mtrZWs2bNUmpqqlq3bq24uDjdddddKi8vdz3m7LPP1tdff63CwsJTLsU+vh+4pKRE//jHP+rUvmfPHo0cOVJxcXFq3bq1zj//fL3yyituxzi+t/ePf/yjZs2apW7duiksLEybNm1q8te/vprefPNNPfzwwzrrrLPUpk0bOZ1O7du3TxMmTNB5552nyMhIRUVFKTs7W1988UW9NZ24fH7YsGGKjIzUDz/8oBtvvFGRkZGKjY3VhAkTVFNTc8q63n33XV177bVKSEhQWFiYunXrpqlTp9b53Msvv1y/+MUvtGnTJl1xxRVq06aNzjrrLM2cObPOMXfu3Kkbb7xRERER6tSpk8aPH6/q6upT1hIeHq6cnBytXLlSe/bsqXP/woUL1bZtW91www1N/prVp7492tXV1Ro/frxiY2Ndz7Fz5846n7t9+3bdfffdOueccxQeHq4OHTropptuclsiPn/+fN10002SpCuuuML1/Xd8f3p9e7Q9/Z588cUXXd+TF198sdatW3fKfzcA4Mwwow0AcLn99tv14IMP6l//+pd+97vfSZJWrFihbdu2afjw4bLb7fr666/14osv6uuvv9batWtls9mUk5OjLVu26I033tCzzz6rjh07SpJiY2MlSXPnzlVqaqpuuOEGhYSEaOnSpbr77rtVW1ursWPHSjoWHq666irFxsYqPz9f7dq10/fff6/Fixe71XjXXXdp/vz5Gj58uO677z6VlJTohRdeUHFxsT777DO1atVKs2bN0r333qvIyEg99NBDkhpeip2SkqIFCxZo/Pjx6ty5s37/+9+7av/pp590+eWX69tvv9U999yjpKQkLVq0SMOGDVNFRYXuv/9+t2PNmzdPhw4d0qhRoxQWFqb27duf0fmYOnWqQkNDNWHCBFVXVys0NFSbNm3SO++8o5tuuklJSUkqKyvTX/7yF2VmZmrTpk1KSEho9Jg1NTXKyspSenq6/vjHP+rDDz/Un/70J3Xr1k1jxoxp9HPnz5+vyMhIPfDAA4qMjNRHH32kRx55RE6nU08//bTbY8vLy3X11VcrJydHN998s95++23l5eXpvPPOU3Z2tiTpp59+0pVXXimHw6H77rtPCQkJWrBggT766KMmfX1yc3P1yiuv6K233tI999zjGt+3b5+WL1+uIUOGKDw8XF9//fUZfc1Oduedd+q1117Tb3/7W/Xr108fffSRrr322jqPW7dunVavXq1bb71VnTt31vfff6+5c+fq8ssv16ZNm9SmTRtddtlluu+++zR79mw9+OCDSklJkSTXf0/m6ffkwoULtX//ft11112y2WyaOXOmcnJytG3btoDdVgAAPsEAAASNefPmGZKMdevWNfiY6OhoIy0tzXX74MGDdR7zxhtvGJKMf//7366xp59+2pBklJSU1Hl8fcfIysoykpOTXbeXLFlyyto++eQTQ5Lx+uuvu41/8MEHdcZTU1ONzMzMBo91sq5duxrXXnut29isWbMMScZrr73mGjt8+LCRkZFhREZGGk6n0zAMwygpKTEkGVFRUcaePXua/JyGYRj/7//9P0OS8eijj7rGVq1aZUgykpOT63ztDh06ZNTU1LiNlZSUGGFhYcbjjz/uNibJmDdvnmts6NChhiS3xxmGYaSlpRl9+vQ5Za31nce77rrLaNOmjXHo0CHXWGZmpiHJePXVV11j1dXVht1uNwYPHuwaO/71feutt1xjVVVVRvfu3Q1JxqpVqxqt5+jRo0Z8fLyRkZHhNl5QUGBIMpYvX24Yxpl9zR599FHjxD+XNm7caEgy7r77brfj/fa3v61zHuv7eq1Zs6bO12bRokUN/nszMzPdvo89/Z7s0KGDsW/fPtdj3333XUOSsXTp0jrPBQAwD0vHAQBuIiMj3To5n7hX+9ChQ9q7d6/69u0rSdqwYUOTjnniMSorK7V3715lZmZq27ZtqqyslCRXA7X3339fR44cqfc4ixYtUnR0tH79619r7969ro8+ffooMjJSq1at8ujfeir//Oc/ZbfbNWTIENdYq1atdN999+nAgQMqLCx0e/zgwYNds/hmGDp0aJ298mFhYa592jU1Nfrxxx8VGRmpc845p8nnY/To0W63f/WrX2nbtm2n/LwTa9m/f7/27t2rX/3qVzp48KD+97//uT02MjLSbc95aGiofvnLX7o9zz//+U/Fx8frN7/5jWusTZs2GjVqVJP+HS1bttStt96qNWvWuC3HXrhwoeLi4nTllVdKMudrdmLNknTfffe5jdd3ObgTv15HjhzRjz/+qO7du6tdu3YeP++Jz+/J9+Qtt9yimJgY1+1f/epXktSk8w0AOH0EbQCAmwMHDqht27au2/v27dP999+vuLg4hYeHKzY2VklJSZLkCsmn8tlnn2nAgAGKiIhQu3btFBsbqwcffNDtGJmZmRo8eLCmTJmijh07auDAgZo3b57bft2tW7eqsrJSnTp1UmxsrNvHgQMH6t2reya2b9+uHj161GlAdnxZ7/bt293Gj39dzFLf8Wpra/Xss8+qR48eCgsLU8eOHRUbG6svv/yySeejdevWdd4MiImJcdvj3pCvv/5agwYNUnR0tKKiohQbG+sK0yc/d+fOnevsbT75ebZv367u3bvXedw555xzylqOO97sbOHChZKO7fn+5JNPdOutt6ply5aSzvxrdqLt27erRYsW6tat2ylr/umnn/TII4+oS5cubs9bUVHh8fOe+PyefE8mJia63T4euptyvgEAp4892gAAl507d6qystLt8lM333yzVq9erT/84Q+64IILFBkZqdraWl199dWqra095TG/++47XXnllerVq5eeeeYZdenSRaGhofrnP/+pZ5991nUMm82mt99+W2vXrtXSpUu1fPlyjRgxQn/605+0du1a1/N26tRJr7/+er3PZeZs8ukwu1N7fcd76qmnNHnyZI0YMUJTp05V+/bt1aJFC40bN65J5+N4+PRURUWFMjMzFRUVpccff1zdunVT69attWHDBuXl5dV57oaexzCM03r+hvTp00e9evXSG2+8oQcffFBvvPGGDMNw6zZ+pl+z03Xvvfdq3rx5GjdunDIyMhQdHS2bzaZbb73Vq897ouY6DwAAdwRtAIDLggULJElZWVmSjs16rVy5UlOmTNEjjzzietzWrVvrfO7Js5LHLV26VNXV1XrvvffcZtcaWubdt29f9e3bV08++aQWLlyo3Nxcvfnmm7rzzjvVrVs3ffjhh7rkkktOGWobqscTXbt21Zdffqna2lq3GcTjy6S7du16xs/hqbfffltXXHGFXn75ZbfxiooKVxM6b/j444/1448/avHixbrssstc4yUlJad9zK5du+q///2vDMNwO1/ffPONR8fJzc3V5MmT9eWXX2rhwoXq0aOHLr74Ytf9Zn7NunbtqtraWn333Xdus9j11fz2229r6NCh+tOf/uQaO3TokCoqKtwe58n3qi9+TwIA6mLpOABAkvTRRx9p6tSpSkpKcs0GHp8NO3n2a9asWXU+PyIiQpLqhIj6jlFZWal58+a5Pa68vLzO81xwwQWS5Fo+fvPNN6umpkZTp06t8/xHjx51e+6IiIg6tXjqmmuuUWlpqf72t7+5Pc/zzz+vyMhIZWZmntHxT0fLli3rfJ0WLVqkH374wevPK7mfx8OHD2vOnDmnfcxrrrlGu3bt0ttvv+0aO3jwoF588UWPjnP8+/WRRx7Rxo0b61w728yv2fGO6bNnz3Ybr+81Ud/zPv/883Uuh9bQa6c+vvg9CQCoixltAAhCy5Yt0//+9z8dPXpUZWVl+uijj7RixQp17dpV7733nlq3bi1JioqK0mWXXaaZM2fqyJEjOuuss/Svf/2r3lnMPn36SJIeeugh3XrrrWrVqpWuv/56XXXVVQoNDdX111+vu+66SwcOHNBLL72kTp06affu3a7Pf+WVVzRnzhwNGjRI3bp10/79+/XSSy8pKipK11xzjaRj+7jvuusuTZs2TRs3btRVV12lVq1aaevWrVq0aJGee+45V2OtPn36aO7cuXriiSfUvXt3derUSf379/fo6zRq1Cj95S9/0bBhw7R+/XqdffbZevvtt/XZZ59p1qxZbnvZm8t1112nxx9/XMOHD1e/fv301Vdf6fXXX1dycrJXn7dfv36KiYnR0KFDdd9998lms2nBggVntAT5d7/7nV544QXdcccdWr9+veLj47VgwQK1adPGo+MkJSWpX79+evfddyWpTtA282t2wQUXaMiQIZozZ44qKyvVr18/rVy5Ut9++22dx1533XVasGCBoqOjde6552rNmjX68MMP1aFDhzrHbNmypWbMmKHKykqFhYW5rjt/Ml/8ngQA1EXQBoAgdHwZeGhoqNq3b6/zzjtPs2bN0vDhw+v8ob5w4ULde++9+vOf/yzDMHTVVVdp2bJlda49fPHFF2vq1KkqKCjQBx98oNraWpWUlOicc87R22+/rYcfflgTJkyQ3W7XmDFjFBsbqxEjRrg+PzMzU//5z3/05ptvqqysTNHR0frlL3+p119/3a0pWEFBgfr06aO//OUvevDBBxUSEqKzzz5bt912my655BK3f+P27ds1c+ZM7d+/X5mZmR4H7fDwcH388cfKz8/XK6+8IqfTqXPOOUfz5s3TsGHDPDqWWR588EFVVVVp4cKF+tvf/qYLL7xQ//jHP5Sfn+/V5+3QoYPef/99/f73v9fDDz+smJgY3XbbbbryyitdWw081aZNG61cuVL33nuvnn/+ebVp00a5ubnKzs7W1Vdf7dGxcnNztXr1av3yl7906zEgmf81+7//+z/Fxsbq9ddf1zvvvKP+/fvrH//4h7p06eL2uOeee04tW7bU66+/rkOHDumSSy7Rhx9+WOfrZbfbVVBQoGnTpmnkyJGqqanRqlWr6g3avvg9CQCoy2bQDQMAAAAAANOwRxsAAAAAABMRtAEAAAAAMBFBGwAAAAAAExG0AQAAAAAwEUEbAAAAAAATEbQBAAAAADCRX15Hu7a2Vrt27VLbtm1ls9msLgcAAAAAEOAMw9D+/fuVkJCgFi0an7P2y6C9a9cudenSxeoyAAAAAABBZseOHercuXOjj/HLoN22bVtJx/6BUVFRFlcDAAAAAAh0TqdTXbp0ceXRxvhl0D6+XDwqKoqgDQAAAABoNk3ZvkwzNAAAAAAATETQBgAAAADARARtAAAAAABM5Jd7tJuqpqZGR44csboMmKBVq1Zq2bKl1WUAAAAAwCkFZNA2DEOlpaWqqKiwuhSYqF27drLb7Vw7HQAAAIBPC8igfTxkd+rUSW3atCGY+TnDMHTw4EHt2bNHkhQfH29xRQAAAADQsIAL2jU1Na6Q3aFDB6vLgUnCw8MlSXv27FGnTp1YRg4AAADAZwVcM7Tje7LbtGljcSUw2/Fzyr57AAAAAL4s4IL2cSwXDzycUwAAAAD+IGCDNgAAAAAAViBoB7Czzz5bs2bNsroMAAAAAAgqBG0fYLPZGv147LHHTuu469at06hRo8wtFgAAAADQKI+D9r///W9df/31SkhIkM1m0zvvvON2v2EYeuSRRxQfH6/w8HANGDBAW7dudXvMvn37lJubq6ioKLVr104jR47UgQMHzugf4s92797t+pg1a5aioqLcxiZMmOB6rGEYOnr0aJOOGxsbS1M4AAAAAGhmHgftqqoqnX/++frzn/9c7/0zZ87U7NmzVVBQoKKiIkVERCgrK0uHDh1yPSY3N1dff/21VqxYoffff1///ve/g3rm1W63uz6io6Nls9lct//3v/+pbdu2WrZsmfr06aOwsDB9+umn+u677zRw4EDFxcUpMjJSF198sT788EO34568dNxms+mvf/2rBg0apDZt2qhHjx567733mvlfCwAAAACBzeOgnZ2drSeeeEKDBg2qc59hGJo1a5YefvhhDRw4UL1799arr76qXbt2uWa+N2/erA8++EB//etflZ6erksvvVTPP/+83nzzTe3ateuM/0FmKnaUa/GGnSp2lFtdivLz8zV9+nRt3rxZvXv31oEDB3TNNddo5cqVKi4u1tVXX63rr79eDoej0eNMmTJFN998s7788ktdc801ys3N1b59+5rpXwEAAAAAgc/UPdolJSUqLS3VgAEDXGPR0dFKT0/XmjVrJElr1qxRu3btdNFFF7keM2DAALVo0UJFRUX1Hre6ulpOp9Ptw9umL9usQXNW64G3vtCgOas1fdlmrz9nYx5//HH9+te/Vrdu3dS+fXudf/75uuuuu/SLX/xCPXr00NSpU9WtW7dTzlAPGzZMQ4YMUffu3fXUU0/pwIED+s9//tNM/woAAAAACHymBu3S0lJJUlxcnNt4XFyc677S0lJ16tTJ7f6QkBC1b9/e9ZiTTZs2TdHR0a6PLl26mFl2HcWOchUUbnMbKyjcZunM9olvTEjSgQMHNGHCBKWkpKhdu3aKjIzU5s2bTzmj3bt3b9f/R0REKCoqSnv27PFKzQAAAAAQjPyi6/ikSZNUWVnp+tixY4dXn69kb5VH480hIiLC7faECRO0ZMkSPfXUU/rkk0+0ceNGnXfeeTp8+HCjx2nVqpXbbZvNptraWtPrBQAAAIBgFWLmwex2uySprKxM8fHxrvGysjJdcMEFrsecPIN69OhR7du3z/X5JwsLC1NYWJiZpTYqqWOER+NW+OyzzzRs2DDXXvkDBw7o+++/t7YoAAAAAIC5M9pJSUmy2+1auXKla8zpdKqoqEgZGRmSpIyMDFVUVGj9+vWux3z00Ueqra1Venq6meWctrTEGI3OTHYbG5OZrLTEGIsqqqtHjx5avHixNm7cqC+++EK//e1vmZkGAAAAAB/g8Yz2gQMH9O2337pul5SUaOPGjWrfvr0SExM1btw4PfHEE+rRo4eSkpI0efJkJSQk6MYbb5QkpaSk6Oqrr9bvfvc7FRQU6MiRI7rnnnt06623KiEhwbR/2JnKz05RVqpdJXurlNQxwqdCtiQ988wzGjFihPr166eOHTsqLy+vWZrEAQAAAAAaZzMMw/DkEz7++GNdccUVdcaHDh2q+fPnyzAMPfroo3rxxRdVUVGhSy+9VHPmzFHPnj1dj923b5/uueceLV26VC1atNDgwYM1e/ZsRUZGNqkGp9Op6OhoVVZWKioqyu2+Q4cOqaSkRElJSWrdurUn/zT4OM4tAAAAAKs0lkNP5nHQ9gUEbe87WH1U1UdrFRbSQm3CTN3Kf9o4twAAAACs4knQ9o0EBZ+yu/In/b/91a7bsW3DFB8dbmFFAAAAAOA//OLyXmg+B6uPuoVsSfp/+6t1sPqoRRUBAAAAgH8haMNN9dH6O5c3NA4AAAAAcEfQhpuwkPq/JRoaBwAAAAC4Iz3BTZuwEMW2DXMbi20b5jMN0QAAAADA15GeUEd8dLiiW7fyua7jAAAAAOAPSFCoV5uwELUJO/XjAAAAAADuWDoOAAAAAICJCNoB5PLLL9e4ceNct88++2zNmjWr0c+x2Wx65513zvi5zToOAAAAAPg7graPuP7663X11VfXe98nn3wim82mL7/80qNjrlu3TqNGjTKjPJfHHntMF1xwQZ3x3bt3Kzs729TnAgCgqYod5Vq8YaeKHeVWlwIAAHu0fcXIkSM1ePBg7dy5U507d3a7b968ebrooovUu3dvj44ZGxtrZomNstvtzfZcvq7YUa6SvVVK6hihtMQYq8sBgIA3fdlmFRRuc90enZms/OwUCysCAAQ7ZrR9xHXXXafY2FjNnz/fbfzAgQNatGiRbrzxRg0ZMkRnnXWW2rRpo/POO09vvPFGo8c8een41q1bddlll6l169Y699xztWLFijqfk5eXp549e6pNmzZKTk7W5MmTdeTIEUnS/PnzNWXKFH3xxRey2Wyy2Wyuek9eOv7VV1+pf//+Cg8PV4cOHTRq1CgdOHDAdf+wYcN044036o9//KPi4+PVoUMHjR071vVc/mr6ss0aNGe1HnjrCw2as1rTl222uiQACGjFjnK3kC1JBYXbmNkGAFiKoN2YoiJpwYJj//WykJAQ3XHHHZo/f74Mw3CNL1q0SDU1NbrtttvUp08f/eMf/9B///tfjRo1Srfffrv+85//NOn4tbW1ysnJUWhoqIqKilRQUKC8vLw6j2vbtq3mz5+vTZs26bnnntNLL72kZ599VpJ0yy236Pe//71SU1O1e/du7d69W7fcckudY1RVVSkrK0sxMTFat26dFi1apA8//FD33HOP2+NWrVql7777TqtWrdIrr7yi+fPn13mjwZ/wxx4ANL+SvVUejQMA0BwI2g3Jy5P69pXuuOPYf+sJpWYbMWKEvvvuOxUWFrrG5s2bp8GDB6tr166aMGGCLrjgAiUnJ+vee+/V1VdfrbfeeqtJx/7www/1v//9T6+++qrOP/98XXbZZXrqqafqPO7hhx9Wv379dPbZZ+v666/XhAkTXM8RHh6uyMhIhYSEyG63y263Kzw8vM4xFi5cqEOHDunVV1/VL37xC/Xv318vvPCCFixYoLKyMtfjYmJi9MILL6hXr1667rrrdO2112rlypWeftl8Bn/sAUDzS+oY4dE4AADNgaBdn6IiaeZM97GZM70+s92rVy/169dP//d//ydJ+vbbb/XJJ59o5MiRqqmp0dSpU3Xeeeepffv2ioyM1PLly+VwOJp07M2bN6tLly5KSEhwjWVkZNR53N/+9jddcsklstvtioyM1MMPP9zk5zjxuc4//3xFRPz8R84ll1yi2tpaffPNN66x1NRUtWzZ0nU7Pj5ee/bs8ei5fAl/7AFA80tLjNHozGS3sTGZyfTIAABYiqBdny1bPBs30ciRI/X3v/9d+/fv17x589StWzdlZmbq6aef1nPPPae8vDytWrVKGzduVFZWlg4fPmzac69Zs0a5ubm65ppr9P7776u4uFgPPfSQqc9xolatWrndttlsqq2t9cpzNQf+2AMAa+Rnp2jJ3f30zM3na8nd/ZRHIzQAgMXoOl6fnj09GzfRzTffrPvvv18LFy7Uq6++qjFjxshms+mzzz7TwIEDddttt0k6tud6y5YtOvfcc5t03JSUFO3YsUO7d+9WfHy8JGnt2rVuj1m9erW6du2qhx56yDW2fft2t8eEhoaqpqbmlM81f/58VVVVuWa1P/vsM7Vo0ULnnHNOk+r1V/nZKcpKtdN1HACaWVpiDD9zAQA+gxnt+qSnSxMnuo/l5R0b97LIyEjdcsstmjRpknbv3q1hw4ZJknr06KEVK1Zo9erV2rx5s+666y63/c6nMmDAAPXs2VNDhw7VF198oU8++cQtUB9/DofDoTfffFPfffedZs+erSVLlrg95uyzz1ZJSYk2btyovXv3qrq6us5z5ebmqnXr1ho6dKj++9//atWqVbr33nt1++23Ky4uzvMvip9JS4xRzoWd+YMPwM+asbkmAACwHkG7ITNmSGvXSq++euy/06c321OPHDlS5eXlysrKcu2pfvjhh3XhhRcqKytLl19+uex2u2688cYmH7NFixZasmSJfvrpJ/3yl7/UnXfeqSeffNLtMTfccIPGjx+ve+65RxdccIFWr16tyZMnuz1m8ODBuvrqq3XFFVcoNja23kuMtWnTRsuXL9e+fft08cUX6ze/+Y2uvPJKvfDCC55/MQDA31nQXBPwN8WOci3esJMrdQAIGDbjxGtJ+Qmn06no6GhVVlYqKirK7b5Dhw6ppKRESUlJat26tUUVwhs4twB8SlHRsd4dPXs2vOKpqOhYuD7Z2rXNskoK8AfTl212uzzm6Mxk5bPPHoAPaiyHnowZbQAAPNXUWWoLm2sC/qDYUe4WsiWpoHAbM9sA/B5BGwAAT3hyCUgLm2vCYuzLb5KSvVUejQOAvyBoAwDgCU9mqS1srgkLsS+/yZI6Rng0DgD+gqANAIAnPJ2ltrC5JizgyYoHKC0xRqMzk93GxmQmc+UOAH4vYK+j7Yc93nAKnFMAPuH4LPWJYepUs9Tp6cxiB4vGVjzwPVCv/OwUZaXaVbK3SkkdIwjZAAJCwAXtVq1aSZIOHjyo8PBwi6uBmQ4ePCjp53MMAJaZMUPKyTl113EEH/bln5a0xBgCNoCAEnBBu2XLlmrXrp327Nkj6dg1nW02m8VVNb+fDh/V4aO1Cg1pofBQ/z7NhmHo4MGD2rNnj9q1a6eWLVtaXRIAMEuN+p3OigcAQMDx7wTWALvdLkmusB1sKn86ov2Hjrput20douhw/58FbteunevcAgDgs1jxAABBz2b44cbXpl4ovKamRkeOHGnGyqy3aVel7n2juM7480PSdG5CtAUVmaNVq1bMZAMAAACwTFNzqBSgM9rHtWzZMujC2fcVe/XD/pp6xo/owuTWFlQEAAAAAMGFy3sFGK5HCQAAAADWImgHGK5HCQAAAADWCuil48GK61ECAAAAgHUI2gGK61ECAAAAgDVYOg4AAAAAgIkI2gAAAAAAmIigDQAAAACAiQjaAAAAAACYiKANAAAAAICJCNoAAAAAAJiIoA0AAAAAgIkI2gAAAAAAmIigDQAAAACAiQjaAAAAAACYiKANAAAAAICJCNoAAAAAAJiIoA0AAAAAgIkI2gAAAAAAmCjE6gIAAACsVOwoV8neKiV1jFBaYozV5QAAAgBBGwAABK3pyzaroHCb6/bozGTlZ6dYWBEAIBCwdBwAAASlYke5W8iWpILCbSp2lFtUEQAgUBC0AQBAUCrZW+XROAAATUXQBgAAQSmpY4RH4wAANBVBGwAABKW0xBiNzkx2GxuTmUxDNADAGaMZGgAACFr52SnKSrXTdRwAYCqCNgAACGppiTEE7ADDJdsAWI2gDQAAgIDBJdsA+AL2aAMAACAgcMk2AL6CoA0AAICAwCXbAPgKgjYAAAACApdsA+ArCNoAAAAICFyyDYCvoBkaAAAAAgaXbAPgCwjaAAAACChcsg2A1Vg6DgAAAACAiZjRBgAAQMApdpSzfByAZQjaAAAACCjTl212u5726Mxk5WenWFgRgGDD0nEAAAAEjGJHuVvIlqSCwm0qdpRbVBGAYETQBgAAQMAo2Vvl0TgAeANBGwAAAAEjqWOER+MA4A0EbQAAgCBR7CjX4g07A3oZdVpijEZnJruNjclMpiEagGZFMzQAAIAgEEwNwvKzU5SVaqfrOADLeGVGe//+/Ro3bpy6du2q8PBw9evXT+vWrXPdbxiGHnnkEcXHxys8PFwDBgzQ1q1bvVEKAABA0AvGBmFpiTHKubAzIRuAJbwStO+8806tWLFCCxYs0FdffaWrrrpKAwYM0A8//CBJmjlzpmbPnq2CggIVFRUpIiJCWVlZOnTokDfKAQAACGo0CAOA5mV60P7pp5/097//XTNnztRll12m7t2767HHHlP37t01d+5cGYahWbNm6eGHH9bAgQPVu3dvvfrqq9q1a5feeecds8sBAAAIejQIA4DmZXrQPnr0qGpqatS6dWu38fDwcH366acqKSlRaWmpBgwY4LovOjpa6enpWrNmTb3HrK6ultPpdPsAAABA09AgDACal+nN0Nq2bauMjAxNnTpVKSkpiouL0xtvvKE1a9aoe/fuKi0tlSTFxcW5fV5cXJzrvpNNmzZNU6ZMMbtUAACAoEGDMABoPl7Zo71gwQIZhqGzzjpLYWFhmj17toYMGaIWLU7v6SZNmqTKykrXx44dO0yuGAAAwL815dJdNAgDgObhlct7devWTYWFhaqqqpLT6VR8fLxuueUWJScny263S5LKysoUHx/v+pyysjJdcMEF9R4vLCxMYWFh3igVAADA7wXTpbsAwB94ZUb7uIiICMXHx6u8vFzLly/XwIEDlZSUJLvdrpUrV7oe53Q6VVRUpIyMDG+WAwAAEHCC8dJdAODrvDKjvXz5chmGoXPOOUfffvut/vCHP6hXr14aPny4bDabxo0bpyeeeEI9evRQUlKSJk+erISEBN14443eKAcAgldRkbRli9Szp5SebnU1ALygsUt3sUQcAKzhlaBdWVmpSZMmaefOnWrfvr0GDx6sJ598Uq1atZIkTZw4UVVVVRo1apQqKip06aWX6oMPPqjTqRwAcAby8qSZM3++PXGiNGOGdfUA8Aou3QUAvsdmGIZhdRGecjqdio6OVmVlpaKioqwuBwB8T1GR1Ldv3fG1a5nZBgLQyXu0x2QmK4892gBgKk9yqFdmtAEAFtuypeFxgjYQcLh0FwD4FoI2AASinj09Gwfg99ISYwjYQFPRwwRe5tWu4wAAi6SnH9uTfaK8PP6YAAAgL+/Y9qo77jj237w8qytCAGKPNgCfVewoZxnkmeIdewAAfkYPE5wB9mgD8HsnN/YZnZmsfBr7eC49nT8cAAA4jh4maCYsHQfgc4od5W4hW5IKCrep2FFuUUUAACAg0MMEzYSgDcDnlOyt8mgcAACgSehhgmbC0nEAPiepY4RH4wAAAE02Y4aUk0MPE3gVM9oAfE5aYoxGZya7jY3JTKYhGgAAMEd6unT77YRseA0z2gB8Un52irJS7XQdBwAAgN8haAPwWWmJMQRsAADQIC4FCl9F0AYAAACBBX6HS4HClxG0AQAAghyBBf6moUuBZqXaeaMIPoFmaAAAAEGsocBS7Ci3qCLg1LgUKHwdQRvwE8WOci3esJM/fAAApiKwwB9xKVD4OpaOA36AJX0AAG8hsMAfHb8U6Il/H3EpUPgSgjbg49iDBADwJgIL/BWXAoUvI2gDPq6xJX38QgEAmIHAAn/FpUCbQVGRtGWL1LOnlJ5udTV+g6AN+DiW9AEAmgOBBUAdeXnSzJk/3544UZoxw7p6/AjN0AAfd3xJ34lY0gcAAACvKipyD9nSsdtFRdbU42eY0Qb8AEv6AO8rdpTzGgMA4LgtWxoeZwn5KRG0AT/Bkj7Ae+jsDwDASXr29Gwcblg6DgAIag119uea9QCAoJaefmxP9ony8pjNbiJmtAEAQY3O/gAANGDGDCknh67jp4GgDQAIanT2BwCgEenpBOzTwNJxAEBQo7M/gkWxo1yLN+xkWwQANANmtAEAQY/O/r6JTvDmoeEfADQvgjYAAKKzv68hGJqnoYZ/Wal2vucBwEtYOg4AAHwKneDN1VjDPwCAdxC0AQCATyEYmouGfwDQ/AjaAADApxAMzUXDPwBofuzRBgAAPuV4MDxx+TjB8MzQ8A8AmpfNMAzD6iI85XQ6FR0drcrKSkVFRVldDgAA8AK6jp8aXyMAaD6e5FBmtAEAgE+iE3zj6MwOAL6LPdoAAAB+hs7sAODbCNoAAAB+hs7sAODbCNoAAAB+hs7sAODbCNoAAAB+hkt2AYBvoxkaAACAH+KSXQDguwjaAAAAforO7ADgm1g6DgAAAACAiQjaAAAAAACYiKANAAAAAICJCNoAAAAAAJiIoA0AAAAAgIkI2gAAAAAAmIigDQAAAACAiQjaAAAAAACYiKANAAAAAICJCNoAAAAAAJiIoA0AAAAAgIkI2gAAAAAAmIigDQAAAACAiQjaAAAAAACYiKANAAAAAICJCNoAAAAAAJiIoA0AAAAAgIkI2gAAAAAAmIigDQAAAACAiQjaAAAAAACYiKANAAAAAICJCNoAAAAAAJiIoA0AAAAAgIkI2gAAAAAAmIigDQAAAACAiUKsLgAAAJij2FGukr1VSuoYobTEGKvLAQAgaBG0AQAIANOXbVZB4TbX7dGZycrPTrGwIgAAghdLxwEA8HPFjnK3kC1JBYXbVOwot6giAACCG0EbAAA/V7K3yqNxAADgXQRtAAD8XFLHCI/GAQCAdxG0AQDwc2mJMRqdmew2NiYzmYZoAABYxPSgXVNTo8mTJyspKUnh4eHq1q2bpk6dKsMwXI8xDEOPPPKI4uPjFR4ergEDBmjr1q1mlwIAQNDIz07Rkrv76Zmbz9eSu/spj0ZoAABYxvSu4zNmzNDcuXP1yiuvKDU1VZ9//rmGDx+u6Oho3XfffZKkmTNnavbs2XrllVeUlJSkyZMnKysrS5s2bVLr1q3NLgkAgKCQlhjDLDYAAD7AZpw41WyC6667TnFxcXr55ZddY4MHD1Z4eLhee+01GYahhIQE/f73v9eECRMkSZWVlYqLi9P8+fN16623nvI5nE6noqOjVVlZqaioKDPLBwAAAACgDk9yqOlLx/v166eVK1dqy5YtkqQvvvhCn376qbKzsyVJJSUlKi0t1YABA1yfEx0drfT0dK1Zs6beY1ZXV8vpdLp9AAAAAADgi0xfOp6fny+n06levXqpZcuWqqmp0ZNPPqnc3FxJUmlpqSQpLi7O7fPi4uJc951s2rRpmjJlitmlAgAAAABgOtNntN966y29/vrrWrhwoTZs2KBXXnlFf/zjH/XKK6+c9jEnTZqkyspK18eOHTtMrBgAAAAAAPOYPqP9hz/8Qfn5+a691uedd562b9+uadOmaejQobLb7ZKksrIyxcfHuz6vrKxMF1xwQb3HDAsLU1hYmNmlAgAAAABgOtNntA8ePKgWLdwP27JlS9XW1kqSkpKSZLfbtXLlStf9TqdTRUVFysjIMLscAAAAAACalekz2tdff72efPJJJSYmKjU1VcXFxXrmmWc0YsQISZLNZtO4ceP0xBNPqEePHq7LeyUkJOjGG280uxwAAAAAAJqV6UH7+eef1+TJk3X33Xdrz549SkhI0F133aVHHnnE9ZiJEyeqqqpKo0aNUkVFhS699FJ98MEHXEMbAAAAAOD3TL+OdnPgOtoAAAAAgObkSQ41fUYbgLmKHeUq2VulpI4RSkuMsbocAAAAAKdA0AZ82PRlm1VQuM11e3RmsvKzUyysCAAAAMCpmN51HIA5ih3lbiFbkgoKt6nYUW5RRQAAAACagqAN+KiSvVUejQMAmlexo1yLN+zkDVAAQB0sHQd8VFLHCI/GAQDNh609AIDGMKMN+Ki0xBiNzkx2GxuTmUxDNACwGFt7AACnwow2Tl9RkbRli9Szp5SebnU1ASk/O0VZqXa6jgNoHD+Pm1VjW3v4OQ0AkAjaOF15edLMmT/fnjhRmjHDunoCWFpiDH+4AWgYP4+bHVt7AACnwtJxeK6oyP2POunY7aIia+oBgGDFz2NLsLUHAHAqzGjDc1u2NDzOkkUAaD78PLYMW3sAAI0haMNzPXt6Ng4A8A5+HluKrT0AgIawdByeS08/tgfwRHl5zJ4AQHPj5zEAAD7JZhiGYXURnnI6nYqOjlZlZaWioqKsLid40eUWAHwDP48BAPA6T3IoQRsAAAAAmkGxo5zeDn7MkxzKHm0AAAAA8LLpyzaroHCb6/bozGTlZ6dYWBG8iT3aAAAAAOBFxY5yt5AtSQWF21TsKLeoIngbQRsAAAAAvKhkb5VH4/B/BG0AAAAA8KKkjhEejcP/EbQBAAAAwIvSEmM0OjPZbWxMZjIN0QIYzdAAAAAAD9E9Gp7Kz05RVqqd75sgQdAGAAAAPED3aJyutMQYAnaQYOk4AAAA0ER0jwbQFARtAAAAoInoHg2gKVg6DjRFUZG0ZYvUs6eUnm51NQAAwCJ0jwbQFMxoA6eSlyf17Svdccex/+blWV0RfECxo1yLN+xkqaAP4ZwAaA50jwbQFDbDMAyri/CU0+lUdHS0KisrFRUVZXU5CGRFRcfC9cnWrmVmO4jRBMf3cE4ANDe6jgPBx5Mcyow20JgtWzwbR8CjCY7v4ZwAsEJaYoxyLuxMyAZQL4I20JiePT0bR8CjCY7v4ZwAAABfQ9AGGpOeLk2c6D6Wl8ey8SBGExzfwzkBAhN9FwD4M7qO45SCfg/SjBlSTg5dxyHp5yY4Jy5VpgmOtTgnQOCh7wIAf0czNDSKX3RA/YL+DSgfxDkBAkOxo1yD5qyuM77k7n68tgFYypMcyow2GtRQg6GsVDu/6BD00hJjeB34GM4JEBga67vAaxyAv2CPNhpEgyEAANDc6LsAIBAQtNEgftEBAIDmdrzvwonouwDA37B0HA2iwRAAALBCfnaKslLt9F0A4LdohoZTosEQAAAAgGBHMzSYigZDAAAAANB07NEGAAAAAMBEzGgDAADAr7HNDYCvIWgDAADAb01fttmtcevozGTlZ6dYWBEAsHQcAAAAfqrYUe4WsiWpoHCbih3lFlUEAMcQtAEAAOCXSvZWeTQOAM2FoA0AAAC/lNQxwqNxAGguBG0AAAD4pbTEGI3OTHYbG5OZTEM0AJajGRoAAAD8Vn52irJS7XQdB+BTCNoAAADwa2mJMQRsAD6FpeMAAAAAAJiIGW0AAOpR7ChnKSoAADgtBG1Ygj9gAfiy6cs2u12bd3RmsvKzUyysCAAA+BOCNpodf8AC8GXFjnK3n1GSVFC4TVmp9gbfGOTNQwAAcCKCNprV6fwBCwDNqWRvVYPj9f2c4s1DAABwMpqhoVk19gcsAPiCpI4RTR5v6M3DYke5V2oDAAD+gaCNZuXJH7AAYIW0xBiNzkx2GxuTmVzvbDZvHgIAgPqwdBzN6vgfsCfOADX0BywAWCU/O0VZqfZT7rvmzUMAAM5cIPY6sRmGYVhdhKecTqeio6NVWVmpqKgoq8vBaQjEFxOA4HTyHu0xmcnKY482AABN4k+9TjzJoQRtAADOEG8eAgDguWJHuQbNWV1nfMnd/Xzy96knOZSl4wAAnKG0xBif/IMAAABf5umVPvwJzdAAAAAAAM0ukHudELQBAAAAAM3Okyt9+BuWjgMAAAAALNHUK334G4I2AAAAAMAygdjrhKXjAAAAAACYiKANAAAAAICJWDoOmITr6AIAAACQCNqAKaYv26yCwm2u26Mzk5WfnWJhRQAAAACswtJx4AwVO8rdQrYkFRRuU7Gj3KKKAAAAAFiJoA2coZK9VR6NAwAAAAhsBG3gDCV1jPBoHAAAAEBgI2gDZygtMUajM5PdxsZkJtMQDQAQFIod5Vq8YSdbpgDgBDRDA0yQn52irFQ7XccBAEGFZqAAUD+CNmCStMQYAjYAIGg01Aw0K9XO70MAQc/0peNnn322bDZbnY+xY8dKkg4dOqSxY8eqQ4cOioyM1ODBg1VWVmZ2GQAAAPAimoECQMNMD9rr1q3T7t27XR8rVqyQJN10002SpPHjx2vp0qVatGiRCgsLtWvXLuXk5JhdBgAAvqmoSFqw4Nh/AT9GM1AAaJjpQTs2NlZ2u9318f7776tbt27KzMxUZWWlXn75ZT3zzDPq37+/+vTpo3nz5mn16tVau3at2aUAAOBb8vKkvn2lO+449t+8PKsrAk4bzUABoGFe3aN9+PBhvfbaa3rggQdks9m0fv16HTlyRAMGDHA9plevXkpMTNSaNWvUt2/feo9TXV2t6upq122n0+nNsgEAMF9RkTRzpvvYzJlSTo6Unm5NTfBPRUXSli1Sz56Wf+/QDBSnq9hRzvcNAppXg/Y777yjiooKDRs2TJJUWlqq0NBQtWvXzu1xcXFxKi0tbfA406ZN05QpU7xYKQAAXrZlS8PjBG00VV6e+xs2EydKM2ZYV49oBgrP0a0ewcCr19F++eWXlZ2drYSEhDM6zqRJk1RZWen62LFjh0kVAgDQTHr29GwcOFlDqyLY7w8/0lC3eq7DjkDjtaC9fft2ffjhh7rzzjtdY3a7XYcPH1ZFRYXbY8vKymS32xs8VlhYmKKiotw+ACBQFDvKtXjDTv7ICHTp6cdmH0+Ul8dsNpqusVURgJ+gWz2ChdeWjs+bN0+dOnXStdde6xrr06ePWrVqpZUrV2rw4MGSpG+++UYOh0MZGRneKgUAfBbL54LMjBnH9mT7yP5a+BlWRSAA0K0ewcIrM9q1tbWaN2+ehg4dqpCQn7N8dHS0Ro4cqQceeECrVq3S+vXrNXz4cGVkZDTYCA0AAhXL54JUerp0++2EbHiOVREIAHSrR7Dwyoz2hx9+KIfDoREjRtS579lnn1WLFi00ePBgVVdXKysrS3PmzPFGGQDg0xpbPscfHADqxaoIBAC61SMY2AzDMKwuwlNOp1PR0dGqrKxkvzYAv1XsKNegOavrjC+5ux9/dAAIGFzGCfBPvHbr8iSHevXyXgCAhh1fPnfi8nGWzwEIJPShAPyT1167RUVBsyKHGW0AsBjvGAMIRKzaAfyT1167eXnulyicOPHYdhg/4kkO9ep1tAEAp5aWGKOcCzvzhyeAgMJlnAD/5JXXblGRe8iWjt0uKjr9Y/o4gjYAAABMx2WcAP/kldfuli2ejQcAgjYAAABMx2WcAP/kldduz56ejQcA9mgDAADAa+hDAfgn01+7J+/RzsuTpk8/8+M2I09yKEEbAAAAAOB9ft51nMt7AQAAAAB8S3q6Xwbs08EebQAAAAAATETQBgAAAADARARtAAAAAABMRNAGAAAAAMBEBG0AAAAAAExE0AYAAAAAwEQEbQAAAAAATETQBgAAAADARARtAAAAAABMRNAGAAAAAMBEIVYXAAAAAlxRkbRli9Szp5SebnU1AAB4HTPaABpU7CjX4g07Vewot7oUAP4qL0/q21e6445j/83Ls7oiAAC8zmYYhmF1EZ5yOp2Kjo5WZWWloqKirC4HCEjTl21WQeE21+3RmcnKz06xsCIAfqeo6Fi4PtnatcxsAwD8jic5lBltAHUUO8rdQrYkFRRuY2YbgGe2bPFsHACAAEHQBlBHyd4qj8YBoF49e3o2DgBAgCBoA6gjqWOER+MAUK/0dGniRPexvDyWjQMAAh5dxwHUkZYYo9GZyW7Lx8dkJistMcbCqgD4pRkzpJwcuo4DAIIKzdAANKjYUa6SvVVK6hhByAYAAM2Kv0PgazzJocxoA2hQWmIMv9gAAECzC6qrnxQVseonALFHGwAAAIDPCKqrn+TlHbsM4h13HPtvXp7VFcEkBG0AAAAAPiNorn5SVCTNnOk+NnPmsXH4PYI2AAAAAJ8RNFc/2bLFs3H4FYI2AAAAAJ9x/OonJwrIq5/07OnZOPwKzdAQ9OhoCQAA4Fvys1OUlWoP7L/R0tOliRPdl4/n5dEQLUBweS8EtaDqaAmcJt6MAgDAi+g67je4vBfQBA11tMxKtRMmgP8fb0YBAOBl6ekE7ADEHm0EraDpaAmcpqC6vAoAAICJCNoIWkHT0RI4TbwZBQAAcHoI2ghaQdPREjhNvBkFAABwetijjaAWFB0tgdN0/M2oE5eP82YUAADAqdF1HADQKLqOAwAA0HUcAGCitMQYAjYAAIAH2KMNAAAAAICJCNoAAAAAAJiIoA0AAAAAgIkI2gAAAAAAmIigDQAAAACAiQjaAAAAAACYiMt7AYAP4FrVAAAAgYOgDQAWm75sswoKt7luj85MVn52ioUVAQAA4EywdBwALFTsKHcL2ZJUULhNxY5yiyoCAADAmSJoA4CFSvZWeTQOAAAA30fQBgALJXWM8GgcAAAAvo+gDQAWSkuM0ejMZLexMZnJNEQDAADwYzRDAwCL5WenKCvVTtdxAACAAEHQBgAfkJYYQ8AGAAAIECwdBwAAAADARARtAAAAAABMRNAGAAAAAMBEBG0AAAAAAExE0AYAAAAAwEQEbQAAAAAATETQBgAAAADARARtAAAAAABMRNAGAAAAAMBEBG0AAAAAAEwUYnUBAADA/xU7ylWyt0pJHSOUlhhjdTkAAF9TVCRt2SL17Cmlp1tdjdcRtAEAwBmZvmyzCgq3uW6PzkxWfnaKhRUBAHxKXp40c+bPtydOlGbMsK6eZsDScQDwIcWOci3esFPFjnKrSwGapNhR7hayJamgcBvfwwCAY4qK3EO2dOx2UZE19TQTZrQBwEcwKwh/VLK3qsFxlpADALRlS8PjAbyEnBltAPABzArCXyV1jPBoHAAQZHr29Gw8QBC04TGWtgLma2xWEPBlaYkxGp2Z7DY2JjOZ2WwAwDHp6cf2ZJ8oLy+gZ7Mllo7DQyxtBbyDWUH4s/zsFGWl2uk6DgCo34wZUk5OUHUd98qM9g8//KDbbrtNHTp0UHh4uM477zx9/vnnrvsNw9Ajjzyi+Ph4hYeHa8CAAdq6das3SoGJWNoKeA+zgvB3aYkxyrmwM9+zAID6padLt98eFCFb8sKMdnl5uS655BJdccUVWrZsmWJjY7V161bFxPz8i3fmzJmaPXu2XnnlFSUlJWny5MnKysrSpk2b1Lp1a7NLgkloeAN4F7OCAAAAgcH0oD1jxgx16dJF8+bNc40lJSW5/t8wDM2aNUsPP/ywBg4cKEl69dVXFRcXp3feeUe33nqr2SXBJCxtBbwvLTGGgA0AAODnTF86/t577+miiy7STTfdpE6dOiktLU0vvfSS6/6SkhKVlpZqwIABrrHo6Gilp6drzZo19R6zurpaTqfT7QPNj6WtCHQ0+gMAAIAZTJ/R3rZtm+bOnasHHnhADz74oNatW6f77rtPoaGhGjp0qEpLSyVJcXFxbp8XFxfnuu9k06ZN05QpU8wuFaeBpa0IVDT6AwAAgFlshmEYZh4wNDRUF110kVavXu0au++++7Ru3TqtWbNGq1ev1iWXXKJdu3YpPj7e9Zibb75ZNptNf/vb3+ocs7q6WtXV1a7bTqdTXbp0UWVlpaKioswsH0AQKnaUa9Cc1XXGl9zdjzeTvKzYUc4bdwAAwC84nU5FR0c3KYeaPqMdHx+vc889120sJSVFf//73yVJdrtdklRWVuYWtMvKynTBBRfUe8ywsDCFhYWZXSoASKLRn1VYRQAAAAKV6Xu0L7nkEn3zzTduY1u2bFHXrl0lHWuMZrfbtXLlStf9TqdTRUVFysjIMLscADglGv01Py4XCAAAApnpQXv8+PFau3atnnrqKX377bdauHChXnzxRY0dO1aSZLPZNG7cOD3xxBN677339NVXX+mOO+5QQkKCbrzxRrPLAYBTotFf82tsFQEAAIC/M33p+MUXX6wlS5Zo0qRJevzxx5WUlKRZs2YpNzfX9ZiJEyeqqqpKo0aNUkVFhS699FJ98MEHXEMbgGVo9Ne8WEUAAAACmenN0JqDJ5vQAQC+6eQ92mMyk5XHHm0AAOCjLG2GBgBAU7CKAAAABCqCNgDAMmmJMQRsAAAQcExvhgYAAAAAQDAjaAMAAAAAYCKCNgAAAAAAJiJoAwAAAABgIoI2AAAAAAAmImgDAAAAAGAigjYAAAAAACYiaAMAAAAAYCKCNgAAAAAAJiJoAwAAAABgIoI2AAAAAAAmImgDAAAAAGCiEKsLAAAAAHDmih3lKtlbpaSOEUpLjLG6HCCoEbQBAAAAPzd92WYVFG5z3R6dmaz87BQLKwKCG0vHAQAAAD9W7Ch3C9mSVFC4TcWOcosqAkDQBgAAAPxYyd4qj8YBeB9BGwAAAPBjSR0jPBoH4H0EbQAAAMCPpSXGaHRmstvYmMxkGqIBFqIZGgCP0NEUAABzmfG7NT87RVmpdn5HAz6CoA2gyehoCgCAucz83ZqWGEPABnwES8cBNAkdTQEAMBe/W4HARdAG0CR0NAUAwFz8bgUCF0EbQJPQ0RQAAHPxuxUIXARtAE1CR1MAAMzF71YgcNkMwzCsLsJTTqdT0dHRqqysVFRUlNXlAEGFruMAAJiL362Af/AkhxK0AQAAAAA4BU9yKEvHAQAAAAAwEUEbAAAAAAATEbQBAAAAADARQRsAAAAAABMRtAEAAAAAMBFBGwAAAAAAExG0AQAAAAAwEUEbAAAAAAATEbQBAAAAADARQRsAAAAAABMRtAEAAAAAMBFBGwAAAAAAExG0AQAAAAAwEUEbAAAAAAATEbQBAAAAADARQRsAAAAAABMRtAEAAAAAMBFBGwAAAAAAExG0AQAAAAAwEUEbAAAAAAATEbQBAAAAADARQRsAAAAAABOFWF0AAACAp4od5SrZW6WkjhFKS4yxuhwAANwQtAEAgF+ZvmyzCgq3uW6PzkxWfnaKhRUBAOCOpeMAAMBvFDvK3UK2JBUUblOxo9yiigAAqIugDQAA/EbJ3iqPxgEAsAJLxwEgiLHPFf4mqWOER+MAAFiBoA0AQYp9rs2PNzbOXFpijEZnJrt9747JTObrCQDwKQRtAAhCDe1zzUq1E1i8hDc2zJOfnaKsVDtvWgAAfBZ7tAEEnWJHuRZv2BnUzZPY59q8aOBlvrTEGOVc2JmQDQDwScxoAwgqzCoewz7X5tXYGxsERQAAAg8z2gCCBrOKPzu+z/VE7HP1Ht7YAAAguDCjDSBoMKvojn2uzYcGXgAABBeCNoCgwaxiXWmJMYS9ZsIbGwAABA+WjgMIGiyXhtVo4AUAQHBgRhtAUGFWEQAAAN5G0AYQdFguDQAAAG9i6TgAAAAAACYiaAMAAAAAYCKCNgAAAAAAJiJoAwAAAABgIoI2AAAAAAAmous4AABeUOwo5zJyAAAEKdNntB977DHZbDa3j169ernuP3TokMaOHasOHTooMjJSgwcPVllZmdllAABgmenLNmvQnNV64K0vNGjOak1fttnqkgAAQDPyytLx1NRU7d692/Xx6aefuu4bP368li5dqkWLFqmwsFC7du1STk6ON8oAAKDZFTvKVVC4zW2soHCbih3lFlUEAACam1eWjoeEhMhut9cZr6ys1Msvv6yFCxeqf//+kqR58+YpJSVFa9euVd++fb1RDgAAzaZkb1WD4ywhBwAgOHhlRnvr1q1KSEhQcnKycnNz5XA4JEnr16/XkSNHNGDAANdje/XqpcTERK1Zs6bB41VXV8vpdLp9AEBzK3aUa/GGncxMolFJHSM8GgcAAIHH9KCdnp6u+fPn64MPPtDcuXNVUlKiX/3qV9q/f79KS0sVGhqqdu3auX1OXFycSktLGzzmtGnTFB0d7fro0qWL2WUDQKPYc4umSkuM0ejMZLexMZnJzGYDABBEbIZhGN58goqKCnXt2lXPPPOMwsPDNXz4cFVXV7s95pe//KWuuOIKzZgxo95jVFdXu32O0+lUly5dVFlZqaioKG+Wf0boOAsEhmJHuQbNWV1nfMnd/Xhto0H8DgAAILA4nU5FR0c3KYd6/fJe7dq1U8+ePfXtt9/q17/+tQ4fPqyKigq3We2ysrJ693QfFxYWprCwMG+Xaqrpyza7NcMZnZms/OwUCysCcLrYc4vTkZYYw/cHAABByit7tE904MABfffdd4qPj1efPn3UqlUrrVy50nX/N998I4fDoYyMDG+X0mzoOAsEFvbcAgAAwBOmB+0JEyaosLBQ33//vVavXq1BgwapZcuWGjJkiKKjozVy5Eg98MADWrVqldavX6/hw4crIyMjoDqONzb7BcD/sOcWAAAAnjB96fjOnTs1ZMgQ/fjjj4qNjdWll16qtWvXKjY2VpL07LPPqkWLFho8eLCqq6uVlZWlOXPmmF2GpZj9AgJPfnaKslLt7LkFAADAKXm9GZo3eLIJ3Son79Eek5msPPZoAwAAAIBf8qlmaMGK2S8gsNFRGgAAAA0haHsRHWeBwMRVBQAAANAYr3cdB4BAwlUFAAAAcCoEbQDwAFcVAACciWJHuRZv2MkbtECAY+k4AHiAqwoAAE4XW4+A4MGMNgB4gGtqAwBOB1uPgODCjDYAeIirCgAAPNXY1iN+jwCBh6ANAKeBqwoAADzB1iMguLB0HAAAAPAyth4BwYUZbQAAAKAZsPUICB4EbQAAAHik2FFOWDxNbD0CggNBGwAAAE3GJaoA4NTYow0AAIAm4RJVANA0BG0AAAA0SWOXqAIA/IygDQAAgCbhElUA0DQEbXhNsaNcizfsZDkZAAABgktUAUDT0AwNXkGjFKAuuvQCCARcogoATo2gDdM11CglK9XOL2MELd58AurHG1D+iUtUAUDjCNowXWONUviljGDEm09A/XgDyouKiqQtW6SePaX0dKurAYCgwx5tmI5GKYA7uvQCdXGZKC/Ky5P69pXuuOPYf/PyrK4IAIIOQRumo1EK4I43n4C6eAPKS4qKpJkz3cdmzjw2DgBoNiwdh1fQKAX42fE3n06cvePNJwQ73oDyki1bGh5nCTkANBuCNryGRinAz3jzCXDHG1Be0rOnZ+MAAK+wGYZhWF2Ep5xOp6Kjo1VZWamoqCirywEAAKeJruNekJfnvnw8L0+aPt26egAgQHiSQwnaAGA2uv0CsBo/hwDAdJ7kUJaOA4CZTp5JmjhRmjHDunoABKf0dAI24K94oywg0HUcAMxCt18AAHAmuDxfwCBoA4BZGuv2CwAA0BjesA8oBG0AMAvdfgEAMF2xo1yLN+xUsaPc6lK8izfsAwp7tAHALOnpx/Zkn9ztl/1VAACclunLNrtdBnB0ZrLys1MsrMiLeMM+oDCjDQBmmjFDWrtWevXVY//lkjoAAJyWYke5W8iWpILCbYE7s338DfsT8Ya932JGGwDMRrdfAADOWMneqgbH0xJjmrmaZjJjhpSTQ9fxAEDQBgAAAOBzkjpGeDQeMHjDPiCwdBwAAACBo6hIWrCATs0BIC0xRqMzk93GxmQmB+5sNgIKM9oAAAAIDHl57g0pJ048thQXfis/O0VZqXaV7K1SUscIQjb8hs0wDMPqIjzldDoVHR2tyspKRUVFWV0OAAAArFZUJPXtW3d87VqW4QIwhSc5lKXjAAAA8H9cgxiADyFoAwAAwP9xDWIAPoSgjSYpdpRr8YadgXvdQgAA4N+4BjEAH0IzNJzS9GWbVVC4zXV7dGay8rNTLKwIAACgHlyDGICPIGg3k2JHuV92Syx2lLuFbEkqKNymrFS7X/07AABAkOAaxAB8AEG7GfjzjHDJ3qoGxwnaAAAAAFAXe7S9rKEZYX/Z65zUMcKjcQAAAAAIdgRtL2tsRtgfpCXGaHRmstvYmMxkZrMBAAC8jGa0gP9i6biXBcKMcH52irJS7X65xxwAAMAf+fPWw+bmr72QENgI2l52fEb4xB+UzTkjbNYPnrTEGH5wAQAANAOa0TYdb0jAVxG0m4FVM8L84AEAAPA/NKNtGt6QgC9jj3YzSUuMUc6FnZt1Jtufm7ABAAAEq0DYetgc/L0XEgIbQTtA8YMHAADAP9GMtml4QwK+jKXjAYofPAAAn1JUJG3ZIvXsKaWnW10N4PNoRntqVvdCAhpjMwzDsLoITzmdTkVHR6uyslJRUVFWl+OzTt6jPSYzWXns0QYANLe8PGnmzJ9vT5wozZhhXT3AGaLLtW/hfKC5eJJDCdoBjh88AABLFRVJffvWHV+7lplt+CWazQLBy5Mcyh7tANfcTdgAIFAUO8q1eMNOmkieqS1bPBsHfBjNZgE0FXu0AQA4CTNWJurZ07NxwIdx2S0ATcWMNgAAJ2DGymTp6cf2ZJ8oL49l4/BLNJsF0FQEbQAATsDlEb1gxoxje7JfffXYf6dPt7oi4LRw2S0ATcXScQAATsCMlZekpzOLjYDAZbcANAUz2gAAnIAZKwCnQrNZAKfCjDYAACdhxgoAAJwJgjYAAPVIS4whYMOvFDvKeXMIAHwEQRsAAMDPcUk6APAt7NEGAADwY1ySDgB8D0EbAADAj3FJOgDwPSwdBwAAp419wdbjknQA4HsI2gAA4LSwL9g3HL8k3YnngkvSAYC1CNoAAMBjDe0Lzkq1E/AswCXpAMC3ELQBAIDHGtsXTMizBpekAwDfQdAGAAAeY18wgh39CQA0hqANAAA8xr5gBDP6EwA4FYI2AAA4LewLRjCiPwGApiBoAwCA08a+YAQb+hMAaIoW3n6C6dOny2azady4ca6xQ4cOaezYserQoYMiIyM1ePBglZWVebsUAAAA4IzQnwBAU3g1aK9bt05/+ctf1Lt3b7fx8ePHa+nSpVq0aJEKCwu1a9cu5eTkeLMUAAAA4Iwd709wIvoTADiZ15aOHzhwQLm5uXrppZf0xBNPuMYrKyv18ssva+HCherfv78kad68eUpJSdHatWvVt29fb5UEAAAAnDH6EwA4Fa/NaI8dO1bXXnutBgwY4Da+fv16HTlyxG28V69eSkxM1Jo1a+o9VnV1tZxOp9sHAAAAYJW0xBjlXNiZkA2gXl6Z0X7zzTe1YcMGrVu3rs59paWlCg0NVbt27dzG4+LiVFpaWu/xpk2bpilTpnijVAAAAAAATGX6jPaOHTt0//336/XXX1fr1q1NOeakSZNUWVnp+tixY4cpxwUAAAAAwGymB+3169drz549uvDCCxUSEqKQkBAVFhZq9uzZCgkJUVxcnA4fPqyKigq3zysrK5Pdbq/3mGFhYYqKinL7AAAAAADAF5m+dPzKK6/UV1995TY2fPhw9erVS3l5eerSpYtatWqllStXavDgwZKkb775Rg6HQxkZGWaXAwBoRsWOcpoDAQCAoGd60G7btq1+8YtfuI1FRESoQ4cOrvGRI0fqgQceUPv27RUVFaV7771XGRkZdBwHAD82fdlmFRRuc90enZms/OwUCysCAACwhtcu79WYZ599Vi1atNDgwYNVXV2trKwszZkzx4pSAAAmKHaUu4VsSSoo3KasVDsz2wAAIOg0S9D++OOP3W63bt1af/7zn/XnP/+5OZ4eAOBlJXurGhwnaAMAgGBjyYw2ACCwJHWM8GgcAIBAQG8SNISgDQA4Y2mJMRqdmey2fHxMZjJ/dAAAAha9SdAYgjYAwBT52SnKSrXzzj4AIODRmwSnQtAGAJgmLTGGPzAAAAGP3iQ4lRZWFwAAAAAA/oTeJDgVgjYAAAAAeOB4b5ITWdmbpNhRrsUbdqrYUW7J86Mulo4DAAAAgId8pTcJTdl8E0EbAAAAAE6D1b1JaMrmu1g6DgAAAAB+qLGmbLAWQRsAAAAA/BBN2XwXQRsAAAAA/JCvNWXDz9ijDQAAAAB+yleassEdQRsAAAAA/JjVTdlQF0vHAQAAAAAwEUEbAAAAAAATEbQBAAAAADARQRsAAAAAABMRtAEAAAAAMBFBGwAAAAAAExG0AQAAAAAwEUEbAAAAAAATEbQBAAAAADARQRsAAAAAABMRtAEAAAAAMBFBGwAAAAAAExG0AQAAAAAwEUEbAAAAAAAThVhdAADA9xU7ylWyt0pJHSOUlhhjdTkAAAA+jaANAGjU9GWbVVC4zXV7dGay8rNTLKwIAADAt7F0HADQoGJHuVvIlqSCwm0qdpRbVBEAAIDvI2gDABpUsrfKo3EAAAAQtAEAjUjqGOHROAAAAAjaAIBGpCXGaHRmstvYmMxkGqIBAAA0gmZoAIBG5WenKCvVTtdxAACAJiJoAwBOKS0xhoANAADQRCwdBwAAAADARARtAAAAAABMRNAGAAAAAMBEBG0AAAAAAExE0AYAAAAAwEQEbQAAAAAATETQBgAAAADARARtAAAAAABMRNAGAAAAAMBEBG0AAAAAAExE0AYAAAAAwEQEbQAAAAAATETQBgAAAADARARtAAAAAABMRNAGAAAAAMBEBG0AAAAAAExE0AYAAAAAwEQEbQAAAAAATETQBgAAAADARARtAAAAAABMRNAGAAAAAMBEBG0AAAAAAExE0AYAAAAAwEQEbQAAAAAATETQBgAAAADARARtAAAAAABMRNAGAAAAAMBEBG0AAAAAAExE0AYAAAAAwEQEbQAAAAAATETQBgAAAADARARtAAAAAABMFGJ1AQAAADBXsaNcJXurlNQxQmmJMVaXAwBBh6ANAAAQQKYv26yCwm2u26Mzk5WfnWJhRQAQfFg6DgAAECCKHeVuIVuSCgq3qdhRblFFABCcCNoAAAABomRvlUfjAADvMD1oz507V71791ZUVJSioqKUkZGhZcuWue4/dOiQxo4dqw4dOigyMlKDBw9WWVmZ2WUAAAAEnaSOER6NAwC8w/Sg3blzZ02fPl3r16/X559/rv79+2vgwIH6+uuvJUnjx4/X0qVLtWjRIhUWFmrXrl3KyckxuwwAAICgk5YYo9GZyW5jYzKTaYgGAM3MZhiG4e0nad++vZ5++mn95je/UWxsrBYuXKjf/OY3kqT//e9/SklJ0Zo1a9S3b98mHc/pdCo6OlqVlZWKioryZukAAAB+h67jAGA+T3KoV7uO19TUaNGiRaqqqlJGRobWr1+vI0eOaMCAAa7H9OrVS4mJiY0G7erqalVXV7tuO51Ob5YNAADg19ISYwjYAGAhrzRD++qrrxQZGamwsDCNHj1aS5Ys0bnnnqvS0lKFhoaqXbt2bo+Pi4tTaWlpg8ebNm2aoqOjXR9dunTxRtkAAAAAAJwxrwTtc845Rxs3blRRUZHGjBmjoUOHatOmTad9vEmTJqmystL1sWPHDhOrBQAAAADAPF5ZOh4aGqru3btLkvr06aN169bpueee0y233KLDhw+roqLCbVa7rKxMdru9weOFhYUpLCzMG6UCAAAAAGCqZrmOdm1traqrq9WnTx+1atVKK1eudN33zTffyOFwKCMjozlKAQAAAADAq0yf0Z40aZKys7OVmJio/fv3a+HChfr444+1fPlyRUdHa+TIkXrggQfUvn17RUVF6d5771VGRkaTO44DAAAAAODLTA/ae/bs0R133KHdu3crOjpavXv31vLly/XrX/9akvTss8+qRYsWGjx4sKqrq5WVlaU5c+aYXQYAAAAAAJZolutom43raAMAAAAAmpMnObRZ9mgDAAAAABAsCNoAAAAAAJiIoA0AAAAAgIkI2gAAAAAAmIigDQAAAACAiQjaAAAAAACYiKANAAAAAICJCNoAAAAAAJiIoA0AAAAAgIkI2gAAAAAAmIigDQAAAACAiQjaAAAAAACYiKANAAAAAICJCNoAAAAAAJiIoA0AAAAAgIlCrC7gdBiGIUlyOp0WVwIAAAAACAbH8+fxPNoYvwza+/fvlyR16dLF4koAAAAAAMFk//79io6ObvQxNqMpcdzH1NbWateuXWrbtq1sNpvV5TTI6XSqS5cu2rFjh6KioqwuB17AOQ58nOPAxzkOfJzj4MB5Dnyc48Dn6+fYMAzt379fCQkJatGi8V3Yfjmj3aJFC3Xu3NnqMposKirKJ79RYB7OceDjHAc+znHg4xwHB85z4OMcBz5fPsenmsk+jmZoAAAAAACYiKANAAAAAICJCNpeFBYWpkcffVRhYWFWlwIv4RwHPs5x4OMcBz7OcXDgPAc+znHgC6Rz7JfN0AAAAAAA8FXMaAMAAAAAYCKCNgAAAAAAJiJoAwAAAABgIoI2AAAAAAAmImifoblz56p3796ui6pnZGRo2bJlrvsPHTqksWPHqkOHDoqMjNTgwYNVVlZmYcU4U9OnT5fNZtO4ceNcY5xn//bYY4/JZrO5ffTq1ct1P+c3MPzwww+67bbb1KFDB4WHh+u8887T559/7rrfMAw98sgjio+PV3h4uAYMGKCtW7daWDE8dfbZZ9d5LdtsNo0dO1YSr+VAUFNTo8mTJyspKUnh4eHq1q2bpk6dqhN7+/Ja9n/79+/XuHHj1LVrV4WHh6tfv35at26d637OsX/597//reuvv14JCQmy2Wx655133O5vyvnct2+fcnNzFRUVpXbt2mnkyJE6cOBAM/4rPEfQPkOdO3fW9OnTtX79en3++efq37+/Bg4cqK+//lqSNH78eC1dulSLFi1SYWGhdu3apZycHIurxulat26d/vKXv6h3795u45xn/5eamqrdu3e7Pj799FPXfZxf/1deXq5LLrlErVq10rJly7Rp0yb96U9/UkxMjOsxM2fO1OzZs1VQUKCioiJFREQoKytLhw4dsrByeGLdunVur+MVK1ZIkm666SZJvJYDwYwZMzR37ly98MIL2rx5s2bMmKGZM2fq+eefdz2G17L/u/POO7VixQotWLBAX331la666ioNGDBAP/zwgyTOsb+pqqrS+eefrz//+c/13t+U85mbm6uvv/5aK1as0Pvvv69///vfGjVqVHP9E06PAdPFxMQYf/3rX42KigqjVatWxqJFi1z3bd682ZBkrFmzxsIKcTr2799v9OjRw1ixYoWRmZlp3H///YZhGJznAPDoo48a559/fr33cX4DQ15ennHppZc2eH9tba1ht9uNp59+2jVWUVFhhIWFGW+88UZzlAgvuP/++41u3boZtbW1vJYDxLXXXmuMGDHCbSwnJ8fIzc01DIPXciA4ePCg0bJlS+P99993G7/wwguNhx56iHPs5yQZS5Yscd1uyvnctGmTIclYt26d6zHLli0zbDab8cMPPzRb7Z5iRttENTU1evPNN1VVVaWMjAytX79eR44c0YABA1yP6dWrlxITE7VmzRoLK8XpGDt2rK699lq38ymJ8xwgtm7dqoSEBCUnJys3N1cOh0MS5zdQvPfee7rooot00003qVOnTkpLS9NLL73kur+kpESlpaVu5zk6Olrp6emcZz91+PBhvfbaaxoxYoRsNhuv5QDRr18/rVy5Ulu2bJEkffHFF/r000+VnZ0tiddyIDh69KhqamrUunVrt/Hw8HB9+umnnOMA05TzuWbNGrVr104XXXSR6zEDBgxQixYtVFRU1Ow1N1WI1QUEgq+++koZGRk6dOiQIiMjtWTJEp177rnauHGjQkND1a5dO7fHx8XFqbS01JpicVrefPNNbdiwwW1/0HGlpaWcZz+Xnp6u+fPn65xzztHu3bs1ZcoU/epXv9J///tfzm+A2LZtm+bOnasHHnhADz74oNatW6f77rtPoaGhGjp0qOtcxsXFuX0e59l/vfPOO6qoqNCwYcMk8bM6UOTn58vpdKpXr15q2bKlampq9OSTTyo3N1eSeC0HgLZt2yojI0NTp05VSkqK4uLi9MYbb2jNmjXq3r075zjANOV8lpaWqlOnTm73h4SEqH379j59zgnaJjjnnHO0ceNGVVZW6u2339bQoUNVWFhodVkwyY4dO3T//fdrxYoVdd5dRWA4PhMiSb1791Z6erq6du2qt956S+Hh4RZWBrPU1tbqoosu0lNPPSVJSktL03//+18VFBRo6NChFlcHb3j55ZeVnZ2thIQEq0uBid566y29/vrrWrhwoVJTU7Vx40aNGzdOCQkJvJYDyIIFCzRixAidddZZatmypS688EINGTJE69evt7o0oMlYOm6C0NBQde/eXX369NG0adN0/vnn67nnnpPdbtfhw4dVUVHh9viysjLZ7XZrioXH1q9frz179ujCCy9USEiIQkJCVFhYqNmzZyskJERxcXGc5wDTrl079ezZU99++y2v4wARHx+vc889120sJSXFtUXg+Lk8uQM159k/bd++XR9++KHuvPNO1xiv5cDwhz/8Qfn5+br11lt13nnn6fbbb9f48eM1bdo0SbyWA0W3bt1UWFioAwcOaMeOHfrPf/6jI0eOKDk5mXMcYJpyPu12u/bs2eN2/9GjR7Vv3z6fPucEbS+ora1VdXW1+vTpo1atWmnlypWu+7755hs5HA5lZGRYWCE8ceWVV+qrr77Sxo0bXR8XXXSRcnNzXf/PeQ4sBw4c0Hfffaf4+HhexwHikksu0TfffOM2tmXLFnXt2lWSlJSUJLvd7naenU6nioqKOM9+aN68eerUqZOuvfZa1xiv5cBw8OBBtWjh/udry5YtVVtbK4nXcqCJiIhQfHy8ysvLtXz5cg0cOJBzHGCacj4zMjJUUVHhtqLho48+Um1trdLT05u95iazuhubv8vPzzcKCwuNkpIS48svvzTy8/MNm81m/Otf/zIMwzBGjx5tJCYmGh999JHx+eefGxkZGUZGRobFVeNMndh13DA4z/7u97//vfHxxx8bJSUlxmeffWYMGDDA6Nixo7Fnzx7DMDi/geA///mPERISYjz55JPG1q1bjddff91o06aN8dprr7keM336dKNdu3bGu+++a3z55ZfGwIEDjaSkJOOnn36ysHJ4qqamxkhMTDTy8vLq3Mdr2f8NHTrUOOuss4z333/fKCkpMRYvXmx07NjRmDhxousxvJb93wcffGAsW7bM2LZtm/Gvf/3LOP/884309HTj8OHDhmFwjv3N/v37jeLiYqO4uNiQZDzzzDNGcXGxsX37dsMwmnY+r776aiMtLc0oKioyPv30U6NHjx7GkCFDrPonNQlB+wyNGDHC6Nq1qxEaGmrExsYaV155pStkG4Zh/PTTT8bdd99txMTEGG3atDEGDRpk7N6928KKYYaTgzbn2b/dcsstRnx8vBEaGmqcddZZxi233GJ8++23rvs5v4Fh6dKlxi9+8QsjLCzM6NWrl/Hiiy+63V9bW2tMnjzZiIuLM8LCwowrr7zS+OabbyyqFqdr+fLlhqR6zx2vZf/ndDqN+++/30hMTDRat25tJCcnGw899JBRXV3tegyvZf/3t7/9zUhOTjZCQ0MNu91ujB071qioqHDdzzn2L6tWrTIk1fkYOnSoYRhNO58//vijMWTIECMyMtKIiooyhg8fbuzfv9+Cf03T2QzDMCycUAcAAAAAIKCwRxsAAAAAABMRtAEAAAAAMBFBGwAAAAAAExG0AQAAAAAwEUEbAAAAAAATEbQBAAAAADARQRsAAAAAABMRtAEAAAAAMBFBGwAAAAAAExG0AQAAAAAwEUEbAAAAAAATEbQBAAAAADDR/wfL/nsdJYkojwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y = train_test_split(data[:, :-1], data[:, -1], test_size=0.2)\n",
    "# train_x, val_x, train_y, val_y = data[:, :-1], data[:, :-1], data[:, -1], data[:, -1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=train_x[:,0], y=train_x[:,1], s=10, label=\"Train\")\n",
    "ax.scatter(x=val_x[:,0], y=val_x[:,1], s=10, color=\"red\", label=\"Validation\")\n",
    "ax.set_title('Dataset for Train and Validation')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看训练集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_train_data = train_x[np.where(train_y[:]==1)]\n",
    "negative_train_data = train_x[np.where(train_y[:]==0)]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=positive_train_data[:,0], y=positive_train_data[:,1], s=10, label=\"Positive\")\n",
    "ax.scatter(x=negative_train_data[:,0], y=negative_train_data[:,1], s=10, label=\"Negative\")\n",
    "ax.set_title('Train Set')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看验证集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9EAAAKqCAYAAAA9ot3FAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAABEhklEQVR4nO3de5yVdaHv8e9wdUAGEJABBRyUFN1mKB0CNMpoI9vsose8TOY1wyjFNEP38ZYp6t6VW9uJdTxeodROaaZmgErhZhsaZoUpCDqiXI4GM1wEEdb5w5eTE6bP4DADzPv9eq1Xrt/zrLV+M/O8hj7zPOu3ykqlUikAAADAe2rT0hMAAACA7YWIBgAAgIJENAAAABQkogEAAKAgEQ0AAAAFiWgAAAAoSEQDAABAQSIaAAAAChLRAAAAUJCIBoD34fnnn09ZWVluvvnm+rFLLrkkZWVlhR5fVlaWSy65pEnn9LGPfSwf+9jHmvQ5AYA3iWgAWo1Pf/rT6dSpU1atWvUP96murk6HDh3y6quvNuPMGm/evHm55JJL8vzzz7f0VBp4/vnnc/LJJ2fPPffMTjvtlMrKynz0ox/NxRdfvEXPd//99zf5HxkA4P0Q0QC0GtXV1Xnttdfy85///B23r127Nvfcc08OO+yw9OjRY4tf53/9r/+V1157bYsfX8S8efNy6aWXvmNE//rXv86vf/3rrfr672TBggUZMmRIHnzwwRx33HH5/ve/n/Hjx6dHjx656qqrtug577///lx66aVNPFMA2HLtWnoCANBcPv3pT6dLly6ZOnVqvvjFL262/Z577smaNWtSXV39vl6nXbt2adeu5f6J7dChQ4u87ve+972sXr06Tz75ZAYMGNBg2/Lly1tkTgDQ1JyJBqDVKC8vz5FHHpkZM2a8Y9RNnTo1Xbp0yac//en89a9/zbnnnpv9998/O++8cyoqKjJ27Nj84Q9/eM/Xeaf3RK9fvz5nn312evXqVf8aixcv3uyxL7zwQr7yla9k7733Tnl5eXr06JGjjz66wRnnm2++OUcffXSS5OMf/3jKyspSVlaWRx55JMk7vyd6+fLlOfXUU9O7d+/stNNOOeCAA3LLLbc02Oet93f/+7//e374wx9mzz33TMeOHfPhD384c+bMec+v+7nnnsvuu+++WUAnya677rrZ2AMPPJBDDjkknTt3TpcuXXL44Yfnz3/+c/32k046Kf/5n/+ZJPVfY9H3mgPA1uJMNACtSnV1dW655Zbceeed+epXv1o//te//rX+MuTy8vL8+c9/zt13352jjz46VVVVWbZsWW644YaMGjUq8+bNS9++fRv1uqeddlpuv/32HH/88RkxYkQeeuihHH744ZvtN2fOnPzXf/1Xjj322Oy+++55/vnnc/311+djH/tY5s2bl06dOuWjH/1ozjzzzFx77bW54IILMnjw4CSp/9+/99prr+VjH/tYFixYkK9+9aupqqrKXXfdlZNOOikrV67MWWed1WD/qVOnZtWqVfnyl7+csrKyXH311TnyyCOzcOHCtG/f/h9+jQMGDMj06dPz0EMP5dBDD33X78dtt92WE088MWPGjMlVV12VtWvX5vrrr8/BBx+cuXPnZo899siXv/zlvPzyy5k2bVpuu+229/oWA0DzKAFAK/LGG2+U+vTpUxo+fHiD8cmTJ5eSlB588MFSqVQqrVu3rrRx48YG+yxatKjUsWPH0re+9a0GY0lKN910U/3YxRdfXHr7P7FPPvlkKUnpK1/5SoPnO/7440tJShdffHH92Nq1azeb8+zZs0tJSrfeemv92F133VVKUnr44Yc323/UqFGlUaNG1d+/5pprSklKt99+e/3Y66+/Xho+fHhp5513LtXV1TX4Wnr06FH661//Wr/vPffcU0pSuvfeezd7rbf705/+VCovLy8lKX3oQx8qnXXWWaW77767tGbNmgb7rVq1qtStW7fSl770pQbjS5cuLXXt2rXB+Pjx40v+7woA2xKXcwPQqrRt2zbHHntsZs+e3eAS6alTp6Z37975xCc+kSTp2LFj2rR585/JjRs35tVXX83OO++cvffeO7///e8b9Zr3339/kuTMM89sMD5hwoTN9i0vL6//7w0bNuTVV1/NXnvtlW7dujX6dd/++pWVlTnuuOPqx9q3b58zzzwzq1evzsyZMxvsf8wxx6R79+719w855JAkycKFC9/1dfbbb788+eST+cIXvpDnn38+//Ef/5HPfvaz6d27d370ox/V7zdt2rSsXLkyxx13XF555ZX6W9u2bTNs2LA8/PDDW/R1AkBzENEAtDpvLRw2derUJMnixYvz29/+Nscee2zatm2bJNm0aVO+973vZdCgQenYsWN69uyZXr165amnnkptbW2jXu+FF15ImzZtsueeezYY33vvvTfb97XXXstFF12Ufv36NXjdlStXNvp13/76gwYNqv+jwFveuvz7hRdeaDDev3//BvffCuoVK1a852t94AMfyG233ZZXXnklTz31VK644oq0a9cup59+eqZPn54kmT9/fpLk0EMPTa9evRrcfv3rX1uEDIBtmvdEA9DqHHTQQdlnn33y4x//OBdccEF+/OMfp1QqNViV+4orrsiFF16YU045JZdddll22WWXtGnTJhMmTMimTZu22ty+9rWv5aabbsqECRMyfPjwdO3aNWVlZTn22GO36uu+3Vt/SPh7pVKpUc+x//77Z//998/w4cPz8Y9/PFOmTMno0aPrv47bbrstlZWVmz22JVc2B4D34l8pAFql6urqXHjhhXnqqacyderUDBo0KB/+8Ifrt//0pz/Nxz/+8dx4440NHrdy5cr07NmzUa81YMCAbNq0Kc8991yDs8/PPPPMZvv+9Kc/zYknnpjvfOc79WPr1q3LypUrG+zXmFWqBwwYkKeeeiqbNm1qcDb6L3/5S/32rWno0KFJkiVLliRJ/Rn5XXfdNaNHj37Xx1qNG4Btjcu5AWiV3jrrfNFFF+XJJ5/c7LOh27Ztu9mZ17vuuisvvfRSo19r7NixSZJrr722wfg111yz2b7v9LrXXXddNm7c2GCsc+fOSbJZXL+Tf/mXf8nSpUtzxx131I+98cYbue6667Lzzjtn1KhRRb6M9/Tb3/42GzZs2Gz8rfeEv/UHhDFjxqSioiJXXHHFO+7///7f/6v/78Z8nQDQHJyJBqBVqqqqyogRI3LPPfckyWYR/alPfSrf+ta3cvLJJ2fEiBH54x//mClTpmTgwIGNfq0PfehDOe644/KDH/wgtbW1GTFiRGbMmJEFCxZstu+nPvWp3HbbbenatWv23XffzJ49O9OnT0+PHj02e862bdvmqquuSm1tbTp27JhDDz30HT+P+fTTT88NN9yQk046KU888UT22GOP/PSnP82jjz6aa665Jl26dGn01/ROrrrqqjzxxBM58sgj88EPfjBJ8vvf/z633nprdtlll/qF1CoqKnL99dfnhBNOyIEHHphjjz02vXr1Sk1NTe67776MHDky3//+95O8eel98uaibGPGjKlfGA4AWoqIBqDVqq6uzn/913/lf/yP/5G99tqrwbYLLrgga9asydSpU3PHHXfkwAMPzH333ZeJEydu0Wv9n//zf9KrV69MmTIld999dw499NDcd9996devX4P9/uM//iNt27bNlClTsm7duowcOTLTp0/PmDFjGuxXWVmZyZMnZ9KkSTn11FOzcePGPPzww+8Y0eXl5XnkkUcyceLE3HLLLamrq8vee++dm266KSeddNIWfT3v5IILLsjUqVMzc+bMTJkyJWvXrk2fPn1y7LHH5sILL0xVVVX9vscff3z69u2bK6+8Mv/2b/+W9evXZ7fddsshhxySk08+uX6/I488Ml/72tfyk5/8JLfffntKpZKIBqBFlZUas0oIAAAAtGLeEw0AAAAFiWgAAAAoSEQDAABAQSIaAAAAChLRAAAAUJCIBgAAgIK2uc+J3rRpU15++eV06dIlZWVlLT0dAAAAdnClUimrVq1K375906bNu59r3uYi+uWXX06/fv1aehoAAAC0Mi+++GJ23333d91nm4voLl26JHlz8hUVFS08GwAAAHZ0dXV16devX32PvpttLqLfuoS7oqJCRAMAANBsiryl2MJiAAAAUJCIBgAAgIJENAAAABS0zb0nuqiNGzdmw4YNLT0NGqF9+/Zp27ZtS08DAABgi213EV0qlbJ06dKsXLmypafCFujWrVsqKyt9BjgAALBd2u4i+q2A3nXXXdOpUycxtp0olUpZu3Ztli9fniTp06dPC88IAACg8bariN64cWN9QPfo0aOlp0MjlZeXJ0mWL1+eXXfd1aXdAADAdme7WljsrfdAd+rUqYVnwpZ662fn/ewAAMD2aLuK6Le4hHv75WcHAABsz7bLiAYAAICWIKK3c4888kjKysrec7XyPfbYI9dcc02zzAkAAGBHJaKbyUknnZSysrKUlZWlQ4cO2WuvvfKtb30rb7zxxvt63hEjRmTJkiXp2rVrkuTmm29Ot27dNttvzpw5Of3009/XawEAALR229Xq3Nu7ww47LDfddFPWr1+f+++/P+PHj0/79u1z/vnnb/FzdujQIZWVle+5X69evbb4NQAAAHiTM9HNqGPHjqmsrMyAAQNyxhlnZPTo0fnFL36RFStW5Itf/GK6d++eTp06ZezYsZk/f37941544YUcccQR6d69ezp37pz99tsv999/f5KGl3M/8sgjOfnkk1NbW1t/1vuSSy5J0vBy7uOPPz7HHHNMg7lt2LAhPXv2zK233pok2bRpUyZNmpSqqqqUl5fngAMOyE9/+tOt/00CAADYhrXqM9Fza1Zk0StrUtWzc4b0797sr19eXp5XX301J510UubPn59f/OIXqaioyDe/+c38y7/8S+bNm5f27dtn/Pjxef311/Ob3/wmnTt3zrx587Lzzjtv9nwjRozINddck4suuijPPPNMkrzjftXV1Tn66KOzevXq+u0PPvhg1q5dm8997nNJkkmTJuX222/P5MmTM2jQoPzmN7/JF77whfTq1SujRo3ait8VAACAbVerjegrH3g6k2curL8/btTATBw7uFleu1QqZcaMGXnwwQczduzY3H333Xn00UczYsSIJMmUKVPSr1+/3H333Tn66KNTU1OTo446Kvvvv3+SZODAge/4vB06dEjXrl1TVlb2rpd4jxkzJp07d87Pf/7znHDCCUmSqVOn5tOf/nS6dOmS9evX54orrsj06dMzfPjw+tecNWtWbrjhBhENAAC0Wq3ycu65NSsaBHSSTJ65MHNrVmzV1/3lL3+ZnXfeOTvttFPGjh2bY445JieddFLatWuXYcOG1e/Xo0eP7L333nn66aeTJGeeeWa+/e1vZ+TIkbn44ovz1FNPva95tGvXLp///OczZcqUJMmaNWtyzz33pLq6OkmyYMGCrF27Np/85Cez8847199uvfXWPPfcc+/rtQEAALZnrTKiF72yplHjTeXjH/94nnzyycyfPz+vvfZabrnllpSVlb3n40477bQsXLgwJ5xwQv74xz9m6NChue66697XXKqrqzNjxowsX748d999d8rLy3PYYYclSVavXp0kue+++/Lkk0/W3+bNm+d90QAAQKvWKiO6qmfnRo03lc6dO2evvfZK//79067dm1fSDx48OG+88UYee+yx+v1effXVPPPMM9l3333rx/r165dx48blZz/7Wc4555z86Ec/esfX6NChQzZu3PiecxkxYkT69euXO+64I1OmTMnRRx+d9u3bJ0n23XffdOzYMTU1Ndlrr70a3Pr16/d+vgUAAADbtVb5nugh/btn3KiBDS7pPmPUwBZZXGzQoEH5zGc+ky996Uu54YYb0qVLl0ycODG77bZbPvOZzyRJJkyYkLFjx+YDH/hAVqxYkYcffjiDB7/z+7f32GOPrF69OjNmzMgBBxyQTp06pVOnTu+47/HHH5/Jkyfn2WefzcMPP1w/3qVLl5x77rk5++yzs2nTphx88MGpra3No48+moqKipx44olN/40AAADYDrTKiE6SiWMHZ8x+lS26Ovdbbrrpppx11ln51Kc+lddffz0f/ehHc//999efGd64cWPGjx+fxYsXp6KiIocddli+973vveNzjRgxIuPGjcsxxxyTV199NRdffHH9x1z9verq6lx++eUZMGBARo4c2WDbZZddll69emXSpElZuHBhunXrlgMPPDAXXHBBk37tAAAA25OyUqlUaulJvF1dXV26du2a2traVFRUNNi2bt26LFq0KFVVVdlpp51aaIa8H36GAADAtubdOvTvtdoz0QDseObWrNgmrjACAHZcIhqAHcKVDzzdYK2LcaMGZuLYd14/AgBgS7XK1bkB2LHMrVnRIKCTZPLMhZlbs6KFZgQA7KhENADbrLk1K/Kz3y9+zxhe9MqaRo0DAGwpl3MDsE1qzOXZVT07N2ocAGBLORMNwDansZdnD+nfPeNGDWwwdsaogRYXAwCanDPRAGxz3u3y7H8UxhPHDs6Y/Sqtzs07snI7AE1FRAOwzdnSy7OH9O8ukNiMldsBaEou5wZgm+PybJqKldsBaGrORFNvjz32yIQJEzJhwoSWngqAy7NpElvy1gAAeDfORDeTk046KWVlZbnyyisbjN99990pKytr1rncfPPN6dat22bjc+bMyemnn96scwF4N0P6d8+RB+4udthiVm4HoKmJ6Ga000475aqrrsqKFdvmJWS9evVKp06dWnoaANBkvDUAgKYmopvR6NGjU1lZmUmTJv3DfWbNmpVDDjkk5eXl6devX84888ysWfO3S9GWLFmSww8/POXl5amqqsrUqVOzxx575Jprrqnf57vf/W7233//dO7cOf369ctXvvKVrF69OknyyCOP5OSTT05tbW3KyspSVlaWSy65JEkaPM/xxx+fY445psHcNmzYkJ49e+bWW29NkmzatCmTJk1KVVVVysvLc8ABB+SnP/1pE3ynAKDpTBw7OD//yoh89/MH5OdfGZFvWlQMgPehdUf04seTP/zkzf9tBm3bts0VV1yR6667LosXL95s+3PPPZfDDjssRx11VJ566qnccccdmTVrVr761a/W7/PFL34xL7/8ch555JH83//7f/PDH/4wy5cvb/A8bdq0ybXXXps///nPueWWW/LQQw/lvPPOS5KMGDEi11xzTSoqKrJkyZIsWbIk55577mZzqa6uzr333lsf30ny4IMPZu3atfnc5z6XJJk0aVJuvfXWTJ48OX/+859z9tln5wtf+EJmzpzZJN8vAGgq3hoAQFNpvQuLTbs4efSav90fOSH55KVb/WU/97nP5UMf+lAuvvji3HjjjQ22TZo0KdXV1fULew0aNCjXXnttRo0aleuvvz7PP/98pk+fnjlz5mTo0KFJkv/9v/93Bg0a1OB53r4w2B577JFvf/vbGTduXH7wgx+kQ4cO6dq1a8rKylJZWfkP5zlmzJh07tw5P//5z3PCCSckSaZOnZpPf/rT6dKlS9avX58rrrgi06dPz/Dhw5MkAwcOzKxZs3LDDTdk1KhR7/dbBQAAsM1pnRG9+PGGAZ28eX/wEcnuQ7f6y1911VU59NBDNzsD/Ic//CFPPfVUpkyZUj9WKpWyadOmLFq0KM8++2zatWuXAw88sH77Xnvtle7dG/5Vffr06Zk0aVL+8pe/pK6uLm+88UbWrVuXtWvXFn7Pc7t27fL5z38+U6ZMyQknnJA1a9bknnvuyU9+8pMkyYIFC7J27dp88pOfbPC4119/PUOGDGnU9wMAAGB70Toj+tUF/3i8GSL6ox/9aMaMGZPzzz8/J510Uv346tWr8+UvfzlnnnnmZo/p379/nn322fd87ueffz6f+tSncsYZZ+Tyyy/PLrvsklmzZuXUU0/N66+/3qiFw6qrqzNq1KgsX74806ZNS3l5eQ477LD6uSbJfffdl912263B4zp27Fj4NQAAALYnrTOie+zVuPGt4Morr8yHPvSh7L333vVjBx54YObNm5e99nrneey999554403Mnfu3Bx00EFJ3jwj/PbVvp944ols2rQp3/nOd9KmzZtveb/zzjsbPE+HDh2ycePG95zjiBEj0q9fv9xxxx154IEHcvTRR6d9+/ZJkn333TcdO3ZMTU2NS7cBAIBWo3VG9O5D33wPdIP3RJ/dLGeh37L//vunuro61157bf3YN7/5zXzkIx/JV7/61Zx22mnp3Llz5s2bl2nTpuX73/9+9tlnn4wePTqnn356rr/++rRv3z7nnHNOysvL6z9req+99sqGDRty3XXX5Ygjjsijjz6ayZMnN3jtPfbYI6tXr86MGTNywAEHpFOnTv/wDPXxxx+fyZMn59lnn83DDz9cP96lS5ece+65Ofvss7Np06YcfPDBqa2tzaOPPpqKioqceOKJW+G7BgAA0LJa7+rcn7w0OW1G8rkb3vzfT17S7FP41re+lU2bNtXf/+AHP5iZM2fm2WefzSGHHJIhQ4bkoosuSt++fev3ufXWW9O7d+989KMfzec+97l86UtfSpcuXbLTTjslSQ444IB897vfzVVXXZV/+qd/ypQpUzb7SK0RI0Zk3LhxOeaYY9KrV69cffXV/3CO1dXVmTdvXnbbbbeMHDmywbbLLrssF154YSZNmpTBgwfnsMMOy3333Zeqqqqm+PYAAABsc8pKpVKppSfxdnV1denatWtqa2tTUVHRYNu6deuyaNGiVFVV1Udja7d48eL069cv06dPzyc+8YmWns578jMEAAC2Ne/WoX+vdV7OvR176KGHsnr16uy///5ZsmRJzjvvvOyxxx756Ec/2tJTAwAA2OGJ6O3Mhg0bcsEFF2ThwoXp0qVLRowYkSlTptQv+AUAAMDWI6K3M2PGjMmYMWNaehoAAACtUutdWAwAAAAaabuM6G1sLTQawc8OAADYnm1XEf3W+37Xrl3bwjNhS731s/MebgAAYHu0Xb0num3btunWrVuWL1+eJOnUqVPKyspaeFYUUSqVsnbt2ixfvjzdunVL27ZtW3pKAAAAjbZdRXSSVFZWJkl9SLN96datW/3PEAAAYHuz3UV0WVlZ+vTpk1133TUbNmxo6enQCO3bt3cGGgAA2K5tdxH9lrZt2woyAAAAmtV2tbAYAAAAtCQRDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQUKMjetWqVZkwYUIGDBiQ8vLyjBgxInPmzKnfXiqVctFFF6VPnz4pLy/P6NGjM3/+/CadNAAAALSERkf0aaedlmnTpuW2227LH//4x/zzP/9zRo8enZdeeilJcvXVV+faa6/N5MmT89hjj6Vz584ZM2ZM1q1b1+STBwAAgOZUViqVSkV3fu2119KlS5fcc889Ofzww+vHDzrooIwdOzaXXXZZ+vbtm3POOSfnnntukqS2tja9e/fOzTffnGOPPfY9X6Ouri5du3ZNbW1tKioqtuBLAgAAgOIa06GNOhP9xhtvZOPGjdlpp50ajJeXl2fWrFlZtGhRli5dmtGjR9dv69q1a4YNG5bZs2c35qUAAABgm9OoiO7SpUuGDx+eyy67LC+//HI2btyY22+/PbNnz86SJUuydOnSJEnv3r0bPK5379712/7e+vXrU1dX1+AGAAAA26JGvyf6tttuS6lUym677ZaOHTvm2muvzXHHHZc2bbZsoe9Jkyala9eu9bd+/fpt0fMAAADA1tbo8t1zzz0zc+bMrF69Oi+++GJ+97vfZcOGDRk4cGAqKyuTJMuWLWvwmGXLltVv+3vnn39+amtr628vvvjiFnwZAAAAsPVt8edEd+7cOX369MmKFSvy4IMP5jOf+UyqqqpSWVmZGTNm1O9XV1eXxx57LMOHD3/H5+nYsWMqKioa3AAAAGBb1K6xD3jwwQdTKpWy9957Z8GCBfnGN76RffbZJyeffHLKysoyYcKEfPvb386gQYNSVVWVCy+8MH379s1nP/vZrTB9AAAAaD6Njuja2tqcf/75Wbx4cXbZZZccddRRufzyy9O+ffskyXnnnZc1a9bk9NNPz8qVK3PwwQfnV7/61WYregMAAMD2plGfE90cfE40sC2aW7Mii15Zk6qenTOkf/eWng4AAE2oMR3a6DPRAK3NlQ88nckzF9bfHzdqYCaOHdyCMwIAoKVs8cJiAK3B3JoVDQI6SSbPXJi5NStaaEYAALQkEQ3wLha9sqZR4wAA7NhENMC7qOrZuVHjAADs2EQ0wLsY0r97xo0a2GDsjFEDLS4GANuguTUr8rPfL/a2K7YqC4sBvIeJYwdnzH6VVucGgG2YhUBpLiIaoIAh/buLZwDYRv2jhUDH7Ffp32+anMu5AQCA7ZqFQGlOIhoAANiuWQiU5iSiAQCA7ZqFQGlO3hMNAABs9ywESnMR0QAAwA7BQqA0B5dzAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAU1K6lJwAAAMC2YW7Niix6ZU2qenbOkP7dW3o62yQRDQAAQK584OlMnrmw/v64UQMzcezgFpzRtsnl3AAAAK3c3JoVDQI6SSbPXJi5NStaaEbbLhENAADQyi16ZU2jxlszEQ0AANDKVfXs3Kjx1kxEAwAAtHJD+nfPuFEDG4ydMWqgxcXegYXFAAAAyMSxgzNmv0qrc78HEQ0AAECSN89Ii+d353JuAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFBQoyJ648aNufDCC1NVVZXy8vLsueeeueyyy1Iqler3KZVKueiii9KnT5+Ul5dn9OjRmT9/fpNPHAAAAJpboyL6qquuyvXXX5/vf//7efrpp3PVVVfl6quvznXXXVe/z9VXX51rr702kydPzmOPPZbOnTtnzJgxWbduXZNPHgAAAJpTWentp5Hfw6c+9an07t07N954Y/3YUUcdlfLy8tx+++0plUrp27dvzjnnnJx77rlJktra2vTu3Ts333xzjj322Pd8jbq6unTt2jW1tbWpqKjYgi8JAAAAimtMhzbqTPSIESMyY8aMPPvss0mSP/zhD5k1a1bGjh2bJFm0aFGWLl2a0aNH1z+ma9euGTZsWGbPnv2Oz7l+/frU1dU1uAEAAMC2qF1jdp44cWLq6uqyzz77pG3bttm4cWMuv/zyVFdXJ0mWLl2aJOndu3eDx/Xu3bt+29+bNGlSLr300i2ZOwAAADSrRp2JvvPOOzNlypRMnTo1v//973PLLbfk3//933PLLbds8QTOP//81NbW1t9efPHFLX4uAAAA2JoadSb6G9/4RiZOnFj/3ub9998/L7zwQiZNmpQTTzwxlZWVSZJly5alT58+9Y9btmxZPvShD73jc3bs2DEdO3bcwukDAABA82nUmei1a9emTZuGD2nbtm02bdqUJKmqqkplZWVmzJhRv72uri6PPfZYhg8f3gTTBQAAgJbTqDPRRxxxRC6//PL0798/++23X+bOnZvvfve7OeWUU5IkZWVlmTBhQr797W9n0KBBqaqqyoUXXpi+ffvms5/97NaYPwAAADSbRkX0ddddlwsvvDBf+cpXsnz58vTt2zdf/vKXc9FFF9Xvc95552XNmjU5/fTTs3Llyhx88MH51a9+lZ122qnJJw8AAADNqVGfE90cfE40AAAAzWmrfU40AAAAtGYiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFBQu5aewHZt8ePJqwuSHnsluw9t6dkA0Ezm1qzIolfWpKpn5wzp372lpwMANCMRvaWmXZw8es3f7o+ckHzy0paaDQDN5MoHns7kmQvr748bNTATxw5uwRkBAM3J5dxbYvHjDQM6efP+4sdbYjYANJO5NSsaBHSSTJ65MHNrVrTQjACA5iait8SrCxo3DsAOYdEraxo1DgDseET0luixV+PGAdghVPXs3KhxAGDHI6K3xO5D33wP9NuNPNviYgA7uCH9u2fcqIENxs4YNdDiYgDQipSVSqVSS0/i7erq6tK1a9fU1tamoqKipafz7qzODdAqWZ0bAHYsjelQEQ0AAECr1pgOdTk3AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBB7Vp6AmzHFj+evLog6bFXsvvQlp4NAADAViei2TLTLk4eveZv90dOSD55aUvNBgAAoFm4nJvGW/x4w4BO3ry/+PGWmA0AAECzEdE03qsLGjcOAACwgxDRNF6PvRo3DgAAsIMQ0TTe7kPffA/024082+JiAADADs/CYmyZT16aDD7C6twAAECrIqLZcrsPFc8AAECr4nJuAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCGhXRe+yxR8rKyja7jR8/Pkmybt26jB8/Pj169MjOO++co446KsuWLdsqEwcAAIDm1qiInjNnTpYsWVJ/mzZtWpLk6KOPTpKcffbZuffee3PXXXdl5syZefnll3PkkUc2/awBAACgBZSVSqXSlj54woQJ+eUvf5n58+enrq4uvXr1ytSpU/M//+f/TJL85S9/yeDBgzN79ux85CMfKfScdXV16dq1a2pra1NRUbGlUwOglZtbsyKLXlmTqp6dM6R/95aeDgCwDWtMh7bb0hd5/fXXc/vtt+frX/96ysrK8sQTT2TDhg0ZPXp0/T777LNP+vfv/64RvX79+qxfv77B5AHg/bjygaczeebC+vvjRg3MxLGDW3BG7Oj80Qag9djiiL777ruzcuXKnHTSSUmSpUuXpkOHDunWrVuD/Xr37p2lS5f+w+eZNGlSLr300i2dBgA0MLdmRYOATpLJMxdmzH6V4oatwh9tAFqXLV6d+8Ybb8zYsWPTt2/f9zWB888/P7W1tfW3F1988X09HwCt26JX1jRqHN6Pf/RHm7k1K1poRgBsbVt0JvqFF17I9OnT87Of/ax+rLKyMq+//npWrlzZ4Gz0smXLUllZ+Q+fq2PHjunYseOWTAMANlPVs3OjxuH9eLc/2rjyAWDHtEVnom+66absuuuuOfzww+vHDjrooLRv3z4zZsyoH3vmmWdSU1OT4cOHv/+ZAkABQ/p3z7hRAxuMnTFqoKBhq/BHG4DWp9Fnojdt2pSbbropJ554Ytq1+9vDu3btmlNPPTVf//rXs8suu6SioiJf+9rXMnz48MIrcwNAU5g4dnDG7FdpoSe2urf+aPP2S7r90QZgx9boiJ4+fXpqampyyimnbLbte9/7Xtq0aZOjjjoq69evz5gxY/KDH/ygSSYKAI0xpH93IUOz8EcbgNblfX1O9Nbgc6IBAABoTo3p0C1enRsAAABaGxENAAAABYloAAAAKGiLPicaAAAA3svcmhU73MKLIhoAAIAmd+UDTzf4CMBxowZm4tjBLTijpuFybgAAAJrU3JoVDQI6SSbPXJi5NStaaEZNR0QDAADQpBa9sqZR49sTEQ0AAECTqurZuVHj2xMRDQAAQJMa0r97xo0a2GDsjFEDd4jFxSwsBgAAQJObOHZwxuxXaXVuAAAAKGJI/+47TDy/xeXcAAAAUJCIBgAAgIJENAAAABQkogEAAKAgEQ0AAAAFiWgAAAAoSEQDAABAQSIaAAAAChLRAAAAUJCIBgAAgIJENAAAABQkogEAAKAgEQ0AAAAFiWgAAAAoSEQDAABAQe1aegIAwNYzt2ZFFr2yJlU9O2dI/+4tPR0A2O6JaADYQV35wNOZPHNh/f1xowZm4tjBLTgjANj+uZwbAHZAc2tWNAjoJJk8c2Hm1qxooRkBwI5BRAPADmjRK2saNQ4AFCOiAWAHVNWzc6PGAYBiRDQA7ICG9O+ecaMGNhg7Y9RAi4sBwPtkYTEA2EFNHDs4Y/artDo3ADQhEQ0AO7Ah/buLZwBoQi7nBgAAgIJENAAAABTkcm4AAICtZG7NCmtT7GBENAAAwFZw5QNPZ/LMhfX3x40amIljB7fgjGgKLucGAABoYnNrVjQI6CSZPHNh5tasaKEZ0VRENAAAQBNb9MqaRo2z/RDRAAAATayqZ+dGjbP9ENEAAABNbEj/7hk3amCDsTNGDbS42A7AwmIAAABbwcSxgzNmv0qrc+9gRDQAAMBWMqR/d/G8g3E5NwAAABQkogEAAKAgEQ0AAAAFiWgAAAAoSEQDAABAQSIaAAAAChLRAAAAUJCIBgAAgIJENAAAABQkogEAAKAgEQ0AAAAFiWgAAAAoSEQDAABAQSIaAAAAChLRAAAAUJCIBgAAgIJENAAAABQkogEAAKAgEQ0AAAAFiWgAAAAoSEQDAABAQSIaAAAAChLRAAAAUJCIBgAAgIJENAAAABQkogEAAKAgEQ0AAAAFiWgAAAAoSEQDAABAQSIaAAAAChLRAAAAUJCIBgAAgIJENAAAABQkogEAAKAgEQ0AAAAFiWgAAAAoSEQDAABAQSIaAAAAChLRAAAAUJCIBgAAgILatfQEAAAA2DHNrVmRRa+sSVXPzhnSv3tLT6dJiGgAAACa3JUPPJ3JMxfW3x83amAmjh3cgjNqGi7nBgAAoEnNrVnRIKCTZPLMhZlbs6KFZtR0RDQAAABNatEraxo1vj0R0QAAADSpqp6dGzW+PRHRAAAANKkh/btn3KiBDcbOGDVwh1hczMJiAAAANLmJYwdnzH6VVucGAACAIob0777DxPNbXM4NAAAABTU6ol966aV84QtfSI8ePVJeXp79998/jz/+eP32UqmUiy66KH369El5eXlGjx6d+fPnN+mkAQAAoCU0KqJXrFiRkSNHpn379nnggQcyb968fOc730n37n87PX/11Vfn2muvzeTJk/PYY4+lc+fOGTNmTNatW9fkkwcAAIDmVFYqlUpFd544cWIeffTR/Pa3v33H7aVSKX379s0555yTc889N0lSW1ub3r175+abb86xxx77nq9RV1eXrl27pra2NhUVFUWnBgAAAFukMR3aqDPRv/jFLzJ06NAcffTR2XXXXTNkyJD86Ec/qt++aNGiLF26NKNHj64f69q1a4YNG5bZs2e/43OuX78+dXV1DW4AAACwLWpURC9cuDDXX399Bg0alAcffDBnnHFGzjzzzNxyyy1JkqVLlyZJevfu3eBxvXv3rt/29yZNmpSuXbvW3/r167clXwcAAABsdY2K6E2bNuXAAw/MFVdckSFDhuT000/Pl770pUyePHmLJ3D++eentra2/vbiiy9u8XMBAADA1tSoiO7Tp0/23XffBmODBw9OTU1NkqSysjJJsmzZsgb7LFu2rH7b3+vYsWMqKioa3AAAAGBb1KiIHjlyZJ555pkGY88++2wGDBiQJKmqqkplZWVmzJhRv72uri6PPfZYhg8f3gTTBQAAgJbTrjE7n3322RkxYkSuuOKKfP7zn8/vfve7/PCHP8wPf/jDJElZWVkmTJiQb3/72xk0aFCqqqpy4YUXpm/fvvnsZz+7NeYPAAAAzaZREf3hD384P//5z3P++efnW9/6VqqqqnLNNdekurq6fp/zzjsva9asyemnn56VK1fm4IMPzq9+9avstNNOTT55AAAAaE6N+pzo5uBzogEAAGhOW+1zogEAAKA1E9EAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFNSoiL7kkktSVlbW4LbPPvvUb1+3bl3Gjx+fHj16ZOedd85RRx2VZcuWNfmkAQAAoCU0+kz0fvvtlyVLltTfZs2aVb/t7LPPzr333pu77rorM2fOzMsvv5wjjzyySScMAAAALaVdox/Qrl0qKys3G6+trc2NN96YqVOn5tBDD02S3HTTTRk8eHD++7//Ox/5yEfe/2wBAACgBTX6TPT8+fPTt2/fDBw4MNXV1ampqUmSPPHEE9mwYUNGjx5dv+8+++yT/v37Z/bs2U03YwAAAGghjToTPWzYsNx8883Ze++9s2TJklx66aU55JBD8qc//SlLly5Nhw4d0q1btwaP6d27d5YuXfoPn3P9+vVZv359/f26urrGfQUAAADQTBoV0WPHjq3/7w9+8IMZNmxYBgwYkDvvvDPl5eVbNIFJkybl0ksv3aLHAgAAQHN6Xx9x1a1bt3zgAx/IggULUllZmddffz0rV65ssM+yZcve8T3Ubzn//PNTW1tbf3vxxRffz5QAAABgq3lfEb169eo899xz6dOnTw466KC0b98+M2bMqN/+zDPPpKamJsOHD/+Hz9GxY8dUVFQ0uAEAAMC2qFGXc5977rk54ogjMmDAgLz88su5+OKL07Zt2xx33HHp2rVrTj311Hz961/PLrvskoqKinzta1/L8OHDrcwNAADADqFREb148eIcd9xxefXVV9OrV68cfPDB+e///u/06tUrSfK9730vbdq0yVFHHZX169dnzJgx+cEPfrBVJg4AAADNraxUKpVaehJvV1dXl65du6a2ttal3QAAAGx1jenQ9/WeaAAAAGhNRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhEAwAAQEEiGgAAAAoS0QAAAFCQiAYAAICCRDQAAAAUJKIBAACgoHYtPQEAgNZkbs2KLHplTap6ds6Q/t1bejoANJKIBgBoJlc+8HQmz1xYf3/cqIGZOHZwC84IgMZyOTcAQDOYW7OiQUAnyeSZCzO3ZkULzQiALSGiAQCawaJX1jRqHIBtk4gGAGgGVT07N2ocgG2TiAYAaAZD+nfPuFEDG4ydMWqgxcUAtjMWFgMAaCYTxw7OmP0qrc4NsB0T0cC2ZfHjyasLkh57JbsPbenZADS5If27i2eA7ZiIBrYd0y5OHr3mb/dHTkg+eWlLzQYAADbjPdHAtmHx4w0DOnnz/uLHW2I2AABb1dyaFfnZ7xf7mLvtkDPRwLbh1QX/eNxl3QDADuTKB55u8Lnx40YNzMSxg1twRjSGM9HAtqHHXo0bBwDYDs2tWdEgoJNk8syFzkhvR0Q0sG3Yfeib74F+u5FnOwsNAOxQFr2yplHjbHtczg1sOz55aTL4CKtzAwA7rKqenRs1zrbHmWhg27L70OSAYwU0ALBDGtK/e8aNGthg7IxRA3303XbEmWgAAIBmNHHs4IzZrzKLXlmTqp6dBfR2RkQDAAA0syH9u4vn7ZTLuQEAAKAgZ6IBAGgRc2tWuJwV2O6IaAAAmt2VDzzd4LNyx40amIljB7fgjACKcTk3AADNam7NigYBnSSTZy7M3JoVLTQjgOJENAAAzWrRK2saNQ6wLRHRAAA0q6qenRs1DrAtEdEAADSrIf27Z9yogQ3Gzhg10OJiwHbBwmIAADS7iWMHZ8x+lVbnBrY7IhoAgBYxpH938Qxsd1zODQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKatfSEwAAtrLFjyevLkh67JXsPrSlZwMA2zURDQA7smkXJ49e87f7Iyckn7y0pWYDANs9l3MDwI5q8eMNAzp58/7ix1tiNgCwQxDRALCjenVB48YBgPckogFgR9Vjr8aNAwDvSUQDwI5q96Fvvgf67UaebXExAHgfLCwGADuyT16aDD7C6twA0ERENADs6HYfKp4BoIm4nBsAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAW1a+kJ/L1SqZQkqaura+GZAAAA0Bq81Z9v9ei72eYietWqVUmSfv36tfBMAAAAaE1WrVqVrl27vus+ZaUiqd2MNm3alJdffjldunRJWVlZS0+HLVBXV5d+/frlxRdfTEVFRUtPhxbkWCBxHPA3jgXe4lggcRzwN9vCsVAqlbJq1ar07ds3bdq8+7uet7kz0W3atMnuu+/e0tOgCVRUVPiFSBLHAm9yHPAWxwJvcSyQOA74m5Y+Ft7rDPRbLCwGAAAABYloAAAAKEhE0+Q6duyYiy++OB07dmzpqdDCHAskjgP+xrHAWxwLJI4D/mZ7Oxa2uYXFAAAAYFvlTDQAAAAUJKIBAACgIBENAAAABYloAAAAKEhE0ySuvPLKlJWVZcKECfVj69aty/jx49OjR4/svPPOOeqoo7Js2bKWmyRbxSWXXJKysrIGt3322ad+u+Og9XjppZfyhS98IT169Eh5eXn233//PP744/XbS6VSLrroovTp0yfl5eUZPXp05s+f34IzZmvYY489NvudUFZWlvHjxyfxO6E12bhxYy688MJUVVWlvLw8e+65Zy677LK8fU1bvxdah1WrVmXChAkZMGBAysvLM2LEiMyZM6d+u+Ngx/Sb3/wmRxxxRPr27ZuysrLcfffdDbYX+bn/9a9/TXV1dSoqKtKtW7eceuqpWb16dTN+Fe9MRPO+zZkzJzfccEM++MEPNhg/++yzc++99+auu+7KzJkz8/LLL+fII49soVmyNe23335ZsmRJ/W3WrFn12xwHrcOKFSsycuTItG/fPg888EDmzZuX73znO+nevXv9PldffXWuvfbaTJ48OY899lg6d+6cMWPGZN26dS04c5ranDlzGvw+mDZtWpLk6KOPTuJ3Qmty1VVX5frrr8/3v//9PP3007nqqqty9dVX57rrrqvfx++F1uG0007LtGnTctttt+WPf/xj/vmf/zmjR4/OSy+9lMRxsKNas2ZNDjjggPznf/7nO24v8nOvrq7On//850ybNi2//OUv85vf/Cann356c30J/1gJ3odVq1aVBg0aVJo2bVpp1KhRpbPOOqtUKpVKK1euLLVv375011131e/79NNPl5KUZs+e3UKzZWu4+OKLSwcccMA7bnMctB7f/OY3SwcffPA/3L5p06ZSZWVl6d/+7d/qx1auXFnq2LFj6cc//nFzTJEWctZZZ5X23HPP0qZNm/xOaGUOP/zw0imnnNJg7MgjjyxVV1eXSiW/F1qLtWvXltq2bVv65S9/2WD8wAMPLP3rv/6r46CVSFL6+c9/Xn+/yM993rx5pSSlOXPm1O/zwAMPlMrKykovvfRSs839nTgTzfsyfvz4HH744Rk9enSD8SeeeCIbNmxoML7PPvukf//+mT17dnNPk61s/vz56du3bwYOHJjq6urU1NQkcRy0Jr/4xS8ydOjQHH300dl1110zZMiQ/OhHP6rfvmjRoixdurTBsdC1a9cMGzbMsbADe/3113P77bfnlFNOSVlZmd8JrcyIESMyY8aMPPvss0mSP/zhD5k1a1bGjh2bxO+F1uKNN97Ixo0bs9NOOzUYLy8vz6xZsxwHrVSRn/vs2bPTrVu3DB06tH6f0aNHp02bNnnssceafc5v165FX53t2k9+8pP8/ve/b/CelrcsXbo0HTp0SLdu3RqM9+7dO0uXLm2mGdIchg0blptvvjl77713lixZkksvvTSHHHJI/vSnPzkOWpGFCxfm+uuvz9e//vVccMEFmTNnTs4888x06NAhJ554Yv3Pu3fv3g0e51jYsd19991ZuXJlTjrppCT+bWhtJk6cmLq6uuyzzz5p27ZtNm7cmMsvvzzV1dVJ4vdCK9GlS5cMHz48l112WQYPHpzevXvnxz/+cWbPnp299trLcdBKFfm5L126NLvuumuD7e3atcsuu+zS4seGiGaLvPjiiznrrLMybdq0zf6ySOvy1hmFJPngBz+YYcOGZcCAAbnzzjtTXl7egjOjOW3atClDhw7NFVdckSQZMmRI/vSnP2Xy5Mk58cQTW3h2tJQbb7wxY8eOTd++fVt6KrSAO++8M1OmTMnUqVOz33775cknn8yECRPSt29fvxdamdtuuy2nnHJKdtttt7Rt2zYHHnhgjjvuuDzxxBMtPTXYIi7nZos88cQTWb58eQ488MC0a9cu7dq1y8yZM3PttdemXbt26d27d15//fWsXLmyweOWLVuWysrKlpk0zaJbt275wAc+kAULFqSystJx0Er06dMn++67b4OxwYMH11/a/9bP++9XYXYs7LheeOGFTJ8+Paeddlr9mN8Jrcs3vvGNTJw4Mccee2z233//nHDCCTn77LMzadKkJH4vtCZ77rlnZs6cmdWrV+fFF1/M7373u2zYsCEDBw50HLRSRX7ulZWVWb58eYPtb7zxRv7617+2+LEhotkin/jEJ/LHP/4xTz75ZP1t6NChqa6urv/v9u3bZ8aMGfWPeeaZZ1JTU5Phw4e34MzZ2lavXp3nnnsuffr0yUEHHeQ4aCVGjhyZZ555psHYs88+mwEDBiRJqqqqUllZ2eBYqKury2OPPeZY2EHddNNN2XXXXXP44YfXj/md0LqsXbs2bdo0/L+abdu2zaZNm5L4vdAade7cOX369MmKFSvy4IMP5jOf+YzjoJUq8nMfPnx4Vq5c2eCKhYceeiibNm3KsGHDmn3ODbTosmbsUN6+OnepVCqNGzeu1L9//9JDDz1Uevzxx0vDhw8vDR8+vOUmyFZxzjnnlB555JHSokWLSo8++mhp9OjRpZ49e5aWL19eKpUcB63F7373u1K7du1Kl19+eWn+/PmlKVOmlDp16lS6/fbb6/e58sorS926dSvdc889paeeeqr0mc98plRVVVV67bXXWnDmbA0bN24s9e/fv/TNb35zs21+J7QeJ554Ymm33XYr/fKXvywtWrSo9LOf/azUs2fP0nnnnVe/j98LrcOvfvWr0gMPPFBauHBh6de//nXpgAMOKA0bNqz0+uuvl0olx8GOatWqVaW5c+eW5s6dW0pS+u53v1uaO3du6YUXXiiVSsV+7ocddlhpyJAhpccee6w0a9as0qBBg0rHHXdcS31J9UQ0TebvI/q1114rfeUrXyl179691KlTp9LnPve50pIlS1pugmwVxxxzTKlPnz6lDh06lHbbbbfSMcccU1qwYEH9dsdB63HvvfeW/umf/qnUsWPH0j777FP64Q9/2GD7pk2bShdeeGGpd+/epY4dO5Y+8YlPlJ555pkWmi1b04MPPlhK8o4/X78TWo+6urrSWWedVerfv39pp512Kg0cOLD0r//6r6X169fX7+P3Qutwxx13lAYOHFjq0KFDqbKysjR+/PjSypUr67c7DnZMDz/8cCnJZrcTTzyxVCoV+7m/+uqrpeOOO6608847lyoqKkonn3xyadWqVS3w1TRUViqVSi14IhwAAAC2G94TDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAKEtEAAABQkIgGAACAgkQ0AAAAFCSiAQAAoCARDQAAAAWJaAAAAChIRAMAAEBBIhoAAAAK+v8J3T5XJkYlGQAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_val_data = val_x[np.where(val_y[:]==1)]\n",
    "negative_val_data = val_x[np.where(val_y[:]==0)]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=positive_val_data[:,0], y=positive_val_data[:,1], s=10, label=\"Positive\")\n",
    "ax.scatter(x=negative_val_data[:,0], y=negative_val_data[:,1], s=10, label=\"Negative\")\n",
    "ax.legend(loc=2)\n",
    "ax.set_title('Validation Set')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "整理维度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(20, 1)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_ex = np.expand_dims(train_y,axis=1)\n",
    "val_y_ex = np.expand_dims(val_y,axis=1)\n",
    "val_y_ex.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "进行逻辑回归，查看参数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '，' (U+FF0C) (206114234.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn [1], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    进行逻辑回归，查看参数\u001B[0m\n\u001B[1;37m          ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid character '，' (U+FF0C)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5000, Train Loss: 0.3812\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5538\n",
      "Epoch: 2/5000, Train Loss: 0.3804\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5531\n",
      "Epoch: 3/5000, Train Loss: 0.3795\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5525\n",
      "Epoch: 4/5000, Train Loss: 0.3786\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5518\n",
      "Epoch: 5/5000, Train Loss: 0.3777\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5511\n",
      "Epoch: 6/5000, Train Loss: 0.3769\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5504\n",
      "Epoch: 7/5000, Train Loss: 0.3760\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5497\n",
      "Epoch: 8/5000, Train Loss: 0.3752\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5491\n",
      "Epoch: 9/5000, Train Loss: 0.3743\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5484\n",
      "Epoch: 10/5000, Train Loss: 0.3735\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5478\n",
      "Epoch: 11/5000, Train Loss: 0.3726\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5471\n",
      "Epoch: 12/5000, Train Loss: 0.3718\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5464\n",
      "Epoch: 13/5000, Train Loss: 0.3710\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5458\n",
      "Epoch: 14/5000, Train Loss: 0.3702\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5452\n",
      "Epoch: 15/5000, Train Loss: 0.3693\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5445\n",
      "Epoch: 16/5000, Train Loss: 0.3685\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5439\n",
      "Epoch: 17/5000, Train Loss: 0.3677\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5432\n",
      "Epoch: 18/5000, Train Loss: 0.3669\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5426\n",
      "Epoch: 19/5000, Train Loss: 0.3661\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5420\n",
      "Epoch: 20/5000, Train Loss: 0.3653\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5414\n",
      "Epoch: 21/5000, Train Loss: 0.3645\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5407\n",
      "Epoch: 22/5000, Train Loss: 0.3637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5401\n",
      "Epoch: 23/5000, Train Loss: 0.3629\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5395\n",
      "Epoch: 24/5000, Train Loss: 0.3621\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5389\n",
      "Epoch: 25/5000, Train Loss: 0.3613\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5383\n",
      "Epoch: 26/5000, Train Loss: 0.3606\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5377\n",
      "Epoch: 27/5000, Train Loss: 0.3598\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5371\n",
      "Epoch: 28/5000, Train Loss: 0.3590\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5365\n",
      "Epoch: 29/5000, Train Loss: 0.3582\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5359\n",
      "Epoch: 30/5000, Train Loss: 0.3575\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5353\n",
      "Epoch: 31/5000, Train Loss: 0.3567\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5347\n",
      "Epoch: 32/5000, Train Loss: 0.3560\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5341\n",
      "Epoch: 33/5000, Train Loss: 0.3552\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5335\n",
      "Epoch: 34/5000, Train Loss: 0.3545\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5330\n",
      "Epoch: 35/5000, Train Loss: 0.3537\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5324\n",
      "Epoch: 36/5000, Train Loss: 0.3530\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5318\n",
      "Epoch: 37/5000, Train Loss: 0.3523\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5312\n",
      "Epoch: 38/5000, Train Loss: 0.3515\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5307\n",
      "Epoch: 39/5000, Train Loss: 0.3508\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5301\n",
      "Epoch: 40/5000, Train Loss: 0.3501\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5296\n",
      "Epoch: 41/5000, Train Loss: 0.3494\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5290\n",
      "Epoch: 42/5000, Train Loss: 0.3486\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5284\n",
      "Epoch: 43/5000, Train Loss: 0.3479\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5279\n",
      "Epoch: 44/5000, Train Loss: 0.3472\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5274\n",
      "Epoch: 45/5000, Train Loss: 0.3465\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5268\n",
      "Epoch: 46/5000, Train Loss: 0.3458\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5263\n",
      "Epoch: 47/5000, Train Loss: 0.3451\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5257\n",
      "Epoch: 48/5000, Train Loss: 0.3444\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5252\n",
      "Epoch: 49/5000, Train Loss: 0.3437\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5247\n",
      "Epoch: 50/5000, Train Loss: 0.3430\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5241\n",
      "Epoch: 51/5000, Train Loss: 0.3423\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5236\n",
      "Epoch: 52/5000, Train Loss: 0.3417\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5231\n",
      "Epoch: 53/5000, Train Loss: 0.3410\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5226\n",
      "Epoch: 54/5000, Train Loss: 0.3403\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5220\n",
      "Epoch: 55/5000, Train Loss: 0.3396\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5215\n",
      "Epoch: 56/5000, Train Loss: 0.3390\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5210\n",
      "Epoch: 57/5000, Train Loss: 0.3383\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5205\n",
      "Epoch: 58/5000, Train Loss: 0.3376\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5200\n",
      "Epoch: 59/5000, Train Loss: 0.3370\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5195\n",
      "Epoch: 60/5000, Train Loss: 0.3363\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5190\n",
      "Epoch: 61/5000, Train Loss: 0.3357\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5185\n",
      "Epoch: 62/5000, Train Loss: 0.3350\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5180\n",
      "Epoch: 63/5000, Train Loss: 0.3344\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5175\n",
      "Epoch: 64/5000, Train Loss: 0.3337\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5170\n",
      "Epoch: 65/5000, Train Loss: 0.3331\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5165\n",
      "Epoch: 66/5000, Train Loss: 0.3325\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5160\n",
      "Epoch: 67/5000, Train Loss: 0.3318\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5155\n",
      "Epoch: 68/5000, Train Loss: 0.3312\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5151\n",
      "Epoch: 69/5000, Train Loss: 0.3306\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5146\n",
      "Epoch: 70/5000, Train Loss: 0.3299\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5141\n",
      "Epoch: 71/5000, Train Loss: 0.3293\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5136\n",
      "Epoch: 72/5000, Train Loss: 0.3287\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5132\n",
      "Epoch: 73/5000, Train Loss: 0.3281\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5127\n",
      "Epoch: 74/5000, Train Loss: 0.3275\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5122\n",
      "Epoch: 75/5000, Train Loss: 0.3269\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5118\n",
      "Epoch: 76/5000, Train Loss: 0.3263\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5113\n",
      "Epoch: 77/5000, Train Loss: 0.3257\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5109\n",
      "Epoch: 78/5000, Train Loss: 0.3251\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5104\n",
      "Epoch: 79/5000, Train Loss: 0.3245\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5099\n",
      "Epoch: 80/5000, Train Loss: 0.3239\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5095\n",
      "Epoch: 81/5000, Train Loss: 0.3233\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5090\n",
      "Epoch: 82/5000, Train Loss: 0.3227\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5086\n",
      "Epoch: 83/5000, Train Loss: 0.3221\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5082\n",
      "Epoch: 84/5000, Train Loss: 0.3215\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5077\n",
      "Epoch: 85/5000, Train Loss: 0.3209\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5073\n",
      "Epoch: 86/5000, Train Loss: 0.3204\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5068\n",
      "Epoch: 87/5000, Train Loss: 0.3198\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5064\n",
      "Epoch: 88/5000, Train Loss: 0.3192\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5060\n",
      "Epoch: 89/5000, Train Loss: 0.3186\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5056\n",
      "Epoch: 90/5000, Train Loss: 0.3181\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5051\n",
      "Epoch: 91/5000, Train Loss: 0.3175\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5047\n",
      "Epoch: 92/5000, Train Loss: 0.3170\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5043\n",
      "Epoch: 93/5000, Train Loss: 0.3164\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5039\n",
      "Epoch: 94/5000, Train Loss: 0.3158\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5034\n",
      "Epoch: 95/5000, Train Loss: 0.3153\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5030\n",
      "Epoch: 96/5000, Train Loss: 0.3147\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5026\n",
      "Epoch: 97/5000, Train Loss: 0.3142\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5022\n",
      "Epoch: 98/5000, Train Loss: 0.3136\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5018\n",
      "Epoch: 99/5000, Train Loss: 0.3131\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5014\n",
      "Epoch: 100/5000, Train Loss: 0.3126\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5010\n",
      "Epoch: 101/5000, Train Loss: 0.3120\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5006\n",
      "Epoch: 102/5000, Train Loss: 0.3115\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5002\n",
      "Epoch: 103/5000, Train Loss: 0.3110\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4998\n",
      "Epoch: 104/5000, Train Loss: 0.3104\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4994\n",
      "Epoch: 105/5000, Train Loss: 0.3099\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4990\n",
      "Epoch: 106/5000, Train Loss: 0.3094\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4986\n",
      "Epoch: 107/5000, Train Loss: 0.3089\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4982\n",
      "Epoch: 108/5000, Train Loss: 0.3083\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4978\n",
      "Epoch: 109/5000, Train Loss: 0.3078\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4974\n",
      "Epoch: 110/5000, Train Loss: 0.3073\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4971\n",
      "Epoch: 111/5000, Train Loss: 0.3068\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4967\n",
      "Epoch: 112/5000, Train Loss: 0.3063\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4963\n",
      "Epoch: 113/5000, Train Loss: 0.3058\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4959\n",
      "Epoch: 114/5000, Train Loss: 0.3053\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4955\n",
      "Epoch: 115/5000, Train Loss: 0.3048\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4952\n",
      "Epoch: 116/5000, Train Loss: 0.3043\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4948\n",
      "Epoch: 117/5000, Train Loss: 0.3038\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4944\n",
      "Epoch: 118/5000, Train Loss: 0.3033\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4941\n",
      "Epoch: 119/5000, Train Loss: 0.3028\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4937\n",
      "Epoch: 120/5000, Train Loss: 0.3023\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4933\n",
      "Epoch: 121/5000, Train Loss: 0.3018\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4930\n",
      "Epoch: 122/5000, Train Loss: 0.3013\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4926\n",
      "Epoch: 123/5000, Train Loss: 0.3008\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4922\n",
      "Epoch: 124/5000, Train Loss: 0.3004\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4919\n",
      "Epoch: 125/5000, Train Loss: 0.2999\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4915\n",
      "Epoch: 126/5000, Train Loss: 0.2994\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4912\n",
      "Epoch: 127/5000, Train Loss: 0.2989\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4908\n",
      "Epoch: 128/5000, Train Loss: 0.2985\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4905\n",
      "Epoch: 129/5000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4901\n",
      "Epoch: 130/5000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4898\n",
      "Epoch: 131/5000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4894\n",
      "Epoch: 132/5000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4891\n",
      "Epoch: 133/5000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4888\n",
      "Epoch: 134/5000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4884\n",
      "Epoch: 135/5000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4881\n",
      "Epoch: 136/5000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4878\n",
      "Epoch: 137/5000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4874\n",
      "Epoch: 138/5000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4871\n",
      "Epoch: 139/5000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4868\n",
      "Epoch: 140/5000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4864\n",
      "Epoch: 141/5000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4861\n",
      "Epoch: 142/5000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4858\n",
      "Epoch: 143/5000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4855\n",
      "Epoch: 144/5000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4851\n",
      "Epoch: 145/5000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4848\n",
      "Epoch: 146/5000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4845\n",
      "Epoch: 147/5000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4842\n",
      "Epoch: 148/5000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4839\n",
      "Epoch: 149/5000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4836\n",
      "Epoch: 150/5000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4832\n",
      "Epoch: 151/5000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4829\n",
      "Epoch: 152/5000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4826\n",
      "Epoch: 153/5000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4823\n",
      "Epoch: 154/5000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4820\n",
      "Epoch: 155/5000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4817\n",
      "Epoch: 156/5000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4814\n",
      "Epoch: 157/5000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4811\n",
      "Epoch: 158/5000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4808\n",
      "Epoch: 159/5000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4805\n",
      "Epoch: 160/5000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4802\n",
      "Epoch: 161/5000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4799\n",
      "Epoch: 162/5000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4796\n",
      "Epoch: 163/5000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4793\n",
      "Epoch: 164/5000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4790\n",
      "Epoch: 165/5000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4788\n",
      "Epoch: 166/5000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4785\n",
      "Epoch: 167/5000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4782\n",
      "Epoch: 168/5000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4779\n",
      "Epoch: 169/5000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4776\n",
      "Epoch: 170/5000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4773\n",
      "Epoch: 171/5000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4771\n",
      "Epoch: 172/5000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4768\n",
      "Epoch: 173/5000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4765\n",
      "Epoch: 174/5000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4762\n",
      "Epoch: 175/5000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4760\n",
      "Epoch: 176/5000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4757\n",
      "Epoch: 177/5000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4754\n",
      "Epoch: 178/5000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4751\n",
      "Epoch: 179/5000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4749\n",
      "Epoch: 180/5000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4746\n",
      "Epoch: 181/5000, Train Loss: 0.2763\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4743\n",
      "Epoch: 182/5000, Train Loss: 0.2759\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4741\n",
      "Epoch: 183/5000, Train Loss: 0.2755\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4738\n",
      "Epoch: 184/5000, Train Loss: 0.2751\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4735\n",
      "Epoch: 185/5000, Train Loss: 0.2748\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4733\n",
      "Epoch: 186/5000, Train Loss: 0.2744\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4730\n",
      "Epoch: 187/5000, Train Loss: 0.2741\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4728\n",
      "Epoch: 188/5000, Train Loss: 0.2737\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4725\n",
      "Epoch: 189/5000, Train Loss: 0.2733\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4723\n",
      "Epoch: 190/5000, Train Loss: 0.2730\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4720\n",
      "Epoch: 191/5000, Train Loss: 0.2726\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4717\n",
      "Epoch: 192/5000, Train Loss: 0.2723\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4715\n",
      "Epoch: 193/5000, Train Loss: 0.2719\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4712\n",
      "Epoch: 194/5000, Train Loss: 0.2716\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4710\n",
      "Epoch: 195/5000, Train Loss: 0.2712\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4707\n",
      "Epoch: 196/5000, Train Loss: 0.2709\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4705\n",
      "Epoch: 197/5000, Train Loss: 0.2705\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4703\n",
      "Epoch: 198/5000, Train Loss: 0.2702\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4700\n",
      "Epoch: 199/5000, Train Loss: 0.2698\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4698\n",
      "Epoch: 200/5000, Train Loss: 0.2695\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4695\n",
      "Epoch: 201/5000, Train Loss: 0.2691\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4693\n",
      "Epoch: 202/5000, Train Loss: 0.2688\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4690\n",
      "Epoch: 203/5000, Train Loss: 0.2685\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4688\n",
      "Epoch: 204/5000, Train Loss: 0.2681\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4686\n",
      "Epoch: 205/5000, Train Loss: 0.2678\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4683\n",
      "Epoch: 206/5000, Train Loss: 0.2674\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4681\n",
      "Epoch: 207/5000, Train Loss: 0.2671\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4679\n",
      "Epoch: 208/5000, Train Loss: 0.2668\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4676\n",
      "Epoch: 209/5000, Train Loss: 0.2664\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4674\n",
      "Epoch: 210/5000, Train Loss: 0.2661\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4672\n",
      "Epoch: 211/5000, Train Loss: 0.2658\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4669\n",
      "Epoch: 212/5000, Train Loss: 0.2655\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4667\n",
      "Epoch: 213/5000, Train Loss: 0.2651\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4665\n",
      "Epoch: 214/5000, Train Loss: 0.2648\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4663\n",
      "Epoch: 215/5000, Train Loss: 0.2645\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4660\n",
      "Epoch: 216/5000, Train Loss: 0.2642\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4658\n",
      "Epoch: 217/5000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4656\n",
      "Epoch: 218/5000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4654\n",
      "Epoch: 219/5000, Train Loss: 0.2632\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4651\n",
      "Epoch: 220/5000, Train Loss: 0.2629\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4649\n",
      "Epoch: 221/5000, Train Loss: 0.2626\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4647\n",
      "Epoch: 222/5000, Train Loss: 0.2623\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4645\n",
      "Epoch: 223/5000, Train Loss: 0.2620\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4643\n",
      "Epoch: 224/5000, Train Loss: 0.2616\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4640\n",
      "Epoch: 225/5000, Train Loss: 0.2613\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4638\n",
      "Epoch: 226/5000, Train Loss: 0.2610\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4636\n",
      "Epoch: 227/5000, Train Loss: 0.2607\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4634\n",
      "Epoch: 228/5000, Train Loss: 0.2604\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4632\n",
      "Epoch: 229/5000, Train Loss: 0.2601\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4630\n",
      "Epoch: 230/5000, Train Loss: 0.2598\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4628\n",
      "Epoch: 231/5000, Train Loss: 0.2595\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4626\n",
      "Epoch: 232/5000, Train Loss: 0.2592\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4624\n",
      "Epoch: 233/5000, Train Loss: 0.2589\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4622\n",
      "Epoch: 234/5000, Train Loss: 0.2586\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4619\n",
      "Epoch: 235/5000, Train Loss: 0.2583\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4617\n",
      "Epoch: 236/5000, Train Loss: 0.2580\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4615\n",
      "Epoch: 237/5000, Train Loss: 0.2577\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4613\n",
      "Epoch: 238/5000, Train Loss: 0.2574\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4611\n",
      "Epoch: 239/5000, Train Loss: 0.2571\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4609\n",
      "Epoch: 240/5000, Train Loss: 0.2568\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4607\n",
      "Epoch: 241/5000, Train Loss: 0.2565\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4605\n",
      "Epoch: 242/5000, Train Loss: 0.2563\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4603\n",
      "Epoch: 243/5000, Train Loss: 0.2560\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4601\n",
      "Epoch: 244/5000, Train Loss: 0.2557\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4599\n",
      "Epoch: 245/5000, Train Loss: 0.2554\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4598\n",
      "Epoch: 246/5000, Train Loss: 0.2551\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4596\n",
      "Epoch: 247/5000, Train Loss: 0.2548\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4594\n",
      "Epoch: 248/5000, Train Loss: 0.2545\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4592\n",
      "Epoch: 249/5000, Train Loss: 0.2543\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4590\n",
      "Epoch: 250/5000, Train Loss: 0.2540\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4588\n",
      "Epoch: 251/5000, Train Loss: 0.2537\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4586\n",
      "Epoch: 252/5000, Train Loss: 0.2534\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4584\n",
      "Epoch: 253/5000, Train Loss: 0.2531\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4582\n",
      "Epoch: 254/5000, Train Loss: 0.2529\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4580\n",
      "Epoch: 255/5000, Train Loss: 0.2526\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4579\n",
      "Epoch: 256/5000, Train Loss: 0.2523\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4577\n",
      "Epoch: 257/5000, Train Loss: 0.2520\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4575\n",
      "Epoch: 258/5000, Train Loss: 0.2518\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4573\n",
      "Epoch: 259/5000, Train Loss: 0.2515\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4571\n",
      "Epoch: 260/5000, Train Loss: 0.2512\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4569\n",
      "Epoch: 261/5000, Train Loss: 0.2510\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4568\n",
      "Epoch: 262/5000, Train Loss: 0.2507\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4566\n",
      "Epoch: 263/5000, Train Loss: 0.2504\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4564\n",
      "Epoch: 264/5000, Train Loss: 0.2502\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4562\n",
      "Epoch: 265/5000, Train Loss: 0.2499\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4560\n",
      "Epoch: 266/5000, Train Loss: 0.2496\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4559\n",
      "Epoch: 267/5000, Train Loss: 0.2494\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4557\n",
      "Epoch: 268/5000, Train Loss: 0.2491\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4555\n",
      "Epoch: 269/5000, Train Loss: 0.2489\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4553\n",
      "Epoch: 270/5000, Train Loss: 0.2486\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4552\n",
      "Epoch: 271/5000, Train Loss: 0.2483\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4550\n",
      "Epoch: 272/5000, Train Loss: 0.2481\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4548\n",
      "Epoch: 273/5000, Train Loss: 0.2478\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4546\n",
      "Epoch: 274/5000, Train Loss: 0.2476\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4545\n",
      "Epoch: 275/5000, Train Loss: 0.2473\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4543\n",
      "Epoch: 276/5000, Train Loss: 0.2471\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4541\n",
      "Epoch: 277/5000, Train Loss: 0.2468\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4540\n",
      "Epoch: 278/5000, Train Loss: 0.2465\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4538\n",
      "Epoch: 279/5000, Train Loss: 0.2463\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4536\n",
      "Epoch: 280/5000, Train Loss: 0.2460\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4535\n",
      "Epoch: 281/5000, Train Loss: 0.2458\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4533\n",
      "Epoch: 282/5000, Train Loss: 0.2455\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4531\n",
      "Epoch: 283/5000, Train Loss: 0.2453\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4530\n",
      "Epoch: 284/5000, Train Loss: 0.2451\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4528\n",
      "Epoch: 285/5000, Train Loss: 0.2448\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4527\n",
      "Epoch: 286/5000, Train Loss: 0.2446\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4525\n",
      "Epoch: 287/5000, Train Loss: 0.2443\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4523\n",
      "Epoch: 288/5000, Train Loss: 0.2441\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4522\n",
      "Epoch: 289/5000, Train Loss: 0.2438\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4520\n",
      "Epoch: 290/5000, Train Loss: 0.2436\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4519\n",
      "Epoch: 291/5000, Train Loss: 0.2434\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4517\n",
      "Epoch: 292/5000, Train Loss: 0.2431\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4515\n",
      "Epoch: 293/5000, Train Loss: 0.2429\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4514\n",
      "Epoch: 294/5000, Train Loss: 0.2426\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4512\n",
      "Epoch: 295/5000, Train Loss: 0.2424\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4511\n",
      "Epoch: 296/5000, Train Loss: 0.2422\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4509\n",
      "Epoch: 297/5000, Train Loss: 0.2419\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4508\n",
      "Epoch: 298/5000, Train Loss: 0.2417\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4506\n",
      "Epoch: 299/5000, Train Loss: 0.2415\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4505\n",
      "Epoch: 300/5000, Train Loss: 0.2412\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4503\n",
      "Epoch: 301/5000, Train Loss: 0.2410\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4502\n",
      "Epoch: 302/5000, Train Loss: 0.2408\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4500\n",
      "Epoch: 303/5000, Train Loss: 0.2405\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4499\n",
      "Epoch: 304/5000, Train Loss: 0.2403\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4497\n",
      "Epoch: 305/5000, Train Loss: 0.2401\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4496\n",
      "Epoch: 306/5000, Train Loss: 0.2399\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4494\n",
      "Epoch: 307/5000, Train Loss: 0.2396\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4493\n",
      "Epoch: 308/5000, Train Loss: 0.2394\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4491\n",
      "Epoch: 309/5000, Train Loss: 0.2392\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4490\n",
      "Epoch: 310/5000, Train Loss: 0.2390\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 311/5000, Train Loss: 0.2387\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 312/5000, Train Loss: 0.2385\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 313/5000, Train Loss: 0.2383\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 314/5000, Train Loss: 0.2381\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4483\n",
      "Epoch: 315/5000, Train Loss: 0.2378\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4481\n",
      "Epoch: 316/5000, Train Loss: 0.2376\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4480\n",
      "Epoch: 317/5000, Train Loss: 0.2374\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4478\n",
      "Epoch: 318/5000, Train Loss: 0.2372\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4477\n",
      "Epoch: 319/5000, Train Loss: 0.2370\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4476\n",
      "Epoch: 320/5000, Train Loss: 0.2368\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4474\n",
      "Epoch: 321/5000, Train Loss: 0.2365\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4473\n",
      "Epoch: 322/5000, Train Loss: 0.2363\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4471\n",
      "Epoch: 323/5000, Train Loss: 0.2361\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4470\n",
      "Epoch: 324/5000, Train Loss: 0.2359\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4469\n",
      "Epoch: 325/5000, Train Loss: 0.2357\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4467\n",
      "Epoch: 326/5000, Train Loss: 0.2355\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4466\n",
      "Epoch: 327/5000, Train Loss: 0.2353\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4465\n",
      "Epoch: 328/5000, Train Loss: 0.2351\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4463\n",
      "Epoch: 329/5000, Train Loss: 0.2348\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4462\n",
      "Epoch: 330/5000, Train Loss: 0.2346\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4461\n",
      "Epoch: 331/5000, Train Loss: 0.2344\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4459\n",
      "Epoch: 332/5000, Train Loss: 0.2342\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4458\n",
      "Epoch: 333/5000, Train Loss: 0.2340\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4457\n",
      "Epoch: 334/5000, Train Loss: 0.2338\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4455\n",
      "Epoch: 335/5000, Train Loss: 0.2336\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4454\n",
      "Epoch: 336/5000, Train Loss: 0.2334\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4453\n",
      "Epoch: 337/5000, Train Loss: 0.2332\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4452\n",
      "Epoch: 338/5000, Train Loss: 0.2330\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4450\n",
      "Epoch: 339/5000, Train Loss: 0.2328\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4449\n",
      "Epoch: 340/5000, Train Loss: 0.2326\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4448\n",
      "Epoch: 341/5000, Train Loss: 0.2324\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4447\n",
      "Epoch: 342/5000, Train Loss: 0.2322\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4445\n",
      "Epoch: 343/5000, Train Loss: 0.2320\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4444\n",
      "Epoch: 344/5000, Train Loss: 0.2318\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4443\n",
      "Epoch: 345/5000, Train Loss: 0.2316\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4442\n",
      "Epoch: 346/5000, Train Loss: 0.2314\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4440\n",
      "Epoch: 347/5000, Train Loss: 0.2312\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4439\n",
      "Epoch: 348/5000, Train Loss: 0.2310\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4438\n",
      "Epoch: 349/5000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4437\n",
      "Epoch: 350/5000, Train Loss: 0.2306\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4435\n",
      "Epoch: 351/5000, Train Loss: 0.2304\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4434\n",
      "Epoch: 352/5000, Train Loss: 0.2302\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4433\n",
      "Epoch: 353/5000, Train Loss: 0.2300\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4432\n",
      "Epoch: 354/5000, Train Loss: 0.2298\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4431\n",
      "Epoch: 355/5000, Train Loss: 0.2296\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4429\n",
      "Epoch: 356/5000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4428\n",
      "Epoch: 357/5000, Train Loss: 0.2292\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4427\n",
      "Epoch: 358/5000, Train Loss: 0.2291\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4426\n",
      "Epoch: 359/5000, Train Loss: 0.2289\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4425\n",
      "Epoch: 360/5000, Train Loss: 0.2287\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4424\n",
      "Epoch: 361/5000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4422\n",
      "Epoch: 362/5000, Train Loss: 0.2283\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4421\n",
      "Epoch: 363/5000, Train Loss: 0.2281\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4420\n",
      "Epoch: 364/5000, Train Loss: 0.2279\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4419\n",
      "Epoch: 365/5000, Train Loss: 0.2277\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4418\n",
      "Epoch: 366/5000, Train Loss: 0.2276\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4417\n",
      "Epoch: 367/5000, Train Loss: 0.2274\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4416\n",
      "Epoch: 368/5000, Train Loss: 0.2272\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4414\n",
      "Epoch: 369/5000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4413\n",
      "Epoch: 370/5000, Train Loss: 0.2268\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4412\n",
      "Epoch: 371/5000, Train Loss: 0.2266\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4411\n",
      "Epoch: 372/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4410\n",
      "Epoch: 373/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4409\n",
      "Epoch: 374/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4408\n",
      "Epoch: 375/5000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4407\n",
      "Epoch: 376/5000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4406\n",
      "Epoch: 377/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4405\n",
      "Epoch: 378/5000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4403\n",
      "Epoch: 379/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4402\n",
      "Epoch: 380/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4401\n",
      "Epoch: 381/5000, Train Loss: 0.2249\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4400\n",
      "Epoch: 382/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4399\n",
      "Epoch: 383/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4398\n",
      "Epoch: 384/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4397\n",
      "Epoch: 385/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4396\n",
      "Epoch: 386/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4395\n",
      "Epoch: 387/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4394\n",
      "Epoch: 388/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4393\n",
      "Epoch: 389/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4392\n",
      "Epoch: 390/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4391\n",
      "Epoch: 391/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4390\n",
      "Epoch: 392/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4389\n",
      "Epoch: 393/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4388\n",
      "Epoch: 394/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4387\n",
      "Epoch: 395/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4386\n",
      "Epoch: 396/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4385\n",
      "Epoch: 397/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4384\n",
      "Epoch: 398/5000, Train Loss: 0.2219\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4383\n",
      "Epoch: 399/5000, Train Loss: 0.2218\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4382\n",
      "Epoch: 400/5000, Train Loss: 0.2216\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4381\n",
      "Epoch: 401/5000, Train Loss: 0.2214\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4380\n",
      "Epoch: 402/5000, Train Loss: 0.2213\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4379\n",
      "Epoch: 403/5000, Train Loss: 0.2211\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4378\n",
      "Epoch: 404/5000, Train Loss: 0.2209\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4377\n",
      "Epoch: 405/5000, Train Loss: 0.2208\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4376\n",
      "Epoch: 406/5000, Train Loss: 0.2206\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4375\n",
      "Epoch: 407/5000, Train Loss: 0.2205\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4374\n",
      "Epoch: 408/5000, Train Loss: 0.2203\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4373\n",
      "Epoch: 409/5000, Train Loss: 0.2201\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4372\n",
      "Epoch: 410/5000, Train Loss: 0.2200\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4371\n",
      "Epoch: 411/5000, Train Loss: 0.2198\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4370\n",
      "Epoch: 412/5000, Train Loss: 0.2196\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4369\n",
      "Epoch: 413/5000, Train Loss: 0.2195\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4368\n",
      "Epoch: 414/5000, Train Loss: 0.2193\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4368\n",
      "Epoch: 415/5000, Train Loss: 0.2192\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4367\n",
      "Epoch: 416/5000, Train Loss: 0.2190\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4366\n",
      "Epoch: 417/5000, Train Loss: 0.2189\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4365\n",
      "Epoch: 418/5000, Train Loss: 0.2187\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4364\n",
      "Epoch: 419/5000, Train Loss: 0.2185\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4363\n",
      "Epoch: 420/5000, Train Loss: 0.2184\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4362\n",
      "Epoch: 421/5000, Train Loss: 0.2182\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 422/5000, Train Loss: 0.2181\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 423/5000, Train Loss: 0.2179\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 424/5000, Train Loss: 0.2178\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 425/5000, Train Loss: 0.2176\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 426/5000, Train Loss: 0.2175\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 427/5000, Train Loss: 0.2173\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 428/5000, Train Loss: 0.2172\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 429/5000, Train Loss: 0.2170\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 430/5000, Train Loss: 0.2168\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 431/5000, Train Loss: 0.2167\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 432/5000, Train Loss: 0.2165\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 433/5000, Train Loss: 0.2164\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 434/5000, Train Loss: 0.2162\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 435/5000, Train Loss: 0.2161\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 436/5000, Train Loss: 0.2159\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 437/5000, Train Loss: 0.2158\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 438/5000, Train Loss: 0.2156\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 439/5000, Train Loss: 0.2155\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 440/5000, Train Loss: 0.2154\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 441/5000, Train Loss: 0.2152\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 442/5000, Train Loss: 0.2151\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 443/5000, Train Loss: 0.2149\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 444/5000, Train Loss: 0.2148\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 445/5000, Train Loss: 0.2146\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 446/5000, Train Loss: 0.2145\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 447/5000, Train Loss: 0.2143\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 448/5000, Train Loss: 0.2142\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 449/5000, Train Loss: 0.2140\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 450/5000, Train Loss: 0.2139\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 451/5000, Train Loss: 0.2138\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 452/5000, Train Loss: 0.2136\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 453/5000, Train Loss: 0.2135\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 454/5000, Train Loss: 0.2133\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 455/5000, Train Loss: 0.2132\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 456/5000, Train Loss: 0.2131\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 457/5000, Train Loss: 0.2129\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 458/5000, Train Loss: 0.2128\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 459/5000, Train Loss: 0.2126\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 460/5000, Train Loss: 0.2125\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 461/5000, Train Loss: 0.2124\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 462/5000, Train Loss: 0.2122\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 463/5000, Train Loss: 0.2121\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 464/5000, Train Loss: 0.2119\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 465/5000, Train Loss: 0.2118\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 466/5000, Train Loss: 0.2117\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 467/5000, Train Loss: 0.2115\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 468/5000, Train Loss: 0.2114\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 469/5000, Train Loss: 0.2113\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 470/5000, Train Loss: 0.2111\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 471/5000, Train Loss: 0.2110\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 472/5000, Train Loss: 0.2109\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 473/5000, Train Loss: 0.2107\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 474/5000, Train Loss: 0.2106\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 475/5000, Train Loss: 0.2105\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 476/5000, Train Loss: 0.2103\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 477/5000, Train Loss: 0.2102\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 478/5000, Train Loss: 0.2101\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 479/5000, Train Loss: 0.2099\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 480/5000, Train Loss: 0.2098\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 481/5000, Train Loss: 0.2097\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 482/5000, Train Loss: 0.2095\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 483/5000, Train Loss: 0.2094\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 484/5000, Train Loss: 0.2093\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 485/5000, Train Loss: 0.2091\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 486/5000, Train Loss: 0.2090\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 487/5000, Train Loss: 0.2089\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 488/5000, Train Loss: 0.2088\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 489/5000, Train Loss: 0.2086\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 490/5000, Train Loss: 0.2085\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 491/5000, Train Loss: 0.2084\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 492/5000, Train Loss: 0.2082\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 493/5000, Train Loss: 0.2081\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 494/5000, Train Loss: 0.2080\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 495/5000, Train Loss: 0.2079\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 496/5000, Train Loss: 0.2077\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 497/5000, Train Loss: 0.2076\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 498/5000, Train Loss: 0.2075\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 499/5000, Train Loss: 0.2074\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 500/5000, Train Loss: 0.2072\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 501/5000, Train Loss: 0.2071\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 502/5000, Train Loss: 0.2070\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 503/5000, Train Loss: 0.2069\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 504/5000, Train Loss: 0.2067\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 505/5000, Train Loss: 0.2066\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 506/5000, Train Loss: 0.2065\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 507/5000, Train Loss: 0.2064\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 508/5000, Train Loss: 0.2063\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 509/5000, Train Loss: 0.2061\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 510/5000, Train Loss: 0.2060\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 511/5000, Train Loss: 0.2059\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 512/5000, Train Loss: 0.2058\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 513/5000, Train Loss: 0.2057\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 514/5000, Train Loss: 0.2055\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 515/5000, Train Loss: 0.2054\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 516/5000, Train Loss: 0.2053\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 517/5000, Train Loss: 0.2052\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 518/5000, Train Loss: 0.2051\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 519/5000, Train Loss: 0.2049\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 520/5000, Train Loss: 0.2048\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 521/5000, Train Loss: 0.2047\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 522/5000, Train Loss: 0.2046\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 523/5000, Train Loss: 0.2045\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 524/5000, Train Loss: 0.2044\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 525/5000, Train Loss: 0.2042\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 526/5000, Train Loss: 0.2041\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 527/5000, Train Loss: 0.2040\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 528/5000, Train Loss: 0.2039\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 529/5000, Train Loss: 0.2038\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 530/5000, Train Loss: 0.2037\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 531/5000, Train Loss: 0.2035\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 532/5000, Train Loss: 0.2034\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 533/5000, Train Loss: 0.2033\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 534/5000, Train Loss: 0.2032\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 535/5000, Train Loss: 0.2031\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 536/5000, Train Loss: 0.2030\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 537/5000, Train Loss: 0.2029\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 538/5000, Train Loss: 0.2027\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 539/5000, Train Loss: 0.2026\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 540/5000, Train Loss: 0.2025\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 541/5000, Train Loss: 0.2024\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 542/5000, Train Loss: 0.2023\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 543/5000, Train Loss: 0.2022\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 544/5000, Train Loss: 0.2021\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 545/5000, Train Loss: 0.2020\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 546/5000, Train Loss: 0.2019\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 547/5000, Train Loss: 0.2017\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 548/5000, Train Loss: 0.2016\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 549/5000, Train Loss: 0.2015\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 550/5000, Train Loss: 0.2014\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 551/5000, Train Loss: 0.2013\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 552/5000, Train Loss: 0.2012\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 553/5000, Train Loss: 0.2011\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 554/5000, Train Loss: 0.2010\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 555/5000, Train Loss: 0.2009\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 556/5000, Train Loss: 0.2008\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 557/5000, Train Loss: 0.2007\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 558/5000, Train Loss: 0.2006\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 559/5000, Train Loss: 0.2004\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 560/5000, Train Loss: 0.2003\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 561/5000, Train Loss: 0.2002\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 562/5000, Train Loss: 0.2001\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 563/5000, Train Loss: 0.2000\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 564/5000, Train Loss: 0.1999\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 565/5000, Train Loss: 0.1998\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 566/5000, Train Loss: 0.1997\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 567/5000, Train Loss: 0.1996\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 568/5000, Train Loss: 0.1995\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 569/5000, Train Loss: 0.1994\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 570/5000, Train Loss: 0.1993\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 571/5000, Train Loss: 0.1992\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 572/5000, Train Loss: 0.1991\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 573/5000, Train Loss: 0.1990\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 574/5000, Train Loss: 0.1989\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 575/5000, Train Loss: 0.1988\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 576/5000, Train Loss: 0.1987\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 577/5000, Train Loss: 0.1986\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 578/5000, Train Loss: 0.1985\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 579/5000, Train Loss: 0.1984\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 580/5000, Train Loss: 0.1983\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 581/5000, Train Loss: 0.1982\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 582/5000, Train Loss: 0.1981\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 583/5000, Train Loss: 0.1980\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 584/5000, Train Loss: 0.1979\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 585/5000, Train Loss: 0.1978\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 586/5000, Train Loss: 0.1977\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 587/5000, Train Loss: 0.1976\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 588/5000, Train Loss: 0.1975\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 589/5000, Train Loss: 0.1974\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 590/5000, Train Loss: 0.1973\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 591/5000, Train Loss: 0.1972\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 592/5000, Train Loss: 0.1971\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 593/5000, Train Loss: 0.1970\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 594/5000, Train Loss: 0.1969\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 595/5000, Train Loss: 0.1968\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 596/5000, Train Loss: 0.1967\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 597/5000, Train Loss: 0.1966\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 598/5000, Train Loss: 0.1965\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 599/5000, Train Loss: 0.1964\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 600/5000, Train Loss: 0.1963\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 601/5000, Train Loss: 0.1962\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 602/5000, Train Loss: 0.1961\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 603/5000, Train Loss: 0.1960\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 604/5000, Train Loss: 0.1959\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 605/5000, Train Loss: 0.1958\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 606/5000, Train Loss: 0.1957\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 607/5000, Train Loss: 0.1956\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 608/5000, Train Loss: 0.1955\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 609/5000, Train Loss: 0.1954\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 610/5000, Train Loss: 0.1953\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 611/5000, Train Loss: 0.1952\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 612/5000, Train Loss: 0.1951\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 613/5000, Train Loss: 0.1950\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 614/5000, Train Loss: 0.1950\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 615/5000, Train Loss: 0.1949\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 616/5000, Train Loss: 0.1948\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 617/5000, Train Loss: 0.1947\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 618/5000, Train Loss: 0.1946\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 619/5000, Train Loss: 0.1945\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 620/5000, Train Loss: 0.1944\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 621/5000, Train Loss: 0.1943\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 622/5000, Train Loss: 0.1942\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 623/5000, Train Loss: 0.1941\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 624/5000, Train Loss: 0.1940\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 625/5000, Train Loss: 0.1939\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 626/5000, Train Loss: 0.1938\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 627/5000, Train Loss: 0.1938\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 628/5000, Train Loss: 0.1937\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 629/5000, Train Loss: 0.1936\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 630/5000, Train Loss: 0.1935\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 631/5000, Train Loss: 0.1934\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 632/5000, Train Loss: 0.1933\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 633/5000, Train Loss: 0.1932\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 634/5000, Train Loss: 0.1931\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 635/5000, Train Loss: 0.1930\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 636/5000, Train Loss: 0.1929\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 637/5000, Train Loss: 0.1929\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 638/5000, Train Loss: 0.1928\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 639/5000, Train Loss: 0.1927\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 640/5000, Train Loss: 0.1926\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 641/5000, Train Loss: 0.1925\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 642/5000, Train Loss: 0.1924\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 643/5000, Train Loss: 0.1923\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 644/5000, Train Loss: 0.1922\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 645/5000, Train Loss: 0.1922\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 646/5000, Train Loss: 0.1921\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 647/5000, Train Loss: 0.1920\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 648/5000, Train Loss: 0.1919\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 649/5000, Train Loss: 0.1918\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 650/5000, Train Loss: 0.1917\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 651/5000, Train Loss: 0.1916\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 652/5000, Train Loss: 0.1915\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 653/5000, Train Loss: 0.1915\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 654/5000, Train Loss: 0.1914\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 655/5000, Train Loss: 0.1913\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 656/5000, Train Loss: 0.1912\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 657/5000, Train Loss: 0.1911\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 658/5000, Train Loss: 0.1910\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 659/5000, Train Loss: 0.1910\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 660/5000, Train Loss: 0.1909\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 661/5000, Train Loss: 0.1908\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 662/5000, Train Loss: 0.1907\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 663/5000, Train Loss: 0.1906\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 664/5000, Train Loss: 0.1905\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 665/5000, Train Loss: 0.1904\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 666/5000, Train Loss: 0.1904\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 667/5000, Train Loss: 0.1903\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 668/5000, Train Loss: 0.1902\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 669/5000, Train Loss: 0.1901\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 670/5000, Train Loss: 0.1900\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 671/5000, Train Loss: 0.1899\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 672/5000, Train Loss: 0.1899\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 673/5000, Train Loss: 0.1898\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 674/5000, Train Loss: 0.1897\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 675/5000, Train Loss: 0.1896\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 676/5000, Train Loss: 0.1895\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 677/5000, Train Loss: 0.1895\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 678/5000, Train Loss: 0.1894\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 679/5000, Train Loss: 0.1893\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 680/5000, Train Loss: 0.1892\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 681/5000, Train Loss: 0.1891\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 682/5000, Train Loss: 0.1891\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 683/5000, Train Loss: 0.1890\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 684/5000, Train Loss: 0.1889\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 685/5000, Train Loss: 0.1888\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 686/5000, Train Loss: 0.1887\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 687/5000, Train Loss: 0.1887\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 688/5000, Train Loss: 0.1886\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 689/5000, Train Loss: 0.1885\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 690/5000, Train Loss: 0.1884\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 691/5000, Train Loss: 0.1883\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 692/5000, Train Loss: 0.1883\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 693/5000, Train Loss: 0.1882\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 694/5000, Train Loss: 0.1881\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 695/5000, Train Loss: 0.1880\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 696/5000, Train Loss: 0.1879\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 697/5000, Train Loss: 0.1879\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 698/5000, Train Loss: 0.1878\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 699/5000, Train Loss: 0.1877\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 700/5000, Train Loss: 0.1876\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 701/5000, Train Loss: 0.1876\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 702/5000, Train Loss: 0.1875\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 703/5000, Train Loss: 0.1874\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 704/5000, Train Loss: 0.1873\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 705/5000, Train Loss: 0.1872\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 706/5000, Train Loss: 0.1872\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 707/5000, Train Loss: 0.1871\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 708/5000, Train Loss: 0.1870\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 709/5000, Train Loss: 0.1869\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 710/5000, Train Loss: 0.1869\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 711/5000, Train Loss: 0.1868\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 712/5000, Train Loss: 0.1867\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 713/5000, Train Loss: 0.1866\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 714/5000, Train Loss: 0.1866\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 715/5000, Train Loss: 0.1865\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 716/5000, Train Loss: 0.1864\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 717/5000, Train Loss: 0.1863\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 718/5000, Train Loss: 0.1863\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 719/5000, Train Loss: 0.1862\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 720/5000, Train Loss: 0.1861\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 721/5000, Train Loss: 0.1860\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 722/5000, Train Loss: 0.1860\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 723/5000, Train Loss: 0.1859\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 724/5000, Train Loss: 0.1858\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 725/5000, Train Loss: 0.1857\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 726/5000, Train Loss: 0.1857\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 727/5000, Train Loss: 0.1856\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 728/5000, Train Loss: 0.1855\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 729/5000, Train Loss: 0.1855\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 730/5000, Train Loss: 0.1854\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 731/5000, Train Loss: 0.1853\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 732/5000, Train Loss: 0.1852\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 733/5000, Train Loss: 0.1852\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 734/5000, Train Loss: 0.1851\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 735/5000, Train Loss: 0.1850\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 736/5000, Train Loss: 0.1849\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 737/5000, Train Loss: 0.1849\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 738/5000, Train Loss: 0.1848\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 739/5000, Train Loss: 0.1847\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 740/5000, Train Loss: 0.1847\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 741/5000, Train Loss: 0.1846\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 742/5000, Train Loss: 0.1845\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 743/5000, Train Loss: 0.1844\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 744/5000, Train Loss: 0.1844\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 745/5000, Train Loss: 0.1843\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 746/5000, Train Loss: 0.1842\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 747/5000, Train Loss: 0.1842\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 748/5000, Train Loss: 0.1841\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 749/5000, Train Loss: 0.1840\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 750/5000, Train Loss: 0.1839\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 751/5000, Train Loss: 0.1839\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 752/5000, Train Loss: 0.1838\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 753/5000, Train Loss: 0.1837\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 754/5000, Train Loss: 0.1837\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 755/5000, Train Loss: 0.1836\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 756/5000, Train Loss: 0.1835\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 757/5000, Train Loss: 0.1835\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 758/5000, Train Loss: 0.1834\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 759/5000, Train Loss: 0.1833\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 760/5000, Train Loss: 0.1833\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 761/5000, Train Loss: 0.1832\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 762/5000, Train Loss: 0.1831\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 763/5000, Train Loss: 0.1831\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 764/5000, Train Loss: 0.1830\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 765/5000, Train Loss: 0.1829\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 766/5000, Train Loss: 0.1828\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 767/5000, Train Loss: 0.1828\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 768/5000, Train Loss: 0.1827\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 769/5000, Train Loss: 0.1826\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 770/5000, Train Loss: 0.1826\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 771/5000, Train Loss: 0.1825\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 772/5000, Train Loss: 0.1824\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 773/5000, Train Loss: 0.1824\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 774/5000, Train Loss: 0.1823\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 775/5000, Train Loss: 0.1822\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 776/5000, Train Loss: 0.1822\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 777/5000, Train Loss: 0.1821\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 778/5000, Train Loss: 0.1820\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 779/5000, Train Loss: 0.1820\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 780/5000, Train Loss: 0.1819\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 781/5000, Train Loss: 0.1818\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 782/5000, Train Loss: 0.1818\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 783/5000, Train Loss: 0.1817\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 784/5000, Train Loss: 0.1816\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 785/5000, Train Loss: 0.1816\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 786/5000, Train Loss: 0.1815\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 787/5000, Train Loss: 0.1814\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 788/5000, Train Loss: 0.1814\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 789/5000, Train Loss: 0.1813\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 790/5000, Train Loss: 0.1813\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 791/5000, Train Loss: 0.1812\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 792/5000, Train Loss: 0.1811\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 793/5000, Train Loss: 0.1811\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 794/5000, Train Loss: 0.1810\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 795/5000, Train Loss: 0.1809\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 796/5000, Train Loss: 0.1809\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 797/5000, Train Loss: 0.1808\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 798/5000, Train Loss: 0.1807\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 799/5000, Train Loss: 0.1807\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 800/5000, Train Loss: 0.1806\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 801/5000, Train Loss: 0.1805\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 802/5000, Train Loss: 0.1805\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 803/5000, Train Loss: 0.1804\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 804/5000, Train Loss: 0.1804\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 805/5000, Train Loss: 0.1803\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 806/5000, Train Loss: 0.1802\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 807/5000, Train Loss: 0.1802\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 808/5000, Train Loss: 0.1801\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 809/5000, Train Loss: 0.1800\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 810/5000, Train Loss: 0.1800\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 811/5000, Train Loss: 0.1799\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 812/5000, Train Loss: 0.1799\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 813/5000, Train Loss: 0.1798\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 814/5000, Train Loss: 0.1797\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 815/5000, Train Loss: 0.1797\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 816/5000, Train Loss: 0.1796\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 817/5000, Train Loss: 0.1795\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 818/5000, Train Loss: 0.1795\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 819/5000, Train Loss: 0.1794\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 820/5000, Train Loss: 0.1794\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 821/5000, Train Loss: 0.1793\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 822/5000, Train Loss: 0.1792\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 823/5000, Train Loss: 0.1792\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 824/5000, Train Loss: 0.1791\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 825/5000, Train Loss: 0.1791\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 826/5000, Train Loss: 0.1790\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 827/5000, Train Loss: 0.1789\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 828/5000, Train Loss: 0.1789\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 829/5000, Train Loss: 0.1788\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 830/5000, Train Loss: 0.1788\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 831/5000, Train Loss: 0.1787\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 832/5000, Train Loss: 0.1786\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 833/5000, Train Loss: 0.1786\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 834/5000, Train Loss: 0.1785\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 835/5000, Train Loss: 0.1785\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 836/5000, Train Loss: 0.1784\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 837/5000, Train Loss: 0.1783\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 838/5000, Train Loss: 0.1783\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 839/5000, Train Loss: 0.1782\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 840/5000, Train Loss: 0.1782\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 841/5000, Train Loss: 0.1781\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 842/5000, Train Loss: 0.1780\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 843/5000, Train Loss: 0.1780\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 844/5000, Train Loss: 0.1779\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 845/5000, Train Loss: 0.1779\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 846/5000, Train Loss: 0.1778\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 847/5000, Train Loss: 0.1777\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 848/5000, Train Loss: 0.1777\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 849/5000, Train Loss: 0.1776\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 850/5000, Train Loss: 0.1776\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 851/5000, Train Loss: 0.1775\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 852/5000, Train Loss: 0.1775\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 853/5000, Train Loss: 0.1774\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 854/5000, Train Loss: 0.1773\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 855/5000, Train Loss: 0.1773\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 856/5000, Train Loss: 0.1772\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 857/5000, Train Loss: 0.1772\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 858/5000, Train Loss: 0.1771\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 859/5000, Train Loss: 0.1770\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 860/5000, Train Loss: 0.1770\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 861/5000, Train Loss: 0.1769\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 862/5000, Train Loss: 0.1769\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 863/5000, Train Loss: 0.1768\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 864/5000, Train Loss: 0.1768\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 865/5000, Train Loss: 0.1767\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 866/5000, Train Loss: 0.1767\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 867/5000, Train Loss: 0.1766\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 868/5000, Train Loss: 0.1765\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 869/5000, Train Loss: 0.1765\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 870/5000, Train Loss: 0.1764\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 871/5000, Train Loss: 0.1764\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 872/5000, Train Loss: 0.1763\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 873/5000, Train Loss: 0.1763\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 874/5000, Train Loss: 0.1762\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 875/5000, Train Loss: 0.1761\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 876/5000, Train Loss: 0.1761\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 877/5000, Train Loss: 0.1760\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 878/5000, Train Loss: 0.1760\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 879/5000, Train Loss: 0.1759\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 880/5000, Train Loss: 0.1759\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 881/5000, Train Loss: 0.1758\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 882/5000, Train Loss: 0.1758\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 883/5000, Train Loss: 0.1757\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 884/5000, Train Loss: 0.1756\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 885/5000, Train Loss: 0.1756\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 886/5000, Train Loss: 0.1755\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 887/5000, Train Loss: 0.1755\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 888/5000, Train Loss: 0.1754\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 889/5000, Train Loss: 0.1754\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 890/5000, Train Loss: 0.1753\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 891/5000, Train Loss: 0.1753\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 892/5000, Train Loss: 0.1752\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 893/5000, Train Loss: 0.1752\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 894/5000, Train Loss: 0.1751\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 895/5000, Train Loss: 0.1750\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 896/5000, Train Loss: 0.1750\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 897/5000, Train Loss: 0.1749\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 898/5000, Train Loss: 0.1749\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 899/5000, Train Loss: 0.1748\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 900/5000, Train Loss: 0.1748\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 901/5000, Train Loss: 0.1747\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 902/5000, Train Loss: 0.1747\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 903/5000, Train Loss: 0.1746\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 904/5000, Train Loss: 0.1746\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 905/5000, Train Loss: 0.1745\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 906/5000, Train Loss: 0.1745\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 907/5000, Train Loss: 0.1744\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 908/5000, Train Loss: 0.1744\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 909/5000, Train Loss: 0.1743\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 910/5000, Train Loss: 0.1743\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 911/5000, Train Loss: 0.1742\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 912/5000, Train Loss: 0.1741\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 913/5000, Train Loss: 0.1741\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 914/5000, Train Loss: 0.1740\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 915/5000, Train Loss: 0.1740\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 916/5000, Train Loss: 0.1739\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 917/5000, Train Loss: 0.1739\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 918/5000, Train Loss: 0.1738\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 919/5000, Train Loss: 0.1738\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 920/5000, Train Loss: 0.1737\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 921/5000, Train Loss: 0.1737\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 922/5000, Train Loss: 0.1736\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 923/5000, Train Loss: 0.1736\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 924/5000, Train Loss: 0.1735\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 925/5000, Train Loss: 0.1735\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 926/5000, Train Loss: 0.1734\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 927/5000, Train Loss: 0.1734\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 928/5000, Train Loss: 0.1733\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 929/5000, Train Loss: 0.1733\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 930/5000, Train Loss: 0.1732\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 931/5000, Train Loss: 0.1732\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 932/5000, Train Loss: 0.1731\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 933/5000, Train Loss: 0.1731\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 934/5000, Train Loss: 0.1730\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 935/5000, Train Loss: 0.1730\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 936/5000, Train Loss: 0.1729\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 937/5000, Train Loss: 0.1729\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 938/5000, Train Loss: 0.1728\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 939/5000, Train Loss: 0.1728\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 940/5000, Train Loss: 0.1727\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 941/5000, Train Loss: 0.1727\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 942/5000, Train Loss: 0.1726\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 943/5000, Train Loss: 0.1726\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 944/5000, Train Loss: 0.1725\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 945/5000, Train Loss: 0.1725\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 946/5000, Train Loss: 0.1724\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 947/5000, Train Loss: 0.1724\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 948/5000, Train Loss: 0.1723\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 949/5000, Train Loss: 0.1723\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 950/5000, Train Loss: 0.1722\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 951/5000, Train Loss: 0.1722\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 952/5000, Train Loss: 0.1721\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 953/5000, Train Loss: 0.1721\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 954/5000, Train Loss: 0.1720\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 955/5000, Train Loss: 0.1720\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 956/5000, Train Loss: 0.1719\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 957/5000, Train Loss: 0.1719\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 958/5000, Train Loss: 0.1718\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 959/5000, Train Loss: 0.1718\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 960/5000, Train Loss: 0.1717\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 961/5000, Train Loss: 0.1717\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 962/5000, Train Loss: 0.1716\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 963/5000, Train Loss: 0.1716\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 964/5000, Train Loss: 0.1715\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 965/5000, Train Loss: 0.1715\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 966/5000, Train Loss: 0.1714\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 967/5000, Train Loss: 0.1714\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 968/5000, Train Loss: 0.1713\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 969/5000, Train Loss: 0.1713\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 970/5000, Train Loss: 0.1712\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 971/5000, Train Loss: 0.1712\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 972/5000, Train Loss: 0.1712\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 973/5000, Train Loss: 0.1711\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 974/5000, Train Loss: 0.1711\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 975/5000, Train Loss: 0.1710\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 976/5000, Train Loss: 0.1710\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 977/5000, Train Loss: 0.1709\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 978/5000, Train Loss: 0.1709\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 979/5000, Train Loss: 0.1708\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 980/5000, Train Loss: 0.1708\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 981/5000, Train Loss: 0.1707\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 982/5000, Train Loss: 0.1707\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 983/5000, Train Loss: 0.1706\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 984/5000, Train Loss: 0.1706\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 985/5000, Train Loss: 0.1705\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 986/5000, Train Loss: 0.1705\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 987/5000, Train Loss: 0.1704\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 988/5000, Train Loss: 0.1704\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 989/5000, Train Loss: 0.1704\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 990/5000, Train Loss: 0.1703\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 991/5000, Train Loss: 0.1703\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 992/5000, Train Loss: 0.1702\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 993/5000, Train Loss: 0.1702\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 994/5000, Train Loss: 0.1701\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 995/5000, Train Loss: 0.1701\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 996/5000, Train Loss: 0.1700\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 997/5000, Train Loss: 0.1700\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 998/5000, Train Loss: 0.1699\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 999/5000, Train Loss: 0.1699\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1000/5000, Train Loss: 0.1699\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1001/5000, Train Loss: 0.1698\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1002/5000, Train Loss: 0.1698\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1003/5000, Train Loss: 0.1697\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1004/5000, Train Loss: 0.1697\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1005/5000, Train Loss: 0.1696\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1006/5000, Train Loss: 0.1696\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1007/5000, Train Loss: 0.1695\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1008/5000, Train Loss: 0.1695\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1009/5000, Train Loss: 0.1694\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1010/5000, Train Loss: 0.1694\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1011/5000, Train Loss: 0.1694\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1012/5000, Train Loss: 0.1693\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1013/5000, Train Loss: 0.1693\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1014/5000, Train Loss: 0.1692\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1015/5000, Train Loss: 0.1692\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1016/5000, Train Loss: 0.1691\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1017/5000, Train Loss: 0.1691\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1018/5000, Train Loss: 0.1690\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1019/5000, Train Loss: 0.1690\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1020/5000, Train Loss: 0.1690\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1021/5000, Train Loss: 0.1689\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1022/5000, Train Loss: 0.1689\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1023/5000, Train Loss: 0.1688\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1024/5000, Train Loss: 0.1688\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1025/5000, Train Loss: 0.1687\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1026/5000, Train Loss: 0.1687\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1027/5000, Train Loss: 0.1686\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1028/5000, Train Loss: 0.1686\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1029/5000, Train Loss: 0.1686\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1030/5000, Train Loss: 0.1685\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1031/5000, Train Loss: 0.1685\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1032/5000, Train Loss: 0.1684\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1033/5000, Train Loss: 0.1684\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1034/5000, Train Loss: 0.1683\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1035/5000, Train Loss: 0.1683\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1036/5000, Train Loss: 0.1683\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1037/5000, Train Loss: 0.1682\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1038/5000, Train Loss: 0.1682\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1039/5000, Train Loss: 0.1681\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1040/5000, Train Loss: 0.1681\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1041/5000, Train Loss: 0.1680\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1042/5000, Train Loss: 0.1680\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1043/5000, Train Loss: 0.1680\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1044/5000, Train Loss: 0.1679\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1045/5000, Train Loss: 0.1679\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1046/5000, Train Loss: 0.1678\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1047/5000, Train Loss: 0.1678\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1048/5000, Train Loss: 0.1677\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1049/5000, Train Loss: 0.1677\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1050/5000, Train Loss: 0.1677\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1051/5000, Train Loss: 0.1676\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1052/5000, Train Loss: 0.1676\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1053/5000, Train Loss: 0.1675\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1054/5000, Train Loss: 0.1675\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1055/5000, Train Loss: 0.1674\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1056/5000, Train Loss: 0.1674\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1057/5000, Train Loss: 0.1674\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1058/5000, Train Loss: 0.1673\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1059/5000, Train Loss: 0.1673\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1060/5000, Train Loss: 0.1672\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1061/5000, Train Loss: 0.1672\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1062/5000, Train Loss: 0.1672\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1063/5000, Train Loss: 0.1671\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1064/5000, Train Loss: 0.1671\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1065/5000, Train Loss: 0.1670\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1066/5000, Train Loss: 0.1670\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1067/5000, Train Loss: 0.1669\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1068/5000, Train Loss: 0.1669\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1069/5000, Train Loss: 0.1669\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1070/5000, Train Loss: 0.1668\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1071/5000, Train Loss: 0.1668\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1072/5000, Train Loss: 0.1667\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1073/5000, Train Loss: 0.1667\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1074/5000, Train Loss: 0.1667\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1075/5000, Train Loss: 0.1666\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1076/5000, Train Loss: 0.1666\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1077/5000, Train Loss: 0.1665\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1078/5000, Train Loss: 0.1665\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1079/5000, Train Loss: 0.1665\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1080/5000, Train Loss: 0.1664\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1081/5000, Train Loss: 0.1664\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1082/5000, Train Loss: 0.1663\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1083/5000, Train Loss: 0.1663\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1084/5000, Train Loss: 0.1663\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1085/5000, Train Loss: 0.1662\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1086/5000, Train Loss: 0.1662\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1087/5000, Train Loss: 0.1661\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1088/5000, Train Loss: 0.1661\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1089/5000, Train Loss: 0.1660\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1090/5000, Train Loss: 0.1660\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1091/5000, Train Loss: 0.1660\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1092/5000, Train Loss: 0.1659\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1093/5000, Train Loss: 0.1659\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1094/5000, Train Loss: 0.1659\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1095/5000, Train Loss: 0.1658\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1096/5000, Train Loss: 0.1658\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1097/5000, Train Loss: 0.1657\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1098/5000, Train Loss: 0.1657\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1099/5000, Train Loss: 0.1657\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1100/5000, Train Loss: 0.1656\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1101/5000, Train Loss: 0.1656\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1102/5000, Train Loss: 0.1655\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1103/5000, Train Loss: 0.1655\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1104/5000, Train Loss: 0.1655\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1105/5000, Train Loss: 0.1654\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1106/5000, Train Loss: 0.1654\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1107/5000, Train Loss: 0.1653\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1108/5000, Train Loss: 0.1653\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1109/5000, Train Loss: 0.1653\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1110/5000, Train Loss: 0.1652\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1111/5000, Train Loss: 0.1652\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1112/5000, Train Loss: 0.1651\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1113/5000, Train Loss: 0.1651\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1114/5000, Train Loss: 0.1651\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1115/5000, Train Loss: 0.1650\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1116/5000, Train Loss: 0.1650\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1117/5000, Train Loss: 0.1650\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1118/5000, Train Loss: 0.1649\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1119/5000, Train Loss: 0.1649\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1120/5000, Train Loss: 0.1648\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1121/5000, Train Loss: 0.1648\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1122/5000, Train Loss: 0.1648\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1123/5000, Train Loss: 0.1647\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1124/5000, Train Loss: 0.1647\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1125/5000, Train Loss: 0.1646\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1126/5000, Train Loss: 0.1646\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1127/5000, Train Loss: 0.1646\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1128/5000, Train Loss: 0.1645\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1129/5000, Train Loss: 0.1645\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1130/5000, Train Loss: 0.1645\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1131/5000, Train Loss: 0.1644\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1132/5000, Train Loss: 0.1644\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1133/5000, Train Loss: 0.1643\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1134/5000, Train Loss: 0.1643\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1135/5000, Train Loss: 0.1643\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1136/5000, Train Loss: 0.1642\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1137/5000, Train Loss: 0.1642\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1138/5000, Train Loss: 0.1642\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1139/5000, Train Loss: 0.1641\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1140/5000, Train Loss: 0.1641\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1141/5000, Train Loss: 0.1640\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1142/5000, Train Loss: 0.1640\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1143/5000, Train Loss: 0.1640\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1144/5000, Train Loss: 0.1639\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1145/5000, Train Loss: 0.1639\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1146/5000, Train Loss: 0.1639\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1147/5000, Train Loss: 0.1638\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1148/5000, Train Loss: 0.1638\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1149/5000, Train Loss: 0.1637\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1150/5000, Train Loss: 0.1637\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1151/5000, Train Loss: 0.1637\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1152/5000, Train Loss: 0.1636\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1153/5000, Train Loss: 0.1636\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1154/5000, Train Loss: 0.1636\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1155/5000, Train Loss: 0.1635\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1156/5000, Train Loss: 0.1635\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1157/5000, Train Loss: 0.1634\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1158/5000, Train Loss: 0.1634\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1159/5000, Train Loss: 0.1634\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1160/5000, Train Loss: 0.1633\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1161/5000, Train Loss: 0.1633\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1162/5000, Train Loss: 0.1633\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1163/5000, Train Loss: 0.1632\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1164/5000, Train Loss: 0.1632\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1165/5000, Train Loss: 0.1632\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1166/5000, Train Loss: 0.1631\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1167/5000, Train Loss: 0.1631\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1168/5000, Train Loss: 0.1631\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1169/5000, Train Loss: 0.1630\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1170/5000, Train Loss: 0.1630\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1171/5000, Train Loss: 0.1629\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1172/5000, Train Loss: 0.1629\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1173/5000, Train Loss: 0.1629\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1174/5000, Train Loss: 0.1628\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1175/5000, Train Loss: 0.1628\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1176/5000, Train Loss: 0.1628\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1177/5000, Train Loss: 0.1627\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1178/5000, Train Loss: 0.1627\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1179/5000, Train Loss: 0.1627\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1180/5000, Train Loss: 0.1626\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1181/5000, Train Loss: 0.1626\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1182/5000, Train Loss: 0.1626\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1183/5000, Train Loss: 0.1625\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1184/5000, Train Loss: 0.1625\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1185/5000, Train Loss: 0.1624\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1186/5000, Train Loss: 0.1624\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1187/5000, Train Loss: 0.1624\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1188/5000, Train Loss: 0.1623\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1189/5000, Train Loss: 0.1623\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1190/5000, Train Loss: 0.1623\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1191/5000, Train Loss: 0.1622\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1192/5000, Train Loss: 0.1622\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1193/5000, Train Loss: 0.1622\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1194/5000, Train Loss: 0.1621\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1195/5000, Train Loss: 0.1621\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1196/5000, Train Loss: 0.1621\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1197/5000, Train Loss: 0.1620\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1198/5000, Train Loss: 0.1620\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1199/5000, Train Loss: 0.1620\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1200/5000, Train Loss: 0.1619\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1201/5000, Train Loss: 0.1619\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1202/5000, Train Loss: 0.1619\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1203/5000, Train Loss: 0.1618\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1204/5000, Train Loss: 0.1618\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1205/5000, Train Loss: 0.1618\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1206/5000, Train Loss: 0.1617\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1207/5000, Train Loss: 0.1617\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1208/5000, Train Loss: 0.1616\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1209/5000, Train Loss: 0.1616\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1210/5000, Train Loss: 0.1616\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1211/5000, Train Loss: 0.1615\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1212/5000, Train Loss: 0.1615\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1213/5000, Train Loss: 0.1615\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1214/5000, Train Loss: 0.1614\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1215/5000, Train Loss: 0.1614\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1216/5000, Train Loss: 0.1614\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1217/5000, Train Loss: 0.1613\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1218/5000, Train Loss: 0.1613\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1219/5000, Train Loss: 0.1613\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1220/5000, Train Loss: 0.1612\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1221/5000, Train Loss: 0.1612\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1222/5000, Train Loss: 0.1612\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1223/5000, Train Loss: 0.1611\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1224/5000, Train Loss: 0.1611\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1225/5000, Train Loss: 0.1611\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1226/5000, Train Loss: 0.1610\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1227/5000, Train Loss: 0.1610\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1228/5000, Train Loss: 0.1610\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1229/5000, Train Loss: 0.1609\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1230/5000, Train Loss: 0.1609\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1231/5000, Train Loss: 0.1609\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1232/5000, Train Loss: 0.1608\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1233/5000, Train Loss: 0.1608\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1234/5000, Train Loss: 0.1608\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1235/5000, Train Loss: 0.1607\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1236/5000, Train Loss: 0.1607\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1237/5000, Train Loss: 0.1607\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1238/5000, Train Loss: 0.1606\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1239/5000, Train Loss: 0.1606\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1240/5000, Train Loss: 0.1606\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1241/5000, Train Loss: 0.1605\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1242/5000, Train Loss: 0.1605\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1243/5000, Train Loss: 0.1605\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1244/5000, Train Loss: 0.1604\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1245/5000, Train Loss: 0.1604\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1246/5000, Train Loss: 0.1604\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1247/5000, Train Loss: 0.1603\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1248/5000, Train Loss: 0.1603\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1249/5000, Train Loss: 0.1603\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1250/5000, Train Loss: 0.1602\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1251/5000, Train Loss: 0.1602\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1252/5000, Train Loss: 0.1602\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1253/5000, Train Loss: 0.1602\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1254/5000, Train Loss: 0.1601\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1255/5000, Train Loss: 0.1601\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1256/5000, Train Loss: 0.1601\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1257/5000, Train Loss: 0.1600\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1258/5000, Train Loss: 0.1600\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1259/5000, Train Loss: 0.1600\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1260/5000, Train Loss: 0.1599\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1261/5000, Train Loss: 0.1599\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1262/5000, Train Loss: 0.1599\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1263/5000, Train Loss: 0.1598\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1264/5000, Train Loss: 0.1598\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1265/5000, Train Loss: 0.1598\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1266/5000, Train Loss: 0.1597\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1267/5000, Train Loss: 0.1597\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1268/5000, Train Loss: 0.1597\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1269/5000, Train Loss: 0.1596\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1270/5000, Train Loss: 0.1596\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1271/5000, Train Loss: 0.1596\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1272/5000, Train Loss: 0.1595\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1273/5000, Train Loss: 0.1595\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1274/5000, Train Loss: 0.1595\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1275/5000, Train Loss: 0.1594\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1276/5000, Train Loss: 0.1594\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1277/5000, Train Loss: 0.1594\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1278/5000, Train Loss: 0.1594\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1279/5000, Train Loss: 0.1593\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1280/5000, Train Loss: 0.1593\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1281/5000, Train Loss: 0.1593\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1282/5000, Train Loss: 0.1592\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1283/5000, Train Loss: 0.1592\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1284/5000, Train Loss: 0.1592\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1285/5000, Train Loss: 0.1591\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1286/5000, Train Loss: 0.1591\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1287/5000, Train Loss: 0.1591\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1288/5000, Train Loss: 0.1590\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1289/5000, Train Loss: 0.1590\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1290/5000, Train Loss: 0.1590\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1291/5000, Train Loss: 0.1590\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1292/5000, Train Loss: 0.1589\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1293/5000, Train Loss: 0.1589\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1294/5000, Train Loss: 0.1589\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1295/5000, Train Loss: 0.1588\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1296/5000, Train Loss: 0.1588\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1297/5000, Train Loss: 0.1588\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1298/5000, Train Loss: 0.1587\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1299/5000, Train Loss: 0.1587\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1300/5000, Train Loss: 0.1587\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1301/5000, Train Loss: 0.1586\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1302/5000, Train Loss: 0.1586\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1303/5000, Train Loss: 0.1586\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1304/5000, Train Loss: 0.1586\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1305/5000, Train Loss: 0.1585\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1306/5000, Train Loss: 0.1585\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1307/5000, Train Loss: 0.1585\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1308/5000, Train Loss: 0.1584\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1309/5000, Train Loss: 0.1584\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1310/5000, Train Loss: 0.1584\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1311/5000, Train Loss: 0.1583\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1312/5000, Train Loss: 0.1583\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1313/5000, Train Loss: 0.1583\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1314/5000, Train Loss: 0.1582\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1315/5000, Train Loss: 0.1582\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1316/5000, Train Loss: 0.1582\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1317/5000, Train Loss: 0.1582\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1318/5000, Train Loss: 0.1581\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1319/5000, Train Loss: 0.1581\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1320/5000, Train Loss: 0.1581\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1321/5000, Train Loss: 0.1580\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1322/5000, Train Loss: 0.1580\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1323/5000, Train Loss: 0.1580\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1324/5000, Train Loss: 0.1580\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1325/5000, Train Loss: 0.1579\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1326/5000, Train Loss: 0.1579\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1327/5000, Train Loss: 0.1579\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1328/5000, Train Loss: 0.1578\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1329/5000, Train Loss: 0.1578\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1330/5000, Train Loss: 0.1578\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1331/5000, Train Loss: 0.1577\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1332/5000, Train Loss: 0.1577\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1333/5000, Train Loss: 0.1577\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1334/5000, Train Loss: 0.1577\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1335/5000, Train Loss: 0.1576\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1336/5000, Train Loss: 0.1576\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1337/5000, Train Loss: 0.1576\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1338/5000, Train Loss: 0.1575\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1339/5000, Train Loss: 0.1575\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1340/5000, Train Loss: 0.1575\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1341/5000, Train Loss: 0.1575\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1342/5000, Train Loss: 0.1574\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1343/5000, Train Loss: 0.1574\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1344/5000, Train Loss: 0.1574\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1345/5000, Train Loss: 0.1573\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1346/5000, Train Loss: 0.1573\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1347/5000, Train Loss: 0.1573\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1348/5000, Train Loss: 0.1572\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1349/5000, Train Loss: 0.1572\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1350/5000, Train Loss: 0.1572\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1351/5000, Train Loss: 0.1572\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1352/5000, Train Loss: 0.1571\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1353/5000, Train Loss: 0.1571\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1354/5000, Train Loss: 0.1571\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1355/5000, Train Loss: 0.1570\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1356/5000, Train Loss: 0.1570\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1357/5000, Train Loss: 0.1570\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1358/5000, Train Loss: 0.1570\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1359/5000, Train Loss: 0.1569\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1360/5000, Train Loss: 0.1569\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1361/5000, Train Loss: 0.1569\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1362/5000, Train Loss: 0.1568\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1363/5000, Train Loss: 0.1568\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1364/5000, Train Loss: 0.1568\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1365/5000, Train Loss: 0.1568\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1366/5000, Train Loss: 0.1567\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1367/5000, Train Loss: 0.1567\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1368/5000, Train Loss: 0.1567\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1369/5000, Train Loss: 0.1566\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1370/5000, Train Loss: 0.1566\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1371/5000, Train Loss: 0.1566\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1372/5000, Train Loss: 0.1566\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1373/5000, Train Loss: 0.1565\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1374/5000, Train Loss: 0.1565\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1375/5000, Train Loss: 0.1565\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1376/5000, Train Loss: 0.1565\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1377/5000, Train Loss: 0.1564\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1378/5000, Train Loss: 0.1564\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1379/5000, Train Loss: 0.1564\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1380/5000, Train Loss: 0.1563\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1381/5000, Train Loss: 0.1563\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1382/5000, Train Loss: 0.1563\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1383/5000, Train Loss: 0.1563\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1384/5000, Train Loss: 0.1562\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1385/5000, Train Loss: 0.1562\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1386/5000, Train Loss: 0.1562\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1387/5000, Train Loss: 0.1561\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1388/5000, Train Loss: 0.1561\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1389/5000, Train Loss: 0.1561\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1390/5000, Train Loss: 0.1561\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1391/5000, Train Loss: 0.1560\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1392/5000, Train Loss: 0.1560\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1393/5000, Train Loss: 0.1560\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1394/5000, Train Loss: 0.1560\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1395/5000, Train Loss: 0.1559\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1396/5000, Train Loss: 0.1559\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1397/5000, Train Loss: 0.1559\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1398/5000, Train Loss: 0.1558\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1399/5000, Train Loss: 0.1558\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1400/5000, Train Loss: 0.1558\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1401/5000, Train Loss: 0.1558\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1402/5000, Train Loss: 0.1557\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1403/5000, Train Loss: 0.1557\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1404/5000, Train Loss: 0.1557\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1405/5000, Train Loss: 0.1557\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1406/5000, Train Loss: 0.1556\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1407/5000, Train Loss: 0.1556\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1408/5000, Train Loss: 0.1556\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1409/5000, Train Loss: 0.1555\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1410/5000, Train Loss: 0.1555\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1411/5000, Train Loss: 0.1555\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1412/5000, Train Loss: 0.1555\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1413/5000, Train Loss: 0.1554\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1414/5000, Train Loss: 0.1554\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1415/5000, Train Loss: 0.1554\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1416/5000, Train Loss: 0.1554\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1417/5000, Train Loss: 0.1553\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1418/5000, Train Loss: 0.1553\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1419/5000, Train Loss: 0.1553\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1420/5000, Train Loss: 0.1552\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1421/5000, Train Loss: 0.1552\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1422/5000, Train Loss: 0.1552\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1423/5000, Train Loss: 0.1552\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1424/5000, Train Loss: 0.1551\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1425/5000, Train Loss: 0.1551\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1426/5000, Train Loss: 0.1551\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1427/5000, Train Loss: 0.1551\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1428/5000, Train Loss: 0.1550\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1429/5000, Train Loss: 0.1550\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1430/5000, Train Loss: 0.1550\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1431/5000, Train Loss: 0.1550\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1432/5000, Train Loss: 0.1549\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1433/5000, Train Loss: 0.1549\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1434/5000, Train Loss: 0.1549\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1435/5000, Train Loss: 0.1548\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1436/5000, Train Loss: 0.1548\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1437/5000, Train Loss: 0.1548\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1438/5000, Train Loss: 0.1548\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1439/5000, Train Loss: 0.1547\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1440/5000, Train Loss: 0.1547\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1441/5000, Train Loss: 0.1547\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1442/5000, Train Loss: 0.1547\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1443/5000, Train Loss: 0.1546\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1444/5000, Train Loss: 0.1546\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4139\n",
      "Epoch: 1445/5000, Train Loss: 0.1546\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1446/5000, Train Loss: 0.1546\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1447/5000, Train Loss: 0.1545\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1448/5000, Train Loss: 0.1545\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1449/5000, Train Loss: 0.1545\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1450/5000, Train Loss: 0.1545\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1451/5000, Train Loss: 0.1544\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1452/5000, Train Loss: 0.1544\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1453/5000, Train Loss: 0.1544\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1454/5000, Train Loss: 0.1544\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1455/5000, Train Loss: 0.1543\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1456/5000, Train Loss: 0.1543\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1457/5000, Train Loss: 0.1543\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1458/5000, Train Loss: 0.1543\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1459/5000, Train Loss: 0.1542\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1460/5000, Train Loss: 0.1542\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1461/5000, Train Loss: 0.1542\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1462/5000, Train Loss: 0.1541\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1463/5000, Train Loss: 0.1541\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1464/5000, Train Loss: 0.1541\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1465/5000, Train Loss: 0.1541\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1466/5000, Train Loss: 0.1540\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1467/5000, Train Loss: 0.1540\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1468/5000, Train Loss: 0.1540\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1469/5000, Train Loss: 0.1540\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1470/5000, Train Loss: 0.1539\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1471/5000, Train Loss: 0.1539\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1472/5000, Train Loss: 0.1539\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1473/5000, Train Loss: 0.1539\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1474/5000, Train Loss: 0.1538\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1475/5000, Train Loss: 0.1538\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1476/5000, Train Loss: 0.1538\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1477/5000, Train Loss: 0.1538\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1478/5000, Train Loss: 0.1537\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1479/5000, Train Loss: 0.1537\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1480/5000, Train Loss: 0.1537\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1481/5000, Train Loss: 0.1537\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1482/5000, Train Loss: 0.1536\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1483/5000, Train Loss: 0.1536\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1484/5000, Train Loss: 0.1536\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1485/5000, Train Loss: 0.1536\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1486/5000, Train Loss: 0.1535\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1487/5000, Train Loss: 0.1535\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1488/5000, Train Loss: 0.1535\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1489/5000, Train Loss: 0.1535\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1490/5000, Train Loss: 0.1534\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1491/5000, Train Loss: 0.1534\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1492/5000, Train Loss: 0.1534\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1493/5000, Train Loss: 0.1534\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1494/5000, Train Loss: 0.1533\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1495/5000, Train Loss: 0.1533\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1496/5000, Train Loss: 0.1533\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1497/5000, Train Loss: 0.1533\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1498/5000, Train Loss: 0.1532\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1499/5000, Train Loss: 0.1532\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1500/5000, Train Loss: 0.1532\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1501/5000, Train Loss: 0.1532\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1502/5000, Train Loss: 0.1531\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1503/5000, Train Loss: 0.1531\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1504/5000, Train Loss: 0.1531\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1505/5000, Train Loss: 0.1531\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1506/5000, Train Loss: 0.1531\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1507/5000, Train Loss: 0.1530\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4140\n",
      "Epoch: 1508/5000, Train Loss: 0.1530\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1509/5000, Train Loss: 0.1530\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1510/5000, Train Loss: 0.1530\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1511/5000, Train Loss: 0.1529\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1512/5000, Train Loss: 0.1529\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1513/5000, Train Loss: 0.1529\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1514/5000, Train Loss: 0.1529\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1515/5000, Train Loss: 0.1528\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1516/5000, Train Loss: 0.1528\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1517/5000, Train Loss: 0.1528\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1518/5000, Train Loss: 0.1528\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1519/5000, Train Loss: 0.1527\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1520/5000, Train Loss: 0.1527\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1521/5000, Train Loss: 0.1527\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1522/5000, Train Loss: 0.1527\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1523/5000, Train Loss: 0.1526\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1524/5000, Train Loss: 0.1526\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1525/5000, Train Loss: 0.1526\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1526/5000, Train Loss: 0.1526\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1527/5000, Train Loss: 0.1525\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1528/5000, Train Loss: 0.1525\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1529/5000, Train Loss: 0.1525\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1530/5000, Train Loss: 0.1525\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1531/5000, Train Loss: 0.1524\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1532/5000, Train Loss: 0.1524\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1533/5000, Train Loss: 0.1524\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1534/5000, Train Loss: 0.1524\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1535/5000, Train Loss: 0.1524\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1536/5000, Train Loss: 0.1523\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1537/5000, Train Loss: 0.1523\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1538/5000, Train Loss: 0.1523\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1539/5000, Train Loss: 0.1523\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1540/5000, Train Loss: 0.1522\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1541/5000, Train Loss: 0.1522\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1542/5000, Train Loss: 0.1522\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1543/5000, Train Loss: 0.1522\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1544/5000, Train Loss: 0.1521\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1545/5000, Train Loss: 0.1521\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1546/5000, Train Loss: 0.1521\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1547/5000, Train Loss: 0.1521\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1548/5000, Train Loss: 0.1520\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1549/5000, Train Loss: 0.1520\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1550/5000, Train Loss: 0.1520\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1551/5000, Train Loss: 0.1520\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1552/5000, Train Loss: 0.1520\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 1553/5000, Train Loss: 0.1519\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1554/5000, Train Loss: 0.1519\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1555/5000, Train Loss: 0.1519\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1556/5000, Train Loss: 0.1519\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1557/5000, Train Loss: 0.1518\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1558/5000, Train Loss: 0.1518\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1559/5000, Train Loss: 0.1518\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1560/5000, Train Loss: 0.1518\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1561/5000, Train Loss: 0.1517\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1562/5000, Train Loss: 0.1517\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1563/5000, Train Loss: 0.1517\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1564/5000, Train Loss: 0.1517\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1565/5000, Train Loss: 0.1517\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1566/5000, Train Loss: 0.1516\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1567/5000, Train Loss: 0.1516\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1568/5000, Train Loss: 0.1516\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1569/5000, Train Loss: 0.1516\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1570/5000, Train Loss: 0.1515\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1571/5000, Train Loss: 0.1515\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1572/5000, Train Loss: 0.1515\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1573/5000, Train Loss: 0.1515\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1574/5000, Train Loss: 0.1514\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1575/5000, Train Loss: 0.1514\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1576/5000, Train Loss: 0.1514\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1577/5000, Train Loss: 0.1514\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1578/5000, Train Loss: 0.1514\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1579/5000, Train Loss: 0.1513\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1580/5000, Train Loss: 0.1513\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1581/5000, Train Loss: 0.1513\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1582/5000, Train Loss: 0.1513\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1583/5000, Train Loss: 0.1512\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1584/5000, Train Loss: 0.1512\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1585/5000, Train Loss: 0.1512\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1586/5000, Train Loss: 0.1512\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1587/5000, Train Loss: 0.1512\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1588/5000, Train Loss: 0.1511\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1589/5000, Train Loss: 0.1511\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1590/5000, Train Loss: 0.1511\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4142\n",
      "Epoch: 1591/5000, Train Loss: 0.1511\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1592/5000, Train Loss: 0.1510\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1593/5000, Train Loss: 0.1510\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1594/5000, Train Loss: 0.1510\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1595/5000, Train Loss: 0.1510\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1596/5000, Train Loss: 0.1510\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1597/5000, Train Loss: 0.1509\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1598/5000, Train Loss: 0.1509\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1599/5000, Train Loss: 0.1509\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1600/5000, Train Loss: 0.1509\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1601/5000, Train Loss: 0.1508\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1602/5000, Train Loss: 0.1508\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1603/5000, Train Loss: 0.1508\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1604/5000, Train Loss: 0.1508\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1605/5000, Train Loss: 0.1508\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1606/5000, Train Loss: 0.1507\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1607/5000, Train Loss: 0.1507\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1608/5000, Train Loss: 0.1507\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1609/5000, Train Loss: 0.1507\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1610/5000, Train Loss: 0.1506\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1611/5000, Train Loss: 0.1506\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1612/5000, Train Loss: 0.1506\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1613/5000, Train Loss: 0.1506\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1614/5000, Train Loss: 0.1506\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1615/5000, Train Loss: 0.1505\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1616/5000, Train Loss: 0.1505\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1617/5000, Train Loss: 0.1505\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1618/5000, Train Loss: 0.1505\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1619/5000, Train Loss: 0.1504\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1620/5000, Train Loss: 0.1504\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1621/5000, Train Loss: 0.1504\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1622/5000, Train Loss: 0.1504\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1623/5000, Train Loss: 0.1504\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1624/5000, Train Loss: 0.1503\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4143\n",
      "Epoch: 1625/5000, Train Loss: 0.1503\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1626/5000, Train Loss: 0.1503\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1627/5000, Train Loss: 0.1503\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1628/5000, Train Loss: 0.1502\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1629/5000, Train Loss: 0.1502\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1630/5000, Train Loss: 0.1502\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1631/5000, Train Loss: 0.1502\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1632/5000, Train Loss: 0.1502\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1633/5000, Train Loss: 0.1501\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1634/5000, Train Loss: 0.1501\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1635/5000, Train Loss: 0.1501\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1636/5000, Train Loss: 0.1501\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1637/5000, Train Loss: 0.1501\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1638/5000, Train Loss: 0.1500\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1639/5000, Train Loss: 0.1500\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1640/5000, Train Loss: 0.1500\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1641/5000, Train Loss: 0.1500\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1642/5000, Train Loss: 0.1499\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1643/5000, Train Loss: 0.1499\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1644/5000, Train Loss: 0.1499\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1645/5000, Train Loss: 0.1499\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1646/5000, Train Loss: 0.1499\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1647/5000, Train Loss: 0.1498\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1648/5000, Train Loss: 0.1498\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1649/5000, Train Loss: 0.1498\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1650/5000, Train Loss: 0.1498\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1651/5000, Train Loss: 0.1498\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1652/5000, Train Loss: 0.1497\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1653/5000, Train Loss: 0.1497\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1654/5000, Train Loss: 0.1497\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1655/5000, Train Loss: 0.1497\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4144\n",
      "Epoch: 1656/5000, Train Loss: 0.1496\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1657/5000, Train Loss: 0.1496\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1658/5000, Train Loss: 0.1496\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1659/5000, Train Loss: 0.1496\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1660/5000, Train Loss: 0.1496\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1661/5000, Train Loss: 0.1495\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1662/5000, Train Loss: 0.1495\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1663/5000, Train Loss: 0.1495\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1664/5000, Train Loss: 0.1495\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1665/5000, Train Loss: 0.1495\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1666/5000, Train Loss: 0.1494\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1667/5000, Train Loss: 0.1494\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1668/5000, Train Loss: 0.1494\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1669/5000, Train Loss: 0.1494\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1670/5000, Train Loss: 0.1494\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1671/5000, Train Loss: 0.1493\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1672/5000, Train Loss: 0.1493\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1673/5000, Train Loss: 0.1493\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1674/5000, Train Loss: 0.1493\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1675/5000, Train Loss: 0.1493\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1676/5000, Train Loss: 0.1492\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1677/5000, Train Loss: 0.1492\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1678/5000, Train Loss: 0.1492\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1679/5000, Train Loss: 0.1492\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1680/5000, Train Loss: 0.1491\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1681/5000, Train Loss: 0.1491\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1682/5000, Train Loss: 0.1491\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1683/5000, Train Loss: 0.1491\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 1684/5000, Train Loss: 0.1491\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1685/5000, Train Loss: 0.1490\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1686/5000, Train Loss: 0.1490\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1687/5000, Train Loss: 0.1490\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1688/5000, Train Loss: 0.1490\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1689/5000, Train Loss: 0.1490\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1690/5000, Train Loss: 0.1489\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1691/5000, Train Loss: 0.1489\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1692/5000, Train Loss: 0.1489\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1693/5000, Train Loss: 0.1489\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1694/5000, Train Loss: 0.1489\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1695/5000, Train Loss: 0.1488\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1696/5000, Train Loss: 0.1488\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1697/5000, Train Loss: 0.1488\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1698/5000, Train Loss: 0.1488\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1699/5000, Train Loss: 0.1488\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1700/5000, Train Loss: 0.1487\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1701/5000, Train Loss: 0.1487\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1702/5000, Train Loss: 0.1487\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1703/5000, Train Loss: 0.1487\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1704/5000, Train Loss: 0.1487\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1705/5000, Train Loss: 0.1486\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1706/5000, Train Loss: 0.1486\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1707/5000, Train Loss: 0.1486\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1708/5000, Train Loss: 0.1486\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1709/5000, Train Loss: 0.1486\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1710/5000, Train Loss: 0.1485\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4146\n",
      "Epoch: 1711/5000, Train Loss: 0.1485\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1712/5000, Train Loss: 0.1485\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1713/5000, Train Loss: 0.1485\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1714/5000, Train Loss: 0.1485\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1715/5000, Train Loss: 0.1484\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1716/5000, Train Loss: 0.1484\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1717/5000, Train Loss: 0.1484\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1718/5000, Train Loss: 0.1484\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1719/5000, Train Loss: 0.1484\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1720/5000, Train Loss: 0.1483\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1721/5000, Train Loss: 0.1483\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1722/5000, Train Loss: 0.1483\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1723/5000, Train Loss: 0.1483\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1724/5000, Train Loss: 0.1483\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1725/5000, Train Loss: 0.1482\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1726/5000, Train Loss: 0.1482\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1727/5000, Train Loss: 0.1482\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1728/5000, Train Loss: 0.1482\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1729/5000, Train Loss: 0.1482\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1730/5000, Train Loss: 0.1481\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1731/5000, Train Loss: 0.1481\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1732/5000, Train Loss: 0.1481\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1733/5000, Train Loss: 0.1481\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1734/5000, Train Loss: 0.1481\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1735/5000, Train Loss: 0.1480\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1736/5000, Train Loss: 0.1480\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4147\n",
      "Epoch: 1737/5000, Train Loss: 0.1480\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1738/5000, Train Loss: 0.1480\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1739/5000, Train Loss: 0.1480\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1740/5000, Train Loss: 0.1479\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1741/5000, Train Loss: 0.1479\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1742/5000, Train Loss: 0.1479\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1743/5000, Train Loss: 0.1479\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1744/5000, Train Loss: 0.1479\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1745/5000, Train Loss: 0.1478\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1746/5000, Train Loss: 0.1478\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1747/5000, Train Loss: 0.1478\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1748/5000, Train Loss: 0.1478\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1749/5000, Train Loss: 0.1478\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1750/5000, Train Loss: 0.1477\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1751/5000, Train Loss: 0.1477\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1752/5000, Train Loss: 0.1477\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1753/5000, Train Loss: 0.1477\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1754/5000, Train Loss: 0.1477\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1755/5000, Train Loss: 0.1477\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1756/5000, Train Loss: 0.1476\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1757/5000, Train Loss: 0.1476\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1758/5000, Train Loss: 0.1476\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1759/5000, Train Loss: 0.1476\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1760/5000, Train Loss: 0.1476\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1761/5000, Train Loss: 0.1475\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 1762/5000, Train Loss: 0.1475\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1763/5000, Train Loss: 0.1475\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1764/5000, Train Loss: 0.1475\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1765/5000, Train Loss: 0.1475\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1766/5000, Train Loss: 0.1474\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1767/5000, Train Loss: 0.1474\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1768/5000, Train Loss: 0.1474\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1769/5000, Train Loss: 0.1474\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1770/5000, Train Loss: 0.1474\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1771/5000, Train Loss: 0.1473\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1772/5000, Train Loss: 0.1473\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1773/5000, Train Loss: 0.1473\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1774/5000, Train Loss: 0.1473\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1775/5000, Train Loss: 0.1473\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1776/5000, Train Loss: 0.1472\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1777/5000, Train Loss: 0.1472\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1778/5000, Train Loss: 0.1472\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1779/5000, Train Loss: 0.1472\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1780/5000, Train Loss: 0.1472\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1781/5000, Train Loss: 0.1472\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1782/5000, Train Loss: 0.1471\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1783/5000, Train Loss: 0.1471\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1784/5000, Train Loss: 0.1471\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1785/5000, Train Loss: 0.1471\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 1786/5000, Train Loss: 0.1471\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1787/5000, Train Loss: 0.1470\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1788/5000, Train Loss: 0.1470\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1789/5000, Train Loss: 0.1470\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1790/5000, Train Loss: 0.1470\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1791/5000, Train Loss: 0.1470\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1792/5000, Train Loss: 0.1469\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1793/5000, Train Loss: 0.1469\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1794/5000, Train Loss: 0.1469\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1795/5000, Train Loss: 0.1469\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1796/5000, Train Loss: 0.1469\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1797/5000, Train Loss: 0.1469\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1798/5000, Train Loss: 0.1468\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1799/5000, Train Loss: 0.1468\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1800/5000, Train Loss: 0.1468\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1801/5000, Train Loss: 0.1468\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1802/5000, Train Loss: 0.1468\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1803/5000, Train Loss: 0.1467\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1804/5000, Train Loss: 0.1467\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1805/5000, Train Loss: 0.1467\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1806/5000, Train Loss: 0.1467\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1807/5000, Train Loss: 0.1467\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1808/5000, Train Loss: 0.1467\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4150\n",
      "Epoch: 1809/5000, Train Loss: 0.1466\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1810/5000, Train Loss: 0.1466\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1811/5000, Train Loss: 0.1466\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1812/5000, Train Loss: 0.1466\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1813/5000, Train Loss: 0.1466\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1814/5000, Train Loss: 0.1465\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1815/5000, Train Loss: 0.1465\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1816/5000, Train Loss: 0.1465\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1817/5000, Train Loss: 0.1465\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1818/5000, Train Loss: 0.1465\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1819/5000, Train Loss: 0.1464\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1820/5000, Train Loss: 0.1464\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1821/5000, Train Loss: 0.1464\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1822/5000, Train Loss: 0.1464\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1823/5000, Train Loss: 0.1464\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1824/5000, Train Loss: 0.1464\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1825/5000, Train Loss: 0.1463\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1826/5000, Train Loss: 0.1463\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1827/5000, Train Loss: 0.1463\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1828/5000, Train Loss: 0.1463\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1829/5000, Train Loss: 0.1463\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1830/5000, Train Loss: 0.1462\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 1831/5000, Train Loss: 0.1462\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1832/5000, Train Loss: 0.1462\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1833/5000, Train Loss: 0.1462\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1834/5000, Train Loss: 0.1462\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1835/5000, Train Loss: 0.1462\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1836/5000, Train Loss: 0.1461\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1837/5000, Train Loss: 0.1461\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1838/5000, Train Loss: 0.1461\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1839/5000, Train Loss: 0.1461\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1840/5000, Train Loss: 0.1461\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1841/5000, Train Loss: 0.1461\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1842/5000, Train Loss: 0.1460\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1843/5000, Train Loss: 0.1460\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1844/5000, Train Loss: 0.1460\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1845/5000, Train Loss: 0.1460\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1846/5000, Train Loss: 0.1460\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1847/5000, Train Loss: 0.1459\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1848/5000, Train Loss: 0.1459\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1849/5000, Train Loss: 0.1459\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1850/5000, Train Loss: 0.1459\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1851/5000, Train Loss: 0.1459\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1852/5000, Train Loss: 0.1459\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 1853/5000, Train Loss: 0.1458\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1854/5000, Train Loss: 0.1458\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1855/5000, Train Loss: 0.1458\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1856/5000, Train Loss: 0.1458\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1857/5000, Train Loss: 0.1458\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1858/5000, Train Loss: 0.1457\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1859/5000, Train Loss: 0.1457\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1860/5000, Train Loss: 0.1457\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1861/5000, Train Loss: 0.1457\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1862/5000, Train Loss: 0.1457\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1863/5000, Train Loss: 0.1457\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1864/5000, Train Loss: 0.1456\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1865/5000, Train Loss: 0.1456\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1866/5000, Train Loss: 0.1456\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1867/5000, Train Loss: 0.1456\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1868/5000, Train Loss: 0.1456\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1869/5000, Train Loss: 0.1456\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1870/5000, Train Loss: 0.1455\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1871/5000, Train Loss: 0.1455\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1872/5000, Train Loss: 0.1455\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1873/5000, Train Loss: 0.1455\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4153\n",
      "Epoch: 1874/5000, Train Loss: 0.1455\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1875/5000, Train Loss: 0.1455\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1876/5000, Train Loss: 0.1454\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1877/5000, Train Loss: 0.1454\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1878/5000, Train Loss: 0.1454\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1879/5000, Train Loss: 0.1454\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1880/5000, Train Loss: 0.1454\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1881/5000, Train Loss: 0.1453\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1882/5000, Train Loss: 0.1453\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1883/5000, Train Loss: 0.1453\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1884/5000, Train Loss: 0.1453\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1885/5000, Train Loss: 0.1453\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1886/5000, Train Loss: 0.1453\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1887/5000, Train Loss: 0.1452\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1888/5000, Train Loss: 0.1452\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1889/5000, Train Loss: 0.1452\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1890/5000, Train Loss: 0.1452\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1891/5000, Train Loss: 0.1452\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1892/5000, Train Loss: 0.1452\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1893/5000, Train Loss: 0.1451\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1894/5000, Train Loss: 0.1451\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4154\n",
      "Epoch: 1895/5000, Train Loss: 0.1451\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1896/5000, Train Loss: 0.1451\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1897/5000, Train Loss: 0.1451\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1898/5000, Train Loss: 0.1451\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1899/5000, Train Loss: 0.1450\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1900/5000, Train Loss: 0.1450\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1901/5000, Train Loss: 0.1450\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1902/5000, Train Loss: 0.1450\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1903/5000, Train Loss: 0.1450\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1904/5000, Train Loss: 0.1450\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1905/5000, Train Loss: 0.1449\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1906/5000, Train Loss: 0.1449\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1907/5000, Train Loss: 0.1449\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1908/5000, Train Loss: 0.1449\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1909/5000, Train Loss: 0.1449\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1910/5000, Train Loss: 0.1448\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1911/5000, Train Loss: 0.1448\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1912/5000, Train Loss: 0.1448\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1913/5000, Train Loss: 0.1448\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1914/5000, Train Loss: 0.1448\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 1915/5000, Train Loss: 0.1448\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1916/5000, Train Loss: 0.1447\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1917/5000, Train Loss: 0.1447\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1918/5000, Train Loss: 0.1447\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1919/5000, Train Loss: 0.1447\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1920/5000, Train Loss: 0.1447\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1921/5000, Train Loss: 0.1447\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1922/5000, Train Loss: 0.1446\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1923/5000, Train Loss: 0.1446\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1924/5000, Train Loss: 0.1446\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1925/5000, Train Loss: 0.1446\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1926/5000, Train Loss: 0.1446\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1927/5000, Train Loss: 0.1446\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1928/5000, Train Loss: 0.1445\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1929/5000, Train Loss: 0.1445\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1930/5000, Train Loss: 0.1445\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1931/5000, Train Loss: 0.1445\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1932/5000, Train Loss: 0.1445\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1933/5000, Train Loss: 0.1445\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1934/5000, Train Loss: 0.1444\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4156\n",
      "Epoch: 1935/5000, Train Loss: 0.1444\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1936/5000, Train Loss: 0.1444\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1937/5000, Train Loss: 0.1444\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1938/5000, Train Loss: 0.1444\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1939/5000, Train Loss: 0.1444\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1940/5000, Train Loss: 0.1443\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1941/5000, Train Loss: 0.1443\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1942/5000, Train Loss: 0.1443\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1943/5000, Train Loss: 0.1443\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1944/5000, Train Loss: 0.1443\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1945/5000, Train Loss: 0.1443\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1946/5000, Train Loss: 0.1442\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1947/5000, Train Loss: 0.1442\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1948/5000, Train Loss: 0.1442\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1949/5000, Train Loss: 0.1442\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1950/5000, Train Loss: 0.1442\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1951/5000, Train Loss: 0.1442\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1952/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1953/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4157\n",
      "Epoch: 1954/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1955/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1956/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1957/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1958/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1959/5000, Train Loss: 0.1440\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1960/5000, Train Loss: 0.1440\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1961/5000, Train Loss: 0.1440\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1962/5000, Train Loss: 0.1440\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1963/5000, Train Loss: 0.1440\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1964/5000, Train Loss: 0.1440\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1965/5000, Train Loss: 0.1439\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1966/5000, Train Loss: 0.1439\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1967/5000, Train Loss: 0.1439\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1968/5000, Train Loss: 0.1439\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1969/5000, Train Loss: 0.1439\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1970/5000, Train Loss: 0.1439\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1971/5000, Train Loss: 0.1438\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1972/5000, Train Loss: 0.1438\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1973/5000, Train Loss: 0.1438\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 1974/5000, Train Loss: 0.1438\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1975/5000, Train Loss: 0.1438\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1976/5000, Train Loss: 0.1438\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1977/5000, Train Loss: 0.1437\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1978/5000, Train Loss: 0.1437\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1979/5000, Train Loss: 0.1437\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1980/5000, Train Loss: 0.1437\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1981/5000, Train Loss: 0.1437\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1982/5000, Train Loss: 0.1437\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1983/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1984/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1985/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1986/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1987/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1988/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1989/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1990/5000, Train Loss: 0.1435\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1991/5000, Train Loss: 0.1435\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1992/5000, Train Loss: 0.1435\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 1993/5000, Train Loss: 0.1435\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 1994/5000, Train Loss: 0.1435\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 1995/5000, Train Loss: 0.1435\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 1996/5000, Train Loss: 0.1434\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 1997/5000, Train Loss: 0.1434\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 1998/5000, Train Loss: 0.1434\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 1999/5000, Train Loss: 0.1434\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 2000/5000, Train Loss: 0.1434\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 2001/5000, Train Loss: 0.1434\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 2002/5000, Train Loss: 0.1433\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 2003/5000, Train Loss: 0.1433\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 2004/5000, Train Loss: 0.1433\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 2005/5000, Train Loss: 0.1433\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 2006/5000, Train Loss: 0.1433\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 2007/5000, Train Loss: 0.1433\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 2008/5000, Train Loss: 0.1433\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 2009/5000, Train Loss: 0.1432\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 2010/5000, Train Loss: 0.1432\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4160\n",
      "Epoch: 2011/5000, Train Loss: 0.1432\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2012/5000, Train Loss: 0.1432\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2013/5000, Train Loss: 0.1432\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2014/5000, Train Loss: 0.1432\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2015/5000, Train Loss: 0.1431\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2016/5000, Train Loss: 0.1431\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2017/5000, Train Loss: 0.1431\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2018/5000, Train Loss: 0.1431\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2019/5000, Train Loss: 0.1431\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2020/5000, Train Loss: 0.1431\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2021/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2022/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2023/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2024/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2025/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2026/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2027/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2028/5000, Train Loss: 0.1429\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2029/5000, Train Loss: 0.1429\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4161\n",
      "Epoch: 2030/5000, Train Loss: 0.1429\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2031/5000, Train Loss: 0.1429\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2032/5000, Train Loss: 0.1429\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2033/5000, Train Loss: 0.1429\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2034/5000, Train Loss: 0.1428\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2035/5000, Train Loss: 0.1428\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2036/5000, Train Loss: 0.1428\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2037/5000, Train Loss: 0.1428\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2038/5000, Train Loss: 0.1428\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2039/5000, Train Loss: 0.1428\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2040/5000, Train Loss: 0.1428\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2041/5000, Train Loss: 0.1427\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2042/5000, Train Loss: 0.1427\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2043/5000, Train Loss: 0.1427\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2044/5000, Train Loss: 0.1427\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2045/5000, Train Loss: 0.1427\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2046/5000, Train Loss: 0.1427\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2047/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 2048/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2049/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2050/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2051/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2052/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2053/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2054/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2055/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2056/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2057/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2058/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2059/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2060/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2061/5000, Train Loss: 0.1424\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2062/5000, Train Loss: 0.1424\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2063/5000, Train Loss: 0.1424\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2064/5000, Train Loss: 0.1424\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2065/5000, Train Loss: 0.1424\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4163\n",
      "Epoch: 2066/5000, Train Loss: 0.1424\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2067/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2068/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2069/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2070/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2071/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2072/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2073/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2074/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2075/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2076/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2077/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2078/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2079/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2080/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2081/5000, Train Loss: 0.1421\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2082/5000, Train Loss: 0.1421\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2083/5000, Train Loss: 0.1421\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 2084/5000, Train Loss: 0.1421\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2085/5000, Train Loss: 0.1421\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2086/5000, Train Loss: 0.1421\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2087/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2088/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2089/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2090/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2091/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2092/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2093/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2094/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2095/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2096/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2097/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2098/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2099/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2100/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2101/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4165\n",
      "Epoch: 2102/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2103/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2104/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2105/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2106/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2107/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2108/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2109/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2110/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2111/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2112/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2113/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2114/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2115/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2116/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2117/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2118/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 2119/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2120/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2121/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2122/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2123/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2124/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2125/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2126/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2127/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2128/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2129/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2130/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2131/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2132/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2133/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2134/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2135/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2136/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4167\n",
      "Epoch: 2137/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2138/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2139/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2140/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2141/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2142/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2143/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2144/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2145/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2146/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2147/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2148/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2149/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2150/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2151/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2152/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2153/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4168\n",
      "Epoch: 2154/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2155/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2156/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2157/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2158/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2159/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2160/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2161/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2162/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2163/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2164/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2165/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2166/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2167/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2168/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2169/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2170/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 2171/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2172/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2173/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2174/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2175/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2176/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2177/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2178/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2179/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2180/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2181/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2182/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2183/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2184/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2185/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2186/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2187/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 2188/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2189/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2190/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2191/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2192/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2193/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2194/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2195/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2196/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2197/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2198/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2199/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2200/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2201/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2202/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2203/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4171\n",
      "Epoch: 2204/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2205/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2206/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2207/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2208/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2209/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2210/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2211/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2212/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2213/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2214/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2215/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2216/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2217/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2218/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2219/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2220/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4172\n",
      "Epoch: 2221/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2222/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2223/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2224/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2225/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2226/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2227/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2228/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2229/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2230/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2231/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2232/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2233/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2234/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2235/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2236/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2237/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 2238/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2239/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2240/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2241/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2242/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2243/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2244/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2245/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2246/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2247/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2248/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2249/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2250/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2251/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2252/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2253/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4174\n",
      "Epoch: 2254/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2255/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2256/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2257/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2258/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2259/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2260/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2261/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2262/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2263/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2264/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2265/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2266/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2267/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2268/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2269/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4175\n",
      "Epoch: 2270/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2271/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2272/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2273/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2274/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2275/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2276/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2277/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2278/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2279/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2280/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2281/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2282/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2283/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2284/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2285/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2286/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 2287/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2288/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2289/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2290/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2291/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2292/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2293/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2294/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2295/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2296/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2297/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2298/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2299/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2300/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2301/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2302/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4177\n",
      "Epoch: 2303/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2304/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2305/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2306/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2307/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2308/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2309/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2310/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2311/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2312/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2313/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2314/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2315/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2316/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2317/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2318/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4178\n",
      "Epoch: 2319/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2320/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2321/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2322/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2323/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2324/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2325/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2326/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2327/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2328/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2329/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2330/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2331/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2332/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2333/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2334/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4179\n",
      "Epoch: 2335/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2336/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2337/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2338/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2339/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2340/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2341/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2342/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2343/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2344/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2345/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2346/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2347/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2348/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2349/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2350/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 2351/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2352/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2353/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2354/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2355/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2356/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2357/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2358/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2359/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2360/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2361/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2362/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2363/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2364/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2365/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2366/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 2367/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2368/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2369/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2370/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2371/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2372/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2373/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2374/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2375/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2376/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2377/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2378/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2379/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2380/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2381/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4182\n",
      "Epoch: 2382/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2383/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2384/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2385/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2386/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2387/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2388/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2389/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2390/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2391/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2392/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2393/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2394/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2395/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2396/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2397/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 2398/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2399/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2400/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2401/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2402/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2403/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2404/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2405/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2406/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2407/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2408/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2409/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2410/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2411/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2412/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2413/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4184\n",
      "Epoch: 2414/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2415/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2416/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2417/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2418/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2419/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2420/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2421/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2422/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2423/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2424/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2425/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2426/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2427/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2428/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4185\n",
      "Epoch: 2429/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2430/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2431/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2432/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2433/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2434/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2435/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2436/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2437/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2438/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2439/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2440/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2441/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2442/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2443/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2444/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4186\n",
      "Epoch: 2445/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2446/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2447/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2448/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2449/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2450/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2451/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2452/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2453/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2454/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2455/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2456/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2457/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2458/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2459/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 2460/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2461/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2462/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2463/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2464/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2465/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2466/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2467/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2468/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2469/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2470/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2471/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2472/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2473/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2474/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4188\n",
      "Epoch: 2475/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2476/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2477/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2478/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2479/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2480/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2481/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2482/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2483/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2484/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2485/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2486/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2487/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2488/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2489/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2490/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4189\n",
      "Epoch: 2491/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2492/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2493/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2494/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2495/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2496/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2497/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2498/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2499/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2500/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2501/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2502/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2503/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2504/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2505/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 2506/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2507/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2508/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2509/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2510/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2511/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2512/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2513/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2514/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2515/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2516/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2517/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2518/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2519/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2520/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4191\n",
      "Epoch: 2521/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2522/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2523/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2524/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2525/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2526/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2527/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2528/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2529/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2530/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2531/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2532/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2533/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2534/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2535/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4192\n",
      "Epoch: 2536/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2537/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2538/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2539/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2540/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2541/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2542/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2543/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2544/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2545/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2546/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2547/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2548/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2549/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2550/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 2551/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2552/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2553/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2554/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2555/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2556/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2557/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2558/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2559/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2560/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2561/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2562/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2563/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2564/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2565/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 2566/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2567/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2568/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2569/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2570/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2571/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2572/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2573/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2574/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2575/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2576/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2577/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2578/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2579/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2580/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4195\n",
      "Epoch: 2581/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2582/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2583/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2584/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2585/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2586/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2587/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2588/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2589/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2590/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2591/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2592/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2593/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2594/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2595/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4196\n",
      "Epoch: 2596/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2597/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2598/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2599/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2600/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2601/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2602/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2603/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2604/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2605/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2606/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2607/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2608/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2609/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2610/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4197\n",
      "Epoch: 2611/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2612/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2613/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2614/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2615/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2616/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2617/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2618/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2619/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2620/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2621/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2622/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2623/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2624/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2625/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 2626/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2627/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2628/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2629/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2630/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2631/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2632/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2633/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2634/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2635/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2636/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2637/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2638/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2639/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2640/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4199\n",
      "Epoch: 2641/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2642/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2643/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2644/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2645/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2646/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2647/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2648/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2649/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2650/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2651/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2652/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2653/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2654/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2655/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4200\n",
      "Epoch: 2656/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2657/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2658/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2659/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2660/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2661/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2662/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2663/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2664/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2665/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2666/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2667/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2668/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2669/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2670/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 2671/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2672/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2673/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2674/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2675/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2676/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2677/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2678/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2679/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2680/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2681/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2682/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2683/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2684/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2685/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4202\n",
      "Epoch: 2686/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 2687/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 2688/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 2689/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 2690/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 2691/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 2692/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 2693/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 2694/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 2695/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 2696/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 2697/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 2698/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 2699/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 2700/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2701/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2702/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2703/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2704/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2705/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2706/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2707/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2708/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2709/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2710/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2711/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2712/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2713/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2714/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4204\n",
      "Epoch: 2715/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2716/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2717/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2718/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2719/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2720/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2721/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2722/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2723/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2724/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2725/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2726/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2727/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2728/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2729/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 2730/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 2731/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 2732/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 2733/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 2734/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 2735/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 2736/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 2737/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 2738/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 2739/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 2740/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 2741/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 2742/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 2743/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4206\n",
      "Epoch: 2744/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2745/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2746/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2747/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2748/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2749/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2750/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2751/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2752/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2753/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2754/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2755/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2756/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2757/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2758/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4207\n",
      "Epoch: 2759/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2760/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2761/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2762/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2763/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2764/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2765/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2766/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2767/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2768/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2769/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2770/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2771/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2772/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2773/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 2774/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 2775/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 2776/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 2777/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 2778/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 2779/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 2780/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 2781/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 2782/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 2783/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 2784/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 2785/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 2786/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 2787/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 2788/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2789/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2790/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2791/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2792/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2793/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2794/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2795/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2796/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2797/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2798/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2799/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2800/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2801/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2802/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4210\n",
      "Epoch: 2803/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 2804/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 2805/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 2806/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 2807/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 2808/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 2809/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 2810/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 2811/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 2812/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 2813/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 2814/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 2815/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 2816/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4211\n",
      "Epoch: 2817/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2818/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2819/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2820/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2821/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2822/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2823/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2824/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2825/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2826/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2827/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2828/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2829/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2830/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2831/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 2832/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 2833/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 2834/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 2835/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 2836/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 2837/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 2838/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 2839/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 2840/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 2841/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 2842/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 2843/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 2844/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 2845/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4213\n",
      "Epoch: 2846/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2847/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2848/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2849/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2850/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2851/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2852/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2853/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2854/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2855/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2856/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2857/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2858/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2859/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2860/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 2861/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 2862/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 2863/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 2864/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 2865/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 2866/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 2867/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 2868/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 2869/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 2870/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 2871/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 2872/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 2873/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 2874/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4215\n",
      "Epoch: 2875/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2876/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2877/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2878/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2879/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2880/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2881/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2882/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2883/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2884/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2885/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2886/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2887/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2888/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2889/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 2890/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 2891/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 2892/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 2893/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 2894/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 2895/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 2896/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 2897/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 2898/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 2899/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 2900/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 2901/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 2902/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 2903/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4217\n",
      "Epoch: 2904/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2905/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2906/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2907/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2908/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2909/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2910/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2911/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2912/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2913/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2914/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2915/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2916/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2917/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2918/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4218\n",
      "Epoch: 2919/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 2920/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 2921/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 2922/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 2923/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 2924/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 2925/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 2926/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 2927/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 2928/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 2929/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 2930/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 2931/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 2932/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 2933/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2934/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2935/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2936/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2937/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2938/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2939/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2940/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2941/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2942/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2943/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2944/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2945/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2946/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2947/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4220\n",
      "Epoch: 2948/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 2949/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 2950/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 2951/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 2952/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 2953/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 2954/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 2955/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 2956/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 2957/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 2958/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 2959/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 2960/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 2961/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4221\n",
      "Epoch: 2962/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 2963/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 2964/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 2965/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 2966/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 2967/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 2968/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 2969/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 2970/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 2971/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 2972/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 2973/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 2974/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 2975/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4222\n",
      "Epoch: 2976/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2977/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2978/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2979/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2980/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2981/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2982/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2983/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2984/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2985/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2986/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2987/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2988/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2989/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2990/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 2991/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 2992/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 2993/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 2994/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 2995/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 2996/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 2997/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 2998/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 2999/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 3000/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 3001/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 3002/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 3003/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 3004/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 3005/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 3006/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 3007/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 3008/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 3009/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 3010/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 3011/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 3012/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 3013/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 3014/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 3015/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 3016/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 3017/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 3018/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4225\n",
      "Epoch: 3019/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3020/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3021/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3022/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3023/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3024/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3025/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3026/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3027/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3028/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3029/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3030/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3031/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3032/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3033/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4226\n",
      "Epoch: 3034/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 3035/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 3036/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 3037/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 3038/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 3039/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 3040/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 3041/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 3042/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 3043/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 3044/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 3045/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 3046/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 3047/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 3048/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 3049/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 3050/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 3051/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 3052/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 3053/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 3054/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 3055/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 3056/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 3057/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 3058/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 3059/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 3060/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 3061/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4228\n",
      "Epoch: 3062/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3063/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3064/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3065/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3066/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3067/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3068/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3069/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3070/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3071/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3072/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3073/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3074/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3075/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3076/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 3077/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 3078/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 3079/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 3080/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 3081/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 3082/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 3083/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 3084/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 3085/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 3086/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 3087/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 3088/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 3089/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 3090/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4230\n",
      "Epoch: 3091/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 3092/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 3093/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 3094/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 3095/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 3096/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 3097/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 3098/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 3099/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 3100/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 3101/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 3102/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 3103/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 3104/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 3105/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 3106/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 3107/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 3108/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 3109/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 3110/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 3111/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 3112/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 3113/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 3114/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 3115/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 3116/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 3117/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 3118/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4232\n",
      "Epoch: 3119/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3120/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3121/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3122/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3123/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3124/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3125/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3126/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3127/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3128/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3129/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3130/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3131/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3132/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3133/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 3134/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 3135/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 3136/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 3137/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 3138/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 3139/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 3140/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 3141/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 3142/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 3143/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 3144/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 3145/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 3146/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 3147/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 3148/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 3149/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 3150/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 3151/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 3152/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 3153/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 3154/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 3155/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 3156/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 3157/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 3158/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 3159/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 3160/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 3161/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4235\n",
      "Epoch: 3162/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 3163/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 3164/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 3165/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 3166/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 3167/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 3168/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 3169/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 3170/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 3171/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 3172/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 3173/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 3174/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 3175/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4236\n",
      "Epoch: 3176/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3177/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3178/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3179/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3180/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3181/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3182/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3183/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3184/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3185/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3186/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3187/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3188/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3189/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3190/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4237\n",
      "Epoch: 3191/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 3192/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 3193/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 3194/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 3195/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 3196/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 3197/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 3198/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 3199/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 3200/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 3201/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 3202/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 3203/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 3204/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 3205/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 3206/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 3207/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 3208/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 3209/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 3210/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 3211/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 3212/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 3213/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 3214/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 3215/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 3216/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 3217/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 3218/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4239\n",
      "Epoch: 3219/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 3220/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 3221/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 3222/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 3223/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 3224/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 3225/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 3226/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 3227/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 3228/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 3229/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 3230/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 3231/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 3232/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4240\n",
      "Epoch: 3233/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3234/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3235/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3236/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3237/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3238/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3239/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3240/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3241/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3242/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3243/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3244/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3245/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3246/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3247/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4241\n",
      "Epoch: 3248/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 3249/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 3250/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 3251/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 3252/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 3253/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 3254/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 3255/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 3256/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 3257/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 3258/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 3259/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 3260/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 3261/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 3262/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 3263/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 3264/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 3265/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 3266/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 3267/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 3268/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 3269/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 3270/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 3271/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 3272/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 3273/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 3274/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 3275/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 3276/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 3277/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 3278/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 3279/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 3280/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 3281/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 3282/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 3283/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 3284/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 3285/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 3286/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 3287/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 3288/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 3289/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4244\n",
      "Epoch: 3290/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3291/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3292/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3293/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3294/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3295/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3296/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3297/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3298/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3299/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3300/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3301/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3302/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3303/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3304/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 3305/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 3306/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 3307/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 3308/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 3309/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 3310/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 3311/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 3312/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 3313/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 3314/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 3315/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 3316/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 3317/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 3318/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4246\n",
      "Epoch: 3319/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 3320/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 3321/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 3322/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 3323/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 3324/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 3325/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 3326/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 3327/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 3328/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 3329/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 3330/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 3331/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 3332/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 3333/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 3334/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 3335/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 3336/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 3337/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 3338/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 3339/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 3340/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 3341/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 3342/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 3343/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 3344/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 3345/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 3346/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4248\n",
      "Epoch: 3347/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 3348/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 3349/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 3350/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 3351/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 3352/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 3353/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 3354/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 3355/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 3356/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 3357/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 3358/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 3359/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 3360/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 3361/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3362/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3363/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3364/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3365/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3366/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3367/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3368/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3369/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3370/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3371/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3372/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3373/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3374/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3375/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4250\n",
      "Epoch: 3376/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 3377/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 3378/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 3379/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 3380/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 3381/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 3382/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 3383/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 3384/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 3385/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 3386/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 3387/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 3388/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 3389/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4251\n",
      "Epoch: 3390/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 3391/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 3392/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 3393/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 3394/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 3395/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 3396/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 3397/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 3398/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 3399/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 3400/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 3401/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 3402/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 3403/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 3404/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 3405/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 3406/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 3407/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 3408/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 3409/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 3410/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 3411/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 3412/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 3413/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 3414/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 3415/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 3416/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 3417/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 3418/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 3419/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 3420/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 3421/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 3422/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 3423/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 3424/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 3425/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 3426/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 3427/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 3428/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 3429/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 3430/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 3431/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4254\n",
      "Epoch: 3432/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3433/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3434/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3435/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3436/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3437/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3438/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3439/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3440/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3441/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3442/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3443/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3444/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3445/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3446/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4255\n",
      "Epoch: 3447/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 3448/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 3449/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 3450/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 3451/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 3452/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 3453/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 3454/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 3455/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 3456/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 3457/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 3458/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 3459/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 3460/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 3461/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 3462/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 3463/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 3464/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 3465/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 3466/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 3467/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 3468/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 3469/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 3470/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 3471/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 3472/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 3473/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 3474/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 3475/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 3476/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 3477/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 3478/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 3479/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 3480/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 3481/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 3482/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 3483/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 3484/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 3485/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 3486/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 3487/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 3488/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4258\n",
      "Epoch: 3489/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 3490/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 3491/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 3492/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 3493/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 3494/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 3495/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 3496/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 3497/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 3498/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 3499/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 3500/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 3501/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 3502/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4259\n",
      "Epoch: 3503/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3504/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3505/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3506/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3507/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3508/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3509/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3510/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3511/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3512/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3513/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3514/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3515/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3516/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3517/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 3518/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 3519/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 3520/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 3521/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 3522/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 3523/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 3524/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 3525/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 3526/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 3527/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 3528/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 3529/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 3530/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 3531/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 3532/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 3533/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 3534/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 3535/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 3536/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 3537/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 3538/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 3539/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 3540/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 3541/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 3542/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 3543/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 3544/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 3545/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4262\n",
      "Epoch: 3546/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 3547/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 3548/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 3549/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 3550/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 3551/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 3552/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 3553/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 3554/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 3555/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 3556/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 3557/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 3558/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 3559/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4263\n",
      "Epoch: 3560/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3561/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3562/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3563/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3564/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3565/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3566/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3567/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3568/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3569/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3570/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3571/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3572/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3573/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3574/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 3575/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 3576/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 3577/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 3578/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 3579/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 3580/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 3581/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 3582/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 3583/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 3584/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 3585/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 3586/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 3587/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 3588/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 3589/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 3590/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 3591/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 3592/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 3593/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 3594/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 3595/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 3596/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 3597/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 3598/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 3599/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 3600/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 3601/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 3602/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4266\n",
      "Epoch: 3603/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 3604/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 3605/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 3606/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 3607/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 3608/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 3609/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 3610/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 3611/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 3612/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 3613/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 3614/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 3615/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 3616/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4267\n",
      "Epoch: 3617/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3618/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3619/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3620/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3621/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3622/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3623/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3624/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3625/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3626/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3627/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3628/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3629/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3630/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3631/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 3632/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 3633/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 3634/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 3635/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 3636/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 3637/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 3638/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 3639/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 3640/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 3641/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 3642/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 3643/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 3644/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 3645/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4269\n",
      "Epoch: 3646/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 3647/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 3648/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 3649/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 3650/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 3651/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 3652/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 3653/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 3654/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 3655/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 3656/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 3657/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 3658/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 3659/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4270\n",
      "Epoch: 3660/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 3661/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 3662/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 3663/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 3664/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 3665/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 3666/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 3667/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 3668/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 3669/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 3670/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 3671/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 3672/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 3673/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4271\n",
      "Epoch: 3674/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3675/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3676/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3677/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3678/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3679/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3680/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3681/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3682/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3683/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3684/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3685/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3686/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3687/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3688/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 3689/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 3690/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 3691/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 3692/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 3693/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 3694/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 3695/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 3696/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 3697/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 3698/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 3699/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 3700/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 3701/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 3702/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4273\n",
      "Epoch: 3703/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 3704/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 3705/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 3706/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 3707/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 3708/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 3709/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 3710/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 3711/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 3712/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 3713/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 3714/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 3715/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 3716/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4274\n",
      "Epoch: 3717/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 3718/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 3719/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 3720/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 3721/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 3722/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 3723/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 3724/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 3725/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 3726/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 3727/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 3728/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 3729/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 3730/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4275\n",
      "Epoch: 3731/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3732/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3733/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3734/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3735/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3736/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3737/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3738/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3739/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3740/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3741/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3742/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3743/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3744/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3745/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 3746/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 3747/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 3748/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 3749/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 3750/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 3751/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 3752/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 3753/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 3754/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 3755/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 3756/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 3757/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 3758/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 3759/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4277\n",
      "Epoch: 3760/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 3761/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 3762/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 3763/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 3764/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 3765/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 3766/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 3767/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 3768/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 3769/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 3770/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 3771/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 3772/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 3773/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4278\n",
      "Epoch: 3774/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3775/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3776/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3777/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3778/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3779/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3780/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3781/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3782/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3783/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3784/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3785/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3786/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3787/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3788/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4279\n",
      "Epoch: 3789/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 3790/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 3791/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 3792/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 3793/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 3794/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 3795/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 3796/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 3797/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 3798/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 3799/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 3800/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 3801/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 3802/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 3803/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 3804/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 3805/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 3806/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 3807/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 3808/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 3809/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 3810/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 3811/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 3812/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 3813/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 3814/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 3815/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 3816/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4281\n",
      "Epoch: 3817/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3818/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3819/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3820/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3821/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3822/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3823/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3824/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3825/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3826/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3827/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3828/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3829/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3830/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3831/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4282\n",
      "Epoch: 3832/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 3833/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 3834/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 3835/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 3836/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 3837/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 3838/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 3839/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 3840/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 3841/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 3842/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 3843/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 3844/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 3845/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4283\n",
      "Epoch: 3846/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 3847/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 3848/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 3849/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 3850/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 3851/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 3852/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 3853/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 3854/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 3855/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 3856/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 3857/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 3858/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 3859/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 3860/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3861/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3862/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3863/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3864/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3865/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3866/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3867/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3868/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3869/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3870/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3871/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3872/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3873/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3874/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4285\n",
      "Epoch: 3875/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 3876/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 3877/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 3878/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 3879/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 3880/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 3881/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 3882/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 3883/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 3884/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 3885/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 3886/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 3887/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 3888/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4286\n",
      "Epoch: 3889/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 3890/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 3891/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 3892/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 3893/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 3894/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 3895/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 3896/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 3897/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 3898/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 3899/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 3900/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 3901/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 3902/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 3903/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3904/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3905/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3906/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3907/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3908/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3909/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3910/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3911/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3912/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3913/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3914/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3915/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3916/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3917/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 3918/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 3919/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 3920/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 3921/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 3922/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 3923/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 3924/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 3925/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 3926/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 3927/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 3928/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 3929/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 3930/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 3931/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4289\n",
      "Epoch: 3932/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3933/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3934/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3935/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3936/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3937/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3938/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3939/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3940/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3941/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3942/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3943/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3944/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3945/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3946/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4290\n",
      "Epoch: 3947/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 3948/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 3949/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 3950/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 3951/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 3952/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 3953/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 3954/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 3955/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 3956/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 3957/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 3958/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 3959/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 3960/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 3961/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 3962/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 3963/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 3964/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 3965/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 3966/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 3967/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 3968/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 3969/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 3970/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 3971/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 3972/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 3973/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 3974/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 3975/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3976/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3977/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3978/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3979/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3980/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3981/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3982/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3983/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3984/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3985/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3986/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3987/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3988/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3989/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4293\n",
      "Epoch: 3990/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 3991/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 3992/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 3993/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 3994/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 3995/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 3996/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 3997/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 3998/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 3999/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 4000/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 4001/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 4002/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 4003/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4294\n",
      "Epoch: 4004/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4005/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4006/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4007/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4008/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4009/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4010/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4011/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4012/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4013/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4014/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4015/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4016/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4017/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4018/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 4019/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 4020/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 4021/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 4022/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 4023/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 4024/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 4025/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 4026/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 4027/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 4028/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 4029/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 4030/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 4031/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 4032/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 4033/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4034/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4035/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4036/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4037/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4038/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4039/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4040/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4041/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4042/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4043/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4044/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4045/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4046/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4047/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4297\n",
      "Epoch: 4048/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 4049/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 4050/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 4051/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 4052/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 4053/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 4054/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 4055/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 4056/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 4057/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 4058/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 4059/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 4060/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 4061/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 4062/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4063/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4064/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4065/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4066/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4067/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4068/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4069/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4070/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4071/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4072/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4073/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4074/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4075/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4076/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4299\n",
      "Epoch: 4077/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 4078/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 4079/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 4080/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 4081/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 4082/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 4083/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 4084/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 4085/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 4086/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 4087/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 4088/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 4089/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 4090/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 4091/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4092/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4093/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4094/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4095/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4096/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4097/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4098/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4099/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4100/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4101/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4102/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4103/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4104/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4105/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4301\n",
      "Epoch: 4106/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 4107/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 4108/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 4109/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 4110/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 4111/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 4112/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 4113/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 4114/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 4115/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 4116/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 4117/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 4118/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 4119/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 4120/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4121/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4122/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4123/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4124/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4125/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4126/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4127/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4128/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4129/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4130/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4131/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4132/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4133/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4134/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4303\n",
      "Epoch: 4135/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 4136/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 4137/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 4138/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 4139/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 4140/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 4141/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 4142/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 4143/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 4144/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 4145/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 4146/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 4147/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 4148/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 4149/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4150/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4151/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4152/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4153/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4154/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4155/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4156/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4157/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4158/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4159/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4160/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4161/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4162/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4163/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 4164/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 4165/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 4166/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 4167/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 4168/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 4169/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 4170/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 4171/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 4172/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 4173/5000, Train Loss: 0.1245\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 4174/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 4175/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 4176/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 4177/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4306\n",
      "Epoch: 4178/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4179/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4180/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4181/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4182/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4183/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4184/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4185/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4186/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4187/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4188/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4189/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4190/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4191/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4192/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4307\n",
      "Epoch: 4193/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4194/5000, Train Loss: 0.1244\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4195/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4196/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4197/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4198/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4199/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4200/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4201/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4202/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4203/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4204/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4205/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4206/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4207/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 4208/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 4209/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 4210/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 4211/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 4212/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 4213/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 4214/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 4215/5000, Train Loss: 0.1243\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 4216/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 4217/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 4218/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 4219/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 4220/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 4221/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4309\n",
      "Epoch: 4222/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4223/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4224/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4225/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4226/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4227/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4228/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4229/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4230/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4231/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4232/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4233/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4234/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4235/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4236/5000, Train Loss: 0.1242\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4310\n",
      "Epoch: 4237/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 4238/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 4239/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 4240/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 4241/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 4242/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 4243/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 4244/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 4245/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 4246/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 4247/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 4248/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 4249/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 4250/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 4251/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4252/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4253/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4254/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4255/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4256/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4257/5000, Train Loss: 0.1241\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4258/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4259/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4260/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4261/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4262/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4263/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4264/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4265/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 4266/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4267/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4268/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4269/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4270/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4271/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4272/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4273/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4274/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4275/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4276/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4277/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4278/5000, Train Loss: 0.1240\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4279/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4280/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4313\n",
      "Epoch: 4281/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 4282/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 4283/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 4284/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 4285/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 4286/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 4287/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 4288/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 4289/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 4290/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 4291/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 4292/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 4293/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 4294/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4314\n",
      "Epoch: 4295/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4296/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4297/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4298/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4299/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4300/5000, Train Loss: 0.1239\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4301/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4302/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4303/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4304/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4305/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4306/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4307/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4308/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4309/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 4310/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4311/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4312/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4313/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4314/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4315/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4316/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4317/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4318/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4319/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4320/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4321/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4322/5000, Train Loss: 0.1238\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4323/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4324/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 4325/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 4326/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 4327/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 4328/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 4329/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 4330/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 4331/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 4332/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 4333/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 4334/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 4335/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 4336/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 4337/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 4338/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4317\n",
      "Epoch: 4339/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4340/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4341/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4342/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4343/5000, Train Loss: 0.1237\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4344/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4345/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4346/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4347/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4348/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4349/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4350/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4351/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4352/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4353/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 4354/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4355/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4356/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4357/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4358/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4359/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4360/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4361/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4362/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4363/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4364/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4365/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4366/5000, Train Loss: 0.1236\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4367/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4368/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4319\n",
      "Epoch: 4369/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4370/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4371/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4372/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4373/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4374/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4375/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4376/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4377/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4378/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4379/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4380/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4381/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4382/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4383/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 4384/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 4385/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 4386/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 4387/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 4388/5000, Train Loss: 0.1235\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 4389/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 4390/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 4391/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 4392/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 4393/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 4394/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 4395/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 4396/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 4397/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 4398/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4399/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4400/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4401/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4402/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4403/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4404/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4405/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4406/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4407/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4408/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4409/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4410/5000, Train Loss: 0.1234\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4411/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4412/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4322\n",
      "Epoch: 4413/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4414/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4415/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4416/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4417/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4418/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4419/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4420/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4421/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4422/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4423/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4424/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4425/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4426/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4427/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4323\n",
      "Epoch: 4428/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4429/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4430/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4431/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4432/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4433/5000, Train Loss: 0.1233\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4434/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4435/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4436/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4437/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4438/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4439/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4440/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4441/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4442/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 4443/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 4444/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 4445/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 4446/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 4447/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 4448/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 4449/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 4450/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 4451/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 4452/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 4453/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 4454/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 4455/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 4456/5000, Train Loss: 0.1232\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4325\n",
      "Epoch: 4457/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4458/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4459/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4460/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4461/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4462/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4463/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4464/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4465/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4466/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4467/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4468/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4469/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4470/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4471/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4326\n",
      "Epoch: 4472/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4473/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4474/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4475/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4476/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4477/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4478/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4479/5000, Train Loss: 0.1231\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4480/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4481/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4482/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4483/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4484/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4485/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4486/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 4487/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4488/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4489/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4490/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4491/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4492/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4493/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4494/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4495/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4496/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4497/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4498/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4499/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4500/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4501/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 4502/5000, Train Loss: 0.1230\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4503/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4504/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4505/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4506/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4507/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4508/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4509/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4510/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4511/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4512/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4513/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4514/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4515/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4516/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 4517/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4518/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4519/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4520/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4521/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4522/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4523/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4524/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4525/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4526/5000, Train Loss: 0.1229\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4527/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4528/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4529/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4530/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4531/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4330\n",
      "Epoch: 4532/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4533/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4534/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4535/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4536/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4537/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4538/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4539/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4540/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4541/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4542/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4543/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4544/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4545/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4546/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4331\n",
      "Epoch: 4547/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4548/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4549/5000, Train Loss: 0.1228\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4550/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4551/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4552/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4553/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4554/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4555/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4556/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4557/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4558/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4559/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4560/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4561/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 4562/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 4563/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 4564/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 4565/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 4566/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 4567/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 4568/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 4569/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 4570/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 4571/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 4572/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 4573/5000, Train Loss: 0.1227\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 4574/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 4575/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4333\n",
      "Epoch: 4576/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4577/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4578/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4579/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4580/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4581/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4582/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4583/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4584/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4585/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4586/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4587/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4588/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4589/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4590/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4334\n",
      "Epoch: 4591/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4592/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4593/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4594/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4595/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4596/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4597/5000, Train Loss: 0.1226\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4598/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4599/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4600/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4601/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4602/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4603/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4604/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4605/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 4606/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4607/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4608/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4609/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4610/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4611/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4612/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4613/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4614/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4615/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4616/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4617/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4618/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4619/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4620/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 4621/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4622/5000, Train Loss: 0.1225\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4623/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4624/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4625/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4626/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4627/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4628/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4629/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4630/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4631/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4632/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4633/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4634/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4635/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4337\n",
      "Epoch: 4636/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4637/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4638/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4639/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4640/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4641/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4642/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4643/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4644/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4645/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4646/5000, Train Loss: 0.1224\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4647/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4648/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4649/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4650/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 4651/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4652/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4653/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4654/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4655/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4656/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4657/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4658/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4659/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4660/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4661/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4662/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4663/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4664/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4665/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4339\n",
      "Epoch: 4666/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4667/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4668/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4669/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4670/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4671/5000, Train Loss: 0.1223\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4672/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4673/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4674/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4675/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4676/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4677/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4678/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4679/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4680/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 4681/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4682/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4683/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4684/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4685/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4686/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4687/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4688/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4689/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4690/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4691/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4692/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4693/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4694/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4695/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4341\n",
      "Epoch: 4696/5000, Train Loss: 0.1222\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4697/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4698/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4699/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4700/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4701/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4702/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4703/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4704/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4705/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4706/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4707/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4708/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4709/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4710/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4711/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4342\n",
      "Epoch: 4712/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4713/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4714/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4715/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4716/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4717/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4718/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4719/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4720/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4721/5000, Train Loss: 0.1221\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4722/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4723/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4724/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4725/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4726/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 4727/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4728/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4729/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4730/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4731/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4732/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4733/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4734/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4735/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4736/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4737/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4738/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4739/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4740/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4741/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 4742/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4743/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4744/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4745/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4746/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4747/5000, Train Loss: 0.1220\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4748/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4749/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4750/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4751/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4752/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4753/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4754/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4755/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4756/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4345\n",
      "Epoch: 4757/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4758/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4759/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4760/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4761/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4762/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4763/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4764/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4765/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4766/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4767/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4768/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4769/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4770/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4771/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 4772/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4773/5000, Train Loss: 0.1219\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4774/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4775/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4776/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4777/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4778/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4779/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4780/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4781/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4782/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4783/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4784/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4785/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4786/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4347\n",
      "Epoch: 4787/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4788/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4789/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4790/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4791/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4792/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4793/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4794/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4795/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4796/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4797/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4798/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4799/5000, Train Loss: 0.1218\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4800/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4801/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 4802/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4803/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4804/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4805/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4806/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4807/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4808/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4809/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4810/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4811/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4812/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4813/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4814/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4815/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4816/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4349\n",
      "Epoch: 4817/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4818/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4819/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4820/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4821/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4822/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4823/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4824/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4825/5000, Train Loss: 0.1217\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4826/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4827/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4828/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4829/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4830/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4831/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4832/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4350\n",
      "Epoch: 4833/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4834/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4835/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4836/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4837/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4838/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4839/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4840/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4841/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4842/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4843/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4844/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4845/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4846/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4847/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 4848/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4849/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4850/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4851/5000, Train Loss: 0.1216\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4852/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4853/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4854/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4855/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4856/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4857/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4858/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4859/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4860/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4861/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4862/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 4863/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4864/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4865/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4866/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4867/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4868/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4869/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4870/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4871/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4872/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4873/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4874/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4875/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4876/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4877/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 4878/5000, Train Loss: 0.1215\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4879/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4880/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4881/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4882/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4883/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4884/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4885/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4886/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4887/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4888/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4889/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4890/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4891/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4892/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4893/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4354\n",
      "Epoch: 4894/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4895/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4896/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4897/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4898/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4899/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4900/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4901/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4902/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4903/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4904/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4905/5000, Train Loss: 0.1214\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4906/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4907/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4908/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 4909/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4910/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4911/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4912/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4913/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4914/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4915/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4916/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4917/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4918/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4919/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4920/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4921/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4922/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4923/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 4924/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4925/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4926/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4927/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4928/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4929/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4930/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4931/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4932/5000, Train Loss: 0.1213\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4933/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4934/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4935/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4936/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4937/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4938/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4939/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4357\n",
      "Epoch: 4940/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4941/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4942/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4943/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4944/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4945/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4946/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4947/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4948/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4949/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4950/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4951/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4952/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4953/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4954/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 4955/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4956/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4957/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4958/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4959/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4960/5000, Train Loss: 0.1212\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4961/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4962/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4963/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4964/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4965/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4966/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4967/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4968/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4969/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4359\n",
      "Epoch: 4970/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4971/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4972/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4973/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4974/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4975/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4976/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4977/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4978/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4979/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4980/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4981/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4982/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4983/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4984/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4985/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 4986/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 4987/5000, Train Loss: 0.1211\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 4988/5000, Train Loss: 0.1210\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 4989/5000, Train Loss: 0.1210\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 4990/5000, Train Loss: 0.1210\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 4991/5000, Train Loss: 0.1210\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 4992/5000, Train Loss: 0.1210\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 4993/5000, Train Loss: 0.1210\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 4994/5000, Train Loss: 0.1210\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 4995/5000, Train Loss: 0.1210\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 4996/5000, Train Loss: 0.1210\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 4997/5000, Train Loss: 0.1210\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 4998/5000, Train Loss: 0.1210\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 4999/5000, Train Loss: 0.1210\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 5000/5000, Train Loss: 0.1210\n",
      "Accuracy on Val set: 80.00%\tLoss on Val set: 0.4361\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[-15.77456412,   0.12468115,   0.12827881]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from LogisticRegression import LogisticRegression\n",
    "\n",
    "epochs = 5000\n",
    "alpha = 0.01\n",
    "logistic_reg = LogisticRegression(x=train_x,y=train_y_ex,val_x=val_x,val_y=val_y_ex,epoch=epochs,lr=alpha)\n",
    "theta,train_loss,val_loss = logistic_reg.train()\n",
    "theta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看准确率、损失和F1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 90.00%\n",
      "My F1 Score: 0.9333\n"
     ]
    }
   ],
   "source": [
    "acc = logistic_reg.test(val_x,val_y_ex)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(acc * 100))\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_true=val_y_ex,y_pred=logistic_reg.predict(val_x))\n",
    "print(\"My F1 Score: {:.4f}\".format(f1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "调用库函数验证"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Accuracy: 95.00%\n",
      "Sklearn Val Loss: 0.5650\n",
      "SKlearn Parameters:  [[-23.4625874    0.18548703   0.19200996]]\n",
      "Sklearn F1 Score: 0.9677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sk_lr = LogisticRegression(max_iter=50000)\n",
    "sk_lr.fit(train_x,train_y)\n",
    "sk_pred = sk_lr.predict(val_x)\n",
    "count = np.sum(np.equal(sk_pred,val_y))\n",
    "sk_acc = count/val_y.shape[0]\n",
    "sk_prob = sk_lr.predict_proba(val_x)\n",
    "\n",
    "from LogisticRegression import bce_loss\n",
    "sk_loss = bce_loss(sk_prob[:,1], val_y_ex)\n",
    "sk_theta = np.array([[sk_lr.intercept_[0],sk_lr.coef_[0,0],sk_lr.coef_[0,1]]])\n",
    "sk_f1 = f1_score(y_true=val_y_ex,y_pred=sk_pred)\n",
    "print(\"Sklearn Accuracy: {:.2f}%\".format(sk_acc * 100))\n",
    "print(\"Sklearn Val Loss: {:.4f}\".format(sk_loss))\n",
    "print(\"SKlearn Parameters: \",sk_theta)\n",
    "print(\"Sklearn F1 Score: {:.4f}\".format(sk_f1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "决策边界可视化"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[122.97092344  -0.97195435  -1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef = -(theta / theta[0,2])  # find the\n",
    "coef1 = -(sk_theta / sk_theta[0,2])\n",
    "print(coef)\n",
    "\n",
    "x = np.arange(data[:,0].min(), data[:,0].max(), step=1)\n",
    "y = coef[0,0] + coef[0,1]*x\n",
    "y1 = coef1[0,0] + coef[0,1]*x\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(x,y,label=\"My Prediction\")\n",
    "ax.plot(x,y1,label=\"Sklearn\")\n",
    "ax.scatter(x=positive_data[:, 0], y=positive_data[:, 1], s=10, color=\"red\",label=\"positive\")\n",
    "ax.scatter(x=negative_data[:, 0], y=negative_data[:, 1], s=10, color=\"blue\",label=\"negative\")\n",
    "ax.set_title(\"Decision Boundary\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "画出训练过程"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAK9CAYAAABYVS0qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAABqzElEQVR4nO3deXwU9f3H8fcmIQk5CVfCEe77Rq4CIipRLhEEKlIQQSvF26KtYhVQ2kLRUu8LDxSrgChKFTkMgogoCHJHPLiCkHBJAgRy7fz+mN8mLOTOJjO7+3o+Ht/HzM7M7n7WTm3f+R7jMAzDEAAAAAAAsFyA1QUAAAAAAAATIR0AAAAAAJsgpAMAAAAAYBOEdAAAAAAAbIKQDgAAAACATRDSAQAAAACwCUI6AAAAAAA2QUgHAAAAAMAmCOkAAAAAANgEIR0AAB81fvx4NWrUyOoyAABAKRDSAQCoZA6Ho0RtzZo1VpdaoNTUVD344INq1aqVwsLCFB4eri5duujvf/+7Tp06ZXV5AAB4NYdhGIbVRQAA4E/eeecdt9dvv/22Vq1apfnz57sdv+aaaxQbG1vm78nOzpbT6VRISEiZP+NimzZt0qBBg3TmzBmNHTtWXbp0kSR99913WrBggXr16qWVK1d67PsAAPA3hHQAACx2991364UXXlBx/5OckZGhsLCwSqrqUqdOnVK7du2Uk5OjNWvWqFWrVm7nU1NTNXfuXD366KPl/q6zZ88qPDy83J8DAIC3Ybg7AAA2dOWVV6pdu3bavHmzrrjiCoWFhemRRx6RJH388ccaPHiw6tatq5CQEDVt2lQzZsxQbm6u22dcPCd9//79cjgceuqpp/Tqq6+qadOmCgkJUbdu3bRp06Zia3rllVf066+/as6cOZcEdEmKjY11C+gOh0PTp0+/5LpGjRpp/Pjxea/nzZsnh8OhtWvX6s4771Tt2rVVv359LV68OO94QbU4HA7t3Lkz79gPP/ygkSNHqnr16goNDVXXrl21dOnSYn8XAAB2EmR1AQAAoGAnTpzQwIEDddNNN2ns2LF5Q9/nzZuniIgITZ48WREREVq9erWmTp2q9PR0Pfnkk8V+7rvvvqvTp0/rT3/6kxwOh2bPnq3hw4dr7969qlKlSqHvW7p0qapWraqRI0d67Dde6M4771StWrU0depUnT17VoMHD1ZERIQWLVqkvn37ul27cOFCtW3bVu3atZMk7dq1S71791a9evX08MMPKzw8XIsWLdKwYcP0wQcf6IYbbqiQmgEA8DRCOgAANpWSkqKXX35Zf/rTn9yOv/vuu6patWre60mTJmnSpEl68cUX9fe//73YOegHDx7UTz/9pJiYGElSy5YtNXToUK1YsULXXXddoe9LSkpSixYtFBwcXI5fVbjq1asrMTFRgYGBeceGDBmixYsX69lnn807npKSorVr17r10t93331q0KCBNm3alPf777zzTl1++eV66KGHCOkAAK/BcHcAAGwqJCREEyZMuOT4hQH99OnTOn78uPr06aOMjAz98MMPxX7uqFGj8gK6JPXp00eStHfv3iLfl56ersjIyJKWX2q33367W0CXzFqPHj3qttL94sWL5XQ6NWrUKEnSyZMntXr1at144415/zyOHz+uEydOqH///vrpp5/066+/VljdAAB4Ej3pAADYVL169Qrstd61a5ceffRRrV69Wunp6W7n0tLSiv3cBg0auL12BfbffvutyPdFRUXp9OnTxX5+WTVu3PiSYwMGDFB0dLQWLlyofv36STKHunfq1EktWrSQJP38888yDEOPPfaYHnvssQI/++jRo6pXr16F1Q4AgKcQ0gEAsKkLe8xdTp06pb59+yoqKkpPPPGEmjZtqtDQUG3ZskUPPfSQnE5nsZ97cW+1S3Gry7dq1Upbt25VVlZWuYa8X7zAnUtBvzckJETDhg3TkiVL9OKLLyo1NVXr16/XP//5z7xrXL/5wQcfVP/+/Qv87GbNmpW5XgAAKhMhHQAAL7JmzRqdOHFCH374oa644oq84/v27avw7x4yZIg2bNigDz74QKNHjy72+piYGJ06dcrtWFZWlo4cOVKq7x01apTeeustJSYmKikpSYZh5A11l6QmTZpIkqpUqaKEhIRSfTYAAHbDnHQAALyIqxf8wl7vrKwsvfjiixX+3ZMmTVKdOnX0wAMP6Mcff7zk/NGjR/X3v/8973XTpk315Zdful3z6quvFtqTXpiEhARVr15dCxcu1MKFC9W9e3e3ofG1a9fWlVdeqVdeeaXAPwAcO3asVN8HAICV6EkHAMCL9OrVSzExMbrlllt07733yuFwaP78+cUOVfeEmJgYLVmyRIMGDVKnTp00duxYdenSRZK0ZcsWvffee+rZs2fe9X/84x81adIkjRgxQtdcc422bdumFStWqGbNmqX63ipVqmj48OFasGCBzp49q6eeeuqSa1544QVdfvnlat++vW6//XY1adJEqamp2rBhgw4dOqRt27aV78cDAFBJCOkAAHiRGjVq6JNPPtEDDzygRx99VDExMRo7dqz69etX6HxsT+rRo4d27typJ598Up9++qnmz5+vgIAAtW7dWg8//LDuvvvuvGtvv/127du3T6+//rqWL1+uPn36aNWqVXkLwJXGqFGj9Nprr8nhcOjGG2+85HybNm303Xff6fHHH9e8efN04sQJ1a5dW507d9bUqVPL9ZsBAKhMDqMy/vQOAAAAAACKxZx0AAAAAABsgpAOAAAAAIBNENIBAAAAALAJQjoAAAAAADZBSAcAAAAAwCYI6QAAAAAA2ITfPSfd6XTq8OHDioyMlMPhsLocAAAAAICPMwxDp0+fVt26dRUQUHRfud+F9MOHDys+Pt7qMgAAAAAAfiY5OVn169cv8hq/C+mRkZGSzH84UVFRFlcDAAAAAPB16enpio+Pz8ujRfG7kO4a4h4VFUVIBwAAAABUmpJMuWbhOAAAAAAAbIKQDgAAAACATRDSAQAAAACwCb+bk14ShmEoJydHubm5VpcCD6hSpYoCAwOtLgMAAAAAikVIv0hWVpaOHDmijIwMq0uBhzgcDtWvX18RERFWlwIAAAAARSKkX8DpdGrfvn0KDAxU3bp1FRwcXKLV92BfhmHo2LFjOnTokJo3b06POgAAAABbI6RfICsrS06nU/Hx8QoLC7O6HHhIrVq1tH//fmVnZxPSAQAAANgaC8cVICCAfyy+hNEQAAAAALwFaRQAAAAAAJsgpAMAAAAAYBOEdBSqUaNGevrpp60uAwAAAAD8BiHdBzgcjiLb9OnTy/S5mzZt0sSJE8tV25VXXqn777+/XJ8BAAAAAP6C1d19wJEjR/L2Fy5cqKlTp2rPnj15xy58PrhhGMrNzVVQUPH/0deqVcuzhQIAAAAAikRPenEMQzp71ppmGCUqMS4uLq9FR0fL4XDkvf7hhx8UGRmpzz77TF26dFFISIi++uor/fLLLxo6dKhiY2MVERGhbt266fPPP3f73IuHuzscDr322mu64YYbFBYWpubNm2vp0qXl+sf7wQcfqG3btgoJCVGjRo3073//2+38iy++qObNmys0NFSxsbEaOXJk3rnFixerffv2qlq1qmrUqKGEhASdPXu2XPUAAAAAgJXoSS9ORoZ0QU90pTpzRgoP98hHPfzww3rqqafUpEkTxcTEKDk5WYMGDdI//vEPhYSE6O2339aQIUO0Z88eNWjQoNDPefzxxzV79mw9+eSTeu655zRmzBgdOHBA1atXL3VNmzdv1o033qjp06dr1KhR+vrrr3XnnXeqRo0aGj9+vL777jvde++9mj9/vnr16qWTJ09q3bp1kszRA6NHj9bs2bN1ww036PTp01q3bp2MEv5hAwAAAADsiJDuJ5544gldc801ea+rV6+ujh075r2eMWOGlixZoqVLl+ruu+8u9HPGjx+v0aNHS5L++c9/6tlnn9XGjRs1YMCAUtc0Z84c9evXT4899pgkqUWLFtq9e7eefPJJjR8/XgcPHlR4eLiuu+46RUZGqmHDhurcubMkM6Tn5ORo+PDhatiwoSSpffv2pa4BAAAAAOyEkF6csDCzR9uq7/aQrl27ur0+c+aMpk+frk8//TQv8J47d04HDx4s8nM6dOiQtx8eHq6oqCgdPXq0TDUlJSVp6NChbsd69+6tp59+Wrm5ubrmmmvUsGFDNWnSRAMGDNCAAQPyhtp37NhR/fr1U/v27dW/f39de+21GjlypGJiYspUCwAAAADYAXPSi+NwmEPOrWgOh8d+RvhFw+YffPBBLVmyRP/85z+1bt06bd26Ve3bt1dWVlaRn1OlSpWL/vE45HQ6PVbnhSIjI7Vlyxa99957qlOnjqZOnaqOHTvq1KlTCgwM1KpVq/TZZ5+pTZs2eu6559SyZUvt27evQmoBAAAAgMpASPdT69ev1/jx43XDDTeoffv2iouL0/79+yu1htatW2v9+vWX1NWiRQsFBgZKkoKCgpSQkKDZs2dr+/bt2r9/v1avXi3J/ANB79699fjjj+v7779XcHCwlixZUqm/AQAAAAA8ieHufqp58+b68MMPNWTIEDkcDj322GMV1iN+7Ngxbd261e1YnTp19MADD6hbt26aMWOGRo0apQ0bNuj555/Xiy++KEn65JNPtHfvXl1xxRWKiYnRsmXL5HQ61bJlS3377bdKTEzUtddeq9q1a+vbb7/VsWPH1Lp16wr5DQAAAABQGQjpfmrOnDm69dZb1atXL9WsWVMPPfSQ0tPTK+S73n33Xb377rtux2bMmKFHH31UixYt0tSpUzVjxgzVqVNHTzzxhMaPHy9Jqlatmj788ENNnz5d58+fV/PmzfXee++pbdu2SkpK0pdffqmnn35a6enpatiwof79739r4MCBFfIbAAAAAKAyOAw/e2ZVenq6oqOjlZaWpqioKLdz58+f1759+9S4cWOFhoZaVCE8jf9cAQAAAFipqBx6MeakAwAAAABgE4R0m8rKkk6elM6etboSAAAAAEBlIaTbVGqqtHevdOKE1ZUAAAAAACoLId2mwsLMbUaGtXUAAAAAACoPId2mLgzp/rW0HwAAAAD4L0K6TYWGSgEBktMpnT9vdTUAAAAAgMpASLcph4Mh7wAAAADgbwjpNkZIBwAAAAD/Qki3MVdI5zFsAAAAAOAfCOk2Fh5ubitr8bgrr7xS999/f8V/EQAAAACgQIR0G7tw8bjMzMKvGzJkiAYMGFDguXXr1snhcGj79u3lrmfevHmqVq1auT8HAAAAAFAwQrqNORxS1armflFD3m+77TatWrVKhw4duuTcm2++qa5du6pDhw4VVCUAAAAAwFMI6cUwDDMgW9EMo2SLx1133XWqVauW5s2b53b8zJkzev/993XbbbfpxIkTGj16tOrVq6ewsDC1b99e7733nkf/WR08eFBDhw5VRESEoqKidOONNyo1NTXv/LZt23TVVVcpMjJSUVFR6tKli7777jtJ0oEDBzRkyBDFxMQoPDxcbdu21bJlyzxaHwAAAADYXZDVBdhdRoYUEWHNd585Y85LP3as6JAeFBSkcePGad68efrb3/4mh8MhSXr//feVm5ur0aNH68yZM+rSpYseeughRUVF6dNPP9XNN9+spk2bqnv37uWu1el05gX0tWvXKicnR3fddZdGjRqlNWvWSJLGjBmjzp0766WXXlJgYKC2bt2qKlWqSJLuuusuZWVl6csvv1R4eLh2796tCKv+wQMAAACARQjpNndhT7phmEPgC3LrrbfqySef1Nq1a3XllVdKMoe6jxgxQtHR0YqOjtaDDz6Yd/0999yjFStWaNGiRR4J6YmJidqxY4f27dun+Ph4SdLbb7+ttm3batOmTerWrZsOHjyov/zlL2rVqpUkqXnz5nnvP3jwoEaMGKH27dtLkpo0aVLumgAAAADA2xDSixEWZvZoW/XdrmCem2suHhcaWvC1rVq1Uq9evfTGG2/oyiuv1M8//6x169bpiSeekCTl5ubqn//8pxYtWqRff/1VWVlZyszMVJjrrwDllJSUpPj4+LyALklt2rRRtWrVlJSUpG7dumny5Mn64x//qPnz5yshIUG///3v1bRpU0nSvffeqzvuuEMrV65UQkKCRowYwTx6AAAAAH6HOenFcDjMIedWNIfDXN29JPPSJXMBuQ8++ECnT5/Wm2++qaZNm6pv376SpCeffFLPPPOMHnroIX3xxRfaunWr+vfvr6ysrAr+J5hv+vTp2rVrlwYPHqzVq1erTZs2WrJkiSTpj3/8o/bu3aubb75ZO3bsUNeuXfXcc89VWm0AAAAAYAeEdC/gel56USu8S9KNN96ogIAAvfvuu3r77bd166235s1PX79+vYYOHaqxY8eqY8eOatKkiX788UeP1di6dWslJycrOTk579ju3bt16tQptWnTJu9YixYt9Oc//1krV67U8OHD9eabb+adi4+P16RJk/Thhx/qgQce0Ny5cz1WHwAAAAB4A4a7ewFXSC9u2H1ERIRGjRqlKVOmKD09XePHj88717x5cy1evFhff/21YmJiNGfOHKWmproF6JLIzc3V1q1b3Y6FhIQoISFB7du315gxY/T0008rJydHd955p/r27auuXbvq3Llz+stf/qKRI0eqcePGOnTokDZt2qQRI0ZIku6//34NHDhQLVq00G+//aYvvvhCrVu3LlVtAAAAAODtCOlewBXSMzIkp9McAl+Y2267Ta+//roGDRqkunXr5h1/9NFHtXfvXvXv319hYWGaOHGihg0bprS0tFLVcubMGXXu3NntWNOmTfXzzz/r448/1j333KMrrrhCAQEBGjBgQN6Q9cDAQJ04cULjxo1TamqqatasqeHDh+vxxx+XZIb/u+66S4cOHVJUVJQGDBig//znP6WqDQAAAAC8ncMwDMPqIipTenq6oqOjlZaWpqioKLdz58+f1759+9S4cWOFFrZCmwUMQ9q61Vw8rnXr/NCOkrHrf64AAAAA/ENROfRizEn3Aq7F66Ti56UDAAAAALwXId1LRESYW0I6AAAAAPguQrqXKOnicQAAAAAA70VI9xKukJ6ZKeXkWFsLAAAAAKBiENILYMe19IKCpJAQc58h76Vjx/88AQAAAKAghPQLVKlSRZKUkZFhcSUFY/G4ssnKypJkPgYOAAAAAOyM56RfIDAwUNWqVdPRo0clSWFhYXI4HBZXlc/Vk56WJlWvbm0t3sLpdOrYsWMKCwtTUBC3OwAAAAB7I7VcJC4uTpLygrqdZGZKx49LJ09aXYl3CQgIUIMGDWz1BxcAAAAAKAgh/SIOh0N16tRR7dq1lZ2dbXU5brKypFGjzLC+bJnUpInVFXmH4OBgBQQwswMAAACA/RHSCxEYGGi7OcyhoVKdOtLatdL69VKbNlZXBAAAAADwJLoXvczll5vbr76ytg4AAAAAgOcR0r1Mnz7mlpAOAAAAAL6HkO5levaUAgKkvXulw4etrgYAAAAA4EmEdC8TFSV16GDu05sOAAAAAL6FkO6FmJcOAAAAAL6JkO6FmJcOAAAAAL6JkO6Fevc2t9u2Senp1tYCAAAAAPAcQroXqldPatxYcjqlDRusrgYAAAAA4CmEdC/FvHQAAAAA8D2EdC/lmpf+5ZfW1gEAAAAA8BxCupe68kpz+803UkaGpaUAAAAAADyEkO6lmjWT6teXsrKkr7+2uhoAAAAAgCcQ0r2UwyFdfbW5v3q1tbUAAAAAADyDkO7FXCH9iy+srQMAAAAA4BmEdC921VXmdtMmnpcOAAAAAL6AkO7FGjSQmjaVcnOldeusrgYAAAAAUF6EdC/HvHQAAAAA8B2EdC/HvHQAAAAA8B2EdC/nel761q3SiRNWVgIAAAAAKC9CupeLi5PatJEMQ1qzxupqAAAAAADlQUj3Af36mdtVq6ytAwAAAABQPoR0HzBggLldvtzsUQcAAAAAeCdCug/o21cKCZEOHJD27LG6GgAAAABAWRHSfUB4uHTFFeb+8uXW1gIAAAAAKDtCuo/o39/crlhhbR0AAAAAgLIjpPsI17z0NWukc+csLQUAAAAAUEaEdB/Rpo1Uv750/rz05ZdWVwMAAAAAKAtCuo9wONxXeQcAAAAAeB9Cug9xzUsnpAMAAACAdyKk+5CEBCkwUPrhB2n/fqurAQAAAACUFiHdh1SrJvXube7/73+WlgIAAAAAKANCuo8ZOtTcLl1qbR0AAAAAgNIjpPuYIUPM7Zo1UlqapaUAAAAAAEqJkO5jmjeXWreWcnKkzz6zuhoAAAAAQGkQ0n3Q9debW4a8AwAAAIB3IaT7IFdIX7ZMys62thYAAAAAQMkR0n1Qjx5SrVrmnPR166yuBgAAAABQUrYI6S+88IIaNWqk0NBQ9ejRQxs3biz02nnz5snhcLi10NDQSqzW/gIDpeuuM/cZ8g4AAAAA3sPykL5w4UJNnjxZ06ZN05YtW9SxY0f1799fR48eLfQ9UVFROnLkSF47cOBAJVbsHVxD3pcskQzD2loAAAAAACVjeUifM2eObr/9dk2YMEFt2rTRyy+/rLCwML3xxhuFvsfhcCguLi6vxcbGVmLF3qF/fyk8XDp4UNq0yepqAAAAAAAlYWlIz8rK0ubNm5WQkJB3LCAgQAkJCdqwYUOh7ztz5owaNmyo+Ph4DR06VLt27Sr02szMTKWnp7s1f1C1av6Q9/fft7YWAAAAAEDJWBrSjx8/rtzc3Et6wmNjY5WSklLge1q2bKk33nhDH3/8sd555x05nU716tVLhw4dKvD6mTNnKjo6Oq/Fx8d7/HfY1e9/b27ff58h7wAAAADgDSwf7l5aPXv21Lhx49SpUyf17dtXH374oWrVqqVXXnmlwOunTJmitLS0vJacnFzJFVtn4EApLEw6cED67jurqwEAAAAAFMfSkF6zZk0FBgYqNTXV7Xhqaqri4uJK9BlVqlRR586d9fPPPxd4PiQkRFFRUW7NX4SFMeQdAAAAALyJpSE9ODhYXbp0UWJiYt4xp9OpxMRE9ezZs0SfkZubqx07dqhOnToVVaZXu/FGc7toEUPeAQAAAMDuLB/uPnnyZM2dO1dvvfWWkpKSdMcdd+js2bOaMGGCJGncuHGaMmVK3vVPPPGEVq5cqb1792rLli0aO3asDhw4oD/+8Y9W/QRbY8g7AAAAAHiPIKsLGDVqlI4dO6apU6cqJSVFnTp10vLly/MWkzt48KACAvL/lvDbb7/p9ttvV0pKimJiYtSlSxd9/fXXatOmjVU/wdZcQ94XLZIWLpS6dbO6IgAAAABAYRyG4V+DoNPT0xUdHa20tDS/mZ/+0UfSDTdIdeuaz00PDLS6IgAAAADwH6XJoZYPd0fFGzRIql5dOnxYWr3a6moAAAAAAIUhpPuB4GBp1Chzf/58a2sBAAAAABSOkO4nbr7Z3H74oXT2rLW1AAAAAAAKRkj3E7/7ndS0qRnQlyyxuhoAAAAAQEEI6X7C4ZDGjjX333nH2loAAAAAAAUjpPsRV0hftUo6csTaWgAAAAAAlyKk+5FmzaSePSWnk950AAAAALAjQrqfufVWczt3rmQY1tYCAAAAAHBHSPczN90kRURIP/0krV1rdTUAAAAAgAsR0v1MRIT0hz+Y+3PnWlsLAAAAAMAdId0PTZxobhcvlk6csLYWAAAAAEA+Qrof6tJF6txZysqS5s+3uhoAAAAAgAsh3U+5etNffZUF5AAAAADALgjpfuoPf5DCwqSkJOmrr6yuBgAAAAAgEdL9VlRU/gJyzz5rbS0AAAAAABMh3Y/de6+5XbJEOnjQ2loAAAAAAIR0v9a+vXTVVVJurvTii1ZXAwAAAAAgpPu5++4zt6++KmVkWFsLAAAAAPg7Qrqfu+46qXFj6bffpHfesboaAAAAAPBvhHQ/Fxgo3X23uf/sszyODQAAAACsREiHbr1VCg+Xdu2SVqywuhoAAAAA8F+EdKhaNWniRHN/1ixLSwEAAAAAv0ZIhyRp8mSpShVp7VppwwarqwEAAAAA/0RIhySpfn3p5pvN/Zkzra0FAAAAAPwVIR15/vpXyeGQ/vc/aedOq6sBAAAAAP9DSEeeli2lESPM/X/9y9paAAAAAMAfEdLhZsoUc/vee9LPP1tbCwAAAAD4G0I63Fx2mTR4sJSbKz3+uNXVAAAAAIB/IaTjEk88YW7/+19p925rawEAAAAAf0JIxyUuu0waPlwyDGn6dKurAQAAAAD/QUhHgR5/3Fzp/f33pa1bra4GAAAAAPwDIR0FatdOGjXK3J861dpaAAAAAMBfENJRqOnTpcBA87npa9daXQ0AAAAA+D5COgrVsqU0caK5P3my5HRaWw8AAAAA+DpCOoo0fboUGSlt2WKu9g4AAAAAqDiEdBSpdm3pkUfM/UcekTIyrK0HAAAAAHwZIR3Fuv9+qWFD6dAhac4cq6sBAAAAAN9FSEexQkOlmTPN/VmzpORka+sBAAAAAF9FSEeJ3HST1Lu3dPas2bMOAAAAAPA8QjpKxOGQXnrJfCTbhx9Ky5ZZXREAAAAA+B5COkqsffv8XvR77pHOnbO0HAAAAADwOYR0lMq0aVK9etLevfnz1AEAAAAAnkFIR6lERkrPPGPuz5ol7dxpbT0AAAAA4EsI6Si14cOlIUOk7Gxp/HgpJ8fqigAAAADANxDSUWoOh/Tyy1K1atLmzdKTT1pdEQAAAAD4BkI6yqRuXenZZ8396dOlXbssLQcAAAAAfAIhHWU2dqx03XVSVpY57D072+qKAAAAAMC7EdJRZg6H9Mor5rD3774zV34HAAAAAJQdIR3lUreuNHeuuT9rlpSYaG09AAAAAODNCOkot5EjpYkTJcOQbr5ZOnbM6ooAAAAAwDsR0uER//mP1Lq1dOSIdOutZmAHAAAAAJQOIR0eERYmLVgghYRIn3wizZ5tdUUAAAAA4H0I6fCYDh2kZ54x9x95RFq1ytp6AAAAAMDbENLhURMnmsPdnU7pppuk/futrggAAAAAvAchHR7lcEgvvCB16yadPCndcIOUkWF1VQAAAADgHQjp8LjQUOmDD6RataStW6Xx482edQAAAABA0QjpqBDx8dLixVKVKtL770tTplhdEQAAAADYHyEdFeaKK6Q33jD3Z8+WXnnF2noAAAAAwO4I6ahQY8dKTzxh7t91l/TZZ9bWAwAAAAB2RkhHhXv0UXNeem6uNHKktH691RUBAAAAgD0R0lHhHA5zqPuAAeZK74MGSVu2WF0VAAAAANgPIR2VIjjYXPG9Tx8pPV3q319KSrK6KgAAAACwF0I6Kk1YmPTJJ1LXrtLx41JCgvTjj1ZXBQAAAAD2QUhHpYqKkpYvl9q1kw4flvr2lXbvtroqAAAAALAHQjoqXY0aUmKi1KGDlJJiBvVt26yuCgAAAACsR0iHJWrXlr74In/o+1VXSZs2WV0VAAAAAFiLkA7LVK8uff651LOn9NtvZlBftszqqgAAAADAOoR0WCo6Wlq5UrrmGunsWen666W5c62uCgAAAACsQUiH5SIipE8/lW65RcrNlSZOlB59VDIMqysDAAAAgMpFSIctVKkivfmmNHWq+fof/5BuusnsXQcAAAAAf0FIh204HNLjj5vD3YOCpEWLpF69pL17ra4MAAAAACoHIR2288c/SqtXmyvAb98udetmLjAHAAAAAL6OkA5b6tNH2rzZDOgnT0r9+0vTpkk5OVZXBgAAAAAVh5AO26pfX/ryS+m22ySnU3riCenqq6XkZKsrAwAAAICKQUiHrYWGSq+9Jv33v1JkpLRundSxo7RkidWVAQAAALCSYZgLTaemWl2JZzkMw78edJWenq7o6GilpaUpKirK6nJQCr/8Yq74/t135uuxY6VnnpGqV7e2LgAAAAAlk5kpnT7tmXbmjDni1vW5wcHW/railCaHEtLhVbKypMcek556yvwvZGys9PLL0rBhVlcGAAAA+J7cXM+F6tOnpezsiqnzxAl7d94R0otASPcN334rTZggJSWZr2+6SfrPf6S4OGvrAgAAAKxkGFJGhmcCdXq6dO5cxdRZtao5nfXCFhV16bHiWkSEFBYmBdh8IjchvQiEdN9x/rz5XPXZs81e9agoc3G5u+4yn7MOAAAAeIOKGgLuSVWqlD5AFxWs/e3/rxPSi0BI9z3ffSfdeae0aZP5un176YUXzMe4AQAAAJ7mDUPAHQ4zDBcUksvSYx0S4vka/QkhvQiEdN/kdEqvvy49/LD5XHVJGjlS+sc/pBYtrK0NAAAA1svOdh/G7dpeuH/xsYuHfrv2K3MIeFlbeLgZ1GEPhPQiENJ924kT0iOPSHPnmvNxAgOliROladPMReYAAADgPXJzzeHbJQnUxZ2viGAdFOS5nmp/HALuTwjpRSCk+4edO81e9U8/NV+Hh0v33y/9+c9SjRqWlgYAAODTXM+uLm2ILuj8mTOery8kxAzRriB94fbiYyUZAk5vNUqCkF4EQrp/WbNG+utf8+erh4eb89cfeICedQAAABfDMBflLU9PtWu/IhYuCwq6NEQXFa4LOxYZae9nacN3EdKLQEj3P4YhLVkizZghbd1qHqta1RwGP3my1KCBpeUBAACUWVZW+QL1hedzcjxbW0BA+QL1hfv0WMPbEdKLQEj3X4ZhDn+fMUPauNE8FhgoDR9uDoXv2ZN/+QMAgIqXk3NpeC5ryM7K8nx9F86rLi48F3U+LIz/bwW4ENKLQEiHYUiffy7NmiWtXp1/vGtXM6yPHMkjJgAAgDun0xzGXZ6eatexiljALCysfIHatY2IMHvAAXgWIb0IhHRcaMcO6ZlnpHfekTIzzWPVq0vjxkm33Sa1a2dtfQAAoOwMQ8rIKFmgLi5kV+QCZmUJ1Bfusyo4YH+E9CIQ0lGQY8ekV1+VXn5ZOnQo/3iPHtIf/yjdeKP5P4IAAKBiGYb5h/Pyzq92bSt7AbOSBm4WMAP8CyG9CIR0FCU3V1q5UnrtNWnp0vwFVEJCpMGDpdGjzW3VqtbWCQCA3WRllX9+tWu/shYwK0sPNguYASgLQnoRCOkoqdRUaf586Y03pKSk/OMREdKwYWbvekICgR0A4L1cC5iVdhh4Qcdc08Y8qTQLmBUVuFnADIDVCOlFIKSjtAxD2r5deu89acEC6cCB/HNVq0rXXisNHWr2sNeubV2dAAD/4FrArCy91Rcfy8jwfH0lWcCsJD3YLGAGwJcQ0otASEd5GIb0zTdmYP/oIyk5Of+cw2E+xm3QIOmaa6QuXcxHvAEAcOECZuUN15W9gNnFxyIjpejogs+zgBkAFIyQXgRCOjzFMKRt26SPPzbnr2/Z4n6+WjXp6qvNwJ6QIDVtylA7APAmhiGdP1++edYsYAYAkAjpRSKko6IkJ0uffCKtWmU+fz0tzf18gwbS5ZebrXdvqW1betoBoCJkZZX/cVsVuYCZJ4aCs4AZAHgXQnoRCOmoDDk50ubNZmD//HPp66+l7Gz3a6KjzeHxl18ude9uDo+vXt2aegHASk6ndPZs/gJmruaad11cuzhcV9QCZp4I1yxgBgD+iZBeBEI6rHDmjPTtt9JXX0nr10sbNhQ8p7BxYzOsd+kide0qXXYZwR2A/bjmV5cmSBd17dmz5md6mmsBs/KG6/BwFjADAJQPIb0IhHTYQU6OtGOHGdq//lr67jvp558LvjY+XmrXzmxt25rb1q3N//MJACVhGGbvcnmC9MXXeHp+tZT/LOuStIiIogM3C5gBAOyEkF4EQjrs6tQpc/G5zZvN0L55s/TLLwVf63BITZqYob1FC6lZM6l5c3Nbvz49PoA3Mwzp3DkzCJ85Y/Yyu/YLaoWdvzh0e3putWT+u8gVll3b0rYL31e1KkPBAQC+iZBeBEI6vMmpU9KuXdLOne7t+PHC3xMSYq4k37y52Ro1Mhetc7Vq1fg/wYCnZGcXH6TLErIr8n+Zw8JKFphL0sLC+KMgAAAlQUgvAiEdvuDoUTOsJyVJP/1ktp9/lvbuLb63LCIiP7DHx5vbunWluLj8Vrs2w0ThG3JzzbnTGRlmGC7v9uJAnZVVsfWHhZn/nb24hYcXfPzi8wWFcJ4qAQBA5SOkF4GQDl+WkyMdPJgf2n/6yXztaseOlexzHA6pZk334B4bK9Wokd+qV3ffDw2t2N8G35Kbaw7pdrXz591fX3isPCG7Ilb5LkhQUH4ILm2QLqzRSw0AgO8gpBeBkA5/du6c+Tz35GT38J6SYrYjR8xe+tzc0n92WFh+cI+JKdmKya798HBzLqqr0dNXsQzDHKadmWn2BGdm5rfiXmdmFh+qS3Ls4kcSVoawMPNeK8+2sKAdHFz5vwcAAHiP0uRQBrQCfqRqVXOhuRYtCr8mN1c6cSI/uF/YTp40z124PXnSfUjxoUPlr7NKFTMQXRjcL34dEmJed3ELDi76eFCQ2TsZEGCOGLh4vyTHDMNc2bq829xcc/RDdra59cR+VlbRQdu1byfBwe7/2YaGur+uWrX84ZoFyQAAgLcgpANwExhozkmvXVvq0KH4651Oc+XoEyfyg/tvv5nH0tPzt0XtZ2S4B8fsbCktzWyoeIGB5h89QkLMwFzQ/oWvLw7QBYXqkh4LCWHkBAAAwIUI6QDKJSBAio42W5MmZf8cp/PSYdGu+cgFHcvKMsO8qxX3+sJjhnFpr3ZBPd2FHStpz3tx5wID83v3g4IK3i/u/MX7wcGFh+vCgjchGQAAwD4I6QBsISDAHJocHm51JQAAAIB1WDcWAAAAAACbIKQDAAAAAGAThHQAAAAAAGyCkA4AAAAAgE0Q0gEAAAAAsAlCOgAAAAAANkFIBwAAAADAJgjpAAAAAADYBCEdAAAAAACbIKQDAAAAAGAThHQAAAAAAGyCkA4AAAAAgE3YIqS/8MILatSokUJDQ9WjRw9t3LixRO9bsGCBHA6Hhg0bVrEFAgAAAABQCSwP6QsXLtTkyZM1bdo0bdmyRR07dlT//v119OjRIt+3f/9+Pfjgg+rTp08lVQoAAAAAQMWyPKTPmTNHt99+uyZMmKA2bdro5ZdfVlhYmN54441C35Obm6sxY8bo8ccfV5MmTSqxWgAAAAAAKo6lIT0rK0ubN29WQkJC3rGAgAAlJCRow4YNhb7viSeeUO3atXXbbbcV+x2ZmZlKT093awAAAAAA2JGlIf348ePKzc1VbGys2/HY2FilpKQU+J6vvvpKr7/+uubOnVui75g5c6aio6PzWnx8fLnrBgAAAACgIlg+3L00Tp8+rZtvvllz585VzZo1S/SeKVOmKC0tLa8lJydXcJUAAAAAAJRNkJVfXrNmTQUGBio1NdXteGpqquLi4i65/pdfftH+/fs1ZMiQvGNOp1OSFBQUpD179qhp06Zu7wkJCVFISEgFVA8AAAAAgGdZ2pMeHBysLl26KDExMe+Y0+lUYmKievbsecn1rVq10o4dO7R169a8dv311+uqq67S1q1bGcoOAAAAAPBqlvakS9LkyZN1yy23qGvXrurevbuefvppnT17VhMmTJAkjRs3TvXq1dPMmTMVGhqqdu3aub2/WrVqknTJcQAAAAAAvI3lIX3UqFE6duyYpk6dqpSUFHXq1EnLly/PW0zu4MGDCgjwqqnzAAAAAACUicMwDMPqIipTenq6oqOjlZaWpqioKKvLAQAAAAD4uNLkULqoAQAAAACwCUI6AAAAAAA2QUgHAAAAAMAmCOkAAAAAANgEIR0AAAAAAJsgpAMAAAAAYBOEdAAAAAAAbIKQDgAAAACATRDSAQAAAACwCUI6AAAAAAA2QUgHAAAAAMAmCOkAAAAAANgEIR0AAAAAAJsgpAMAAAAAYBOEdAAAAAAAbIKQbmfnz0vp6VZXAQAAAACoJIR0u3r0USk8XJo1y+pKAAAAAACVhJBuV7VqSU6ntGeP1ZUAAAAAACoJId2uWrUytz/8YG0dAAAAAIBKQ0i3q5Ytze3PP0s5OdbWAgAAAACoFIR0u2rQQAoNlbKypP37ra4GAAAAAFAJCOl2FRAgtWhh7jMvHQAAAAD8AiHdzpiXDgAAAAB+hZBuZ6556YR0AAAAAPALhHQ7c/WkM9wdAAAAAPwCId3O6EkHAAAAAL9CSLczV0g/dkw6edLaWgAAAAAAFY6QbmcREVK9euY+Q94BAAAAwOcR0u2OeekAAAAA4DcI6XbHvHQAAAAA8BuEdLujJx0AAAAA/AYh3e5cIZ2edAAAAADweYR0u3MNd//5Zyk729paAAAAAAAVipBud/XrS2FhUk6OtG+f1dUAAAAAACoQId3uAgKkFi3M/aQka2sBAAAAAFQoQro3aNPG3O7ebW0dAAAAAIAKRUj3Bm3bmttdu6ytAwAAAABQoQjp3oCQDgAAAAB+gZDuDVwh/YcfpNxca2sBAAAAAFQYQro3aNxYCg2Vzp+X9u61uhoAAAAAQAUhpHuDwECpdWtznyHvAAAAAOCzCOnegnnpAAAAAODzCOnegpAOAAAAAD6PkO4tXCGdZ6UDAAAAgM8ipHsLVngHAAAAAJ9HSPcWjRpJYWFSZqb0yy9WVwMAAAAAqACEdG8REMAK7wAAAADg4wjp3oTF4wAAAADApxHSvQkhHQAAAAB8GiHdm7RpY24J6QAAAADgkwjp3qRdO3O7Z4+UnW1tLQAAAAAAjyOke5MGDaTISCkrS/rxR6urAQAAAAB4GCHdmwQESO3bm/vbtllbCwAAAADA4wjp3qZjR3O7fbu1dQAAAAAAPI6Q7m1cIZ2edAAAAADwOYR0b9Ohg7klpAMAAACAzyGkexvXnPQjR6Rjx6ytBQAAAADgUYR0bxMRITVtau4zLx0AAAAAfAoh3RuxeBwAAAAA+CRCujdi8TgAAAAA8EmEdG/E4nEAAAAA4JMI6d7I1ZO+e7eUnW1tLQAAAAAAjylTSE9OTtahQ4fyXm/cuFH333+/Xn31VY8VhiI0bChFRkpZWdKePVZXAwAAAADwkDKF9D/84Q/64osvJEkpKSm65pprtHHjRv3tb3/TE0884dECUYCAAIa8AwAAAIAPKlNI37lzp7p37y5JWrRokdq1a6evv/5a//3vfzVv3jxP1ofCuEI6K7wDAAAAgM8oU0jPzs5WSEiIJOnzzz/X9ddfL0lq1aqVjhw54rnqUDhWeAcAAAAAn1OmkN62bVu9/PLLWrdunVatWqUBAwZIkg4fPqwaNWp4tEAUwhXSt261tAwAAAAAgOeUKaT/61//0iuvvKIrr7xSo0ePVsf/D4xLly7NGwaPCtahgzk3PTVVOnzY6moAAAAAAB4QVJY3XXnllTp+/LjS09MVExOTd3zixIkKCwvzWHEoQliY1Lq1tGuXtHmzVLeu1RUBAAAAAMqpTD3p586dU2ZmZl5AP3DggJ5++mnt2bNHtWvX9miBKEKXLuZ282Zr6wAAAAAAeESZQvrQoUP19ttvS5JOnTqlHj166N///reGDRuml156yaMFogiEdAAAAADwKWUK6Vu2bFGfPn0kSYsXL1ZsbKwOHDigt99+W88++6xHC0QRCOkAAAAA4FPKFNIzMjIUGRkpSVq5cqWGDx+ugIAA/e53v9OBAwc8WiCK0LGj5HBIR46YDQAAAADg1coU0ps1a6aPPvpIycnJWrFiha699lpJ0tGjRxUVFeXRAlGEiAipVStzf8sWa2sBAAAAAJRbmUL61KlT9eCDD6pRo0bq3r27evbsKcnsVe/cubNHC0QxGPIOAAAAAD6jTCF95MiROnjwoL777jutWLEi73i/fv30n//8x2PFoQQI6QAAAADgM8r0nHRJiouLU1xcnA4dOiRJql+/vrp37+6xwlBChHQAAAAA8Bll6kl3Op164oknFB0drYYNG6phw4aqVq2aZsyYIafT6ekaUZROnczF4379VUpNtboaAAAAAEA5lKkn/W9/+5tef/11zZo1S71795YkffXVV5o+fbrOnz+vf/zjHx4tEkWIjJRatJD27DEXjxs40OqKAAAAAABlVKaQ/tZbb+m1117T9ddfn3esQ4cOqlevnu68805CemXr0sUM6Zs3E9IBAAAAwIuVabj7yZMn1cr16K8LtGrVSidPnix3USgl5qUDAAAAgE8oU0jv2LGjnn/++UuOP//88+rQoUO5i0Ipde1qbjdutLYOAAAAAEC5lGm4++zZszV48GB9/vnnec9I37Bhg5KTk7Vs2TKPFogS6NJFCgyUDh+WDh2S6te3uiIAAAAAQBmUqSe9b9+++vHHH3XDDTfo1KlTOnXqlIYPH65du3Zp/vz5nq4RxQkPl9q1M/e/+cbaWgAAAAAAZeYwDMPw1Idt27ZNl112mXJzcz31kR6Xnp6u6OhopaWlKSoqyupyPGfSJOmVV6QHH5SefNLqagAAAAAA/680ObRMPemwoR49zO2331pbBwAAAACgzAjpvsIV0jdvlnJyrK0FAAAAAFAmhHRf0aqVFBUlZWRIO3daXQ0AAAAAoAxKtbr78OHDizx/6tSp8tSC8ggIkLp3lz7/3Fw8rlMnqysCAAAAAJRSqUJ6dHR0sefHjRtXroJQDj16mCH922/NheQAAAAAAF6lVCH9zTffrKg64AksHgcAAAAAXo056b7EFdJ/+EFKS7O2FgAAAABAqRHSfUnt2lKjRpJhSJs2WV0NAAAAAKCUCOm+5ne/M7fffGNtHQAAAACAUiOk+xpXSP/6a2vrAAAAAACUGiHd1/TubW6//lpyOq2tBQAAAABQKoR0X9OpkxQebi4ct2uX1dUAAAAAAEqBkO5rgoLyh7x/9ZW1tQAAAAAASoWQ7osuv9zcEtIBAAAAwKsQ0n0RIR0AAAAAvBIh3Rf16CEFBkoHD5oNAAAAAOAVCOm+KDLSXEBOktavt7QUAAAAAEDJEdJ9FUPeAQAAAMDrENJ9FSEdAAAAALwOId1X9e5tbnfskE6dsrQUAAAAAEDJENJ9VZ06UtOmkmFIGzZYXQ0AAAAAoAQI6b7MNeT9yy+trQMAAAAAUCKEdF/Wt6+5XbPG0jIAAAAAACVDSPdlV11lbjdtkk6ftrYWAAAAAECxCOm+rFEjs+Xmsso7AAAAAHgBQrqvc/Wmf/GFtXUAAAAAAIpFSPd1hHQAAAAA8BqEdF/nCulbtkhpadbWAgAAAAAoEiHd19WvLzVvLjmdPIoNAAAAAGyOkO4PGPIOAAAAAF6BkO4PCOkAAAAA4BUI6f7gyivN7bZt0smTlpYCAAAAACgcId0fxMVJrVtLhiGtWWN1NQAAAACAQtgipL/wwgtq1KiRQkND1aNHD23cuLHQaz/88EN17dpV1apVU3h4uDp16qT58+dXYrVeql8/c7tqlbV1AAAAAAAKZXlIX7hwoSZPnqxp06Zpy5Yt6tixo/r376+jR48WeH316tX1t7/9TRs2bND27ds1YcIETZgwQStWrKjkyr1M//7mduVKa+sAAAAAABTKYRiGYWUBPXr0ULdu3fT8889LkpxOp+Lj43XPPffo4YcfLtFnXHbZZRo8eLBmzJhR7LXp6emKjo5WWlqaoqKiylW7VzlzRqpeXcrOln76SWrWzOqKAAAAAMAvlCaHWtqTnpWVpc2bNyshISHvWEBAgBISErRhw4Zi328YhhITE7Vnzx5dccUVBV6TmZmp9PR0t+aXIiKk3r3NfXrTAQAAAMCWLA3px48fV25urmJjY92Ox8bGKiUlpdD3paWlKSIiQsHBwRo8eLCee+45XXPNNQVeO3PmTEVHR+e1+Ph4j/4Gr3LtteaWqQEAAAAAYEuWz0kvi8jISG3dulWbNm3SP/7xD02ePFlrClm1fMqUKUpLS8trycnJlVusnbhC+urV5rB3AAAAAICtBFn55TVr1lRgYKBSU1PdjqempiouLq7Q9wUEBKjZ/8+p7tSpk5KSkjRz5kxd6Xoe+AVCQkIUEhLi0bq9VufOUs2a0vHj0oYNUiFTBAAAAAAA1rC0Jz04OFhdunRRYmJi3jGn06nExET17NmzxJ/jdDqVmZlZESX6loAAyTUtgHnpAAAAAGA7lg93nzx5subOnau33npLSUlJuuOOO3T27FlNmDBBkjRu3DhNmTIl7/qZM2dq1apV2rt3r5KSkvTvf/9b8+fP19ixY636Cd7F9Sg25qUDAAAAgO1YOtxdkkaNGqVjx45p6tSpSklJUadOnbR8+fK8xeQOHjyogID8vyWcPXtWd955pw4dOqSqVauqVatWeueddzRq1CirfoJ3cfWkb95sDnuvWdPaegAAAAAAeSx/Tnpl89vnpF+oQwdpxw7pnXekMWOsrgYAAAAAfJrXPCcdFhk82Nx+8om1dQAAAAAA3BDS/dGQIeZ2+XIexQYAAAAANkJI90c9ekg1akinTknr11tdDQAAAADg/xHS/VFgoDRokLnPkHcAAAAAsA1Cur9yDXknpAMAAACAbRDS/dW110pBQdKePdJPP1ldDQAAAABAhHT/FR0t9e1r7tObDgAAAAC2QEj3Z9ddZ27/9z9r6wAAAAAASCKk+zdXSF+3zlzpHQAAAABgKUK6P2vWTGrVSsrJkT77zOpqAAAAAMDvEdL93bBh5vbDDy0tAwAAAABASMeIEeZ22TIpI8PaWgAAAADAzxHS/V2XLlKDBmZAX7HC6moAAAAAwK8R0v2dwyENH27uM+QdAAAAACxFSEf+kPf//U/KyrK2FgAAAADwY4R0SL16SXFxUlqalJhodTUAAAAA4LcI6ZACAqQbbjD3P/jA2loAAAAAwI8R0mFyDXn/+GPzuekAAAAAgEpHSIfpiiuk6tWl48elL7+0uhoAAAAA8EuEdJiqVMkf8r5ggbW1AAAAAICfIqQj3x/+YG4XL2aVdwAAAACwACEd+fr2lerUkX77TVqxwupqAAAAAMDvENKRLzBQGjXK3H/3XWtrAQAAAAA/REiHO9eQ96VLpTNnrK0FAAAAAPwMIR3uunaVmjaVMjLMoA4AAAAAqDSEdLhzOPJ70997z9paAAAAAMDPENJxqdGjze3y5dKJE9bWAgAAAAB+hJCOS7VuLXXuLOXkSIsWWV0NAAAAAPgNQjoKdvPN5nbePEvLAAAAAAB/QkhHwcaMkYKCpI0bpd27ra4GAAAAAPwCIR0Fq11bGjzY3H/zTWtrAQAAAAA/QUhH4SZMMLfz50vZ2dbWAgAAAAB+gJCOwg0aZPaop6ZKK1ZYXQ0AAAAA+DxCOgpXpYo0dqy5z5B3AAAAAKhwhHQUbfx4c/u//0nHj1taCgAAAAD4OkI6ita+vdSlizknff58q6sBAAAAAJ9GSEfxbr/d3L7yimQY1tYCAAAAAD6MkI7i/eEPUkSEtGePtGaN1dUAAAAAgM8ipKN4kZH5C8i99JK1tQAAAACADyOko2QmTTK3S5ZIKSnW1gIAAAAAPoqQjpLp2FHq2VPKyZFef93qagAAAADAJxHSUXJ33GFuX31Vys21thYAAAAA8EGEdJTc738vVa8uHTwoffaZ1dUAAAAAgM8hpKPkQkOlCRPM/eeft7YWAAAAAPBBhHSUzh13SA6HtGKFlJRkdTUAAAAA4FMI6Sidpk2loUPN/aeftrQUAAAAAPA1hHSU3p//bG7ffls6ftzaWgAAAADAhxDSUXp9+kiXXSadPy+98orV1QAAAACAzyCko/Qcjvze9BdekLKyrK0HAAAAAHwEIR1lc+ONUp060pEj0sKFVlcDAAAAAD6BkI6yCQ6W7r7b3J8zRzIMa+sBAAAAAB9ASEfZ/elPUni4tHWr+Ug2AAAAAEC5ENJRdjVqmEFdkv75T2trAQAAAAAfQEhH+UyebA59X7dO+uorq6sBAAAAAK9GSEf51KsnjR9v7s+caWkpAAAAAODtCOkov7/+VQoIkJYtM+enAwAAAADKhJCO8mvaVBo1ytynNx0AAAAAyoyQDs94+GFz+/770p491tYCAAAAAF6KkA7P6NBBGjrUfF76449bXQ0AAAAAeCVCOjzHFc4XLJB27rS2FgAAAADwQoR0eE7HjtLvf2/2pk+bZnU1AAAAAOB1COnwrOnTJYdD+vBDacsWq6sBAAAAAK9CSIdntWkjjRlj7k+dam0tAAAAAOBlCOnwvGnTpMBA6dNPpQ0brK4GAAAAALwGIR2e16yZNH68uT9lijlHHQAAAABQLEI6Ksa0aVJoqLR2rfTJJ1ZXAwAAAABegZCOihEfL/35z+b+X/4iZWdbWw8AAAAAeAFCOirOQw9JNWtKe/ZIr71mdTUAAAAAYHuEdFSc6GjzkWySuU1Pt7IaAAAAALA9Qjoq1sSJUosW0tGj0uzZVlcDAAAAALZGSEfFqlJF+te/zP1//1vav9/ScgAAAADAzgjpqHhDh0pXXSWdPy9Nnmx1NQAAAABgW4R0VDyHQ3ruOSkwUFqyRFqxwuqKAAAAAMCWCOmoHG3bSvfea+7fe6+UlWVtPQAAAABgQ4R0VJ5p06TYWOnHH6X//MfqagAAAADAdgjpqDzR0fkrvM+YIR06ZG09AAAAAGAzhHRUrptvlnr3ls6ele67z+pqAAAAAMBWCOmoXA6H9OKLUlCQ9OGH5kJyAAAAAABJhHRYoUMH6a9/Nffvuks6dcrScgAAAADALgjpsMZjj0ktWkhHjkgPPWR1NQAAAABgC4R0WCM0VHr1VXP/1VeltWutrQcAAAAAbICQDuv07StNnGju3367dO6ctfUAAAAAgMUI6bDWv/4l1akj/fSTNGWK1dUAAAAAgKUI6bBWtWrS66+b+888I61ebWk5AAAAAGAlQjqsN3Cg9Kc/mfvjx0tpaZaWAwAAAABWIaTDHp56SmrSREpOlu67z+pqAAAAAMAShHTYQ0SE9PbbUkCA9NZb0pIlVlcEAAAAAJWOkA776N1b+utfzf3bb5cOHbK2HgAAAACoZIR02Mv06dJll0knTkh/+IOUk2N1RQAAAABQaQjpsJeQEGnhQikyUlq3Tnr8casrAgAAAIBKQ0iH/TRrJr36qrn/j39IiYnW1gMAAAAAlYSQDnu66SZzXrphSGPGSKmpVlcEAAAAABWOkA77evppqW1bM6AzPx0AAACAHyCkw77CwqRFi6TwcGn1amnKFKsrAgAAAIAKRUiHvbVpI82bZ+4/9ZS0YIGl5QAAAABARSKkw/5GjpQeftjcv/VWaft2a+sBAAAAgApCSId3+PvfpWuvlc6dk264QTp50uqKAAAAAMDjCOnwDoGB0nvvSY0bS3v3Sr//vZSdbXVVAAAAAOBRhHR4j+rVpY8+kiIizIXk7rjDfEQbAAAAAPgIQjq8S4cO0sKFUkCA9Prr0uzZVlcEAAAAAB5DSIf3GTRIeuYZc//hh6XFi62tBwAAAAA8hJAO73T33dK995r7N98sffuttfUAAAAAgAcQ0uG95syRBg+Wzp83t0lJVlcEAAAAAOVCSIf3CgyUFiyQunWTTpwwH9GWnGx1VQAAAABQZoR0eLeICGnZMqlVK+nQITOoHz9udVUAAAAAUCaEdHi/mjWlFSuk+vWlH34wF5Y7fdrqqgAAAACg1Ajp8A0NGkgrV0o1akibNkk33CCdO2d1VQAAAABQKoR0+I7WraXPPjOHwCcmSsOGmYvKAQAAAICXIKTDt3TrZs5RDwsze9aHD5cyM62uCgAAAABKhJAO39Onj/Tpp1LVqmbP+ogRBHUAAAAAXoGQDt905ZXSJ59IoaFmYL/xRikry+qqAAAAAKBIhHT4rquvlv73PzOoL10qDR0qZWRYXRUAAAAAFIqQDt+WkGAG9LAwaflyacAAKS3N6qoAAAAAoECEdPi+a64xF5GLjpbWrZP69ZOOH7e6KgAAAAC4BCEd/qF3b+mLL6RataTNm6W+faVff7W6KgAAAABwQ0iH/+jcWfryS6l+fWn3bjO4JyVZXRUAAAAA5CGkw7+0amUOeW/eXDpwQOrVywzuAAAAAGADhHT4n0aNpK+/lnr2lE6dMuesL1hgdVUAAAAAQEiHn6pZU0pMlEaMMJ+fPnq0NHu2ZBhWVwYAAADAj9kipL/wwgtq1KiRQkND1aNHD23cuLHQa+fOnas+ffooJiZGMTExSkhIKPJ6oFBVq0qLFkl//rP5+qGHpIkTzdAOAAAAABawPKQvXLhQkydP1rRp07RlyxZ17NhR/fv319GjRwu8fs2aNRo9erS++OILbdiwQfHx8br22mv1Kyt1oywCAqQ5c6Snnzb3X3tNuvpqKTXV6soAAAAA+CGHYVg7vrdHjx7q1q2bnn/+eUmS0+lUfHy87rnnHj388MPFvj83N1cxMTF6/vnnNW7cuGKvT09PV3R0tNLS0hQVFVXu+uFDli+XbrpJSkuT4uOljz6SLrvM6qoAAAAAeLnS5FBLe9KzsrK0efNmJSQk5B0LCAhQQkKCNmzYUKLPyMjIUHZ2tqpXr17g+czMTKWnp7s1oEADBkjffiu1bCklJ0uXX86CcgAAAAAqlaUh/fjx48rNzVVsbKzb8djYWKWkpJToMx566CHVrVvXLehfaObMmYqOjs5r8fHx5a4bPqxlSzOoDxoknTtnLij34INSdrbVlQEAAADwA5bPSS+PWbNmacGCBVqyZIlCQ0MLvGbKlClKS0vLa8nJyZVcJbxOdLS0dKm5kJwk/fvf0pVXSocOWVoWAAAAAN9naUivWbOmAgMDlXrRIl2pqamKi4sr8r1PPfWUZs2apZUrV6pDhw6FXhcSEqKoqCi3BhQrMFCaNUtassQM7V9/LXXuLK1YYXVlAAAAAHyYpSE9ODhYXbp0UWJiYt4xp9OpxMRE9ezZs9D3zZ49WzNmzNDy5cvVtWvXyigV/mrYMGnLFnMBuePHpYEDpccek3Jzra4MAAAAgA+yfLj75MmTNXfuXL311ltKSkrSHXfcobNnz2rChAmSpHHjxmnKlCl51//rX//SY489pjfeeEONGjVSSkqKUlJSdObMGat+AnxdkybS+vXSHXdIhiH9/e/SVVdJ+/dbXRkAAAAAH2N5SB81apSeeuopTZ06VZ06ddLWrVu1fPnyvMXkDh48qCNHjuRd/9JLLykrK0sjR45UnTp18tpTTz1l1U+APwgNlV58UXr3XSkyUlq3TurYUfrvf62uDAAAAIAPsfw56ZWN56Sj3PbulcaOlVyPCRw92gzw1apZWhYAAAAAe/Ka56QDXqlJE+nLL6XHHzcXmHvvPalDB+mLL6yuDAAAAICXI6QDZREUJE2dKn31ldS0qZScLF19tXTnndLp01ZXBwAAAMBLEdKB8vjd76Tvv5cmTjRfv/SS1K6dtHKltXUBAAAA8EqEdKC8IiOlV16RPv9catRIOnhQ6t9fuu026dQpq6sDAAAA4EUI6YCn9Osn7dgh3Xuv5HBIb7whtW0rffCB+eg2AAAAACgGIR3wpIgI6ZlnzIXlmjeXDh+WRo6UBg+WfvnF6uoAAAAA2BwhHagIl18ubdsmPfaYFBwsffaZOVd9xgwpM9Pq6gAAAADYFCEdqChVq0pPPCFt324OhT9/3lwRvn17adUqq6sDAAAAYEOEdKCitWxphvJ335Xi4qSffpKuvVYaNszcBwAAAID/R0gHKoPDIY0eLf3wg7mwXGCg9PHH5sJyDzzAKvAAAAAAJBHSgcoVHW0uLLdjhzRwoJSdLc2ZIzVrZj5jPSfH6goBAAAAWIiQDlihdWtp2TJzQbnWraUTJ6Q775Q6djR72HlkGwAAAOCXCOmAlQYMMBeWe/55qUYNafduc656r17SmjVWVwcAAACgkhHSAasFBUl33WUuIjdlihQWJn3zjXTVVVL//tLmzVZXCAAAAKCSENIBu4iJkf75T+mXX8zQHhQkrVwpde0q3XijlJRkdYUAAAAAKhghHbCbuDhz+PuePdLYsebK8O+/b64EP2qUuegcAAAAAJ9ESAfsqkkTaf58ads2c566YUiLFkkdOkgjRkhbt1pdIQAAAAAPI6QDdte+vbRkiRnWf/97s2f9ww+lzp2l66+XNm2yukIAAAAAHkJIB7xFhw5mT/rOndIf/iAFBEj/+5/UvbuUkCAtX86j2wAAAAAvR0gHvE2bNtJ//2suJDdunBQYKCUmSgMHmkH+rbekrCyrqwQAAABQBoR0wFu1aGEG8r17pT//WYqIMHvZx4+XGjeWZs+W0tKsrhIAAABAKRDSAW/XoIE0Z46UnCzNmiXVqSMdPiw99JAUHy/de6+5UjwAAAAA2yOkA76iWjUzmO/fL735pvnIttOnpeeek1q1kvr3N+ew5+ZaXSkAAACAQhDSAV8THGwOed+xQ1qxQhoyxFwRfuVKczX45s2lp56STp60ulIAAAAAFyGkA77K4ZCuvVZaulT65RfpL3+RYmKkffvM/Xr1pFtvlTZsYFV4AAAAwCYI6YA/cC0kd+iQ9NprUseO0vnz5rD4Xr3MZ7E//bR04oTVlQIAAAB+jZAO+JOwMOm226Tvv5e++kq65RapalVp1y5zhfi6daXRo81HujmdVlcLAAAA+B2HYfjXONf09HRFR0crLS1NUVFRVpcDWO/UKem996S5c83w7tK4sTRhgjR2rLkPAAAAoExKk0MJ6QDybdliDof/73+l9PT845dfLt18s/T735vz2gEAAACUGCG9CIR0oAQyMqTFi6W335ZWr85fWC442Fwt/uabpYEDzdcAAAAAikRILwIhHSilQ4ekd9+V5s+Xdu7MP16jhnTjjdJNN0m9e0uBgdbVCAAAANgYIb0IhHSgjAxD2r7dDOvvvisdOZJ/rk4daeRIM7T36iUFsCYlAAAA4EJILwIhHfCA3FxzBfgFC6QlS8zF51zq1jXnrt94o/S73xHYAQAA4PcI6UUgpAMelpUlff65tHCh9NFH7gvO1a8vjRghDRtmLj4XFGRVlQAAAIBlCOlFIKQDFSgzU1q5Ulq0SPr4Y+n06fxz1aubi84NGyZde635zHYAAADADxDSi0BIByrJ+fPS8uVm7/r//iedPJl/LjTUDOrDhknXXSfVqmVVlQAAAECFI6QXgZAOWCAnR1q/3gzsH30k7d+ffy4gwFwdfvBgadAgqV07yeGwqFAAAADA8wjpRSCkAxYzDGnHjvzA/v337ufr1zefwT5okNSvnxQZaUWVAAAAgMcQ0otASAds5sAB6ZNPpM8+k1avls6dyz9XpYrUp09+aG/dml52AAAAeB1CehEI6YCNnTsnrV1rBvZly6Sff3Y/37ChdM01UkKCdPXVzGUHAACAVyCkF4GQDniRn37KD+xr1pirx1+oUyczsCckmI94Cw+3okoAAACgSIT0IhDSAS+VkWH2sicmms9l37bN/XxwsNSrV35o79KF57IDAADAFgjpRSCkAz7i6FFzDvvnn0urVkkHD7qfj4w0e9f79pWuuELq2tWc4w4AAABUMkJ6EQjpgA8yDOmXX8zA/vnnZnj/7Tf3a8LCzJ72K64wg3v37ubz2gEAAIAKRkgvAiEd8AO5ueZj3tauNduXX0onTrhfExIi9ehhBva+fc39iAhr6gUAAIBPI6QXgZAO+CGnU0pKyg/ta9dKqanu1wQESB06mL3trtaoEY98AwAAQLkR0otASAcgwzBXjnf1sn/55aVz2iUpNtY9tF92GUPkAQAAUGqE9CIQ0gEU6NdfpQ0bpK+/NtuWLVJ2tvs1wcFmUO/Vy5zT3q2b1Lgxve0AAAAoEiG9CIR0ACVy/ry0eXN+aP/6a3NF+YvVqGGG9QtbXFzl1wsAAADbIqQXgZAOoEwMQ9q3zwzrGzZImzaZz2rPyrr02vj4/MDevbv5zPbo6MqvGQAAALZASC8CIR2Ax2RmStu3m4F90yZp40ZzgbqC/rXasqXUubN7q1mz8msGAABApSOkF4GQDqBCnT5tzmd3hfZNm6T9+wu+tn79S4N7gwbMcQcAAPAxhPQiENIBVLpjx8z57d9/n99+/rnga2NizLDeqVP+tmVLqUqVyqwYAAAAHkRILwIhHYAtpKebc9q3bs0P7rt2XbqivGQG9FatpPbt3Vt8PL3uAAAAXoCQXgRCOgDbysyUdu9273Hfvt0cQl+Q6GipXTszsHfoYG7btZOqVavUsgEAAFA0QnoRCOkAvIphSAcPSjt2uLcffpBycgp+T3y8GdjbtDFb69ZmY4V5AAAASxDSi0BIB+ATsrLMoH5xeE9OLvw9devmB/bWrfMDfO3aDJsHAACoQIT0IhDSAfi0U6eknTvNwJ6UZLbdu6XDhwt/T0yMe4+7qzVoIAUEVFrpAAAAvoqQXgRCOgC/lJZm9rzv3u0e3vftK/i57pIUGio1aya1aJHfmjc3t7Vq0fsOAABQQoT0IhDSAeAC585JP/6YH9pdAf7HHwtead4lOto9vF8Y4iMjK69+AAAAL0BILwIhHQBKICfHXLDuxx8vbQcPFt77LklxcfmBvWnT/NakiTm0HgAAwM8Q0otASAeAcjp/Xvrll4ID/NGjRb83JiY/sF8Y3ps2lerVkwIDK+c3AAAAVCJCehEI6QBQgdLSpJ9+yg/te/eagX7vXiklpej3BgdLjRpdGt6bNpUaNpQiIirlJwAAAHgaIb0IhHQAsMjZs2ZYdwV3V9u7V9q/v+g58JJUs6YZ1hs1ym+u1w0bSvw7HQAA2BQhvQiEdACwodxc8xnvFwb4C3vhT50q/jNiYgoO8K4WHV2BPwAAAKBwhPQiENIBwAulpUkHDpg97vv3X7p/4kTxnxEdbYb1Bg2k+PhLW7165pB7AAAADyOkF4GQDgA+6PTp/OBeUJg/dqxknxMbW3CAd7U6daSgoIr7HQAAwCcR0otASAcAP3T2rPnouH37zGH1BbXMzOI/JyBAqls3P7TXr5+/rVvX7I2vU4ceeQAA4IaQXgRCOgDgEoYhHT9eeIBPTpZ+/dV8fnxJ1KplhnZXcC9oW6uWGfoBAIDPI6QXgZAOACiT3FwpNbXgAH/4sBniDx8ufpV6l6Ags9e9sDDv2o+KkhyOiv1tAACgQpUmhzKxDgCAkggMzA/PPXoUfI3TKZ08mR/YXduL91NTzV55V8gvSmioFBdXfIuNNa8FAABejZAOAICnBASYz3OvWVPq2LHw67KzzaBeWIh37Z86JZ0/n78QXnGqVStZoK9Z0/yjAwAAsB1COgAAla1KFXOxufr1i74uI8MM8ykpxbesLDPUnzol/fBD0Z8bECDVrp3fA1+rlvn6wnbhsbAwT/1yAABQDEI6AAB2FRYmNW5stqIYhhnOSxLmjx0zh+W7XpdEePilwb2g17Vrm730rG4PAECZEdIBAPB2DocUE2O21q2LvjYnxwzqqanSkSPS0aP57dgx99dHj5qPpjt71nx83b59JaunWrVLw3ytWvlTAWrWlGrUyN8PD2dxPAAA/h8hHQAAf+JaVb5OHalTp6KvNQzpzJlLg3tBYf7oUfMxdrm5+cPuf/yxZDWFhLiH9otDfEGvw8II9gAAn0RIBwAABXM4pMhIszVtWvz1Tqf022+XBvrUVDPAHz8unTiRv3/8uNlTn5mZv2heSYWEFB/qq1d3b9HRLJgHALA9QjoAAPCMgAAzHNeoUfywe8nsqc/IcA/tF4f4i18fP24ukpeZaa6C/+uvJa/P4TCH4rtCe0zMpUH+wnbheebZAwAqCSEdAABYw+Ew56OHh0sNG5bsPYZhzpEvKMRfHOh/+818bv3Jk+awfcMwj/32m/TLL6WrNTy88ABfULivVs1sUVHmHy8AACghQjoAAPAeDocUEWG2Ro1K/r6srPzQfmF4L6hdeP633/L/MHD2rJScXPp6o6Lcg3thraBrIiOZew8AfoaQDgAAfF9wsPlM+NjY0r3P6ZTS0goO8EWF+7Q06dw5M+CnpZmtLAICzLn0RQX5gsJ+dLTZIiLoyQcAL0NIBwAAKExAQP7j7UqyeN6Fzp83w7lrtfuC2m+/FX48Kyt/Mb7ffitb/a7F/6KizNBe3Lawc6Gh9OgDQCUhpAMAAFSE0FCzlbb33uX8+aKDfHGBPzvb7MlPTzfboUNl/y1VqpQ86Be0jYoy/1jAAnwAUCxCOgAAgB2FhkpxcWYrLcMwV8BPSzMDelm36enmZ2VnmwvznThRvt8UEpL/WL/yNobyA/BRhHQAAABf43CUvydfMofbnz1btpB/4f65c+bnZWaa7fhxz/zO8PDSh3tXr/6FLTxcCgtjSD8AWyCkAwAAoGABAflBtjxycqTTpz3XcnLMz3Wtup+SUv7feuEjAV1PEPDEftWqhH8ApUJIBwAAQMUKCspfgK+8XEP5XYE9Pb18gf/MmfzPPXPGbKmp5a/TxRX+yxv2XX9AcPX6h4VJgYGeqxOAbRDSAQAA4D0uHMpfq1b5P8/pNIfjnzlj9sq7gnpJ9os6l5Fhfv6F4d/TQkLMsO4K7hdvS3vu4mMhIYwCACxASAcAAID/CgjI76H2JKfTDOqeDP9nz+aHfyl/jn9ZH9FXnICA/PBenj8ChIWZw/6rVnXfdzVGBABuCOkAAACApwUE5A9Z9yTDMHv+MzLM5gruF2/Lcywry/wup7PiRgFcKDi44ABfmtclvZbRAfAChHQAAADAWzgc+b3TFSUnp3Shvrhzrj8qnDuX3zIz878vK8tsaWkV95tcXNMlyhLwXc013cLVLj5W0DX8YQClQEgHAAAAkC8oyHxUXVRUxX1Hbq50/nzBAb48rws7l5trfq9rJILrsYCVJSSk9MHeU9cEBFTub0W5EdIBAAAAVK7AwIpZC6Aw2dmeCfyZmeb++fP57eLXrmNOZ/73u9YPqIzRAhcLDi4+yLtaSEj+HxRKul+Sa4ODGU1QCoR0AAAAAL6tShWzVeTogAsZhjltoLggX5KwX5ZrXCMHpPzpBOnplfPbC1OWPwCU5o8BAweafwzwAYR0AAAAAPAkhyP/DwORkZX//Rf+gaAkYd+1ToCrnT/vvi3LvmsBQhfX8Yr6Y0FaGiEdAAAAAGBDQUEV83SB0nA6zaBeklBfnj8GuPZDQ637rR5GSAcAAAAAeFZAQP5c9+hoq6vxKiz1BwAAAACATRDSAQAAAACwCUI6AAAAAAA2QUgHAAAAAMAmCOkAAAAAANgEIR0AAAAAAJsgpAMAAAAAYBOEdAAAAAAAbIKQDgAAAACATRDSAQAAAACwCUI6AAAAAAA2QUgHAAAAAMAmCOkAAAAAANgEIR0AAAAAAJsgpAMAAAAAYBOEdAAAAAAAbIKQDgAAAACATRDSAQAAAACwCUI6AAAAAAA2QUgHAAAAAMAmCOkAAAAAANiE5SH9hRdeUKNGjRQaGqoePXpo48aNhV67a9cujRgxQo0aNZLD4dDTTz9deYUCAAAAAFDBLA3pCxcu1OTJkzVt2jRt2bJFHTt2VP/+/XX06NECr8/IyFCTJk00a9YsxcXFVXK1AAAAAABULEtD+pw5c3T77bdrwoQJatOmjV5++WWFhYXpjTfeKPD6bt266cknn9RNN92kkJCQSq4WAAAAAICKZVlIz8rK0ubNm5WQkJBfTECAEhIStGHDBo99T2ZmptLT090aAAAAAAB2FGTVFx8/fly5ubmKjY11Ox4bG6sffvjBY98zc+ZMPf7445ccJ6wDAAAAACqDK38ahlHstZaF9MoyZcoUTZ48Oe/1r7/+qjZt2ig+Pt7CqgAAAAAA/ub06dOKjo4u8hrLQnrNmjUVGBio1NRUt+OpqakeXRQuJCTEbf56RESEkpOTFRkZKYfD4bHv8bT09HTFx8crOTlZUVFRVpcDFIj7FHbHPQq74x6F3XGPwu685R41DEOnT59W3bp1i73WspAeHBysLl26KDExUcOGDZMkOZ1OJSYm6u67766w7w0ICFD9+vUr7PM9LSoqytY3GyBxn8L+uEdhd9yjsDvuUdidN9yjxfWgu1g63H3y5Mm65ZZb1LVrV3Xv3l1PP/20zp49qwkTJkiSxo0bp3r16mnmzJmSzMXmdu/enbf/66+/auvWrYqIiFCzZs0s+x0AAAAAAHiCpSF91KhROnbsmKZOnaqUlBR16tRJy5cvz1tM7uDBgwoIyF+A/vDhw+rcuXPe66eeekpPPfWU+vbtqzVr1lR2+QAAAAAAeJTlC8fdfffdhQ5vvzh4N2rUqESr4fmCkJAQTZs2jefBw9a4T2F33KOwO+5R2B33KOzOF+9Rh+EvqRcAAAAAAJsLKP4SAAAAAABQGQjpAAAAAADYBCEdAAAAAACbIKQDAAAAAGAThHSbeuGFF9SoUSOFhoaqR48e2rhxo9UlwUd9+eWXGjJkiOrWrSuHw6GPPvrI7bxhGJo6darq1KmjqlWrKiEhQT/99JPbNSdPntSYMWMUFRWlatWq6bbbbtOZM2fcrtm+fbv69Omj0NBQxcfHa/bs2RX90+ADZs6cqW7duikyMlK1a9fWsGHDtGfPHrdrzp8/r7vuuks1atRQRESERowYodTUVLdrDh48qMGDByssLEy1a9fWX/7yF+Xk5Lhds2bNGl122WUKCQlRs2bNNG/evIr+efABL730kjp06KCoqChFRUWpZ8+e+uyzz/LOc3/CbmbNmiWHw6H7778/7xj3Kaw2ffp0ORwOt9aqVau88353jxqwnQULFhjBwcHGG2+8Yezatcu4/fbbjWrVqhmpqalWlwYftGzZMuNvf/ub8eGHHxqSjCVLlridnzVrlhEdHW189NFHxrZt24zrr7/eaNy4sXHu3Lm8awYMGGB07NjR+Oabb4x169YZzZo1M0aPHp13Pi0tzYiNjTXGjBlj7Ny503jvvfeMqlWrGq+88kpl/Ux4qf79+xtvvvmmsXPnTmPr1q3GoEGDjAYNGhhnzpzJu2bSpElGfHy8kZiYaHz33XfG7373O6NXr15553Nycox27doZCQkJxvfff28sW7bMqFmzpjFlypS8a/bu3WuEhYUZkydPNnbv3m0899xzRmBgoLF8+fJK/b3wPkuXLjU+/fRT48cffzT27NljPPLII0aVKlWMnTt3GobB/Ql72bhxo9GoUSOjQ4cOxn333Zd3nPsUVps2bZrRtm1b48iRI3nt2LFjeef97R4lpNtQ9+7djbvuuivvdW5urlG3bl1j5syZFlYFf3BxSHc6nUZcXJzx5JNP5h07deqUERISYrz33nuGYRjG7t27DUnGpk2b8q757LPPDIfDYfz666+GYRjGiy++aMTExBiZmZl51zz00ENGy5YtK/gXwdccPXrUkGSsXbvWMAzzfqxSpYrx/vvv512TlJRkSDI2bNhgGIb5h6iAgAAjJSUl75qXXnrJiIqKyrsn//rXvxpt27Z1+65Ro0YZ/fv3r+ifBB8UExNjvPbaa9yfsJXTp08bzZs3N1atWmX07ds3L6Rzn8IOpk2bZnTs2LHAc/54jzLc3WaysrK0efNmJSQk5B0LCAhQQkKCNmzYYGFl8Ef79u1TSkqK2/0YHR2tHj165N2PGzZsULVq1dS1a9e8axISEhQQEKBvv/0275orrrhCwcHBedf0799fe/bs0W+//VZJvwa+IC0tTZJUvXp1SdLmzZuVnZ3tdo+2atVKDRo0cLtH27dvr9jY2Lxr+vfvr/T0dO3atSvvmgs/w3UN/95FaeTm5mrBggU6e/asevbsyf0JW7nrrrs0ePDgS+4l7lPYxU8//aS6deuqSZMmGjNmjA4ePCjJP+9RQrrNHD9+XLm5uW43mCTFxsYqJSXFoqrgr1z3XFH3Y0pKimrXru12PigoSNWrV3e7pqDPuPA7gOI4nU7df//96t27t9q1ayfJvH+Cg4NVrVo1t2svvkeLu/8KuyY9PV3nzp2riJ8DH7Jjxw5FREQoJCREkyZN0pIlS9SmTRvuT9jGggULtGXLFs2cOfOSc9ynsIMePXpo3rx5Wr58uV566SXt27dPffr00enTp/3yHg2yugAAAErirrvu0s6dO/XVV19ZXQrgpmXLltq6davS0tK0ePFi3XLLLVq7dq3VZQGSpOTkZN13331atWqVQkNDrS4HKNDAgQPz9jt06KAePXqoYcOGWrRokapWrWphZdagJ91matasqcDAwEtWK0xNTVVcXJxFVcFfue65ou7HuLg4HT161O18Tk6OTp486XZNQZ9x4XcARbn77rv1ySef6IsvvlD9+vXzjsfFxSkrK0unTp1yu/7ie7S4+6+wa6Kiovzy/xygdIKDg9WsWTN16dJFM2fOVMeOHfXMM89wf8IWNm/erKNHj+qyyy5TUFCQgoKCtHbtWj377LMKCgpSbGws9ylsp1q1amrRooV+/vlnv/x3KSHdZoKDg9WlSxclJibmHXM6nUpMTFTPnj0trAz+qHHjxoqLi3O7H9PT0/Xtt9/m3Y89e/bUqVOntHnz5rxrVq9eLafTqR49euRd8+WXXyo7OzvvmlWrVqlly5aKiYmppF8Db2QYhu6++24tWbJEq1evVuPGjd3Od+nSRVWqVHG7R/fs2aODBw+63aM7duxw+2PSqlWrFBUVpTZt2uRdc+FnuK7h37soC6fTqczMTO5P2EK/fv20Y8cObd26Na917dpVY8aMydvnPoXdnDlzRr/88ovq1Knjn/8utXrlOlxqwYIFRkhIiDFv3jxj9+7dxsSJE41q1aq5rVYIeMrp06eN77//3vj+++8NScacOXOM77//3jhw4IBhGOYj2KpVq2Z8/PHHxvbt242hQ4cW+Ai2zp07G99++63x1VdfGc2bN3d7BNupU6eM2NhY4+abbzZ27txpLFiwwAgLC+MRbCjWHXfcYURHRxtr1qxxeyxLRkZG3jWTJk0yGjRoYKxevdr47rvvjJ49exo9e/bMO+96LMu1115rbN261Vi+fLlRq1atAh/L8pe//MVISkoyXnjhBds+lgX28vDDDxtr16419u3bZ2zfvt14+OGHDYfDYaxcudIwDO5P2NOFq7sbBvcprPfAAw8Ya9asMfbt22esX7/eSEhIMGrWrGkcPXrUMAz/u0cJ6Tb13HPPGQ0aNDCCg4ON7t27G998843VJcFHffHFF4akS9ott9xiGIb5GLbHHnvMiI2NNUJCQox+/foZe/bscfuMEydOGKNHjzYiIiKMqKgoY8KECcbp06fdrtm2bZtx+eWXGyEhIUa9evWMWbNmVdZPhBcr6N6UZLz55pt515w7d8648847jZiYGCMsLMy44YYbjCNHjrh9zv79+42BAwcaVatWNWrWrGk88MADRnZ2tts1X3zxhdGpUycjODjYaNKkidt3AIW59dZbjYYNGxrBwcFGrVq1jH79+uUFdMPg/oQ9XRzSuU9htVGjRhl16tQxgoODjXr16hmjRo0yfv7557zz/naPOgzDMKzpwwcAAAAAABdiTjoAAAAAADZBSAcAAAAAwCYI6QAAAAAA2AQhHQAAAAAAmyCkAwAAAABgE4R0AAAAAABsgpAOAAAAAIBNENIBAAAAALAJQjoAAKhQDodDH330kdVlAADgFQjpAAD4sPHjx8vhcFzSBgwYYHVpAACgAEFWFwAAACrWgAED9Oabb7odCwkJsagaAABQFHrSAQDwcSEhIYqLi3NrMTExksyh6C+99JIGDhyoqlWrqkmTJlq8eLHb+3fs2KGrr75aVatWVY0aNTRx4kSdOXPG7Zo33nhDbdu2VUhIiOrUqaO7777b7fzx48d1ww03KCwsTM2bN9fSpUsr9kcDAOClCOkAAPi5xx57TCNGjNC2bds0ZswY3XTTTUpKSpIknT17Vv3791dMTIw2bdqk999/X59//rlbCH/ppZd01113aeLEidqxY4eWLl2qZs2auX3H448/rhtvvFHbt2/XoEGDNGbMGJ08ebJSfycAAN7AYRiGYXURAACgYowfP17vvPOOQkND3Y4/8sgjeuSRR+RwODRp0iS99NJLeed+97vf6bLLLtOLL76ouXPn6qGHHlJycrLCw8MlScuWLdOQIUN0+PBhxcbGql69epowYYL+/ve/F1iDw+HQo48+qhkzZkgyg39ERIQ+++wz5sYDAHAR5qQDAODjrrrqKrcQLknVq1fP2+/Zs6fbuZ49e2rr1q2SpKSkJHXs2DEvoEtS79695XQ6tWfPHjkcDh0+fFj9+vUrsoYOHTrk7YeHhysqKkpHjx4t608CAMBnEdIBAPBx4eHhlww/95SqVauW6LoqVaq4vXY4HHI6nRVREgAAXo056QAA+LlvvvnmktetW7eWJLVu3Vrbtm3T2bNn886vX79eAQEBatmypSIjI9WoUSMlJiZWas0AAPgqetIBAPBxmZmZSklJcTsWFBSkmjVrSpLef/99de3aVZdffrn++9//auPGjXr99dclSWPGjNG0adN0yy23aPr06Tp27Jjuuece3XzzzYqNjZUkTZ8+XZMmTVLt2rU1cOBAnT59WuvXr9c999xTuT8UAAAfQEgHAMDHLV++XHXq1HE71rJlS/3www+SzJXXFyxYoDvvvFN16tTRe++9pzZt2kiSwsLCtGLFCt13333q1q2bwsLCNGLECM2ZMyfvs2655RadP39e//nPf/Tggw+qZs2aGjlyZOX9QAAAfAiruwMA4MccDoeWLFmiYcOGWV0KAAAQc9IBAAAAALANQjoAAAAAADbBnHQAAPwYs94AALAXetIBAAAAALAJQjoAAAAAADZBSAcAAAAAwCYI6QAAAAAA2AQhHQAAAAAAmyCkAwAAAABgE4R0AAAAAABsgpAOAAAAAIBN/B/GF06ZdS1IOwAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(np.arange(1,epochs+1), train_loss, 'r', label=\"Train Loss\")\n",
    "ax.plot(np.arange(1,epochs+1), val_loss, 'b', label=\"Val Loss\")\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Train Curve')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 正则化\n",
    "### regularized cost（正则化代价函数）\n",
    "$$J\\left( \\theta  \\right)=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[-{{y}^{(i)}}\\log \\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)-\\left( 1-{{y}^{(i)}} \\right)\\log \\left( 1-{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)]}+\\frac{\\lambda }{2m}\\sum\\limits_{j=1}^{n}{\\theta _{j}^{2}}$$\n",
    "正则化项实现了对参数的缩小，使得某些导致过拟合的特征的参数变小。\n",
    "从另一个角度来说，使得对损失不敏感的参数缩小较大，对损失敏感的参数缩小较小。详见Deep Learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.051267 ,  0.69956  ,  1.       ],\n       [-0.092742 ,  0.68494  ,  1.       ],\n       [-0.21371  ,  0.69225  ,  1.       ],\n       [-0.375    ,  0.50219  ,  1.       ],\n       [-0.51325  ,  0.46564  ,  1.       ],\n       [-0.52477  ,  0.2098   ,  1.       ],\n       [-0.39804  ,  0.034357 ,  1.       ],\n       [-0.30588  , -0.19225  ,  1.       ],\n       [ 0.016705 , -0.40424  ,  1.       ],\n       [ 0.13191  , -0.51389  ,  1.       ],\n       [ 0.38537  , -0.56506  ,  1.       ],\n       [ 0.52938  , -0.5212   ,  1.       ],\n       [ 0.63882  , -0.24342  ,  1.       ],\n       [ 0.73675  , -0.18494  ,  1.       ],\n       [ 0.54666  ,  0.48757  ,  1.       ],\n       [ 0.322    ,  0.5826   ,  1.       ],\n       [ 0.16647  ,  0.53874  ,  1.       ],\n       [-0.046659 ,  0.81652  ,  1.       ],\n       [-0.17339  ,  0.69956  ,  1.       ],\n       [-0.47869  ,  0.63377  ,  1.       ],\n       [-0.60541  ,  0.59722  ,  1.       ],\n       [-0.62846  ,  0.33406  ,  1.       ],\n       [-0.59389  ,  0.005117 ,  1.       ],\n       [-0.42108  , -0.27266  ,  1.       ],\n       [-0.11578  , -0.39693  ,  1.       ],\n       [ 0.20104  , -0.60161  ,  1.       ],\n       [ 0.46601  , -0.53582  ,  1.       ],\n       [ 0.67339  , -0.53582  ,  1.       ],\n       [-0.13882  ,  0.54605  ,  1.       ],\n       [-0.29435  ,  0.77997  ,  1.       ],\n       [-0.26555  ,  0.96272  ,  1.       ],\n       [-0.16187  ,  0.8019   ,  1.       ],\n       [-0.17339  ,  0.64839  ,  1.       ],\n       [-0.28283  ,  0.47295  ,  1.       ],\n       [-0.36348  ,  0.31213  ,  1.       ],\n       [-0.30012  ,  0.027047 ,  1.       ],\n       [-0.23675  , -0.21418  ,  1.       ],\n       [-0.06394  , -0.18494  ,  1.       ],\n       [ 0.062788 , -0.16301  ,  1.       ],\n       [ 0.22984  , -0.41155  ,  1.       ],\n       [ 0.2932   , -0.2288   ,  1.       ],\n       [ 0.48329  , -0.18494  ,  1.       ],\n       [ 0.64459  , -0.14108  ,  1.       ],\n       [ 0.46025  ,  0.012427 ,  1.       ],\n       [ 0.6273   ,  0.15863  ,  1.       ],\n       [ 0.57546  ,  0.26827  ,  1.       ],\n       [ 0.72523  ,  0.44371  ,  1.       ],\n       [ 0.22408  ,  0.52412  ,  1.       ],\n       [ 0.44297  ,  0.67032  ,  1.       ],\n       [ 0.322    ,  0.69225  ,  1.       ],\n       [ 0.13767  ,  0.57529  ,  1.       ],\n       [-0.0063364,  0.39985  ,  1.       ],\n       [-0.092742 ,  0.55336  ,  1.       ],\n       [-0.20795  ,  0.35599  ,  1.       ],\n       [-0.20795  ,  0.17325  ,  1.       ],\n       [-0.43836  ,  0.21711  ,  1.       ],\n       [-0.21947  , -0.016813 ,  1.       ],\n       [-0.13882  , -0.27266  ,  1.       ],\n       [ 0.18376  ,  0.93348  ,  0.       ],\n       [ 0.22408  ,  0.77997  ,  0.       ],\n       [ 0.29896  ,  0.61915  ,  0.       ],\n       [ 0.50634  ,  0.75804  ,  0.       ],\n       [ 0.61578  ,  0.7288   ,  0.       ],\n       [ 0.60426  ,  0.59722  ,  0.       ],\n       [ 0.76555  ,  0.50219  ,  0.       ],\n       [ 0.92684  ,  0.3633   ,  0.       ],\n       [ 0.82316  ,  0.27558  ,  0.       ],\n       [ 0.96141  ,  0.085526 ,  0.       ],\n       [ 0.93836  ,  0.012427 ,  0.       ],\n       [ 0.86348  , -0.082602 ,  0.       ],\n       [ 0.89804  , -0.20687  ,  0.       ],\n       [ 0.85196  , -0.36769  ,  0.       ],\n       [ 0.82892  , -0.5212   ,  0.       ],\n       [ 0.79435  , -0.55775  ,  0.       ],\n       [ 0.59274  , -0.7405   ,  0.       ],\n       [ 0.51786  , -0.5943   ,  0.       ],\n       [ 0.46601  , -0.41886  ,  0.       ],\n       [ 0.35081  , -0.57968  ,  0.       ],\n       [ 0.28744  , -0.76974  ,  0.       ],\n       [ 0.085829 , -0.75512  ,  0.       ],\n       [ 0.14919  , -0.57968  ,  0.       ],\n       [-0.13306  , -0.4481   ,  0.       ],\n       [-0.40956  , -0.41155  ,  0.       ],\n       [-0.39228  , -0.25804  ,  0.       ],\n       [-0.74366  , -0.25804  ,  0.       ],\n       [-0.69758  ,  0.041667 ,  0.       ],\n       [-0.75518  ,  0.2902   ,  0.       ],\n       [-0.69758  ,  0.68494  ,  0.       ],\n       [-0.4038   ,  0.70687  ,  0.       ],\n       [-0.38076  ,  0.91886  ,  0.       ],\n       [-0.50749  ,  0.90424  ,  0.       ],\n       [-0.54781  ,  0.70687  ,  0.       ],\n       [ 0.10311  ,  0.77997  ,  0.       ],\n       [ 0.057028 ,  0.91886  ,  0.       ],\n       [-0.10426  ,  0.99196  ,  0.       ],\n       [-0.081221 ,  1.1089   ,  0.       ],\n       [ 0.28744  ,  1.087    ,  0.       ],\n       [ 0.39689  ,  0.82383  ,  0.       ],\n       [ 0.63882  ,  0.88962  ,  0.       ],\n       [ 0.82316  ,  0.66301  ,  0.       ],\n       [ 0.67339  ,  0.64108  ,  0.       ],\n       [ 1.0709   ,  0.10015  ,  0.       ],\n       [-0.046659 , -0.57968  ,  0.       ],\n       [-0.23675  , -0.63816  ,  0.       ],\n       [-0.15035  , -0.36769  ,  0.       ],\n       [-0.49021  , -0.3019   ,  0.       ],\n       [-0.46717  , -0.13377  ,  0.       ],\n       [-0.28859  , -0.060673 ,  0.       ],\n       [-0.61118  , -0.067982 ,  0.       ],\n       [-0.66302  , -0.21418  ,  0.       ],\n       [-0.59965  , -0.41886  ,  0.       ],\n       [-0.72638  , -0.082602 ,  0.       ],\n       [-0.83007  ,  0.31213  ,  0.       ],\n       [-0.72062  ,  0.53874  ,  0.       ],\n       [-0.59389  ,  0.49488  ,  0.       ],\n       [-0.48445  ,  0.99927  ,  0.       ],\n       [-0.0063364,  0.99927  ,  0.       ],\n       [ 0.63265  , -0.030612 ,  0.       ]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt('ex2data2.txt', delimiter=',')\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看数据集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "positive_data_idx= np.where(data[:,2]==1)\n",
    "positive_data = data[positive_data_idx]\n",
    "negative_data_idx= np.where(data[:, 2] == 0)\n",
    "negative_data = data[negative_data_idx]\n",
    "ax.scatter(x=positive_data[:, 0], y=positive_data[:, 1], s=10, color=\"red\",label=\"positive\")\n",
    "ax.scatter(x=negative_data[:, 0], y=negative_data[:, 1], s=10, label=\"negative\")\n",
    "ax.set_title(\"Dataset\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "划分训练集和验证集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y = train_test_split(data[:, :-1], data[:, -1], test_size=0.2)\n",
    "# train_x, val_x, train_y, val_y = data[:, :-1], data[:, :-1], data[:, -1], data[:, -1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=train_x[:,0], y=train_x[:,1], s=10, label=\"Train\")\n",
    "ax.scatter(x=val_x[:,0], y=val_x[:,1], s=10, color=\"red\", label=\"Validation\")\n",
    "ax.set_title('Dataset for Train and Validation')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看训练集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAKqCAYAAABGhh8JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAABiPElEQVR4nO3df1xUVeL/8TeggJKDKCoakCCti2aKkqxSUSsG5rr9+pRulj+2NO3Xqv3SviWZu6nVp2Uri7a1zFY/9uOj1W5qS5TuJ3MtFKtV143EZSdFE5ERLH/A/f7BOjryc5CZe2fm9Xw85oH3zJk7Z7hzZd5zzj0nyDAMQwAAAAAAwHTBZjcAAAAAAADUIaQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAABJ0qRJk9S7d2+zmwEAQEAjpAMAYHFBQUEtuq1fv97sptazZ88eTZ48WX369FF4eLhiYmJ0+eWXKycnp1X7W7NmjR577LG2bSQAABYSZBiGYXYjAABA4/74xz+6bC9btkz5+fl6/fXXXcpHjhypHj16tPp5Tpw4odraWoWFhbV6H2cqLi7WJZdcog4dOuiXv/ylevfurX379mnr1q1au3atfvjhB7f3effdd2vx4sXi4wsAwF+1M7sBAACgabfccovL9t/+9jfl5+fXKz/b0aNH1bFjxxY/T/v27VvVvsb89re/VVVVlbZt26YLLrjA5b4DBw606XMBAOAvGO4OAIAfuOKKK3TRRRdpy5Ytuvzyy9WxY0c9/PDDkqR3331Xo0ePVq9evRQWFqY+ffpo/vz5qqmpcdnH2dek79mzR0FBQXr66af1+9//Xn369FFYWJguueQSff7558226ZtvvlFsbGy9gC5J3bt3r1e2du1aXXbZZYqIiFCnTp00evRobd++3aV9ixcvluR6CQAAAP6EnnQAAPxEeXm5Ro0apXHjxumWW25xDn1funSpzjvvPM2aNUvnnXeePvroI82dO1cOh0NPPfVUs/tdsWKFjhw5ojvuuENBQUF68skndf3112v37t1N9r5fcMEF+vDDD/XRRx/ppz/9aZPP8frrr2vixInKysrSokWLdPToUb344ou69NJLVVRUpN69e+uOO+7Q3r17GxzqDwCAv+CadAAAfExD12VfccUV2rBhg/Ly8nTHHXe41P/+++/VoUMHl7Jp06bp9ddf16FDh5zXoE+aNEnr16/Xnj17JNX1pCckJKhr1676+uuvFRUVJUl67733dM011+hPf/qTfvaznzXazu3bt+uSSy7R999/r0GDBikjI0NXXnmlRo4c6TIMv6qqSnFxcbrxxhv1+9//3lm+f/9+9e3bVzfddJOznGvSAQD+juHuAAD4ibCwME2ePLle+ZkB/ciRIzp48KAuu+wyHT16VP/4xz+a3e/YsWOdAV2SLrvsMknS7t27m3xc//79tW3bNt1yyy3as2ePfve73+naa69Vjx499PLLLzvr5efn6/Dhw/rFL36hgwcPOm8hISFKS0vTxx9/3GwbAQDwFwx3BwDAT5x//vkKDQ2tV759+3Y98sgj+uijj+RwOFzuq6ysbHa/8fHxLtunAntFRUWzj/3Rj36k119/XTU1NdqxY4f+/Oc/68knn9TUqVOVkJCgzMxMff3115LU6JB4m83W7PMAAOAvCOkAAPiJs4e0S9Lhw4eVkZEhm82mxx9/3Lle+datW/XQQw+ptra22f2GhIQ0WO7OkPOQkBANGDBAAwYM0LBhw3TllVdq+fLlyszMdLbh9ddfV0xMTL3HtmvHxxUAQODgrx4AAH5s/fr1Ki8v16pVq3T55Zc7y0tKSkxrU2pqqiRp3759kqQ+ffpIqpvxPTMzs8nHMps7AMDfcU06AAB+7FQv+Jm93sePH9cLL7zg8ef+v//7P504caJe+Zo1ayRJffv2lSRlZWXJZrPpiSeeaLD+d9995/x3RESEpLoRAgAA+CN60gEA8GPDhw9XVFSUJk6cqHvvvVdBQUF6/fXXvTI7+qJFi7RlyxZdf/31uvjiiyVJW7du1bJly9SlSxfNmDFDUt015y+++KJuvfVWDR48WOPGjVO3bt1UWlqq999/X+np6Xr++eclSUOGDJEk3XvvvcrKylJISIjGjRvn8dcCAIC3ENIBAPBjXbt21Z///Gfdd999euSRRxQVFaVbbrlFI0aMUFZWlkef++GHH9aKFSu0YcMGLV++XEePHlXPnj01btw4Pfroo0pISHDWvfnmm9WrVy8tXLhQTz31lI4dO6bzzz9fl112mcuM9ddff73uuecerVy5Un/84x9lGAYhHQDgV1gnHQAAAAAAi+CadAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFhEQK6TXltbq71796pTp04KCgoyuzkAAAAAAD9nGIaOHDmiXr16KTi48f7ygAzpe/fuVVxcnNnNAAAAAAAEmH//+9+KjY1t9P6ADOmdOnWSVPfLsdlsJrcGAAAAAODvHA6H4uLinHm0MQEZ0k8NcbfZbIR0AAAAAIDXNHfJNRPHAQAAAABgEYR0AAAAAAAsgpAOAAAAAIBFBOQ16S1VU1OjEydOmN0MuCE0NLTJ5QwAAAAAwMoI6Q0wDENlZWU6fPiw2U2Bm4KDg5WQkKDQ0FCzmwIAAAAAbiOkN+BUQO/evbs6duzY7Ox7sIba2lrt3btX+/btU3x8PMcNAAAAgM8hpJ+lpqbGGdC7du1qdnPgpm7dumnv3r06efKk2rdvb3ZzAAAAAMAtXLx7llPXoHfs2NHklqA1Tg1zr6mpMbklAAAAAOA+QnojGCrtmzhuAAAAAHwZIR0AAAAAAIsgpKNZ69evV1BQULOz3ffu3Vu5ubleaRMAAAAA+CNCuh+ZNGmSgoKCFBQUpNDQUCUlJenxxx/XyZMnz2m/w4cP1759+xQZGSlJWrp0qTp37lyv3ueff66pU6ee03MBAAAAQCBjdnc/k52drVdffVXHjh3TmjVrdNddd6l9+/aaM2dOq/cZGhqqmJiYZut169at1c8BAAAAAKAn3e+EhYUpJiZGF1xwgaZPn67MzEy99957qqio0IQJExQVFaWOHTtq1KhR+vrrr52P+9e//qUxY8YoKipKERER6t+/v9asWSPJdbj7+vXrNXnyZFVWVjp77R977DFJrsPdb775Zo0dO9albSdOnFB0dLSWLVsmqW5d8wULFighIUEdOnTQwIED9fbbb3v+lwQAAAAAFkVPugcVlVao5GC1EqIjlBIfZUobOnTooPLyck2aNElff/213nvvPdlsNj300EO6+uqrtWPHDrVv31533XWXjh8/rr/+9a+KiIjQjh07dN5559Xb3/Dhw5Wbm6u5c+dq165dktRgvfHjx+vGG29UVVWV8/4PPvhAR48e1XXXXSdJWrBggf74xz8qLy9PF154of7617/qlltuUbdu3ZSRkeHB3woAAAAAWBMh3UMWrt2pvA27ndvTMhI1e1Sy157fMAwVFBTogw8+0KhRo/TOO+9o48aNGj58uCRp+fLliouL0zvvvKMbb7xRpaWluuGGGzRgwABJUmJiYoP7DQ0NVWRkpIKCgpocAp+VlaWIiAitXr1at956qyRpxYoV+vnPf65OnTrp2LFjeuKJJ/Thhx9q2LBhzuf85JNP9NJLLxHSAQAAAAQkhrt7QFFphUtAl6S8DbtVVFrh8ef+85//rPPOO0/h4eEaNWqUxo4dq0mTJqldu3ZKS0tz1uvatav69u2rnTt3SpLuvfde/frXv1Z6erpycnL05ZdfnlM72rVrp5tuuknLly+XJFVXV+vdd9/V+PHjJUnFxcU6evSoRo4cqfPOO895W7Zsmb755ptzem4AAAAA8FWEdA8oOVjtVnlbuvLKK7Vt2zZ9/fXX+v777/Xaa68pKCio2cfdfvvt2r17t2699VZ99dVXSk1N1XPPPXdObRk/frwKCgp04MABvfPOO+rQoYOys7MlSVVVVZKk999/X9u2bXPeduzYwXXpAAAAAAIWId0DEqIj3CpvSxEREUpKSlJ8fLzatau7miE5OVknT57U5s2bnfXKy8u1a9cu9evXz1kWFxenadOmadWqVbrvvvv08ssvN/gcoaGhqqmpabYtw4cPV1xcnN544w0tX75cN954o9q3by9J6tevn8LCwlRaWqqkpCSXW1xc3Ln8CgAAAADAZ3FNugekxEdpWkaiy5D36RmJpk0ed+GFF+qaa67RlClT9NJLL6lTp06aPXu2zj//fF1zzTWSpBkzZmjUqFH60Y9+pIqKCn388cdKTm74GvrevXurqqpKBQUFGjhwoDp27KiOHTs2WPfmm29WXl6e/vnPf+rjjz92lnfq1En333+/Zs6cqdraWl166aWqrKzUxo0bZbPZNHHixLb/RQAAAACAxRHSPWT2qGRl9Y8xfXb3U1599VX96le/0s9+9jMdP35cl19+udasWePs2a6pqdFdd90lu90um82m7Oxs/fa3v21wX8OHD9e0adM0duxYlZeXKycnx7kM29nGjx+v3/zmN7rggguUnp7uct/8+fPVrVs3LViwQLt371bnzp01ePBgPfzww2362gEAAADAVwQZhmGY3QhvczgcioyMVGVlpWw2m8t9P/zwg0pKSpSQkKDw8HCTWojW4vgBAAAAsKKmcuiZ6EkHAKAx9kKpvFjqmiTFpprdGgAAEAAI6QAANCQ/R9qYe3o7fYY0cp5ZrQEAAAGC2d0BADibvdA1oEt12/ZCM1oDAAACCCEdAICzlRe7Vw4AANBGCOkAAJyta5J75QAAAG2EkA4AwNliU+uuQT9T+kwmjwMAAB7HxHEAADRk5DwpeQyzuwMAAK8ipAMA0JjYVMI5AADwKoa7AwAAAABgEYR0eFXv3r2Vm5trdjMAAAAAwJII6X5k0qRJCgoK0sKFC13K33nnHQUFBXm1LUuXLlXnzp3rlX/++eeaOnWqV9sCAAAAAL6CkO5nwsPDtWjRIlVUVJjdlAZ169ZNHTt2NLsZAAAAAGBJhHQ/k5mZqZiYGC1YsKDROp988okuu+wydejQQXFxcbr33ntVXV3tvH/fvn0aPXq0OnTooISEBK1YsaLeMPVnnnlGAwYMUEREhOLi4nTnnXeqqqpKkrR+/XpNnjxZlZWVCgoKUlBQkB577DFJrsPdb775Zo0dO9albSdOnFB0dLSWLVsmSaqtrdWCBQuUkJCgDh06aODAgXr77bfb4DcFAAAAANZDSPcke6H0xcq6n14SEhKiJ554Qs8995zsdnu9+7/55htlZ2frhhtu0Jdffqk33nhDn3zyie6++25nnQkTJmjv3r1av369/vd//1e///3vdeDAAZf9BAcH69lnn9X27dv12muv6aOPPtKDDz4oSRo+fLhyc3Nls9m0b98+7du3T/fff3+9towfP15/+tOfnOFekj744AMdPXpU1113nSRpwYIFWrZsmfLy8rR9+3bNnDlTt9xyizZs2NAmvy8AAAAAsBKWYPOU/BxpY+7p7fQZdWvuesF1112nQYMGKScnR0uWLHG5b8GCBRo/frxmzJghSbrwwgv17LPPKiMjQy+++KL27NmjDz/8UJ9//rlSU+uWHfrDH/6gCy+80GU/px4v1fWO//rXv9a0adP0wgsvKDQ0VJGRkQoKClJMTEyj7czKylJERIRWr16tW2+9VZK0YsUK/fznP1enTp107NgxPfHEE/rwww81bNgwSVJiYqI++eQTvfTSS8rIyDjXXxUAAAAAWAoh3RPsha4BXarbTh7jtfV2Fy1apJ/+9Kf1erC/+OILffnll1q+fLmzzDAM1dbWqqSkRP/85z/Vrl07DR482Hl/UlKSoqKiXPbz4YcfasGCBfrHP/4hh8OhkydP6ocfftDRo0dbfM15u3btdNNNN2n58uW69dZbVV1drXfffVcrV66UJBUXF+vo0aMaOXKky+OOHz+ulJQUt34fAAAAAOALCOmeUF7ceLmXQvrll1+urKwszZkzR5MmTXKWV1VV6Y477tC9995b7zHx8fH65z//2ey+9+zZo5/97GeaPn26fvOb36hLly765JNPdNttt+n48eNuTQw3fvx4ZWRk6MCBA8rPz1eHDh2UnZ3tbKskvf/++zr//PNdHhcWFtbi5wAAAAAAX0FI94SuSe6Ve8jChQs1aNAg9e3b11k2ePBg7dixQ0lJDbelb9++OnnypIqKijRkyBBJdT3aZ84Wv2XLFtXW1uq///u/FRxcN63Bm2++6bKf0NBQ1dTUNNvG4cOHKy4uTm+88YbWrl2rG2+8Ue3bt5ck9evXT2FhYSotLWVoOwAAAICAQEj3hNjUumvQXa5Jn+m1XvRTBgwYoPHjx+vZZ591lj300EP6yU9+orvvvlu33367IiIitGPHDuXn5+v555/Xj3/8Y2VmZmrq1Kl68cUX1b59e913333q0KGDc631pKQknThxQs8995zGjBmjjRs3Ki8vz+W5e/furaqqKhUUFGjgwIHq2LFjoz3sN998s/Ly8vTPf/5TH3/8sbO8U6dOuv/++zVz5kzV1tbq0ksvVWVlpTZu3CibzaaJEyd64LcGAAAAAOZhdndPGTlPur1Auu6lup8jHzOlGY8//rhqa2ud2xdffLE2bNigf/7zn7rsssuUkpKiuXPnqlevXs46y5YtU48ePXT55Zfruuuu05QpU9SpUyeFh4dLkgYOHKhnnnlGixYt0kUXXaTly5fXW/Jt+PDhmjZtmsaOHatu3brpySefbLSN48eP144dO3T++ecrPT3d5b758+fr0Ucf1YIFC5ScnKzs7Gy9//77SkhIaItfDwAAAABYSpBhGIbZjfA2h8OhyMhIVVZWymazudz3ww8/qKSkRAkJCc5QGujsdrvi4uL04YcfasSIEWY3p0kcPwAAAABW1FQOPRPD3VHPRx99pKqqKg0YMED79u3Tgw8+qN69e+vyyy83u2kAAAAA4NcI6ajnxIkTevjhh7V792516tRJw4cP1/Lly50TugEAAAAAPIOQjnqysrKUlZVldjMAAAAAIOAwcRwAAAAAABZBSG9EAM6n5xc4bgAAAAB8GSH9LKeuuz569KjJLUFrHD9+XJIUEhJicksAAAAAwH1ck36WkJAQde7cWQcOHJAkdezYUUFBQSa3Ci1RW1ur7777Th07dlS7dry1AQAAAPgekkwDYmJiJMkZ1OE7goODFR8fzxcrAAAAAHwSIb0BQUFB6tmzp7p3764TJ06Y3Ry4ITQ0VMHBXMUBAAAAwDcR0psQEhLCtc0AAAAAAK/xaJfjX//6V40ZM0a9evVSUFCQ3nnnnWYfs379eg0ePFhhYWFKSkrS0qVL69VZvHixevfurfDwcKWlpemzzz5r+8YDAAAAAOBlHg3p1dXVGjhwoBYvXtyi+iUlJRo9erSuvPJKbdu2TTNmzNDtt9+uDz74wFnnjTfe0KxZs5STk6OtW7dq4MCBysrK4vpxAAAAAIDPCzK8tLB0UFCQVq9erWuvvbbROg899JDef/99/f3vf3eWjRs3TocPH9a6deskSWlpabrkkkv0/PPPS6qb0TsuLk733HOPZs+e3aK2OBwORUZGqrKyUjabrfUvCggU9kKpvFjqmiTFpprdGiAwcR4CAODTWppDLXVN+qZNm5SZmelSlpWVpRkzZkiqWwN7y5YtmjNnjvP+4OBgZWZmatOmTd5sKhA48nOkjbmnt9NnSCPnmdUaIDBxHgIAEDAsNQ12WVmZevTo4VLWo0cPORwOff/99zp48KBqamoarFNWVtbofo8dOyaHw+FyA9AC9kLXYCDVbdsLzWgNEJg4DwEACCiWCumesmDBAkVGRjpvcXFxZjcJ8A3lxe6VA2h7nIcAAAQUS4X0mJgY7d+/36Vs//79stls6tChg6KjoxUSEtJgnZiYmEb3O2fOHFVWVjpv//73vz3SfsDvdE1yrxxA2+M8BAAgoFgqpA8bNkwFBQUuZfn5+Ro2bJgkKTQ0VEOGDHGpU1tbq4KCAmedhoSFhclms7ncALRAbGrdta9nSp/JpFWAN3EeAgAQUDw6cVxVVZWKi08PxyspKdG2bdvUpUsXxcfHa86cOfr222+1bNkySdK0adP0/PPP68EHH9Qvf/lLffTRR3rzzTf1/vvvO/cxa9YsTZw4UampqRo6dKhyc3NVXV2tyZMne/KlAIFr5DwpeQyzSgNm4jwEACBgeDSkFxYW6sorr3Ruz5o1S5I0ceJELV26VPv27VNpaanz/oSEBL3//vuaOXOmfve73yk2NlZ/+MMflJWV5awzduxYfffdd5o7d67Kyso0aNAgrVu3rt5kcgDaUGwqoQAwG+chAAABwWvrpFsJ66QDAAAAALyppTnUUtekAwAAAAAQyAjpAAAAAABYhEevSQcAeF5RaYVKDlYrITpCKfFRZjcHAAAA54CQDgA+bOHancrbsNu5PS0jUbNHJZvYIgAAAJwLhrsDgI8qKq1wCeiSlLdht4pKK0xqEQAAAM4VIR0AfFTJwWq3ygEAAGB9hHQA8FEJ0RFulQMAAMD6COkA4KNS4qM0LSPRpWx6RiKTxwEAAPgwJo4DAB82e1SysvrHMLs7AACAnyCkA4CPS4mPIpwDAAD4CYa7AwAAAABgEfSkAwAAnGIvlMqLpa5JUmyq2a0BAAQgQjoAAIAk5edIG3NPb6fPkEbOM6s1AIAAxXB3AAAAe6FrQJfqtu2FZrQGABDACOkAAADlxe6VAwDgIQx3BxAYuM4UaJ1AOXe6JrlXDgCAhxDSAfg/rjMFWieQzp3Y1LrX5/J6Z/r3FxMAAEsKMgzDMLsR3uZwOBQZGanKykrZbDazmwPAk+yF0h9G1C+/vYAP30BTAvXcCZSRAwAAr2tpDuWadAD+jetMgdYJ1HMnNlUaOI6ADgAwDcPdgUAVKL1FXGcKtA7nDgAApqAnHQhE+Tl1w1hX31H3Mz/H7BZ5zqnrTM/EdaZA8zh3AAAwBdekc006Ag3Xmfr36wTaGucOAABtoqU5lOHuQKBp6jpTf/4AHpvq368P8BTOHQAAvIrh7kCg4TpTAAAAwLII6UCg4TpTAADgTfZC6YuVdT8BNIvh7kAgGjlPSh7DdaYAAMCz8nOkjbmnt9Nn1H0OAdAoQjoQqLjOFAAAeJK90DWgS3XbyWP4DAI0geHuAAAAANpeU5PVAmgUIR0AAABA22OyWqBVCOkAAAAA2h6T1QKtwjXpAAAAADyDyWoBtxHSAQAAAHgOk9UCbmG4OwAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYRDuzGwAAAAA0yF4olRdLXZOk2FSzWwMAXkFIBwAAgPXk50gbc09vp8+QRs4zqzUA4DUMdwcAwEOKSiu0aqtdRaUVZjcF8C32QteALtVt2wvNaA0AeBU96QAAeMDCtTuVt2G3c3taRqJmj0o2sUWADykvbrycYe8A/Bw96QAAtLGi0gqXgC5JeRt206MOtFTXJPfKAcCPENIBAGhjJQer3SoHcJbY1Lpr0M+UPpNedAABgeHuAAC0sYToCLfKATRg5DwpeQyzuwMIOPSkAwBM528TrKXER2laRqJL2fSMRKXER5nUIsBHxaZKA8cR0AEEFHrSAQCm8tcJ1maPSlZW/xiVHKxWQnQEAR0AALQIIR0AYJrGJljL6h/jF6E2JT7KL14HAADwHoa7AwBMwwRrAAAArgjpAADTMMEaAACAK0I6AMA0TLAGAADgimvSAQCmYoK1AGUvZGktAAAaQEgHAJiOCdYCTH6OtDH39Hb6jLo1sQEAAMPdAQCAF9kLXQO6VLdtLzSjNQAAWA4hHQAAeE95sXvlAAAEGEI6AADwnq5J7pUDABBgCOkAAMB7YlPrrkE/U/pMJo8DAOA/mDgOAAB418h5UvIYZncHAKABhHQAAOB9samEcwAAGuCV4e6LFy9W7969FR4errS0NH322WeN1r3iiisUFBRU7zZ69GhnnUmTJtW7Pzs72xsvBQAAAAAAj/F4T/obb7yhWbNmKS8vT2lpacrNzVVWVpZ27dql7t2716u/atUqHT9+3LldXl6ugQMH6sYbb3Spl52drVdffdW5HRYW5rkXAQAAAACAF3i8J/2ZZ57RlClTNHnyZPXr1095eXnq2LGjXnnllQbrd+nSRTExMc5bfn6+OnbsWC+kh4WFudSLiory9EsBAAAAAMCjPBrSjx8/ri1btigzM/P0EwYHKzMzU5s2bWrRPpYsWaJx48YpIiLCpXz9+vXq3r27+vbtq+nTp6u8vLzRfRw7dkwOh8PlBgAAAACA1Xg0pB88eFA1NTXq0aOHS3mPHj1UVlbW7OM/++wz/f3vf9ftt9/uUp6dna1ly5apoKBAixYt0oYNGzRq1CjV1NQ0uJ8FCxYoMjLSeYuLi2v9iwIAAAAAwEMsPbv7kiVLNGDAAA0dOtSlfNy4cc5/DxgwQBdffLH69Omj9evXa8SIEfX2M2fOHM2aNcu57XA4COoAAAAAAMvxaE96dHS0QkJCtH//fpfy/fv3KyYmpsnHVldXa+XKlbrtttuafZ7ExERFR0eruLi4wfvDwsJks9lcbgAAAAAAWI1HQ3poaKiGDBmigoICZ1ltba0KCgo0bNiwJh/71ltv6dixY7rllluafR673a7y8nL17NnznNsMAAAAAIBZPD67+6xZs/Tyyy/rtdde086dOzV9+nRVV1dr8uTJkqQJEyZozpw59R63ZMkSXXvtteratatLeVVVlR544AH97W9/0549e1RQUKBrrrlGSUlJysrK8vTLAQAAACBJ9kLpi5V1PwG0GY9fkz527Fh99913mjt3rsrKyjRo0CCtW7fOOZlcaWmpgoNdvyvYtWuXPvnkE/3lL3+pt7+QkBB9+eWXeu2113T48GH16tVLV111lebPn89a6QAAAIA35OdIG3NPb6fPkEbOM6s1gF8JMgzDMLsR3uZwOBQZGanKykquTwcAAADcYS+U/lB/smbdXiDFpnq/PYCPaGkO9fhwdwAAAAB+pLzhyZobLQfgFkI6AAAAgJbrmuReOQC3ENIBAAAAtFxsat016GdKn8lQd6CNeHziOABtyF5YN5SsaxJ/CCV+HwAAmGXkPCl5DH+HAQ8gpAO+gllUXfH7AADAXLGphHPAAxjuDvgCe6FrIJXqtgN1XVJ+Hz6rqLRCq7baVVRaYXZT0ASOEwAA5qEnHfAFTc2iGojfYPP78EkL1+5U3obdzu1pGYmaPSrZxBahIRwnAADMRU864AuYRdUVvw+vaote1aLSCpfgJ0l5G3bTU2sxHCdIjKQAALPRkw74glOzqLpcgx3As6jy+/CatupVLTlY3Wh5SnxUq9uHtsVxAiMpAMB8hHTAVzCLqit+Hx7XWK9qVv8YtwNbQnSEW+UwB8cpsLXlOQ8AaD2Gu8Oa7IXSFyuZCOxssanSwHEE0lP4fXhUU72q7kqJj9K0jESXsukZiZb54M/w3jpWP07wrLY85wEArUdPOqyHpbUAS2jrXtXZo5KV1T9GJQerlRAdYZngx/BeV1Y9TvA8RlIAgDXQkw5rYWktwDI80auaEh+l6wfHWib4MVFaw6x2nOAdjKQAAGugJx3WwtJagKX4e68qE6UBrvz9nAcAX0BIh7WwtBZgOSnxUX77QZ3hvUB9/nzOn1JUWsEXEQAsi+HusJZTS2udiaW1AHgIw3uBwLNw7U5d98KnmvXmF7ruhU+1cO1Os5sEAC6CDMMwzG6EtzkcDkVGRqqyslI2m83s5qAh9kKW1gLgNfSqAYGhqLRC173wab3y1XcO59yHb+Izs09paQ5luDusKTaV/2gAeE0gDO8FwDwU8DOsiOS3GO4OAACAgMA8FPAbrIjk1wjpAAAACAjMQwG/0dSKSPB5DHcHAABAwGCZOfgFVkTya4R0AIDXMEEbACtgHgr4vFMrIrlck86KSP6CkA4A8IqFa3cqb8Nu5/a0jETNHpVsYosAAPBhI+dJyWOY3d0PEdIBAB5XVFrhEtAlKW/DbmX1j6E3CwDQPJYaaxgrIvklQjoAwONY9ggA0GosNYYAw+zuANxSVFqhVVvtKiqtMLsp8CEsewQAaBWWGkMAoicdQItxTTFa69SyR2e+f1j2CADQrKaWGmOYN/wUIR1Ai3BNMc4Vyx4BANzGUmMIQAx3B9AiTV1TDLRUSnyUrh8cS0AHALTMqaXGzsRSY/Bz9KQDaBGuKQYAAKZgqTEEGHrSAbTIqWuKz8Q1xQAAwCtiU6WB4wjoCAj0pANoMa4pBgAAADyLkA7ALSnxUYRzAAAAwEMY7g4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFsE16QAAAAAaZy9k+TPAiwjpAAAAABqWnyNtzD29nT6jbt1yAB7DcHcAAAAA9dkLXQO6VLdtLzSjNUDAIKQDAAAAqK+82L1yAG2C4e4AAABwKiqtUMnBaiVERyglPsrs5sBMXZPcKwfQJgjpAAAAkCQtXLtTeRt2O7enZSRq9qhkE1sEU8Wm1l2D7nJN+kwmjwM8jJAOAAB8Dr29ba+otMIloEtS3obdyuofw+84kI2cJyWPYXZ3wIsI6QAAwKfQ2+sZJQerGy0npAe42FTCOeBFTBwHAAB8RmO9vUWlFSa1yH8kREe4VQ4A8AxCOgAA8BlN9fbi3KTER2laRqJL2fSMRHrRAcDLGO4OAAB8Br29njV7VLKy+sdwvT8AmIiedAAA4DPo7fW8lPgoXT84lt8pAJiEnnQAAOBT6O0FAPgzQjoAIOCxnJfvSYmP4lgBAPwSIR0AENBYzgsAAFgJ16QDAHxGUWmFVm21t9lyWyznBQAArIaedACAT/BEj3dTy3kxlBoAAJiBnnR4j71Q+mJl3U8AcIOnerxZzivwtPVoDAAA2ho96fCO/BxpY+7p7fQZ0sh5ZrUGgI/xVI/3qeW8zvwCgOW8/BfzDwAAfAEhHZ5nL3QN6FLddvIYKTbVjBYB8DGe7PFmOa/A0NhojKz+MRxzAIClMNwdnlde7F45AJzlVI/3mdqyxzslPkrXD44lrPmxpkZjAABgJfSkw/O6JrlXDgANoMcb54L5BwAAvoKedHhebGrdNehnSp/JUHcAbqPHG63l6dEYDWGSOgBAawQZhmGY3QhvczgcioyMVGVlpWw2m9nNCRz2wroh7l2TCOgAAFMUlVZ4ZTQGk9QBAM7W0hxKSCekAwCANlRUWqHrXvi0XvnqO4czCgQAAlhLcyjD3QEAANoQk9QBAM4FIR0AAKANMUkdAOBceCWkL168WL1791Z4eLjS0tL02WefNVp36dKlCgoKcrmFh4e71DEMQ3PnzlXPnj3VoUMHZWZm6uuvv/b0ywAAAGiWGZPUAQD8h8eXYHvjjTc0a9Ys5eXlKS0tTbm5ucrKytKuXbvUvXv3Bh9js9m0a9cu53ZQUJDL/U8++aSeffZZvfbaa0pISNCjjz6qrKws7dixo16gB4CzeWviKACBiyUDgQDGZMk4Rx6fOC4tLU2XXHKJnn/+eUlSbW2t4uLidM8992j27Nn16i9dulQzZszQ4cOHG9yfYRjq1auX7rvvPt1///2SpMrKSvXo0UNLly7VuHHjmm0TE8cBgYsZlwEAgMfk50gbc09vp8+QRs4zqzWwGEtMHHf8+HFt2bJFmZmZp58wOFiZmZnatGlTo4+rqqrSBRdcoLi4OF1zzTXavn27876SkhKVlZW57DMyMlJpaWlN7hPwOnuh9MXKup+whKLSCpeALkl5G3azhjEAADh39kLXgC7VbfNZEG7yaEg/ePCgampq1KNHD5fyHj16qKysrMHH9O3bV6+88oreffdd/fGPf1Rtba2GDx8uu90uSc7HubPPY8eOyeFwuNwAj8rPkf4wQlp9R93P/ByzWwQx4zIAAPCg8mL3yoFGWG5292HDhmnChAkaNGiQMjIytGrVKnXr1k0vvfRSq/e5YMECRUZGOm9xcXFt2GLgLHyLalnMuAwA8BdFpRVatdXOaDAr6ZrkXjnQCI+G9OjoaIWEhGj//v0u5fv371dMTEyL9tG+fXulpKSouLjuG6hTj3Nnn3PmzFFlZaXz9u9//9vdlwK0HN+iWhYzLgMA/MHCtTt13QufatabX+i6Fz7VwrU7zW4SpLpJ4tJnuJalz2TyOLjNo7O7h4aGasiQISooKNC1114rqW7iuIKCAt19990t2kdNTY2++uorXX311ZKkhIQExcTEqKCgQIMGDZJUdwH+5s2bNX369Ab3ERYWprCwsHN+PUCL8C2qpTHjMgDAlzU2v0pW/xj+plnByHlS8hhmd8c58fgSbLNmzdLEiROVmpqqoUOHKjc3V9XV1Zo8ebIkacKECTr//PO1YMECSdLjjz+un/zkJ0pKStLhw4f11FNP6V//+pduv/12SXXLsc2YMUO//vWvdeGFFzqXYOvVq5fziwDAVKe+RXWZ2ZNvUa0kJT6KDzIAAJ/U1Pwq/G2ziNhUPvfhnHg8pI8dO1bfffed5s6dq7KyMg0aNEjr1q1zTvxWWlqq4ODTo+4rKio0ZcoUlZWVKSoqSkOGDNGnn36qfv36Oes8+OCDqq6u1tSpU3X48GFdeumlWrduHWukwzr4FhUAAHgA86sA/s/j66RbEeukA/AlRaUVDM8HADgtXLvTZcj79IxEPTQq2cQWAWiJluZQj/ekAwBa7+wPYtMyEjWbD2IAENCYXwXwb4R0IMDQK+s7mBwIANAY5lcB/BchHQgg9Mr6FiYHAgAACDweXScdgHU01itbVFphUovQHCYHAgAACDyEdCBANNUrC2tKiY/StIxEl7LpGYn0ogMAAPgxhrsDAYJeWd/E5EAAAACBhZ50IEDQK+u7UuKjdP3gWI4VAABAAKAnHQgg9MoCAAAA1kZIBwIMS7YAAAC4YolaWAkhHQAAAEDAYolaWA3XpAMAAAAISCxRCysipAMAAAAISCxRCysipAMAAAAISCxRCysipAMAAAAISCxRCyti4jgAAAAAAYslamE1hHQAAAAAAY0lamElDHcHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALILZ3QEA8AFFpRUsDwQAQAAgpAMAYHEL1+5U3obdzu1pGYmaPSrZxBYBAABPYbg7AAAWVlRa4RLQJSlvw24VlVaY1CIAAOBJhHQAACys5GC1W+UAAMC3EdIBALCwhOgIt8oBAIBvI6QDAGBhKfFRmpaR6FI2PSORyeMAAPBTTBwHAIDFzR6VrKz+MczuDgBAACCkAwDgA1LiowjnAAAEAIa7AwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFcE06AAAAAMAc9kKpvFjqmiTFpprdGksgpAMAAAAAvC8/R9qYe3o7fYY0cp5ZrbEMhrsDAFqsqLRCq7baVVRaYXZTAACAL7MXugZ0qW7bXmhGayyFnnQAQIssXLtTeRt2O7enZSRq9qhkE1sEAAB8Vnlx4+UBPuydnnQAQLOKSitcArok5W3YTY86AABona5J7pUHEEI6AKBZJQer3SoHAABoUmxq3TXoZ0qfGfC96BLD3QEALZAQHeFWOQAAQLNGzpOSxzC7+1noSQcANCslPkrTMhJdyqZnJColPsqkFgEAAL8QmyoNHEdAPwM96UADikorVHKwWgnREYQQ4D9mj0pWVv8Yzg0AAAAPIqQDZ2EGa6BxKfFRhHMAAAAPYrg7cAZmsAYAAABgJkI6cAZmsAYAAABgJkI6cAZmsAYAAABgJkI6cAZmsAYAAABgJiaOA87CDNYAAAAAzEJItzJ7oVReLHVNYt1AL2MG68DDsnsAAACwAkK6VeXnSBtzT2+nz5BGzjOrNYBfY9k9AAAAWAXXpFuRvdA1oEt12/ZCM1oD+DWW3QMAAICVENKtqLzYvXIArcayewAAALASQroVdU1yrxxAq7HsHgAAAKyEkG5Fsal116CfKX0mk8cBHsCyewAAALCSIMMwDLMb4W0Oh0ORkZGqrKyUzWYzuzmNs9rs7lZrD9CGmN0dAAAAntTSHEpIt3JItxJmmwcAAACAVmtpDmW4O5rHbPMAAAAA4BWEdDSP2eYBAAAAwCsI6Wges80DAAAAgFcQ0tE8ZpsHAAAArMdeKH2xkstQ/Uw7sxsAHzFynpQ8htndAQAAACtgYme/RUhHy8WmEs4BAAAAszU2sXPyGD6v+wGGuwMAAACAL2FiZ79GSAcAAAAAX8LEzn6NkA4AAAAAvoSJnf2aV0L64sWL1bt3b4WHhystLU2fffZZo3VffvllXXbZZYqKilJUVJQyMzPr1Z80aZKCgoJcbtnZ2Z5+GQAAAABgDSPnSbcXSNe9VPdz5GNmtwhtxOMh/Y033tCsWbOUk5OjrVu3auDAgcrKytKBAwcarL9+/Xr94he/0Mcff6xNmzYpLi5OV111lb799luXetnZ2dq3b5/z9j//8z+efikAAAAAYB2xqdLAcfSg+5kgwzAMTz5BWlqaLrnkEj3//POSpNraWsXFxemee+7R7Nmzm318TU2NoqKi9Pzzz2vChAmS6nrSDx8+rHfeeadVbXI4HIqMjFRlZaVsNlur9gEAAAAAQEu1NId6tCf9+PHj2rJlizIzM08/YXCwMjMztWnTphbt4+jRozpx4oS6dOniUr5+/Xp1795dffv21fTp01VeXt7oPo4dOyaHw+FyAwAAAADAajwa0g8ePKiamhr16NHDpbxHjx4qKytr0T4eeugh9erVyyXoZ2dna9myZSooKNCiRYu0YcMGjRo1SjU1NQ3uY8GCBYqMjHTe4uLiWv+iAAAAAADwkHZmN6ApCxcu1MqVK7V+/XqFh4c7y8eNG+f894ABA3TxxRerT58+Wr9+vUaMGFFvP3PmzNGsWbOc2w6Hg6AOAAAAALAcj/akR0dHKyQkRPv373cp379/v2JiYpp87NNPP62FCxfqL3/5iy6++OIm6yYmJio6OlrFxcUN3h8WFiabzeZyAwAAAADAajwa0kNDQzVkyBAVFBQ4y2pra1VQUKBhw4Y1+rgnn3xS8+fP17p165Sa2vxMhXa7XeXl5erZs2ebtBsAAAAAADN4fAm2WbNm6eWXX9Zrr72mnTt3avr06aqurtbkyZMlSRMmTNCcOXOc9RctWqRHH31Ur7zyinr37q2ysjKVlZWpqqpKklRVVaUHHnhAf/vb37Rnzx4VFBTommuuUVJSkrKysjz9cgAAAAAA8BiPX5M+duxYfffdd5o7d67Kyso0aNAgrVu3zjmZXGlpqYKDT39X8OKLL+r48eP6r//6L5f95OTk6LHHHlNISIi+/PJLvfbaazp8+LB69eqlq666SvPnz1dYWJinXw4AAAAAAB7j8XXSrYh10gEAAAAA3tTSHGrp2d0B+Lei0gqVHKxWQnSEUuKjzG4OAAAAYDpCOgBTLFy7U3kbdju3p2UkavaoZBNbBAAAAJjP4xPHATBHUWmFVm21q6i0wuym1FNUWuES0CUpb8NuS7YVAAAA8CZ60gE/ZPVe6pKD1Y2WM+wdAAAAgYyedMDP+EIvdUJ0hFvlAAAAQKAgpAN+pqleaqtIiY/StIxEl7LpGYn0ogMAACDgMdwd8DO+0ks9e1SysvrHMLs7AAAAcAZ60gE/40u91CnxUbp+cKwl2wYAAACYgZ50wA/RSw0AAAD4JkI64KdS4qMI5wAAAICPYbg7AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwiHZmNwAAAACAfygqrVDJwWolREcoJT7K7OYAPomQDgAAAOCcLVy7U3kbdju3p2UkavaoZBNbBPgmhrsDAAAAOCdFpRUuAV2S8jbsVlFphUktAnwXIR0AAADAOSk5WO1WOYDGEdIBAAAAnJOE6Ai3ygE0jpAOAAAA4JykxEdpWkaiS9n0jEQmjwNagYnjAAAAAJyz2aOSldU/htndgXNESAcAAADQJlLiowjnwDliuDsAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEe3MbgAAAAAAAK1mL5TKi6WuSVJsqtmtOWeEdAAAAACAb8rPkTbmnt5OnyGNnGdWa9oEw90BAAAAAL7HXuga0KW6bXuhGa1pM4R0AAAAAIDvKS92r9xHENIBAAAAAL6na5J75T6CkA4AAAAA8D2xqXXXoJ8pfabPTx7HxHEAAAAAAN80cp6UPIbZ3QEAAAAAsITYVL8I56cw3B0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCGZ3hzXZC/1qGQUAAAAAaAlCOqwnP0famHt6O31G3fqHAAAAAODnGO4Oa7EXugZ0qW7bXmhGawAAAADAqwjpsJbyYvfKgf8oKq3Qqq12FZVWmN0UAAAAoNUY7g5r6ZrkXjkgaeHancrbsNu5PS0jUbNHJZvYIgAAAKB16EmHtcSm1l2Dfqb0mUweh0YVlVa4BHRJytuw22d61BkBAAAAgDPRkw7rGTlPSh7D7O5okZKD1Y2Wp8RHebk17mEEAAAAAM5GTzqsKTZVGjiOgI5mJURHuFVuFb4+AgAAAACeQUgH4NNS4qM0LSPRpWx6RqLle9GbGgEAAACAwMVwdwA+b/aoZGX1j1HJwWolREdYPqBLvjsCAAACQVFphU/9TQH8kr0wYC9/JaQD8Asp8VE+9UHq1AiAM4e8+8IIAADwd8wXAlhAfo60Mff0dvqMunmrAoRXhrsvXrxYvXv3Vnh4uNLS0vTZZ581Wf+tt97Sj3/8Y4WHh2vAgAFas2aNy/2GYWju3Lnq2bOnOnTooMzMTH399deefAmA25i1G82ZPSpZq+8crmduGqjVdw7XQ3wIBABTMV8IYAH2QteALtVt2wvNaI0pPB7S33jjDc2aNUs5OTnaunWrBg4cqKysLB04cKDB+p9++ql+8Ytf6LbbblNRUZGuvfZaXXvttfr73//urPPkk0/q2WefVV5enjZv3qyIiAhlZWXphx9+8PTLAVpk4dqduu6FTzXrzS903QufauHanWY3CRaVEh+l6wfH0oMOABbAfCGABZQXu1fuhzwe0p955hlNmTJFkydPVr9+/ZSXl6eOHTvqlVdeabD+7373O2VnZ+uBBx5QcnKy5s+fr8GDB+v555+XVNeLnpubq0ceeUTXXHONLr74Yi1btkx79+7VO++84+mXAzSLb+EBAPBNzBcCWEDXJPfK/ZBHQ/rx48e1ZcsWZWZmnn7C4GBlZmZq06ZNDT5m06ZNLvUlKSsry1m/pKREZWVlLnUiIyOVlpbW6D4Bb+JbeAAAfJOvrhgC+JXY1Lpr0M+UPjOgJo/z6MRxBw8eVE1NjXr06OFS3qNHD/3jH/9o8DFlZWUN1i8rK3Pef6qssTpnO3bsmI4dO+bcdjgc7r0QwA18Cw8AgO/yxRVDAL8zcp6UPCZgZ3cPiHXSFyxYoMjISOctLi7O7CbBj/EtPAAAvo35QgALiE2VBo4LuIAuebgnPTo6WiEhIdq/f79L+f79+xUTE9PgY2JiYpqsf+rn/v371bNnT5c6gwYNanCfc+bM0axZs5zbDoeDoA6P4lt4AAAAAK3h0Z700NBQDRkyRAUFBc6y2tpaFRQUaNiwYQ0+ZtiwYS71JSk/P99ZPyEhQTExMS51HA6HNm/e3Og+w8LCZLPZXG6Ap/EtPAAAAAB3ebQnXZJmzZqliRMnKjU1VUOHDlVubq6qq6s1efJkSdKECRN0/vnna8GCBZKkX/3qV8rIyNB///d/a/To0Vq5cqUKCwv1+9//XpIUFBSkGTNm6Ne//rUuvPBCJSQk6NFHH1WvXr107bXXevrlAAAAAADgMR4P6WPHjtV3332nuXPnqqysTIMGDdK6deucE7+VlpYqOPh0h/7w4cO1YsUKPfLII3r44Yd14YUX6p133tFFF13krPPggw+qurpaU6dO1eHDh3XppZdq3bp1Cg8P9/TLAQAAAADAY4IMwzDMboS3ORwORUZGqrKykqHvAAAAAACPa2kODYjZ3QEAAAAA8AWEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBHtzG4AAKAB9kKpvFjqmiTFpprdGgAAAHgJIR0ArCY/R9qYe3o7fYY0cp5ZrQEAAIAXMdwdaC17ofTFyrqfQFuxF7oGdKlum/cZAABAQKAnHWgNejrhKeXFjZcz7B0AAMDv0ZMOuIueTnhS1yT3ygEAAOBXCOmAu5rq6QTOVWxq3ciMM6XPpBcdAAAgQDDcHXAXPZ3wtJHzpOQxzO4OAAC8h5VlLIOQDrjrVE+nyzXp9HSijcWm8p4CAADewXxLlhJkGIZhdiO8zeFwKDIyUpWVlbLZbGY3B76KbxsBAADg6+yF0h9G1C+/vYDPuG2spTmUnnSgtejpBAAAgK9jZRnLYeI4AAAAAAhUzLdkOYR0AAAAAAhUrCxjOQx3BwAAAIBAxsoylkJIBwAAAIBAx3xLlsFwdwAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBHtzG4AAD9hL5TKi6WuSVJsqtmtAQAAAHwSIR3AucvPkTbmnt5OnyGNnGdWawAAAACfxXB3AOfGXuga0KW6bXuhGa0BAAAWVlRaoVVb7SoqrTC7KYBl0ZMO4NyUFzdezrB3AADwHwvX7lTeht3O7WkZiZo9KtnEFgHWRE86gHPTNcm9cgAAEHCKSitcArok5W3YTY860ABCOoBzE5tadw36mdJn0osOAACcSg5Wu1UOBDKGuwM4dyPnScljmN0dAAA0KCE6wq1yIJDRkw6gbcSmSgPHEdABAEA9KfFRmpaR6FI2PSNRKfFRJrUIsC560gEAQIsUlVao5GC1EqIj+GANwG2zRyUrq38M/48AzSCkAwCAZjErM4C2kBIfRTgHmsFwdwAA0CRmZQYAwHsI6QAAoEnMygwAgPcQ0gEAQJOYlRkAAO8hpAMAgCYxKzMAAN7DxHEAAKBZzMoMAIB3ENIBAGilQFuSjFmZgfoC7f+BQMPxhRkI6QAAtAJLkgHg/wH/xvGFWbgmHQBMUFRaoVVb7Sxh5aNYkgwA/w/4N44vzERPOgB4Gd/M+76mliRjOCQQGPh/wL9xfGEmetIBwIv4Zt4/sCQZAP4f8G8cX5iJkA4AXtTUN/PwHSxJBoD/B/wbxxdmYrg7AHgR38z7D5YkA8D/A/6N49sK9kKpvFjqmiTFpprdGp8VZBiGYXYjvM3hcCgyMlKVlZWy2WxmNwdAgDn7mvTpGYl6iGvSAQCAL8vPkTbmnt5OnyGNnGdWayyppTmUkE5IB2AC1l0FAAB+w14o/WFE/fLbC+hRP0NLcyjD3eGfGGoDi0uJjzI1nPMlAQAAaDPlxY2X81ncbYR0+B+G2gBNYgk4AADQpromuVeOJjG7O/yLvdA1oEt12/ZCM1oDWA5LwAEAgDYXm1rXMXam9Jn0orcSPenwLwy1AZrU1BJwDHsHAACtNnKelDyGS07bACEd/oWhNkCTWAIOAAB4TGwq4bwNMNwd/oWhNkCTUuKjNC0j0aVsekYivegAAAAWwRJsLMHmn5jdHWgSs7sDAAB4F+ukN4GQDgAAAADwJtZJBwAAAGA6Rm8B7vHYNemHDh3S+PHjZbPZ1LlzZ912222qqqpqsv4999yjvn37qkOHDoqPj9e9996ryspKl3pBQUH1bitXrvTUywAAAADQSgvX7tR1L3yqWW9+oete+FQL1+40u0mA5XmsJ338+PHat2+f8vPzdeLECU2ePFlTp07VihUrGqy/d+9e7d27V08//bT69eunf/3rX5o2bZr27t2rt99+26Xuq6++quzsbOd2586dPfUyAAAAALRCUWmF8jbsdinL27BbWf1j6FEHmuCRkL5z506tW7dOn3/+uVJT6ybteu6553T11Vfr6aefVq9eveo95qKLLtL//u//Orf79Omj3/zmN7rlllt08uRJtWt3uqmdO3dWTEyMJ5oOAAAAoA2UHKxutJyQDjTOI8PdN23apM6dOzsDuiRlZmYqODhYmzdvbvF+Tl1Qf2ZAl6S77rpL0dHRGjp0qF555RU1N/fdsWPH5HA4XG4AAAAAPCchOsKtcgB1PBLSy8rK1L17d5eydu3aqUuXLiorK2vRPg4ePKj58+dr6tSpLuWPP/643nzzTeXn5+uGG27QnXfeqeeee67JfS1YsECRkZHOW1xcnHsvCI2zF0pfrKz7CVgF70sAAEyXEh+laRmJLmXTMxLpRQea4dZw99mzZ2vRokVN1tm589wng3A4HBo9erT69eunxx57zOW+Rx991PnvlJQUVVdX66mnntK9997b6P7mzJmjWbNmueyfoN4G8nOkjbmnt9NnSCPnmdUaoA7vSwAALGP2qGRl9Y9hdnfADW6F9Pvuu0+TJk1qsk5iYqJiYmJ04MABl/KTJ0/q0KFDzV5LfuTIEWVnZ6tTp05avXq12rdv32T9tLQ0zZ8/X8eOHVNYWFiDdcLCwhq9D61kL3QNQlLddvIYKTa1oUcAnsf7EgAAy0mJjyKcA25wK6R369ZN3bp1a7besGHDdPjwYW3ZskVDhgyRJH300Ueqra1VWlpao49zOBzKyspSWFiY3nvvPYWHhzf7XNu2bVNUVBQh3NvKixsvJwzBLLwvAQAA4OM8Mrt7cnKysrOzNWXKFOXl5enEiRO6++67NW7cOOfM7t9++61GjBihZcuWaejQoXI4HLrqqqt09OhR/fGPf3SZ4K1bt24KCQnRn/70J+3fv18/+clPFB4ervz8fD3xxBO6//77PfEy0JSuSe6VA61QVFrh3vA43pd+z+33BAAAgI/x2Drpy5cv1913360RI0YoODhYN9xwg5599lnn/SdOnNCuXbt09OhRSdLWrVudM78nJbl+oC4pKVHv3r3Vvn17LV68WDNnzpRhGEpKStIzzzyjKVOmeOploDGxqXXX+rpc+zuT3kq0mYVrd7qsrTotI1GzRyU3/SDel36tVe8JAAAAHxNkNLd+mR9yOByKjIx0LvGGc2AvrBtK3DWJIIQ2U1Raoete+LRe+eo7h7es95T3pd855/cEAACAyVqaQz3Wk44AEZtKCEKbKzlY3Wh5iwIZ70u/c87vCQAAAB/hkXXSAeBcJERHuFUO/8d7AgAABApCOgDLSYmP0rSMRJey6RmJ9JgGMN4TAAAgUHBNOtekA5bFTN44G+8JAADgq1qaQwnphHQAAAAAgIe1NIcy3B0AAAAAAItgdncAjWMpMwAAAMCrCOkAGpafI23MPb2dPkMaOc+s1gAAAAABgeHuAOqzF7oGdKlu215oRmsAAACAgEFIB1BfebF75QAAAADaBCEdQH1dk9wrBwAAANAmCOkA6otNrbsG/UzpM5k8DgAAAPAwJo4D0LCR86TkMczuDgAAAHgRIR1A42JTCecAAACAFzHcHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsop3ZDQAAoEH2Qqm8WOqaJMWmmt0aAAD8B39jLY2QDgCwnvwcaWPu6e30GdLIeWa1BgAA/8HfWMtjuDsAwFrsha4fHqS6bXuhGa0BAMB/8DfWJxDSAQDWUl7sXjkAAGgZ/sb6BEI6AMBauia5Vw4AAFqGv7E+gZAOALCW2NS66+POlD6TiW0AADhX/I31CUGGYRhmN8LbHA6HIiMjVVlZKZvNZnZzAAANYeZZAAA8g7+xpmhpDmV2dwCANcWm8sEBAABP4G+spTHcHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABbBEmwAfA9rewIAAMBPEdIB+Jb8HGlj7unt9BnSyHlmtQYAAABoUwx3B+A77IWuAV2q27YXmtEaAEAgsBdKX6zkbw0Ar6EnHYDvKC9uvJxh7wCAtsboLQAmoCcdgO/omuReOQAArcXoLQAmIaQD8B2xqXW9GGdKn0kvOgCg7TU1egsAPIjh7gB8y8h5UvIYZncHAHgWo7cAmISedAC+JzZVGjiOgA4A8BxGbwEwCT3pAAAAQEMYvQXABIR0AAAAoDGxqYRzAF5FSAcA+CZ7Ib1bAADA7xDSAQC+h7WLAQCAn2LiOACAb2HtYgAA4McI6QAA38LaxQAAwI8R0gEAvoW1iwEAgB8jpAMAfAtrFwMAAD/GxHEAAN/D2sUAAMBPEdIBAL6JtYsBAIAfYrg7AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALMJjIf3QoUMaP368bDabOnfurNtuu01VVVVNPuaKK65QUFCQy23atGkudUpLSzV69Gh17NhR3bt31wMPPKCTJ0966mUAAAAAAOA1Hlsnffz48dq3b5/y8/N14sQJTZ48WVOnTtWKFSuafNyUKVP0+OOPO7c7duzo/HdNTY1Gjx6tmJgYffrpp9q3b58mTJig9u3b64knnvDUSwEAAAAAwCuCDMMw2nqnO3fuVL9+/fT5558rNTVVkrRu3TpdffXVstvt6tWrV4OPu+KKKzRo0CDl5uY2eP/atWv1s5/9THv37lWPHj0kSXl5eXrooYf03XffKTQ0tEXtczgcioyMVGVlpWw2m/svEAAAAAAAN7Q0h3pkuPumTZvUuXNnZ0CXpMzMTAUHB2vz5s1NPnb58uWKjo7WRRddpDlz5ujo0aMu+x0wYIAzoEtSVlaWHA6Htm/f3vYvBAAAAAAAL/LIcPeysjJ1797d9YnatVOXLl1UVlbW6ONuvvlmXXDBBerVq5e+/PJLPfTQQ9q1a5dWrVrl3O+ZAV2Sc7up/R47dkzHjh1zbjscDrdfEwAAAAAAnuZWSJ89e7YWLVrUZJ2dO3e2ujFTp051/nvAgAHq2bOnRowYoW+++UZ9+vRp9X4XLFigefPmtfrxAAAAAAB4g1sh/b777tOkSZOarJOYmKiYmBgdOHDApfzkyZM6dOiQYmJiWvx8aWlpkqTi4mL16dNHMTEx+uyzz1zq7N+/X5Ka3O+cOXM0a9Ys57bD4VBcXFyL2wEAAMxXVFqhkoPVSoiOUEp8lNnNAQDAI9wK6d26dVO3bt2arTds2DAdPnxYW7Zs0ZAhQyRJH330kWpra53BuyW2bdsmSerZs6dzv7/5zW904MAB53D6/Px82Ww29evXr9H9hIWFKSwsrMXPCwAArGXh2p3K27DbuT0tI1GzRyWb2CIAADzDIxPHJScnKzs7W1OmTNFnn32mjRs36u6779a4ceOcM7t/++23+vGPf+zsGf/mm280f/58bdmyRXv27NF7772nCRMm6PLLL9fFF18sSbrqqqvUr18/3Xrrrfriiy/0wQcf6JFHHtFdd91FCAcAwE8VlVa4BHRJytuwW0WlFSa1CPC8otIKrdpq532OlrMXSl+srPsJn+axddKXL1+uu+++WyNGjFBwcLBuuOEGPfvss877T5w4oV27djlnbw8NDdWHH36o3NxcVVdXKy4uTjfccIMeeeQR52NCQkL05z//WdOnT9ewYcMUERGhiRMnuqyrDgAA/EvJwepGyxn2Dn/EyBG4LT9H2ph7ejt9hjSSObl8lUfWSbc61kkHAMB3FJVW6LoXPq1XvvrO4YR0+B3e73CbvVD6w4j65bcXSLGp9cthGlPXSQcAAGgrKfFRmpaR6FI2PSORwAK/1NTIEaBB5cXulcPyPDbcHQAAoK3MHpWsrP4xzO4Ov5cQHeFWOaCuSe6Vw/LoSQcAAD4hJT5K1w+OJaDDrzFyBG6LTa27Bv1M6TMZ6u7DuCada9IBAABgMUWlFYwcgXvshXVD3LsmEdAtqqU5lJBOSAcAAAAAeBgTxwEAAAAA4GMI6QAAAAAAWAQhHQAAAAAAi2AJNgAAAAAwGxO/4T8I6QAAAABgpvwcaWPu6e30GdLIeWa1BiZjuDsAAAAAmMVe6BrQpbpte6EZrYEFENIBAAAAwCzlxe6Vw+8R0gEAAADALF2T3CuH3yOkAwAAAIBZYlPrrkE/U/pMJo8LYEwcBwAAAABmGjlPSh7D7O6QREgHAMBzWE4HgYT3O3BuYlM5dyCJkA4AgGewnA4CCe93AGgzXJMOAEBbYzkdBBLe7wDQpgjpAAC0NZbTQSDh/Q4AbYqQDgBAW2M5HQQS3u8A0KYI6QAAtDWW00Eg4f0OAG0qyDAMw+xGeJvD4VBkZKQqKytls9nMbg4AwF8x27XfKSqtUMnBaiVERyglPsrs5lgL73cAaFJLcyizuwMA4Cksp+NXFq7dqbwNu53b0zISNXtUsoktshje7wDQJhjuDgAA0Iyi0gqXgC5JeRt2q6i0wqQWAQD8FSEdAACgGSUHq90qBwCgtQjpAAAAzUiIjnCrHACA1iKkAwAANCMlPkrTMhJdyqZnJDJ5HACgzTFxHAAAQAvMHpWsrP4xzO4OAPAoQjoAAEALpcRHEc4BAB7FcHcAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAiuSQeAQGQvlMqLpa5JUmyq2a0BAADAfxDSASDQ5OdIG3NPb6fPkEbOM6s1AAAAOAPD3QEgkNgLXQO6VLdtLzSjNQAAADgLIR0AAkl5sXvlAAAA8CpCOgAEkq5J7pUDAADAqwjpABBIYlPrrkE/U/pMJo8DAACwCCaOA4BAM3KelDyG2d0BAAAsiJAOAIEoNpVwDgAAYEEMdwcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALAIQjoAAAAAABZBSAcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0AAAAAAAsgpAOAAAAAIBFENIBAAAAALCIdmY3AAAAAIBF2Aul8mKpa5IUm2p2a4CA5LGe9EOHDmn8+PGy2Wzq3LmzbrvtNlVVVTVaf8+ePQoKCmrw9tZbbznrNXT/ypUrPfUyAAAAgMCQnyP9YYS0+o66n/k5ZrcICEhBhmEYntjxqFGjtG/fPr300ks6ceKEJk+erEsuuUQrVqxosH5NTY2+++47l7Lf//73euqpp7Rv3z6dd955dQ0OCtKrr76q7OxsZ73OnTsrPDy8xW1zOByKjIxUZWWlbDZbK14dAAAA4EfshXXB/Gy3F9CjDrSRluZQjwx337lzp9atW6fPP/9cqal1J/Vzzz2nq6++Wk8//bR69epV7zEhISGKiYlxKVu9erVuuukmZ0A/pXPnzvXqAgAAAGil8uLGywnpgFd5ZLj7pk2b1LlzZ2dAl6TMzEwFBwdr8+bNLdrHli1btG3bNt1222317rvrrrsUHR2toUOH6pVXXlFzgwGOHTsmh8PhcgMAAADwH12T3CsH4DEeCellZWXq3r27S1m7du3UpUsXlZWVtWgfS5YsUXJysoYPH+5S/vjjj+vNN99Ufn6+brjhBt1555167rnnmtzXggULFBkZ6bzFxcW594IAAAAAfxabKqXPcC1Ln0kvOmACt4a7z549W4sWLWqyzs6dO8+pQZL0/fffa8WKFXr00Ufr3XdmWUpKiqqrq/XUU0/p3nvvbXR/c+bM0axZs5zbDoeDoA4AAACcaeQ8KXkMs7sDJnMrpN93332aNGlSk3USExMVExOjAwcOuJSfPHlShw4datG15G+//baOHj2qCRMmNFs3LS1N8+fP17FjxxQWFtZgnbCwsEbvAwAAAPAfsamEc8BkboX0bt26qVu3bs3WGzZsmA4fPqwtW7ZoyJAhkqSPPvpItbW1SktLa/bxS5Ys0c9//vMWPde2bdsUFRVFCAcAAJBY5xoAfJxHZndPTk5Wdna2pkyZory8PJ04cUJ33323xo0b55zZ/dtvv9WIESO0bNkyDR061PnY4uJi/fWvf9WaNWvq7fdPf/qT9u/fr5/85CcKDw9Xfn6+nnjiCd1///2eeBkAAAC+JT9H2ph7ejt9Rt0QZgCAz/BISJek5cuX6+6779aIESMUHBysG264Qc8++6zz/hMnTmjXrl06evSoy+NeeeUVxcbG6qqrrqq3z/bt22vx4sWaOXOmDMNQUlKSnnnmGU2ZMsVTLwMAAMA32AtdA7pUt508hh51APAhQUZz65f5oZYuIg8AAOAzvlgprb6jfvl1L0kDx3m/PQAAFy3NoR5Zgg0AAABexjrXAOAXCOkAAAD+gHWuAcAveOyadAAAAHgZ61wDgM8jpAMAAPgT1rkGAJ/GcHcAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYRDuzG2AGwzAkSQ6Hw+SWAAAAAAACwan8eSqPNiYgQ/qRI0ckSXFxcSa3BAAAAAAQSI4cOaLIyMhG7w8ymovxfqi2tlZ79+5Vp06dFBQUZHZzfI7D4VBcXJz+/e9/y2azmd0ctBGOq3/iuPonjqt/4rj6J46rf+K4+idPH1fDMHTkyBH16tVLwcGNX3kekD3pwcHBio2NNbsZPs9ms/Gfkh/iuPonjqt/4rj6J46rf+K4+ieOq3/y5HFtqgf9FCaOAwAAAADAIgjpAAAAAABYBCEdbgsLC1NOTo7CwsLMbgraEMfVP3Fc/RPH1T9xXP0Tx9U/cVz9k1WOa0BOHAcAAAAAgBXRkw4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpqOfQoUMaP368bDabOnfurNtuu01VVVWN1t+zZ4+CgoIavL311lvOeg3dv3LlSm+8JMj94ypJV1xxRb1jNm3aNJc6paWlGj16tDp27Kju3bvrgQce0MmTJz35UnAGd4/roUOHdM8996hv377q0KGD4uPjde+996qystKlHuer9y1evFi9e/dWeHi40tLS9NlnnzVZ/6233tKPf/xjhYeHa8CAAVqzZo3L/YZhaO7cuerZs6c6dOigzMxMff311558CWiAO8f15Zdf1mWXXaaoqChFRUUpMzOzXv1JkybVOzezs7M9/TJwFneO69KlS+sds/DwcJc6nK/mc+eYNvT5KCgoSKNHj3bW4Vw131//+leNGTNGvXr1UlBQkN55551mH7N+/XoNHjxYYWFhSkpK0tKlS+vVcffvdasYwFmys7ONgQMHGn/729+M//u//zOSkpKMX/ziF43WP3nypLFv3z6X27x584zzzjvPOHLkiLOeJOPVV191qff999974yXBcP+4GoZhZGRkGFOmTHE5ZpWVlc77T548aVx00UVGZmamUVRUZKxZs8aIjo425syZ4+mXg/9w97h+9dVXxvXXX2+89957RnFxsVFQUGBceOGFxg033OBSj/PVu1auXGmEhoYar7zyirF9+3ZjypQpRufOnY39+/c3WH/jxo1GSEiI8eSTTxo7duwwHnnkEaN9+/bGV1995ayzcOFCIzIy0njnnXeML774wvj5z39uJCQkcBy9yN3jevPNNxuLFy82ioqKjJ07dxqTJk0yIiMjDbvd7qwzceJEIzs72+XcPHTokLdeEgz3j+urr75q2Gw2l2NWVlbmUofz1VzuHtPy8nKX4/n3v//dCAkJMV599VVnHc5V861Zs8b4f//v/xmrVq0yJBmrV69usv7u3buNjh07GrNmzTJ27NhhPPfcc0ZISIixbt06Zx133yutRUiHix07dhiSjM8//9xZtnbtWiMoKMj49ttvW7yfQYMGGb/85S9dylpycsAzWntcMzIyjF/96leN3r9mzRojODjY5cPGiy++aNhsNuPYsWNt0nY0rq3O1zfffNMIDQ01Tpw44SzjfPWuoUOHGnfddZdzu6amxujVq5exYMGCBuvfdNNNxujRo13K0tLSjDvuuMMwDMOora01YmJijKeeesp5/+HDh42wsDDjf/7nfzzwCtAQd4/r2U6ePGl06tTJeO2115xlEydONK655pq2birc4O5xffXVV43IyMhG98f5ar5zPVd/+9vfGp06dTKqqqqcZZyr1tKSzzUPPvig0b9/f5eysWPHGllZWc7tc32vtBTD3eFi06ZN6ty5s1JTU51lmZmZCg4O1ubNm1u0jy1btmjbtm267bbb6t131113KTo6WkOHDtUrr7wiwzDarO1o3Lkc1+XLlys6OloXXXSR5syZo6NHj7rsd8CAAerRo4ezLCsrSw6HQ9u3b2/7FwIXbXG+SlJlZaVsNpvatWvnUs756h3Hjx/Xli1blJmZ6SwLDg5WZmamNm3a1OBjNm3a5FJfqjv3TtUvKSlRWVmZS53IyEilpaU1uk+0rdYc17MdPXpUJ06cUJcuXVzK169fr+7du6tv376aPn26ysvL27TtaFxrj2tVVZUuuOACxcXF6ZprrnH5G8n5aq62OFeXLFmicePGKSIiwqWcc9W3NPe3tS3eKy3VrvkqCCRlZWXq3r27S1m7du3UpUsXlZWVtWgfS5YsUXJysoYPH+5S/vjjj+unP/2pOnbsqL/85S+68847VVVVpXvvvbfN2o+Gtfa43nzzzbrgggvUq1cvffnll3rooYe0a9curVq1yrnfMwO6JOd2S98vaL22OF8PHjyo+fPna+rUqS7lnK/ec/DgQdXU1DR4Lv3jH/9o8DGNnXunjvupn03VgWe15rie7aGHHlKvXr1cPhBmZ2fr+uuvV0JCgr755hs9/PDDGjVqlDZt2qSQkJA2fQ2orzXHtW/fvnrllVd08cUXq7KyUk8//bSGDx+u7du3KzY2lvPVZOd6rn722Wf6+9//riVLlriUc676nsb+tjocDn3//feqqKg45//XW4qQHiBmz56tRYsWNVln586d5/w833//vVasWKFHH3203n1nlqWkpKi6ulpPPfUUH/rPgaeP65nBbcCAAerZs6dGjBihb775Rn369Gn1ftE0b52vDodDo0ePVr9+/fTYY4+53Mf5Cphr4cKFWrlypdavX+8yydi4ceOc/x4wYIAuvvhi9enTR+vXr9eIESPMaCqaMWzYMA0bNsy5PXz4cCUnJ+ull17S/PnzTWwZ2sKSJUs0YMAADR061KWccxXngpAeIO677z5NmjSpyTqJiYmKiYnRgQMHXMpPnjypQ4cOKSYmptnnefvtt3X06FFNmDCh2bppaWmaP3++jh07prCwsGbroz5vHddT0tLSJEnFxcXq06ePYmJi6s1ouX//fklya79w5Y3jeuTIEWVnZ6tTp05avXq12rdv32R9zlfPiY6OVkhIiPPcOWX//v2NHseYmJgm65/6uX//fvXs2dOlzqBBg9qw9WhMa47rKU8//bQWLlyoDz/8UBdffHGTdRMTExUdHa3i4mI++HvBuRzXU9q3b6+UlBQVFxdL4nw127kc0+rqaq1cuVKPP/54s8/DuWp9jf1ttdls6tChg0JCQs75/G8prkkPEN26ddOPf/zjJm+hoaEaNmyYDh8+rC1btjgf+9FHH6m2ttYZ0JqyZMkS/fznP1e3bt2arbtt2zZFRUXxgf8ceOu4nrJt2zZJcn6IGDZsmL766iuXoJifny+bzaZ+/fq1zYsMQJ4+rg6HQ1dddZVCQ0P13nvv1VsKqCGcr54TGhqqIUOGqKCgwFlWW1urgoICl963Mw0bNsylvlR37p2qn5CQoJiYGJc6DodDmzdvbnSfaFutOa6S9OSTT2r+/Plat26dy3wTjbHb7SovL3cJd/Cc1h7XM9XU1Oirr75yHjPOV3OdyzF96623dOzYMd1yyy3NPg/nqvU197e1Lc7/FmvTaejgF7Kzs42UlBRj8+bNxieffGJceOGFLks62e12o2/fvsbmzZtdHvf1118bQUFBxtq1a+vt87333jNefvll46uvvjK+/vpr44UXXjA6duxozJ071+OvB3XcPa7FxcXG448/bhQWFholJSXGu+++ayQmJhqXX3658zGnlmC76qqrjG3bthnr1q0zunXrxhJsXuTuca2srDTS0tKMAQMGGMXFxS5Lw5w8edIwDM5XM6xcudIICwszli5dauzYscOYOnWq0blzZ+fKCbfeeqsxe/ZsZ/2NGzca7dq1M55++mlj586dRk5OToNLsHXu3Nl49913jS+//NK45pprWNLJy9w9rgsXLjRCQ0ONt99+2+XcPLWc6ZEjR4z777/f2LRpk1FSUmJ8+OGHxuDBg40LL7zQ+OGHH0x5jYHI3eM6b94844MPPjC++eYbY8uWLca4ceOM8PBwY/v27c46nK/mcveYnnLppZcaY8eOrVfOuWoNR44cMYqKioyioiJDkvHMM88YRUVFxr/+9S/DMAxj9uzZxq233uqsf2oJtgceeMDYuXOnsXjx4gaXYGvqvdJWCOmop7y83PjFL35hnHfeeYbNZjMmT57sst55SUmJIcn4+OOPXR43Z84cIy4uzqipqam3z7Vr1xqDBg0yzjvvPCMiIsIYOHCgkZeX12BdeIa7x7W0tNS4/PLLjS5duhhhYWFGUlKS8cADD7isk24YhrFnzx5j1KhRRocOHYzo6Gjjvvvuc1nKC57l7nH9+OOPDUkN3kpKSgzD4Hw1y3PPPWfEx8cboaGhxtChQ42//e1vzvsyMjKMiRMnutR/8803jR/96EdGaGio0b9/f+P99993ub+2ttZ49NFHjR49ehhhYWHGiBEjjF27dnnjpeAM7hzXCy64oMFzMycnxzAMwzh69Khx1VVXGd26dTPat29vXHDBBcaUKVPa/MMhmufOcZ0xY4azbo8ePYyrr77a2Lp1q8v+OF/N5+7/wf/4xz8MScZf/vKXevviXLWGxj7znDqWEydONDIyMuo9ZtCgQUZoaKiRmJhovPrqq/X229R7pa0EGQZr6gAAAAAAYAVckw4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIv4/GoeIaNnfT7YAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_train_data = train_x[np.where(train_y[:]==1)]\n",
    "negative_train_data = train_x[np.where(train_y[:]==0)]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=positive_train_data[:,0], y=positive_train_data[:,1], s=10, label=\"Positive\")\n",
    "ax.scatter(x=negative_train_data[:,0], y=negative_train_data[:,1], s=10, label=\"Negative\")\n",
    "ax.set_title('Train Set')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看测试集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()\n",
    "positive_val_data = val_x[np.where(val_y[:] == 1)]\n",
    "negative_val_data = val_x[np.where(val_y[:] == 0)]\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.scatter(x=positive_val_data[:, 0], y=positive_val_data[:, 1], s=10, label=\"Positive\")\n",
    "ax.scatter(x=negative_val_data[:, 0], y=negative_val_data[:, 1], s=10, label=\"Negative\")\n",
    "ax.legend(loc=2)\n",
    "ax.set_title('Validation Set')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "整理维度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(24, 1)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_ex = np.expand_dims(train_y,axis=1)\n",
    "val_y_ex = np.expand_dims(val_y,axis=1)\n",
    "val_y_ex.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "特征映射\n",
    "$$\\mathbf{X}=[x_{1}, x_{2}, x_{1}^{2}, x_{1}x_{2}, x_{2}^{2}, x_{1}^{3}, x_{1}^{2}x_{2},\\cdots]$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.09800000e-01,  4.40160400e-02,  9.23456519e-03, ...,\n        -3.97965108e-02, -8.34930797e-03,  2.08840150e-02],\n       [ 8.55260000e-02,  7.31469668e-03,  6.25596748e-04, ...,\n         8.21378206e-01,  7.02491925e-02,  7.89681221e-01],\n       [ 3.12130000e-01,  9.74251369e-02,  3.04093080e-02, ...,\n        -6.34457590e-03, -1.98033247e-03,  2.30612645e-03],\n       ...,\n       [ 5.24120000e-01,  2.74701774e-01,  1.43976694e-01, ...,\n         5.64957111e-04,  2.96105321e-04,  1.26595589e-04],\n       [-3.01900000e-01,  9.11436100e-02, -2.75162559e-02, ...,\n        -2.83081072e-02,  8.54621757e-03,  1.38769172e-02],\n       [ 1.58630000e-01,  2.51634769e-02,  3.99168234e-03, ...,\n         9.71351550e-02,  1.54085496e-02,  6.09328828e-02]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_mapping(x, degree):\n",
    "    feature = np.zeros([x.shape[0],1])\n",
    "    for i in range(0, 1 + degree):\n",
    "        for j in range(0, 1 + degree - i):\n",
    "            if i==0 and j==0: continue\n",
    "            feature=np.concatenate((feature, np.expand_dims(np.multiply(np.power(x[:, 0], i) , np.power(x[:, 1], j)), axis=1)),axis=1)\n",
    "    return feature[:,1:]\n",
    "\n",
    "train_x_map = feature_mapping(train_x,degree=6)\n",
    "val_x_map = feature_mapping(val_x,degree=6)\n",
    "train_x_map"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "训练逻辑回归"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/8000, Train Loss: 0.3392\n",
      "Accuracy on Val set: 62.50%\tLoss on Val set: 0.3136\n",
      "Epoch: 2/8000, Train Loss: 0.2689\n",
      "Accuracy on Val set: 62.50%\tLoss on Val set: 0.3171\n",
      "Epoch: 3/8000, Train Loss: 0.2449\n",
      "Accuracy on Val set: 62.50%\tLoss on Val set: 0.3220\n",
      "Epoch: 4/8000, Train Loss: 0.2319\n",
      "Accuracy on Val set: 66.67%\tLoss on Val set: 0.3262\n",
      "Epoch: 5/8000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 62.50%\tLoss on Val set: 0.3298\n",
      "Epoch: 6/8000, Train Loss: 0.2186\n",
      "Accuracy on Val set: 66.67%\tLoss on Val set: 0.3327\n",
      "Epoch: 7/8000, Train Loss: 0.2150\n",
      "Accuracy on Val set: 66.67%\tLoss on Val set: 0.3352\n",
      "Epoch: 8/8000, Train Loss: 0.2125\n",
      "Accuracy on Val set: 66.67%\tLoss on Val set: 0.3374\n",
      "Epoch: 9/8000, Train Loss: 0.2107\n",
      "Accuracy on Val set: 66.67%\tLoss on Val set: 0.3395\n",
      "Epoch: 10/8000, Train Loss: 0.2095\n",
      "Accuracy on Val set: 66.67%\tLoss on Val set: 0.3413\n",
      "Epoch: 11/8000, Train Loss: 0.2087\n",
      "Accuracy on Val set: 66.67%\tLoss on Val set: 0.3431\n",
      "Epoch: 12/8000, Train Loss: 0.2082\n",
      "Accuracy on Val set: 66.67%\tLoss on Val set: 0.3448\n",
      "Epoch: 13/8000, Train Loss: 0.2080\n",
      "Accuracy on Val set: 66.67%\tLoss on Val set: 0.3465\n",
      "Epoch: 14/8000, Train Loss: 0.2079\n",
      "Accuracy on Val set: 66.67%\tLoss on Val set: 0.3481\n",
      "Epoch: 15/8000, Train Loss: 0.2081\n",
      "Accuracy on Val set: 66.67%\tLoss on Val set: 0.3498\n",
      "Epoch: 16/8000, Train Loss: 0.2084\n",
      "Accuracy on Val set: 66.67%\tLoss on Val set: 0.3514\n",
      "Epoch: 17/8000, Train Loss: 0.2087\n",
      "Accuracy on Val set: 66.67%\tLoss on Val set: 0.3530\n",
      "Epoch: 18/8000, Train Loss: 0.2092\n",
      "Accuracy on Val set: 70.83%\tLoss on Val set: 0.3546\n",
      "Epoch: 19/8000, Train Loss: 0.2098\n",
      "Accuracy on Val set: 70.83%\tLoss on Val set: 0.3562\n",
      "Epoch: 20/8000, Train Loss: 0.2104\n",
      "Accuracy on Val set: 70.83%\tLoss on Val set: 0.3577\n",
      "Epoch: 21/8000, Train Loss: 0.2110\n",
      "Accuracy on Val set: 70.83%\tLoss on Val set: 0.3593\n",
      "Epoch: 22/8000, Train Loss: 0.2117\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3609\n",
      "Epoch: 23/8000, Train Loss: 0.2125\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3624\n",
      "Epoch: 24/8000, Train Loss: 0.2133\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3639\n",
      "Epoch: 25/8000, Train Loss: 0.2140\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3654\n",
      "Epoch: 26/8000, Train Loss: 0.2149\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3669\n",
      "Epoch: 27/8000, Train Loss: 0.2157\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3684\n",
      "Epoch: 28/8000, Train Loss: 0.2165\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3699\n",
      "Epoch: 29/8000, Train Loss: 0.2173\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3713\n",
      "Epoch: 30/8000, Train Loss: 0.2182\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3727\n",
      "Epoch: 31/8000, Train Loss: 0.2190\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3741\n",
      "Epoch: 32/8000, Train Loss: 0.2199\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3755\n",
      "Epoch: 33/8000, Train Loss: 0.2207\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3769\n",
      "Epoch: 34/8000, Train Loss: 0.2215\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3782\n",
      "Epoch: 35/8000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3795\n",
      "Epoch: 36/8000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3808\n",
      "Epoch: 37/8000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3821\n",
      "Epoch: 38/8000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3833\n",
      "Epoch: 39/8000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3846\n",
      "Epoch: 40/8000, Train Loss: 0.2264\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3858\n",
      "Epoch: 41/8000, Train Loss: 0.2271\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3870\n",
      "Epoch: 42/8000, Train Loss: 0.2279\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3881\n",
      "Epoch: 43/8000, Train Loss: 0.2287\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3893\n",
      "Epoch: 44/8000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3904\n",
      "Epoch: 45/8000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3915\n",
      "Epoch: 46/8000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3926\n",
      "Epoch: 47/8000, Train Loss: 0.2315\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3936\n",
      "Epoch: 48/8000, Train Loss: 0.2322\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3947\n",
      "Epoch: 49/8000, Train Loss: 0.2329\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3957\n",
      "Epoch: 50/8000, Train Loss: 0.2335\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3967\n",
      "Epoch: 51/8000, Train Loss: 0.2342\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3977\n",
      "Epoch: 52/8000, Train Loss: 0.2348\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3987\n",
      "Epoch: 53/8000, Train Loss: 0.2354\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.3996\n",
      "Epoch: 54/8000, Train Loss: 0.2361\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4005\n",
      "Epoch: 55/8000, Train Loss: 0.2367\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4014\n",
      "Epoch: 56/8000, Train Loss: 0.2372\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4023\n",
      "Epoch: 57/8000, Train Loss: 0.2378\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4032\n",
      "Epoch: 58/8000, Train Loss: 0.2384\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4041\n",
      "Epoch: 59/8000, Train Loss: 0.2389\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4049\n",
      "Epoch: 60/8000, Train Loss: 0.2395\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4057\n",
      "Epoch: 61/8000, Train Loss: 0.2400\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4066\n",
      "Epoch: 62/8000, Train Loss: 0.2405\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4074\n",
      "Epoch: 63/8000, Train Loss: 0.2410\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4081\n",
      "Epoch: 64/8000, Train Loss: 0.2415\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4089\n",
      "Epoch: 65/8000, Train Loss: 0.2420\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4096\n",
      "Epoch: 66/8000, Train Loss: 0.2425\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4104\n",
      "Epoch: 67/8000, Train Loss: 0.2429\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4111\n",
      "Epoch: 68/8000, Train Loss: 0.2434\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4118\n",
      "Epoch: 69/8000, Train Loss: 0.2438\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4125\n",
      "Epoch: 70/8000, Train Loss: 0.2442\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4132\n",
      "Epoch: 71/8000, Train Loss: 0.2447\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4138\n",
      "Epoch: 72/8000, Train Loss: 0.2451\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 73/8000, Train Loss: 0.2455\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4151\n",
      "Epoch: 74/8000, Train Loss: 0.2459\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4158\n",
      "Epoch: 75/8000, Train Loss: 0.2463\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4164\n",
      "Epoch: 76/8000, Train Loss: 0.2466\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4170\n",
      "Epoch: 77/8000, Train Loss: 0.2470\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 78/8000, Train Loss: 0.2474\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4181\n",
      "Epoch: 79/8000, Train Loss: 0.2477\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 80/8000, Train Loss: 0.2481\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4193\n",
      "Epoch: 81/8000, Train Loss: 0.2484\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 82/8000, Train Loss: 0.2487\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4203\n",
      "Epoch: 83/8000, Train Loss: 0.2490\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4209\n",
      "Epoch: 84/8000, Train Loss: 0.2494\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4214\n",
      "Epoch: 85/8000, Train Loss: 0.2497\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 86/8000, Train Loss: 0.2500\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4224\n",
      "Epoch: 87/8000, Train Loss: 0.2503\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4229\n",
      "Epoch: 88/8000, Train Loss: 0.2505\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4233\n",
      "Epoch: 89/8000, Train Loss: 0.2508\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 90/8000, Train Loss: 0.2511\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4243\n",
      "Epoch: 91/8000, Train Loss: 0.2514\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4247\n",
      "Epoch: 92/8000, Train Loss: 0.2516\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4252\n",
      "Epoch: 93/8000, Train Loss: 0.2519\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4256\n",
      "Epoch: 94/8000, Train Loss: 0.2521\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4260\n",
      "Epoch: 95/8000, Train Loss: 0.2524\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4264\n",
      "Epoch: 96/8000, Train Loss: 0.2526\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 97/8000, Train Loss: 0.2529\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 98/8000, Train Loss: 0.2531\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 99/8000, Train Loss: 0.2533\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 100/8000, Train Loss: 0.2535\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 101/8000, Train Loss: 0.2537\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4287\n",
      "Epoch: 102/8000, Train Loss: 0.2539\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4291\n",
      "Epoch: 103/8000, Train Loss: 0.2542\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4295\n",
      "Epoch: 104/8000, Train Loss: 0.2544\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4298\n",
      "Epoch: 105/8000, Train Loss: 0.2545\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4302\n",
      "Epoch: 106/8000, Train Loss: 0.2547\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4305\n",
      "Epoch: 107/8000, Train Loss: 0.2549\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 108/8000, Train Loss: 0.2551\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4311\n",
      "Epoch: 109/8000, Train Loss: 0.2553\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4315\n",
      "Epoch: 110/8000, Train Loss: 0.2555\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4318\n",
      "Epoch: 111/8000, Train Loss: 0.2556\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4321\n",
      "Epoch: 112/8000, Train Loss: 0.2558\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 113/8000, Train Loss: 0.2560\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4327\n",
      "Epoch: 114/8000, Train Loss: 0.2561\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4329\n",
      "Epoch: 115/8000, Train Loss: 0.2563\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 116/8000, Train Loss: 0.2564\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4335\n",
      "Epoch: 117/8000, Train Loss: 0.2566\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4338\n",
      "Epoch: 118/8000, Train Loss: 0.2567\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 119/8000, Train Loss: 0.2569\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4343\n",
      "Epoch: 120/8000, Train Loss: 0.2570\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4346\n",
      "Epoch: 121/8000, Train Loss: 0.2571\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 122/8000, Train Loss: 0.2573\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4351\n",
      "Epoch: 123/8000, Train Loss: 0.2574\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4353\n",
      "Epoch: 124/8000, Train Loss: 0.2575\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4355\n",
      "Epoch: 125/8000, Train Loss: 0.2577\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4358\n",
      "Epoch: 126/8000, Train Loss: 0.2578\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4360\n",
      "Epoch: 127/8000, Train Loss: 0.2579\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4362\n",
      "Epoch: 128/8000, Train Loss: 0.2580\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4364\n",
      "Epoch: 129/8000, Train Loss: 0.2581\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4367\n",
      "Epoch: 130/8000, Train Loss: 0.2583\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4369\n",
      "Epoch: 131/8000, Train Loss: 0.2584\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4371\n",
      "Epoch: 132/8000, Train Loss: 0.2585\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4373\n",
      "Epoch: 133/8000, Train Loss: 0.2586\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4375\n",
      "Epoch: 134/8000, Train Loss: 0.2587\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4377\n",
      "Epoch: 135/8000, Train Loss: 0.2588\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4379\n",
      "Epoch: 136/8000, Train Loss: 0.2589\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4381\n",
      "Epoch: 137/8000, Train Loss: 0.2590\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4383\n",
      "Epoch: 138/8000, Train Loss: 0.2591\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4384\n",
      "Epoch: 139/8000, Train Loss: 0.2592\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4386\n",
      "Epoch: 140/8000, Train Loss: 0.2593\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4388\n",
      "Epoch: 141/8000, Train Loss: 0.2593\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4390\n",
      "Epoch: 142/8000, Train Loss: 0.2594\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4391\n",
      "Epoch: 143/8000, Train Loss: 0.2595\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4393\n",
      "Epoch: 144/8000, Train Loss: 0.2596\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4395\n",
      "Epoch: 145/8000, Train Loss: 0.2597\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4396\n",
      "Epoch: 146/8000, Train Loss: 0.2598\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4398\n",
      "Epoch: 147/8000, Train Loss: 0.2598\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4399\n",
      "Epoch: 148/8000, Train Loss: 0.2599\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4401\n",
      "Epoch: 149/8000, Train Loss: 0.2600\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4402\n",
      "Epoch: 150/8000, Train Loss: 0.2601\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4404\n",
      "Epoch: 151/8000, Train Loss: 0.2601\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4405\n",
      "Epoch: 152/8000, Train Loss: 0.2602\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4407\n",
      "Epoch: 153/8000, Train Loss: 0.2603\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4408\n",
      "Epoch: 154/8000, Train Loss: 0.2603\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4409\n",
      "Epoch: 155/8000, Train Loss: 0.2604\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4411\n",
      "Epoch: 156/8000, Train Loss: 0.2605\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4412\n",
      "Epoch: 157/8000, Train Loss: 0.2605\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4413\n",
      "Epoch: 158/8000, Train Loss: 0.2606\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4415\n",
      "Epoch: 159/8000, Train Loss: 0.2607\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4416\n",
      "Epoch: 160/8000, Train Loss: 0.2607\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4417\n",
      "Epoch: 161/8000, Train Loss: 0.2608\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4418\n",
      "Epoch: 162/8000, Train Loss: 0.2608\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4420\n",
      "Epoch: 163/8000, Train Loss: 0.2609\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4421\n",
      "Epoch: 164/8000, Train Loss: 0.2610\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4422\n",
      "Epoch: 165/8000, Train Loss: 0.2610\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4423\n",
      "Epoch: 166/8000, Train Loss: 0.2611\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4424\n",
      "Epoch: 167/8000, Train Loss: 0.2611\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4425\n",
      "Epoch: 168/8000, Train Loss: 0.2612\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4426\n",
      "Epoch: 169/8000, Train Loss: 0.2612\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4427\n",
      "Epoch: 170/8000, Train Loss: 0.2613\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4428\n",
      "Epoch: 171/8000, Train Loss: 0.2613\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4429\n",
      "Epoch: 172/8000, Train Loss: 0.2614\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4430\n",
      "Epoch: 173/8000, Train Loss: 0.2614\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4431\n",
      "Epoch: 174/8000, Train Loss: 0.2614\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4432\n",
      "Epoch: 175/8000, Train Loss: 0.2615\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4433\n",
      "Epoch: 176/8000, Train Loss: 0.2615\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4434\n",
      "Epoch: 177/8000, Train Loss: 0.2616\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4435\n",
      "Epoch: 178/8000, Train Loss: 0.2616\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4436\n",
      "Epoch: 179/8000, Train Loss: 0.2617\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4437\n",
      "Epoch: 180/8000, Train Loss: 0.2617\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4438\n",
      "Epoch: 181/8000, Train Loss: 0.2617\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4438\n",
      "Epoch: 182/8000, Train Loss: 0.2618\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4439\n",
      "Epoch: 183/8000, Train Loss: 0.2618\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4440\n",
      "Epoch: 184/8000, Train Loss: 0.2619\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4441\n",
      "Epoch: 185/8000, Train Loss: 0.2619\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4442\n",
      "Epoch: 186/8000, Train Loss: 0.2619\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4442\n",
      "Epoch: 187/8000, Train Loss: 0.2620\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4443\n",
      "Epoch: 188/8000, Train Loss: 0.2620\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4444\n",
      "Epoch: 189/8000, Train Loss: 0.2620\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4445\n",
      "Epoch: 190/8000, Train Loss: 0.2621\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4445\n",
      "Epoch: 191/8000, Train Loss: 0.2621\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4446\n",
      "Epoch: 192/8000, Train Loss: 0.2621\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4447\n",
      "Epoch: 193/8000, Train Loss: 0.2622\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4447\n",
      "Epoch: 194/8000, Train Loss: 0.2622\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4448\n",
      "Epoch: 195/8000, Train Loss: 0.2622\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4449\n",
      "Epoch: 196/8000, Train Loss: 0.2622\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4449\n",
      "Epoch: 197/8000, Train Loss: 0.2623\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4450\n",
      "Epoch: 198/8000, Train Loss: 0.2623\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4451\n",
      "Epoch: 199/8000, Train Loss: 0.2623\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4451\n",
      "Epoch: 200/8000, Train Loss: 0.2624\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4452\n",
      "Epoch: 201/8000, Train Loss: 0.2624\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4453\n",
      "Epoch: 202/8000, Train Loss: 0.2624\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4453\n",
      "Epoch: 203/8000, Train Loss: 0.2624\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4454\n",
      "Epoch: 204/8000, Train Loss: 0.2625\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4454\n",
      "Epoch: 205/8000, Train Loss: 0.2625\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4455\n",
      "Epoch: 206/8000, Train Loss: 0.2625\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4455\n",
      "Epoch: 207/8000, Train Loss: 0.2625\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4456\n",
      "Epoch: 208/8000, Train Loss: 0.2626\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4456\n",
      "Epoch: 209/8000, Train Loss: 0.2626\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4457\n",
      "Epoch: 210/8000, Train Loss: 0.2626\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4457\n",
      "Epoch: 211/8000, Train Loss: 0.2626\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4458\n",
      "Epoch: 212/8000, Train Loss: 0.2626\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4458\n",
      "Epoch: 213/8000, Train Loss: 0.2627\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4459\n",
      "Epoch: 214/8000, Train Loss: 0.2627\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4459\n",
      "Epoch: 215/8000, Train Loss: 0.2627\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4460\n",
      "Epoch: 216/8000, Train Loss: 0.2627\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4460\n",
      "Epoch: 217/8000, Train Loss: 0.2627\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4461\n",
      "Epoch: 218/8000, Train Loss: 0.2628\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4461\n",
      "Epoch: 219/8000, Train Loss: 0.2628\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4462\n",
      "Epoch: 220/8000, Train Loss: 0.2628\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4462\n",
      "Epoch: 221/8000, Train Loss: 0.2628\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4463\n",
      "Epoch: 222/8000, Train Loss: 0.2628\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4463\n",
      "Epoch: 223/8000, Train Loss: 0.2629\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4463\n",
      "Epoch: 224/8000, Train Loss: 0.2629\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4464\n",
      "Epoch: 225/8000, Train Loss: 0.2629\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4464\n",
      "Epoch: 226/8000, Train Loss: 0.2629\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4465\n",
      "Epoch: 227/8000, Train Loss: 0.2629\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4465\n",
      "Epoch: 228/8000, Train Loss: 0.2629\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4465\n",
      "Epoch: 229/8000, Train Loss: 0.2630\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4466\n",
      "Epoch: 230/8000, Train Loss: 0.2630\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4466\n",
      "Epoch: 231/8000, Train Loss: 0.2630\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4466\n",
      "Epoch: 232/8000, Train Loss: 0.2630\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4467\n",
      "Epoch: 233/8000, Train Loss: 0.2630\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4467\n",
      "Epoch: 234/8000, Train Loss: 0.2630\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4467\n",
      "Epoch: 235/8000, Train Loss: 0.2630\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4468\n",
      "Epoch: 236/8000, Train Loss: 0.2631\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4468\n",
      "Epoch: 237/8000, Train Loss: 0.2631\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4468\n",
      "Epoch: 238/8000, Train Loss: 0.2631\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4469\n",
      "Epoch: 239/8000, Train Loss: 0.2631\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4469\n",
      "Epoch: 240/8000, Train Loss: 0.2631\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4469\n",
      "Epoch: 241/8000, Train Loss: 0.2631\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4470\n",
      "Epoch: 242/8000, Train Loss: 0.2631\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4470\n",
      "Epoch: 243/8000, Train Loss: 0.2631\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4470\n",
      "Epoch: 244/8000, Train Loss: 0.2632\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4471\n",
      "Epoch: 245/8000, Train Loss: 0.2632\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4471\n",
      "Epoch: 246/8000, Train Loss: 0.2632\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4471\n",
      "Epoch: 247/8000, Train Loss: 0.2632\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4471\n",
      "Epoch: 248/8000, Train Loss: 0.2632\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4472\n",
      "Epoch: 249/8000, Train Loss: 0.2632\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4472\n",
      "Epoch: 250/8000, Train Loss: 0.2632\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4472\n",
      "Epoch: 251/8000, Train Loss: 0.2632\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4472\n",
      "Epoch: 252/8000, Train Loss: 0.2632\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4473\n",
      "Epoch: 253/8000, Train Loss: 0.2633\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4473\n",
      "Epoch: 254/8000, Train Loss: 0.2633\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4473\n",
      "Epoch: 255/8000, Train Loss: 0.2633\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4473\n",
      "Epoch: 256/8000, Train Loss: 0.2633\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4474\n",
      "Epoch: 257/8000, Train Loss: 0.2633\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4474\n",
      "Epoch: 258/8000, Train Loss: 0.2633\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4474\n",
      "Epoch: 259/8000, Train Loss: 0.2633\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4474\n",
      "Epoch: 260/8000, Train Loss: 0.2633\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4475\n",
      "Epoch: 261/8000, Train Loss: 0.2633\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4475\n",
      "Epoch: 262/8000, Train Loss: 0.2633\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4475\n",
      "Epoch: 263/8000, Train Loss: 0.2633\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4475\n",
      "Epoch: 264/8000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4475\n",
      "Epoch: 265/8000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4476\n",
      "Epoch: 266/8000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4476\n",
      "Epoch: 267/8000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4476\n",
      "Epoch: 268/8000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4476\n",
      "Epoch: 269/8000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4476\n",
      "Epoch: 270/8000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4477\n",
      "Epoch: 271/8000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4477\n",
      "Epoch: 272/8000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4477\n",
      "Epoch: 273/8000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4477\n",
      "Epoch: 274/8000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4477\n",
      "Epoch: 275/8000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4478\n",
      "Epoch: 276/8000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4478\n",
      "Epoch: 277/8000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4478\n",
      "Epoch: 278/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4478\n",
      "Epoch: 279/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4478\n",
      "Epoch: 280/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4478\n",
      "Epoch: 281/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4479\n",
      "Epoch: 282/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4479\n",
      "Epoch: 283/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4479\n",
      "Epoch: 284/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4479\n",
      "Epoch: 285/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4479\n",
      "Epoch: 286/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4479\n",
      "Epoch: 287/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4479\n",
      "Epoch: 288/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4480\n",
      "Epoch: 289/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4480\n",
      "Epoch: 290/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4480\n",
      "Epoch: 291/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4480\n",
      "Epoch: 292/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4480\n",
      "Epoch: 293/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4480\n",
      "Epoch: 294/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4480\n",
      "Epoch: 295/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4481\n",
      "Epoch: 296/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4481\n",
      "Epoch: 297/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4481\n",
      "Epoch: 298/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4481\n",
      "Epoch: 299/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4481\n",
      "Epoch: 300/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4481\n",
      "Epoch: 301/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4481\n",
      "Epoch: 302/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4481\n",
      "Epoch: 303/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4481\n",
      "Epoch: 304/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4482\n",
      "Epoch: 305/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4482\n",
      "Epoch: 306/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4482\n",
      "Epoch: 307/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4482\n",
      "Epoch: 308/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4482\n",
      "Epoch: 309/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4482\n",
      "Epoch: 310/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4482\n",
      "Epoch: 311/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4482\n",
      "Epoch: 312/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4482\n",
      "Epoch: 313/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4482\n",
      "Epoch: 314/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4483\n",
      "Epoch: 315/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4483\n",
      "Epoch: 316/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4483\n",
      "Epoch: 317/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4483\n",
      "Epoch: 318/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4483\n",
      "Epoch: 319/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4483\n",
      "Epoch: 320/8000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4483\n",
      "Epoch: 321/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4483\n",
      "Epoch: 322/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4483\n",
      "Epoch: 323/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4483\n",
      "Epoch: 324/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4483\n",
      "Epoch: 325/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 326/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 327/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 328/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 329/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 330/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 331/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 332/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 333/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 334/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 335/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 336/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 337/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 338/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 339/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 340/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 341/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 342/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 343/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 344/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 345/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 346/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 347/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 348/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 349/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 350/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 351/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 352/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 353/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 354/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 355/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 356/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4485\n",
      "Epoch: 357/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 358/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 359/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 360/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 361/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 362/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 363/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 364/8000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 365/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 366/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 367/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 368/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 369/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 370/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 371/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 372/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 373/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 374/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 375/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 376/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 377/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 378/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 379/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 380/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 381/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 382/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4486\n",
      "Epoch: 383/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 384/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 385/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 386/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 387/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 388/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 389/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 390/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 391/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 392/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 393/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 394/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 395/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 396/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 397/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 398/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 399/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 400/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 401/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 402/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 403/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 404/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 405/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 406/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 407/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 408/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 409/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 410/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 411/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 412/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 413/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 414/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 415/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 416/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 417/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 418/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 419/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 420/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 421/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 422/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 423/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4487\n",
      "Epoch: 424/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 425/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 426/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 427/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 428/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 429/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 430/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 431/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 432/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 433/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 434/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 435/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 436/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 437/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 438/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 439/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 440/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 441/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 442/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 443/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 444/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 445/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 446/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 447/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 448/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 449/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 450/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 451/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 452/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 453/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 454/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 455/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 456/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 457/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 458/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 459/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 460/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 461/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 462/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 463/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 464/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 465/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 466/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 467/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 468/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 469/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 470/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 471/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 472/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 473/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 474/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 475/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 476/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 477/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 478/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 479/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 480/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 481/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 482/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 483/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 484/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 485/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 486/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 487/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 488/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 489/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 490/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 491/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 492/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 493/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 494/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 495/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 496/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 497/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 498/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 499/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 500/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 501/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 502/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 503/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 504/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 505/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 506/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 507/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 508/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 509/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 510/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 511/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 512/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 513/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 514/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 515/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 516/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 517/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 518/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 519/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 520/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 521/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 522/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 523/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 524/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 525/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 526/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 527/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 528/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 529/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 530/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 531/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 532/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 533/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 534/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 535/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 536/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 537/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 538/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 539/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 540/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 541/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 542/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 543/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 544/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 545/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 546/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 547/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 548/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 549/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 550/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 551/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 552/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 553/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 554/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 555/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 556/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 557/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 558/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 559/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 560/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 561/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 562/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 563/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 564/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 565/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 566/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 567/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 568/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 569/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 570/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 571/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 572/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 573/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 574/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 575/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 576/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 577/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 578/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 579/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 580/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 581/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 582/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 583/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 584/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 585/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 586/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 587/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 588/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 589/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 590/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 591/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 592/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 593/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 594/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 595/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 596/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 597/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 598/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 599/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 600/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 601/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 602/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 603/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 604/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 605/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 606/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 607/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 608/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 609/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 610/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 611/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 612/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 613/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 614/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 615/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 616/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 617/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 618/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 619/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 620/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 621/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 622/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 623/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 624/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 625/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 626/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 627/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 628/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 629/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 630/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 631/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 632/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 633/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 634/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 635/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 636/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 637/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 638/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 639/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 640/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 641/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 642/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 643/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 644/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 645/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 646/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 647/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 648/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 649/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 650/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 651/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 652/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 653/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 654/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 655/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 656/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 657/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 658/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 659/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 660/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 661/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 662/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 663/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 664/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 665/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 666/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 667/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 668/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 669/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 670/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 671/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 672/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 673/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 674/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 675/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 676/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 677/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 678/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 679/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 680/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 681/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 682/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 683/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 684/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 685/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 686/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 687/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 688/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 689/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 690/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 691/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 692/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 693/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 694/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 695/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 696/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 697/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 698/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 699/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 700/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 701/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 702/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 703/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 704/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 705/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 706/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 707/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 708/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 709/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 710/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 711/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 712/8000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 713/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 714/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 715/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 716/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 717/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 718/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 719/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 720/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 721/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 722/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 723/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 724/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 725/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 726/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 727/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 728/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 729/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 730/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 731/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 732/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 733/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 734/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 735/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 736/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 737/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 738/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 739/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 740/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 741/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 742/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 743/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 744/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 745/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 746/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 747/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 748/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 749/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 750/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 751/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 752/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 753/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 754/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 755/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 756/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 757/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 758/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 759/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 760/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 761/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 762/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 763/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 764/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 765/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 766/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 767/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 768/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 769/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 770/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 771/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 772/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 773/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 774/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 775/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 776/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 777/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 778/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 779/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 780/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 781/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 782/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 783/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 784/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 785/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 786/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 787/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 788/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 789/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 790/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 791/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 792/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 793/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 794/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 795/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 796/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 797/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 798/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 799/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 800/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 801/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 802/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 803/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 804/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 805/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 806/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 807/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 808/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 809/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 810/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 811/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 812/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 813/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 814/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 815/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 816/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 817/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 818/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 819/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 820/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 821/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 822/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 823/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 824/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 825/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 826/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 827/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 828/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 829/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 830/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 831/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 832/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 833/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 834/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 835/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 836/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 837/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 838/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 839/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 840/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 841/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 842/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 843/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 844/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 845/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 846/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 847/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 848/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 849/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 850/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 851/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 852/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 853/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 854/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 855/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 856/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 857/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 858/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 859/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 860/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 861/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 862/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 863/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 864/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 865/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 866/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 867/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 868/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 869/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 870/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 871/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 872/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 873/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 874/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 875/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 876/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 877/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 878/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 879/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 880/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 881/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 882/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 883/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 884/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 885/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 886/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 887/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 888/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 889/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 890/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 891/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 892/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 893/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 894/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 895/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 896/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 897/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 898/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 899/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 900/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 901/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 902/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 903/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 904/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 905/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 906/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 907/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 908/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 909/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 910/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 911/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 912/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 913/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 914/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 915/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 916/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 917/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 918/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 919/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 920/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 921/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 922/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 923/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 924/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 925/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 926/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 927/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 928/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 929/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 930/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 931/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 932/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 933/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 934/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 935/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 936/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 937/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 938/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 939/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 940/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 941/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 942/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 943/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 944/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 945/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 946/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 947/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 948/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 949/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 950/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 951/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 952/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 953/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 954/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 955/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 956/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 957/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 958/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 959/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 960/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 961/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 962/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 963/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 964/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 965/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 966/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 967/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 968/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 969/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 970/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 971/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 972/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 973/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 974/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 975/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 976/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 977/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 978/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 979/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 980/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 981/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 982/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 983/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 984/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 985/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 986/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 987/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 988/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 989/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 990/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 991/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 992/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 993/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 994/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 995/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 996/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 997/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 998/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 999/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1000/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1001/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1002/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1003/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1004/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1005/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1006/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1007/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1008/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1009/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1010/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1011/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1012/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1013/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1014/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1015/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1016/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1017/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1018/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1019/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1020/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1021/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1022/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1023/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1024/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1025/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1026/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1027/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1028/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1029/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1030/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1031/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1032/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1033/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1034/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1035/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1036/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1037/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1038/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1039/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1040/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1041/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1042/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1043/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1044/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1045/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1046/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1047/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1048/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1049/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1050/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1051/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1052/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1053/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1054/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1055/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1056/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1057/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1058/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1059/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1060/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1061/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1062/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1063/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1064/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1065/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1066/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1067/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1068/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1069/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1070/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1071/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1072/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1073/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1074/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1075/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1076/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1077/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1078/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1079/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1080/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1081/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1082/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1083/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1084/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1085/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1086/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1087/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1088/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1089/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1090/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1091/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1092/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1093/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1094/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1095/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1096/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1097/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1098/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1099/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1100/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1101/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1102/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1103/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1104/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1105/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1106/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1107/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1108/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1109/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1110/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1111/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1112/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1113/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1114/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1115/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1116/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1117/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1118/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1119/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1120/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1121/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1122/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1123/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1124/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1125/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1126/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1127/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1128/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1129/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1130/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1131/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1132/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1133/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1134/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1135/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1136/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1137/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1138/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1139/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1140/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1141/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1142/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1143/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1144/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1145/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1146/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1147/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1148/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1149/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1150/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1151/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1152/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1153/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1154/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1155/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1156/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1157/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1158/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1159/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1160/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1161/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1162/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1163/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1164/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1165/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1166/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1167/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1168/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1169/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1170/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1171/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1172/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1173/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1174/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1175/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1176/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1177/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1178/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1179/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1180/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1181/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1182/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1183/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1184/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1185/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1186/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1187/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1188/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1189/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1190/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1191/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1192/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1193/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1194/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1195/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1196/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1197/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1198/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1199/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1200/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1201/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1202/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1203/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1204/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1205/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1206/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1207/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1208/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1209/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1210/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1211/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1212/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1213/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1214/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1215/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1216/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1217/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1218/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1219/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1220/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1221/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1222/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1223/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1224/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1225/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1226/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1227/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1228/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1229/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1230/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1231/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1232/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1233/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1234/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1235/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1236/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1237/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1238/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1239/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1240/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1241/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1242/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1243/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1244/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1245/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1246/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1247/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1248/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1249/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1250/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1251/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1252/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1253/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1254/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1255/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1256/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1257/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1258/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1259/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1260/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1261/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1262/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1263/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1264/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1265/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1266/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1267/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1268/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1269/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1270/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1271/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1272/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1273/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1274/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1275/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1276/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1277/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1278/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1279/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1280/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1281/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1282/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1283/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1284/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1285/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1286/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1287/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1288/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1289/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1290/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1291/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1292/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1293/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1294/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1295/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1296/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1297/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1298/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1299/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1300/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1301/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1302/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1303/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1304/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1305/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1306/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1307/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1308/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1309/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1310/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1311/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1312/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1313/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1314/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1315/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1316/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1317/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1318/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1319/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1320/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1321/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1322/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1323/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1324/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1325/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1326/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1327/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1328/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1329/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1330/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1331/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1332/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1333/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1334/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1335/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1336/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1337/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1338/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1339/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1340/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1341/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1342/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1343/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1344/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1345/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1346/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1347/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1348/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1349/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1350/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1351/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1352/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1353/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1354/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1355/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1356/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1357/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1358/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1359/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1360/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1361/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1362/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1363/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1364/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1365/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1366/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1367/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1368/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1369/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1370/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1371/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1372/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1373/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1374/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1375/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1376/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1377/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1378/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1379/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1380/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1381/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1382/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1383/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1384/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1385/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1386/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1387/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1388/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1389/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1390/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1391/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1392/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1393/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1394/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1395/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1396/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1397/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1398/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1399/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1400/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1401/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1402/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1403/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1404/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1405/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1406/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1407/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1408/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1409/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1410/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1411/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1412/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1413/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1414/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1415/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1416/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1417/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1418/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1419/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1420/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1421/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1422/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1423/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1424/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1425/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1426/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1427/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1428/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1429/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1430/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1431/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1432/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1433/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1434/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1435/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1436/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1437/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1438/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1439/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1440/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1441/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1442/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1443/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1444/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1445/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1446/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1447/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1448/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1449/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1450/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1451/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1452/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1453/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1454/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1455/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1456/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1457/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1458/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1459/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1460/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1461/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1462/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1463/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1464/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1465/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1466/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1467/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1468/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1469/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1470/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1471/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1472/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1473/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1474/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1475/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1476/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1477/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1478/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1479/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1480/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1481/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1482/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1483/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1484/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1485/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1486/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1487/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1488/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1489/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1490/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1491/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1492/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1493/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1494/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1495/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1496/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1497/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1498/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1499/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1500/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1501/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1502/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1503/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1504/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1505/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1506/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1507/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1508/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1509/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1510/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1511/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1512/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1513/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1514/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1515/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1516/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1517/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1518/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1519/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1520/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1521/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1522/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1523/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1524/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1525/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1526/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1527/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1528/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1529/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1530/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1531/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1532/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1533/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1534/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1535/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1536/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1537/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1538/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1539/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1540/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1541/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1542/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1543/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1544/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1545/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1546/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1547/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1548/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1549/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1550/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1551/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1552/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1553/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1554/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1555/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1556/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1557/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1558/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1559/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1560/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1561/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1562/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1563/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1564/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1565/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1566/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1567/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1568/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1569/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1570/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1571/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1572/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1573/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1574/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1575/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1576/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1577/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1578/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1579/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1580/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1581/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1582/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1583/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1584/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1585/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1586/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1587/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1588/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1589/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1590/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1591/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1592/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1593/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1594/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1595/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1596/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1597/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1598/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1599/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1600/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1601/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1602/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1603/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1604/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1605/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1606/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1607/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1608/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1609/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1610/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1611/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1612/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1613/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1614/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1615/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1616/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1617/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1618/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1619/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1620/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1621/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1622/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1623/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1624/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1625/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1626/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1627/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1628/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1629/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1630/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1631/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1632/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1633/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1634/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1635/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1636/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1637/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1638/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1639/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1640/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1641/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1642/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1643/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1644/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1645/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1646/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1647/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1648/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1649/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1650/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1651/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1652/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1653/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1654/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1655/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1656/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1657/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1658/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1659/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1660/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1661/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1662/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1663/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1664/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1665/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1666/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1667/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1668/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1669/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1670/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1671/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1672/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1673/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1674/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1675/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1676/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1677/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1678/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1679/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1680/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1681/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1682/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1683/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1684/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1685/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1686/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1687/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1688/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1689/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1690/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1691/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1692/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1693/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1694/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1695/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1696/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1697/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1698/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1699/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1700/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1701/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1702/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1703/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1704/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1705/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1706/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1707/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1708/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1709/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1710/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1711/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1712/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1713/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1714/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1715/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1716/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1717/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1718/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1719/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1720/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1721/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1722/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1723/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1724/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1725/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1726/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1727/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1728/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1729/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1730/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1731/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1732/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1733/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1734/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1735/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1736/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1737/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1738/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1739/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1740/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1741/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1742/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1743/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1744/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1745/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1746/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1747/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1748/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1749/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1750/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1751/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1752/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1753/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1754/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1755/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1756/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1757/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1758/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1759/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1760/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1761/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1762/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1763/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1764/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1765/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1766/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1767/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1768/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1769/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1770/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1771/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1772/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1773/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1774/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1775/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1776/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1777/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1778/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1779/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1780/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1781/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1782/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1783/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1784/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1785/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1786/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1787/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1788/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1789/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1790/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1791/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1792/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1793/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1794/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1795/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1796/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1797/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1798/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1799/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1800/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1801/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1802/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1803/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1804/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1805/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1806/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1807/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1808/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1809/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1810/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1811/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1812/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1813/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1814/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1815/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1816/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1817/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1818/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1819/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1820/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1821/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1822/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1823/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1824/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1825/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1826/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1827/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1828/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1829/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1830/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1831/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1832/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1833/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1834/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1835/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1836/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1837/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1838/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1839/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1840/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1841/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1842/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1843/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1844/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1845/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1846/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1847/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1848/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1849/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1850/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1851/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1852/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1853/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1854/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1855/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1856/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1857/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1858/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1859/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1860/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1861/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1862/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1863/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1864/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1865/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1866/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1867/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1868/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1869/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1870/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1871/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1872/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1873/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1874/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1875/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1876/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1877/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1878/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1879/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1880/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1881/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1882/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1883/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1884/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1885/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1886/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1887/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1888/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1889/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1890/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1891/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1892/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1893/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1894/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1895/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1896/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1897/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1898/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1899/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1900/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1901/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1902/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1903/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1904/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1905/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1906/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1907/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1908/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1909/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1910/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1911/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1912/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1913/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1914/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1915/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1916/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1917/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1918/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1919/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1920/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1921/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1922/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1923/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1924/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1925/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1926/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1927/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1928/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1929/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1930/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1931/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1932/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1933/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1934/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1935/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1936/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1937/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1938/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1939/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1940/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1941/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1942/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1943/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1944/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1945/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1946/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1947/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1948/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1949/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1950/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1951/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1952/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1953/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1954/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1955/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1956/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1957/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1958/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1959/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1960/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1961/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1962/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1963/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1964/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1965/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1966/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1967/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1968/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1969/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1970/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1971/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1972/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1973/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1974/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1975/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1976/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1977/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1978/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1979/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1980/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1981/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1982/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1983/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1984/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1985/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1986/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1987/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1988/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1989/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1990/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1991/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1992/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1993/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1994/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1995/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1996/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1997/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1998/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 1999/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2000/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2001/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2002/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2003/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2004/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2005/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2006/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2007/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2008/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2009/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2010/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2011/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2012/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2013/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2014/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2015/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2016/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2017/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2018/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2019/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2020/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2021/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2022/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2023/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2024/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2025/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2026/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2027/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2028/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2029/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2030/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2031/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2032/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2033/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2034/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2035/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2036/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2037/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2038/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2039/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2040/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2041/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2042/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2043/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2044/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2045/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2046/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2047/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2048/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2049/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2050/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2051/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2052/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2053/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2054/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2055/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2056/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2057/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2058/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2059/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2060/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2061/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2062/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2063/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2064/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2065/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2066/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2067/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2068/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2069/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2070/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2071/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2072/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2073/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2074/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2075/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2076/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2077/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2078/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2079/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2080/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2081/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2082/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2083/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2084/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2085/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2086/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2087/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2088/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2089/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2090/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2091/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2092/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2093/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2094/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2095/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2096/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2097/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2098/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2099/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2100/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2101/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2102/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2103/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2104/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2105/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2106/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2107/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2108/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2109/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2110/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2111/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2112/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2113/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2114/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2115/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2116/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2117/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2118/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2119/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2120/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2121/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2122/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2123/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2124/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2125/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2126/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2127/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2128/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2129/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2130/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2131/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2132/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2133/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2134/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2135/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2136/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2137/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2138/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2139/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2140/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2141/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2142/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2143/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2144/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2145/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2146/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2147/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2148/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2149/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2150/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2151/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2152/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2153/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2154/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2155/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2156/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2157/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2158/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2159/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2160/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2161/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2162/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2163/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2164/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2165/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2166/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2167/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2168/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2169/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2170/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2171/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2172/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2173/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2174/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2175/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2176/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2177/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2178/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2179/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2180/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2181/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2182/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2183/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2184/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2185/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2186/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2187/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2188/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2189/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2190/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2191/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2192/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2193/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2194/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2195/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2196/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2197/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2198/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2199/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2200/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2201/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2202/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2203/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2204/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2205/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2206/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2207/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2208/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2209/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2210/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2211/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2212/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2213/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2214/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2215/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2216/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2217/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2218/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2219/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2220/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2221/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2222/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2223/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2224/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2225/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2226/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2227/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2228/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2229/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2230/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2231/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2232/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2233/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2234/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2235/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2236/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2237/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2238/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2239/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2240/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2241/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2242/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2243/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2244/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2245/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2246/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2247/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2248/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2249/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2250/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2251/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2252/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2253/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2254/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2255/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2256/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2257/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2258/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2259/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2260/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2261/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2262/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2263/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2264/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2265/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2266/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2267/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2268/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2269/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2270/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2271/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2272/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2273/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2274/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2275/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2276/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2277/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2278/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2279/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2280/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2281/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2282/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2283/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2284/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2285/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2286/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2287/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2288/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2289/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2290/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2291/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2292/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2293/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2294/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2295/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2296/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2297/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2298/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2299/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2300/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2301/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2302/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2303/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2304/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2305/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2306/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2307/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2308/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2309/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2310/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2311/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2312/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2313/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2314/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2315/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2316/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2317/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2318/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2319/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2320/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2321/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2322/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2323/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2324/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2325/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2326/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2327/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2328/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2329/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2330/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2331/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2332/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2333/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2334/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2335/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2336/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2337/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2338/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2339/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2340/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2341/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2342/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2343/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2344/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2345/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2346/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2347/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2348/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2349/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2350/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2351/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2352/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2353/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2354/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2355/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2356/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2357/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2358/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2359/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2360/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2361/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2362/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2363/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2364/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2365/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2366/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2367/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2368/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2369/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2370/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2371/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2372/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2373/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2374/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2375/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2376/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2377/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2378/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2379/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2380/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2381/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2382/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2383/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2384/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2385/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2386/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2387/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2388/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2389/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2390/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2391/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2392/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2393/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2394/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2395/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2396/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2397/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2398/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2399/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2400/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2401/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2402/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2403/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2404/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2405/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2406/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2407/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2408/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2409/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2410/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2411/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2412/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2413/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2414/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2415/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2416/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2417/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2418/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2419/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2420/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2421/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2422/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2423/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2424/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2425/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2426/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2427/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2428/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2429/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2430/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2431/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2432/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2433/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2434/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2435/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2436/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2437/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2438/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2439/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2440/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2441/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2442/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2443/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2444/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2445/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2446/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2447/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2448/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2449/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2450/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2451/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2452/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2453/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2454/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2455/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2456/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2457/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2458/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2459/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2460/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2461/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2462/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2463/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2464/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2465/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2466/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2467/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2468/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2469/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2470/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2471/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2472/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2473/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2474/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2475/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2476/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2477/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2478/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2479/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2480/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2481/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2482/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2483/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2484/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2485/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2486/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2487/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2488/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2489/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2490/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2491/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2492/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2493/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2494/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2495/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2496/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2497/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2498/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2499/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2500/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2501/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2502/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2503/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2504/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2505/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2506/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2507/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2508/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2509/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2510/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2511/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2512/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2513/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2514/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2515/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2516/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2517/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2518/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2519/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2520/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2521/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2522/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2523/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2524/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2525/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2526/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2527/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2528/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2529/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2530/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2531/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2532/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2533/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2534/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2535/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2536/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2537/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2538/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2539/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2540/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2541/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2542/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2543/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2544/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2545/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2546/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2547/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2548/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2549/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2550/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2551/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2552/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2553/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2554/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2555/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2556/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2557/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2558/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2559/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2560/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2561/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2562/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2563/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2564/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2565/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2566/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2567/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2568/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2569/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2570/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2571/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2572/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2573/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2574/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2575/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2576/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2577/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2578/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2579/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2580/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2581/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2582/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2583/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2584/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2585/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2586/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2587/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2588/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2589/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2590/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2591/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2592/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2593/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2594/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2595/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2596/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2597/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2598/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2599/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2600/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2601/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2602/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2603/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2604/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2605/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2606/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2607/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2608/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2609/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2610/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2611/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2612/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2613/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2614/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2615/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2616/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2617/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2618/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2619/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2620/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2621/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2622/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2623/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2624/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2625/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2626/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2627/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2628/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2629/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2630/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2631/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2632/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2633/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2634/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2635/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2636/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2637/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2638/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2639/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2640/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2641/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2642/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2643/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2644/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2645/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2646/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2647/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2648/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2649/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2650/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2651/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2652/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2653/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2654/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2655/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2656/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2657/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2658/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2659/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2660/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2661/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2662/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2663/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2664/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2665/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2666/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2667/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2668/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2669/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2670/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2671/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2672/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2673/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2674/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2675/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2676/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2677/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2678/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2679/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2680/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2681/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2682/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2683/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2684/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2685/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2686/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2687/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2688/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2689/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2690/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2691/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2692/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2693/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2694/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2695/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2696/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2697/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2698/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2699/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2700/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2701/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2702/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2703/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2704/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2705/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2706/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2707/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2708/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2709/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2710/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2711/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2712/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2713/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2714/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2715/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2716/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2717/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2718/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2719/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2720/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2721/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2722/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2723/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2724/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2725/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2726/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2727/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2728/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2729/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2730/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2731/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2732/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2733/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2734/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2735/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2736/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2737/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2738/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2739/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2740/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2741/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2742/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2743/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2744/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2745/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2746/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2747/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2748/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2749/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2750/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2751/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2752/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2753/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2754/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2755/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2756/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2757/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2758/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2759/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2760/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2761/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2762/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2763/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2764/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2765/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2766/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2767/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2768/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2769/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2770/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2771/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2772/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2773/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2774/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2775/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2776/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2777/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2778/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2779/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2780/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2781/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2782/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2783/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2784/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2785/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2786/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2787/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2788/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2789/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2790/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2791/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2792/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2793/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2794/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2795/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2796/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2797/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2798/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2799/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2800/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2801/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2802/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2803/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2804/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2805/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2806/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2807/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2808/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2809/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2810/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2811/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2812/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2813/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2814/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2815/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2816/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2817/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2818/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2819/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2820/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2821/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2822/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2823/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2824/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2825/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2826/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2827/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2828/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2829/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2830/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2831/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2832/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2833/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2834/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2835/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2836/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2837/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2838/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2839/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2840/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2841/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2842/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2843/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2844/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2845/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2846/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2847/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2848/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2849/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2850/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2851/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2852/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2853/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2854/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2855/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2856/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2857/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2858/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2859/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2860/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2861/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2862/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2863/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2864/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2865/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2866/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2867/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2868/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2869/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2870/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2871/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2872/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2873/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2874/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2875/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2876/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2877/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2878/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2879/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2880/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2881/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2882/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2883/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2884/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2885/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2886/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2887/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2888/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2889/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2890/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2891/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2892/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2893/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2894/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2895/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2896/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2897/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2898/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2899/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2900/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2901/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2902/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2903/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2904/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2905/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2906/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2907/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2908/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2909/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2910/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2911/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2912/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2913/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2914/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2915/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2916/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2917/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2918/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2919/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2920/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2921/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2922/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2923/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2924/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2925/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2926/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2927/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2928/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2929/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2930/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2931/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2932/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2933/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2934/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2935/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2936/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2937/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2938/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2939/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2940/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2941/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2942/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2943/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2944/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2945/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2946/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2947/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2948/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2949/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2950/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2951/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2952/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2953/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2954/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2955/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2956/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2957/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2958/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2959/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2960/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2961/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2962/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2963/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2964/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2965/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2966/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2967/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2968/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2969/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2970/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2971/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2972/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2973/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2974/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2975/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2976/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2977/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2978/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2979/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2980/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2981/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2982/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2983/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2984/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2985/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2986/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2987/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2988/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2989/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2990/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2991/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2992/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2993/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2994/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2995/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2996/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2997/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2998/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 2999/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3000/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3001/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3002/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3003/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3004/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3005/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3006/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3007/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3008/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3009/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3010/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3011/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3012/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3013/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3014/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3015/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3016/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3017/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3018/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3019/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3020/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3021/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3022/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3023/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3024/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3025/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3026/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3027/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3028/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3029/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3030/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3031/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3032/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3033/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3034/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3035/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3036/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3037/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3038/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3039/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3040/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3041/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3042/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3043/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3044/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3045/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3046/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3047/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3048/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3049/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3050/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3051/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3052/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3053/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3054/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3055/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3056/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3057/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3058/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3059/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3060/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3061/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3062/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3063/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3064/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3065/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3066/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3067/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3068/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3069/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3070/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3071/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3072/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3073/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3074/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3075/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3076/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3077/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3078/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3079/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3080/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3081/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3082/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3083/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3084/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3085/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3086/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3087/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3088/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3089/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3090/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3091/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3092/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3093/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3094/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3095/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3096/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3097/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3098/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3099/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3100/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3101/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3102/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3103/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3104/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3105/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3106/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3107/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3108/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3109/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3110/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3111/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3112/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3113/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3114/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3115/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3116/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3117/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3118/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3119/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3120/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3121/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3122/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3123/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3124/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3125/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3126/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3127/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3128/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3129/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3130/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3131/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3132/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3133/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3134/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3135/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3136/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3137/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3138/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3139/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3140/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3141/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3142/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3143/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3144/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3145/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3146/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3147/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3148/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3149/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3150/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3151/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3152/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3153/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3154/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3155/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3156/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3157/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3158/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3159/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3160/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3161/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3162/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3163/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3164/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3165/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3166/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3167/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3168/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3169/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3170/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3171/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3172/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3173/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3174/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3175/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3176/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3177/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3178/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3179/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3180/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3181/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3182/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3183/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3184/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3185/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3186/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3187/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3188/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3189/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3190/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3191/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3192/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3193/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3194/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3195/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3196/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3197/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3198/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3199/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3200/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3201/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3202/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3203/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3204/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3205/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3206/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3207/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3208/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3209/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3210/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3211/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3212/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3213/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3214/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3215/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3216/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3217/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3218/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3219/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3220/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3221/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3222/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3223/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3224/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3225/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3226/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3227/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3228/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3229/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3230/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3231/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3232/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3233/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3234/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3235/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3236/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3237/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3238/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3239/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3240/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3241/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3242/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3243/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3244/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3245/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3246/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3247/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3248/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3249/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3250/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3251/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3252/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3253/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3254/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3255/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3256/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3257/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3258/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3259/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3260/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3261/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3262/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3263/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3264/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3265/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3266/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3267/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3268/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3269/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3270/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3271/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3272/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3273/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3274/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3275/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3276/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3277/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3278/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3279/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3280/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3281/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3282/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3283/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3284/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3285/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3286/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3287/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3288/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3289/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3290/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3291/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3292/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3293/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3294/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3295/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3296/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3297/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3298/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3299/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3300/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3301/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3302/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3303/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3304/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3305/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3306/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3307/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3308/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3309/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3310/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3311/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3312/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3313/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3314/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3315/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3316/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3317/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3318/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3319/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3320/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3321/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3322/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3323/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3324/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3325/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3326/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3327/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3328/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3329/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3330/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3331/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3332/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3333/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3334/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3335/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3336/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3337/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3338/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3339/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3340/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3341/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3342/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3343/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3344/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3345/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3346/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3347/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3348/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3349/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3350/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3351/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3352/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3353/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3354/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3355/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3356/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3357/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3358/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3359/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3360/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3361/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3362/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3363/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3364/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3365/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3366/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3367/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3368/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3369/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3370/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3371/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3372/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3373/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3374/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3375/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3376/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3377/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3378/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3379/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3380/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3381/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3382/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3383/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3384/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3385/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3386/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3387/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3388/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3389/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3390/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3391/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3392/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3393/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3394/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3395/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3396/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3397/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3398/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3399/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3400/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3401/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3402/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3403/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3404/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3405/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3406/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3407/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3408/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3409/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3410/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3411/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3412/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3413/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3414/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3415/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3416/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3417/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3418/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3419/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3420/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3421/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3422/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3423/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3424/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3425/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3426/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3427/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3428/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3429/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3430/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3431/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3432/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3433/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3434/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3435/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3436/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3437/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3438/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3439/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3440/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3441/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3442/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3443/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3444/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3445/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3446/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3447/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3448/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3449/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3450/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3451/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3452/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3453/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3454/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3455/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3456/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3457/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3458/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3459/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3460/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3461/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3462/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3463/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3464/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3465/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3466/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3467/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3468/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3469/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3470/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3471/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3472/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3473/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3474/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3475/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3476/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3477/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3478/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3479/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3480/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3481/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3482/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3483/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3484/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3485/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3486/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3487/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3488/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3489/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3490/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3491/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3492/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3493/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3494/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3495/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3496/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3497/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3498/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3499/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3500/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3501/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3502/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3503/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3504/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3505/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3506/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3507/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3508/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3509/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3510/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3511/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3512/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3513/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3514/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3515/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3516/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3517/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3518/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3519/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3520/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3521/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3522/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3523/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3524/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3525/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3526/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3527/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3528/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3529/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3530/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3531/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3532/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3533/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3534/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3535/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3536/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3537/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3538/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3539/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3540/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3541/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3542/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3543/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3544/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3545/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3546/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3547/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3548/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3549/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3550/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3551/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3552/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3553/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3554/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3555/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3556/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3557/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3558/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3559/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3560/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3561/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3562/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3563/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3564/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3565/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3566/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3567/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3568/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3569/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3570/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3571/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3572/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3573/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3574/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3575/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3576/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3577/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3578/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3579/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3580/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3581/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3582/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3583/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3584/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3585/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3586/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3587/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3588/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3589/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3590/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3591/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3592/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3593/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3594/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3595/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3596/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3597/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3598/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3599/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3600/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3601/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3602/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3603/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3604/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3605/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3606/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3607/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3608/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3609/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3610/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3611/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3612/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3613/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3614/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3615/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3616/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3617/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3618/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3619/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3620/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3621/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3622/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3623/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3624/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3625/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3626/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3627/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3628/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3629/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3630/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3631/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3632/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3633/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3634/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3635/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3636/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3637/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3638/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3639/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3640/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3641/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3642/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3643/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3644/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3645/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3646/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3647/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3648/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3649/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3650/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3651/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3652/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3653/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3654/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3655/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3656/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3657/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3658/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3659/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3660/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3661/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3662/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3663/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3664/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3665/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3666/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3667/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3668/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3669/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3670/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3671/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3672/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3673/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3674/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3675/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3676/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3677/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3678/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3679/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3680/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3681/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3682/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3683/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3684/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3685/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3686/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3687/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3688/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3689/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3690/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3691/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3692/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3693/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3694/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3695/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3696/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3697/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3698/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3699/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3700/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3701/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3702/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3703/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3704/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3705/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3706/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3707/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3708/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3709/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3710/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3711/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3712/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3713/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3714/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3715/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3716/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3717/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3718/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3719/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3720/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3721/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3722/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3723/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3724/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3725/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3726/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3727/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3728/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3729/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3730/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3731/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3732/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3733/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3734/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3735/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3736/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3737/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3738/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3739/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3740/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3741/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3742/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3743/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3744/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3745/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3746/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3747/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3748/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3749/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3750/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3751/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3752/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3753/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3754/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3755/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3756/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3757/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3758/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3759/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3760/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3761/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3762/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3763/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3764/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3765/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3766/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3767/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3768/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3769/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3770/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3771/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3772/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3773/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3774/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3775/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3776/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3777/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3778/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3779/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3780/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3781/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3782/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3783/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3784/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3785/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3786/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3787/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3788/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3789/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3790/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3791/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3792/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3793/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3794/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3795/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3796/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3797/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3798/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3799/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3800/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3801/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3802/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3803/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3804/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3805/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3806/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3807/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3808/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3809/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3810/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3811/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3812/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3813/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3814/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3815/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3816/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3817/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3818/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3819/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3820/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3821/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3822/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3823/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3824/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3825/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3826/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3827/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3828/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3829/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3830/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3831/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3832/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3833/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3834/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3835/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3836/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3837/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3838/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3839/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3840/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3841/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3842/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3843/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3844/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3845/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3846/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3847/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3848/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3849/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3850/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3851/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3852/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3853/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3854/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3855/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3856/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3857/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3858/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3859/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3860/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3861/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3862/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3863/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3864/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3865/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3866/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3867/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3868/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3869/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3870/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3871/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3872/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3873/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3874/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3875/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3876/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3877/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3878/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3879/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3880/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3881/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3882/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3883/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3884/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3885/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3886/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3887/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3888/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3889/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3890/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3891/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3892/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3893/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3894/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3895/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3896/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3897/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3898/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3899/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3900/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3901/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3902/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3903/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3904/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3905/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3906/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3907/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3908/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3909/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3910/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3911/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3912/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3913/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3914/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3915/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3916/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3917/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3918/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3919/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3920/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3921/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3922/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3923/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3924/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3925/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3926/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3927/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3928/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3929/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3930/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3931/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3932/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3933/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3934/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3935/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3936/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3937/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3938/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3939/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3940/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3941/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3942/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3943/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3944/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3945/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3946/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3947/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3948/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3949/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3950/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3951/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3952/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3953/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3954/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3955/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3956/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3957/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3958/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3959/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3960/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3961/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3962/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3963/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3964/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3965/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3966/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3967/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3968/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3969/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3970/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3971/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3972/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3973/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3974/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3975/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3976/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3977/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3978/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3979/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3980/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3981/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3982/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3983/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3984/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3985/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3986/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3987/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3988/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3989/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3990/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3991/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3992/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3993/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3994/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3995/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3996/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3997/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3998/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 3999/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4000/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4001/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4002/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4003/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4004/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4005/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4006/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4007/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4008/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4009/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4010/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4011/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4012/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4013/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4014/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4015/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4016/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4017/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4018/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4019/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4020/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4021/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4022/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4023/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4024/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4025/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4026/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4027/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4028/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4029/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4030/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4031/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4032/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4033/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4034/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4035/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4036/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4037/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4038/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4039/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4040/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4041/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4042/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4043/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4044/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4045/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4046/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4047/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4048/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4049/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4050/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4051/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4052/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4053/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4054/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4055/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4056/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4057/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4058/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4059/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4060/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4061/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4062/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4063/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4064/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4065/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4066/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4067/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4068/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4069/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4070/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4071/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4072/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4073/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4074/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4075/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4076/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4077/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4078/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4079/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4080/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4081/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4082/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4083/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4084/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4085/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4086/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4087/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4088/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4089/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4090/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4091/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4092/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4093/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4094/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4095/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4096/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4097/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4098/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4099/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4100/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4101/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4102/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4103/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4104/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4105/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4106/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4107/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4108/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4109/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4110/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4111/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4112/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4113/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4114/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4115/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4116/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4117/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4118/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4119/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4120/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4121/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4122/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4123/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4124/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4125/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4126/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4127/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4128/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4129/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4130/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4131/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4132/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4133/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4134/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4135/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4136/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4137/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4138/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4139/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4140/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4141/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4142/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4143/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4144/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4145/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4146/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4147/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4148/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4149/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4150/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4151/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4152/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4153/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4154/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4155/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4156/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4157/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4158/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4159/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4160/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4161/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4162/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4163/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4164/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4165/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4166/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4167/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4168/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4169/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4170/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4171/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4172/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4173/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4174/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4175/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4176/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4177/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4178/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4179/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4180/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4181/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4182/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4183/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4184/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4185/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4186/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4187/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4188/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4189/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4190/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4191/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4192/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4193/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4194/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4195/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4196/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4197/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4198/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4199/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4200/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4201/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4202/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4203/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4204/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4205/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4206/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4207/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4208/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4209/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4210/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4211/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4212/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4213/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4214/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4215/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4216/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4217/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4218/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4219/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4220/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4221/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4222/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4223/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4224/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4225/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4226/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4227/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4228/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4229/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4230/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4231/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4232/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4233/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4234/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4235/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4236/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4237/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4238/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4239/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4240/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4241/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4242/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4243/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4244/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4245/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4246/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4247/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4248/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4249/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4250/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4251/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4252/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4253/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4254/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4255/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4256/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4257/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4258/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4259/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4260/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4261/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4262/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4263/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4264/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4265/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4266/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4267/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4268/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4269/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4270/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4271/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4272/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4273/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4274/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4275/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4276/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4277/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4278/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4279/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4280/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4281/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4282/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4283/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4284/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4285/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4286/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4287/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4288/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4289/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4290/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4291/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4292/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4293/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4294/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4295/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4296/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4297/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4298/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4299/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4300/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4301/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4302/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4303/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4304/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4305/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4306/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4307/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4308/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4309/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4310/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4311/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4312/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4313/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4314/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4315/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4316/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4317/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4318/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4319/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4320/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4321/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4322/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4323/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4324/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4325/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4326/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4327/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4328/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4329/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4330/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4331/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4332/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4333/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4334/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4335/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4336/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4337/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4338/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4339/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4340/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4341/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4342/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4343/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4344/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4345/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4346/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4347/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4348/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4349/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4350/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4351/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4352/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4353/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4354/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4355/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4356/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4357/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4358/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4359/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4360/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4361/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4362/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4363/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4364/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4365/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4366/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4367/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4368/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4369/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4370/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4371/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4372/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4373/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4374/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4375/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4376/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4377/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4378/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4379/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4380/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4381/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4382/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4383/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4384/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4385/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4386/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4387/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4388/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4389/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4390/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4391/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4392/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4393/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4394/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4395/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4396/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4397/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4398/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4399/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4400/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4401/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4402/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4403/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4404/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4405/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4406/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4407/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4408/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4409/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4410/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4411/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4412/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4413/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4414/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4415/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4416/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4417/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4418/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4419/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4420/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4421/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4422/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4423/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4424/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4425/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4426/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4427/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4428/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4429/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4430/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4431/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4432/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4433/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4434/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4435/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4436/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4437/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4438/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4439/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4440/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4441/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4442/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4443/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4444/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4445/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4446/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4447/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4448/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4449/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4450/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4451/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4452/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4453/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4454/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4455/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4456/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4457/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4458/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4459/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4460/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4461/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4462/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4463/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4464/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4465/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4466/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4467/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4468/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4469/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4470/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4471/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4472/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4473/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4474/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4475/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4476/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4477/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4478/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4479/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4480/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4481/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4482/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4483/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4484/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4485/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4486/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4487/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4488/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4489/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4490/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4491/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4492/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4493/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4494/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4495/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4496/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4497/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4498/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4499/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4500/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4501/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4502/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4503/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4504/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4505/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4506/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4507/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4508/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4509/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4510/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4511/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4512/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4513/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4514/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4515/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4516/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4517/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4518/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4519/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4520/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4521/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4522/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4523/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4524/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4525/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4526/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4527/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4528/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4529/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4530/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4531/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4532/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4533/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4534/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4535/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4536/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4537/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4538/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4539/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4540/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4541/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4542/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4543/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4544/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4545/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4546/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4547/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4548/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4549/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4550/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4551/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4552/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4553/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4554/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4555/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4556/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4557/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4558/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4559/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4560/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4561/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4562/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4563/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4564/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4565/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4566/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4567/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4568/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4569/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4570/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4571/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4572/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4573/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4574/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4575/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4576/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4577/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4578/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4579/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4580/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4581/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4582/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4583/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4584/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4585/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4586/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4587/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4588/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4589/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4590/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4591/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4592/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4593/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4594/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4595/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4596/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4597/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4598/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4599/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4600/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4601/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4602/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4603/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4604/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4605/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4606/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4607/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4608/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4609/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4610/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4611/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4612/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4613/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4614/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4615/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4616/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4617/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4618/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4619/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4620/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4621/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4622/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4623/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4624/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4625/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4626/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4627/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4628/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4629/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4630/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4631/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4632/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4633/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4634/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4635/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4636/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4637/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4638/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4639/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4640/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4641/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4642/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4643/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4644/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4645/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4646/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4647/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4648/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4649/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4650/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4651/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4652/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4653/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4654/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4655/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4656/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4657/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4658/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4659/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4660/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4661/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4662/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4663/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4664/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4665/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4666/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4667/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4668/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4669/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4670/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4671/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4672/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4673/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4674/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4675/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4676/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4677/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4678/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4679/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4680/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4681/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4682/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4683/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4684/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4685/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4686/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4687/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4688/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4689/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4690/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4691/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4692/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4693/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4694/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4695/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4696/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4697/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4698/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4699/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4700/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4701/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4702/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4703/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4704/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4705/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4706/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4707/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4708/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4709/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4710/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4711/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4712/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4713/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4714/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4715/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4716/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4717/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4718/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4719/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4720/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4721/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4722/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4723/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4724/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4725/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4726/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4727/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4728/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4729/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4730/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4731/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4732/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4733/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4734/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4735/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4736/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4737/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4738/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4739/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4740/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4741/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4742/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4743/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4744/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4745/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4746/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4747/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4748/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4749/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4750/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4751/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4752/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4753/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4754/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4755/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4756/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4757/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4758/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4759/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4760/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4761/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4762/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4763/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4764/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4765/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4766/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4767/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4768/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4769/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4770/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4771/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4772/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4773/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4774/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4775/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4776/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4777/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4778/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4779/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4780/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4781/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4782/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4783/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4784/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4785/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4786/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4787/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4788/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4789/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4790/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4791/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4792/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4793/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4794/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4795/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4796/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4797/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4798/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4799/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4800/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4801/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4802/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4803/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4804/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4805/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4806/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4807/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4808/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4809/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4810/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4811/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4812/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4813/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4814/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4815/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4816/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4817/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4818/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4819/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4820/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4821/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4822/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4823/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4824/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4825/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4826/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4827/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4828/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4829/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4830/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4831/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4832/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4833/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4834/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4835/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4836/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4837/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4838/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4839/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4840/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4841/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4842/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4843/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4844/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4845/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4846/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4847/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4848/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4849/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4850/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4851/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4852/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4853/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4854/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4855/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4856/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4857/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4858/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4859/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4860/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4861/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4862/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4863/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4864/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4865/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4866/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4867/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4868/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4869/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4870/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4871/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4872/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4873/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4874/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4875/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4876/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4877/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4878/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4879/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4880/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4881/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4882/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4883/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4884/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4885/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4886/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4887/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4888/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4889/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4890/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4891/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4892/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4893/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4894/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4895/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4896/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4897/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4898/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4899/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4900/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4901/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4902/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4903/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4904/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4905/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4906/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4907/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4908/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4909/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4910/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4911/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4912/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4913/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4914/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4915/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4916/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4917/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4918/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4919/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4920/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4921/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4922/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4923/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4924/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4925/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4926/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4927/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4928/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4929/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4930/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4931/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4932/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4933/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4934/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4935/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4936/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4937/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4938/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4939/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4940/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4941/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4942/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4943/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4944/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4945/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4946/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4947/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4948/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4949/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4950/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4951/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4952/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4953/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4954/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4955/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4956/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4957/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4958/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4959/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4960/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4961/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4962/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4963/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4964/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4965/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4966/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4967/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4968/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4969/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4970/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4971/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4972/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4973/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4974/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4975/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4976/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4977/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4978/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4979/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4980/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4981/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4982/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4983/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4984/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4985/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4986/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4987/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4988/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4989/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4990/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4991/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4992/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4993/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4994/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4995/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4996/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4997/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4998/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 4999/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5000/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5001/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5002/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5003/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5004/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5005/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5006/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5007/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5008/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5009/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5010/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5011/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5012/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5013/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5014/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5015/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5016/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5017/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5018/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5019/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5020/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5021/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5022/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5023/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5024/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5025/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5026/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5027/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5028/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5029/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5030/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5031/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5032/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5033/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5034/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5035/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5036/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5037/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5038/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5039/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5040/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5041/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5042/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5043/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5044/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5045/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5046/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5047/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5048/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5049/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5050/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5051/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5052/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5053/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5054/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5055/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5056/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5057/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5058/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5059/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5060/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5061/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5062/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5063/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5064/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5065/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5066/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5067/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5068/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5069/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5070/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5071/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5072/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5073/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5074/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5075/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5076/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5077/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5078/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5079/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5080/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5081/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5082/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5083/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5084/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5085/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5086/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5087/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5088/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5089/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5090/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5091/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5092/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5093/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5094/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5095/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5096/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5097/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5098/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5099/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5100/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5101/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5102/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5103/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5104/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5105/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5106/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5107/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5108/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5109/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5110/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5111/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5112/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5113/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5114/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5115/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5116/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5117/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5118/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5119/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5120/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5121/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5122/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5123/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5124/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5125/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5126/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5127/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5128/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5129/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5130/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5131/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5132/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5133/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5134/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5135/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5136/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5137/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5138/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5139/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5140/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5141/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5142/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5143/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5144/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5145/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5146/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5147/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5148/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5149/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5150/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5151/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5152/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5153/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5154/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5155/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5156/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5157/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5158/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5159/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5160/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5161/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5162/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5163/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5164/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5165/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5166/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5167/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5168/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5169/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5170/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5171/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5172/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5173/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5174/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5175/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5176/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5177/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5178/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5179/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5180/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5181/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5182/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5183/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5184/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5185/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5186/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5187/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5188/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5189/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5190/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5191/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5192/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5193/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5194/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5195/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5196/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5197/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5198/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5199/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5200/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5201/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5202/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5203/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5204/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5205/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5206/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5207/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5208/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5209/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5210/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5211/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5212/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5213/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5214/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5215/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5216/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5217/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5218/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5219/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5220/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5221/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5222/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5223/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5224/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5225/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5226/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5227/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5228/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5229/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5230/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5231/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5232/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5233/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5234/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5235/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5236/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5237/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5238/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5239/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5240/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5241/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5242/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5243/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5244/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5245/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5246/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5247/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5248/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5249/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5250/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5251/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5252/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5253/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5254/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5255/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5256/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5257/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5258/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5259/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5260/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5261/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5262/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5263/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5264/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5265/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5266/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5267/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5268/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5269/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5270/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5271/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5272/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5273/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5274/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5275/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5276/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5277/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5278/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5279/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5280/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5281/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5282/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5283/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5284/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5285/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5286/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5287/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5288/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5289/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5290/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5291/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5292/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5293/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5294/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5295/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5296/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5297/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5298/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5299/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5300/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5301/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5302/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5303/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5304/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5305/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5306/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5307/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5308/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5309/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5310/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5311/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5312/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5313/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5314/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5315/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5316/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5317/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5318/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5319/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5320/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5321/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5322/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5323/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5324/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5325/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5326/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5327/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5328/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5329/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5330/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5331/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5332/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5333/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5334/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5335/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5336/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5337/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5338/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5339/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5340/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5341/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5342/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5343/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5344/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5345/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5346/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5347/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5348/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5349/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5350/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5351/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5352/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5353/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5354/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5355/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5356/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5357/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5358/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5359/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5360/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5361/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5362/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5363/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5364/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5365/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5366/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5367/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5368/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5369/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5370/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5371/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5372/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5373/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5374/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5375/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5376/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5377/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5378/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5379/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5380/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5381/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5382/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5383/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5384/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5385/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5386/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5387/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5388/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5389/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5390/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5391/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5392/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5393/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5394/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5395/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5396/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5397/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5398/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5399/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5400/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5401/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5402/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5403/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5404/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5405/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5406/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5407/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5408/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5409/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5410/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5411/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5412/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5413/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5414/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5415/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5416/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5417/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5418/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5419/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5420/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5421/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5422/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5423/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5424/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5425/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5426/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5427/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5428/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5429/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5430/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5431/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5432/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5433/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5434/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5435/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5436/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5437/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5438/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5439/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5440/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5441/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5442/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5443/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5444/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5445/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5446/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5447/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5448/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5449/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5450/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5451/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5452/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5453/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5454/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5455/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5456/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5457/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5458/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5459/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5460/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5461/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5462/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5463/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5464/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5465/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5466/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5467/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5468/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5469/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5470/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5471/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5472/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5473/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5474/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5475/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5476/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5477/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5478/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5479/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5480/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5481/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5482/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5483/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5484/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5485/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5486/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5487/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5488/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5489/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5490/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5491/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5492/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5493/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5494/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5495/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5496/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5497/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5498/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5499/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5500/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5501/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5502/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5503/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5504/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5505/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5506/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5507/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5508/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5509/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5510/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5511/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5512/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5513/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5514/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5515/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5516/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5517/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5518/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5519/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5520/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5521/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5522/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5523/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5524/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5525/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5526/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5527/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5528/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5529/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5530/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5531/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5532/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5533/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5534/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5535/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5536/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5537/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5538/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5539/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5540/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5541/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5542/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5543/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5544/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5545/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5546/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5547/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5548/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5549/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5550/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5551/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5552/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5553/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5554/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5555/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5556/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5557/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5558/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5559/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5560/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5561/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5562/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5563/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5564/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5565/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5566/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5567/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5568/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5569/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5570/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5571/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5572/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5573/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5574/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5575/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5576/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5577/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5578/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5579/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5580/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5581/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5582/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5583/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5584/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5585/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5586/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5587/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5588/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5589/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5590/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5591/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5592/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5593/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5594/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5595/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5596/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5597/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5598/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5599/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5600/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5601/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5602/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5603/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5604/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5605/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5606/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5607/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5608/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5609/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5610/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5611/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5612/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5613/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5614/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5615/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5616/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5617/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5618/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5619/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5620/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5621/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5622/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5623/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5624/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5625/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5626/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5627/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5628/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5629/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5630/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5631/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5632/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5633/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5634/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5635/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5636/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5637/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5638/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5639/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5640/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5641/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5642/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5643/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5644/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5645/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5646/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5647/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5648/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5649/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5650/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5651/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5652/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5653/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5654/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5655/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5656/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5657/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5658/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5659/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5660/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5661/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5662/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5663/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5664/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5665/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5666/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5667/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5668/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5669/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5670/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5671/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5672/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5673/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5674/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5675/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5676/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5677/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5678/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5679/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5680/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5681/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5682/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5683/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5684/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5685/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5686/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5687/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5688/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5689/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5690/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5691/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5692/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5693/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5694/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5695/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5696/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5697/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5698/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5699/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5700/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5701/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5702/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5703/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5704/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5705/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5706/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5707/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5708/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5709/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5710/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5711/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5712/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5713/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5714/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5715/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5716/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5717/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5718/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5719/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5720/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5721/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5722/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5723/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5724/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5725/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5726/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5727/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5728/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5729/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5730/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5731/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5732/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5733/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5734/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5735/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5736/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5737/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5738/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5739/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5740/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5741/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5742/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5743/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5744/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5745/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5746/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5747/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5748/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5749/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5750/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5751/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5752/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5753/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5754/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5755/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5756/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5757/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5758/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5759/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5760/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5761/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5762/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5763/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5764/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5765/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5766/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5767/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5768/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5769/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5770/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5771/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5772/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5773/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5774/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5775/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5776/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5777/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5778/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5779/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5780/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5781/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5782/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5783/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5784/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5785/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5786/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5787/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5788/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5789/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5790/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5791/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5792/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5793/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5794/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5795/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5796/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5797/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5798/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5799/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5800/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5801/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5802/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5803/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5804/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5805/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5806/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5807/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5808/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5809/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5810/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5811/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5812/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5813/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5814/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5815/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5816/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5817/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5818/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5819/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5820/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5821/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5822/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5823/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5824/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5825/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5826/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5827/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5828/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5829/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5830/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5831/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5832/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5833/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5834/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5835/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5836/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5837/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5838/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5839/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5840/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5841/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5842/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5843/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5844/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5845/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5846/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5847/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5848/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5849/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5850/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5851/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5852/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5853/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5854/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5855/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5856/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5857/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5858/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5859/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5860/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5861/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5862/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5863/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5864/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5865/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5866/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5867/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5868/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5869/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5870/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5871/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5872/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5873/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5874/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5875/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5876/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5877/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5878/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5879/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5880/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5881/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5882/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5883/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5884/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5885/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5886/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5887/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5888/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5889/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5890/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5891/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5892/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5893/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5894/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5895/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5896/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5897/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5898/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5899/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5900/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5901/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5902/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5903/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5904/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5905/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5906/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5907/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5908/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5909/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5910/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5911/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5912/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5913/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5914/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5915/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5916/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5917/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5918/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5919/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5920/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5921/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5922/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5923/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5924/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5925/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5926/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5927/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5928/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5929/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5930/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5931/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5932/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5933/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5934/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5935/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5936/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5937/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5938/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5939/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5940/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5941/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5942/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5943/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5944/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5945/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5946/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5947/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5948/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5949/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5950/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5951/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5952/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5953/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5954/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5955/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5956/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5957/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5958/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5959/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5960/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5961/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5962/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5963/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5964/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5965/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5966/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5967/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5968/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5969/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5970/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5971/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5972/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5973/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5974/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5975/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5976/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5977/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5978/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5979/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5980/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5981/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5982/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5983/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5984/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5985/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5986/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5987/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5988/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5989/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5990/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5991/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5992/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5993/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5994/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5995/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5996/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5997/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5998/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 5999/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6000/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6001/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6002/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6003/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6004/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6005/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6006/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6007/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6008/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6009/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6010/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6011/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6012/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6013/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6014/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6015/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6016/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6017/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6018/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6019/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6020/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6021/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6022/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6023/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6024/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6025/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6026/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6027/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6028/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6029/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6030/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6031/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6032/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6033/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6034/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6035/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6036/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6037/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6038/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6039/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6040/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6041/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6042/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6043/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6044/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6045/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6046/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6047/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6048/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6049/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6050/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6051/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6052/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6053/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6054/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6055/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6056/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6057/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6058/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6059/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6060/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6061/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6062/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6063/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6064/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6065/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6066/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6067/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6068/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6069/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6070/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6071/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6072/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6073/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6074/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6075/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6076/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6077/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6078/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6079/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6080/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6081/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6082/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6083/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6084/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6085/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6086/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6087/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6088/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6089/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6090/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6091/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6092/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6093/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6094/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6095/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6096/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6097/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6098/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6099/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6100/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6101/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6102/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6103/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6104/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6105/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6106/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6107/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6108/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6109/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6110/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6111/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6112/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6113/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6114/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6115/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6116/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6117/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6118/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6119/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6120/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6121/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6122/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6123/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6124/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6125/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6126/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6127/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6128/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6129/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6130/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6131/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6132/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6133/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6134/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6135/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6136/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6137/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6138/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6139/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6140/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6141/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6142/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6143/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6144/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6145/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6146/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6147/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6148/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6149/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6150/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6151/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6152/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6153/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6154/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6155/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6156/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6157/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6158/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6159/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6160/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6161/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6162/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6163/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6164/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6165/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6166/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6167/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6168/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6169/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6170/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6171/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6172/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6173/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6174/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6175/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6176/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6177/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6178/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6179/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6180/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6181/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6182/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6183/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6184/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6185/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6186/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6187/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6188/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6189/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6190/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6191/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6192/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6193/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6194/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6195/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6196/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6197/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6198/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6199/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6200/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6201/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6202/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6203/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6204/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6205/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6206/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6207/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6208/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6209/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6210/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6211/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6212/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6213/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6214/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6215/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6216/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6217/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6218/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6219/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6220/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6221/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6222/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6223/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6224/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6225/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6226/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6227/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6228/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6229/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6230/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6231/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6232/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6233/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6234/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6235/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6236/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6237/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6238/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6239/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6240/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6241/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6242/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6243/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6244/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6245/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6246/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6247/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6248/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6249/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6250/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6251/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6252/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6253/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6254/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6255/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6256/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6257/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6258/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6259/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6260/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6261/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6262/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6263/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6264/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6265/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6266/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6267/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6268/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6269/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6270/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6271/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6272/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6273/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6274/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6275/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6276/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6277/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6278/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6279/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6280/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6281/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6282/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6283/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6284/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6285/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6286/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6287/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6288/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6289/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6290/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6291/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6292/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6293/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6294/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6295/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6296/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6297/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6298/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6299/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6300/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6301/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6302/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6303/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6304/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6305/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6306/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6307/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6308/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6309/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6310/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6311/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6312/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6313/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6314/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6315/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6316/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6317/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6318/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6319/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6320/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6321/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6322/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6323/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6324/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6325/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6326/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6327/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6328/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6329/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6330/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6331/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6332/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6333/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6334/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6335/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6336/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6337/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6338/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6339/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6340/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6341/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6342/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6343/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6344/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6345/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6346/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6347/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6348/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6349/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6350/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6351/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6352/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6353/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6354/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6355/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6356/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6357/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6358/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6359/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6360/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6361/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6362/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6363/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6364/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6365/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6366/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6367/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6368/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6369/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6370/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6371/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6372/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6373/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6374/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6375/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6376/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6377/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6378/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6379/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6380/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6381/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6382/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6383/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6384/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6385/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6386/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6387/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6388/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6389/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6390/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6391/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6392/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6393/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6394/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6395/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6396/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6397/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6398/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6399/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6400/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6401/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6402/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6403/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6404/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6405/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6406/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6407/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6408/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6409/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6410/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6411/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6412/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6413/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6414/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6415/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6416/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6417/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6418/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6419/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6420/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6421/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6422/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6423/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6424/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6425/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6426/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6427/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6428/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6429/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6430/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6431/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6432/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6433/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6434/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6435/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6436/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6437/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6438/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6439/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6440/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6441/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6442/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6443/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6444/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6445/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6446/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6447/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6448/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6449/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6450/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6451/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6452/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6453/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6454/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6455/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6456/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6457/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6458/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6459/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6460/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6461/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6462/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6463/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6464/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6465/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6466/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6467/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6468/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6469/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6470/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6471/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6472/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6473/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6474/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6475/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6476/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6477/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6478/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6479/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6480/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6481/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6482/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6483/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6484/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6485/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6486/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6487/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6488/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6489/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6490/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6491/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6492/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6493/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6494/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6495/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6496/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6497/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6498/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6499/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6500/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6501/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6502/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6503/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6504/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6505/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6506/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6507/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6508/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6509/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6510/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6511/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6512/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6513/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6514/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6515/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6516/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6517/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6518/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6519/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6520/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6521/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6522/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6523/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6524/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6525/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6526/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6527/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6528/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6529/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6530/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6531/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6532/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6533/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6534/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6535/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6536/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6537/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6538/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6539/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6540/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6541/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6542/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6543/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6544/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6545/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6546/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6547/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6548/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6549/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6550/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6551/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6552/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6553/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6554/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6555/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6556/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6557/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6558/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6559/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6560/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6561/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6562/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6563/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6564/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6565/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6566/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6567/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6568/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6569/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6570/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6571/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6572/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6573/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6574/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6575/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6576/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6577/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6578/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6579/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6580/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6581/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6582/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6583/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6584/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6585/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6586/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6587/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6588/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6589/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6590/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6591/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6592/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6593/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6594/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6595/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6596/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6597/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6598/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6599/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6600/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6601/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6602/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6603/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6604/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6605/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6606/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6607/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6608/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6609/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6610/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6611/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6612/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6613/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6614/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6615/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6616/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6617/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6618/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6619/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6620/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6621/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6622/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6623/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6624/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6625/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6626/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6627/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6628/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6629/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6630/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6631/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6632/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6633/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6634/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6635/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6636/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6637/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6638/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6639/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6640/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6641/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6642/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6643/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6644/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6645/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6646/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6647/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6648/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6649/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6650/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6651/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6652/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6653/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6654/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6655/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6656/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6657/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6658/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6659/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6660/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6661/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6662/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6663/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6664/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6665/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6666/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6667/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6668/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6669/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6670/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6671/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6672/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6673/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6674/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6675/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6676/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6677/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6678/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6679/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6680/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6681/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6682/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6683/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6684/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6685/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6686/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6687/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6688/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6689/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6690/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6691/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6692/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6693/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6694/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6695/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6696/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6697/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6698/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6699/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6700/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6701/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6702/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6703/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6704/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6705/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6706/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6707/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6708/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6709/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6710/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6711/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6712/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6713/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6714/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6715/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6716/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6717/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6718/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6719/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6720/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6721/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6722/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6723/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6724/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6725/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6726/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6727/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6728/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6729/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6730/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6731/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6732/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6733/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6734/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6735/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6736/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6737/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6738/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6739/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6740/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6741/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6742/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6743/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6744/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6745/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6746/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6747/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6748/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6749/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6750/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6751/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6752/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6753/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6754/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6755/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6756/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6757/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6758/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6759/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6760/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6761/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6762/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6763/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6764/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6765/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6766/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6767/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6768/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6769/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6770/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6771/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6772/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6773/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6774/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6775/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6776/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6777/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6778/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6779/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6780/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6781/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6782/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6783/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6784/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6785/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6786/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6787/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6788/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6789/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6790/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6791/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6792/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6793/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6794/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6795/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6796/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6797/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6798/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6799/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6800/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6801/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6802/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6803/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6804/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6805/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6806/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6807/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6808/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6809/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6810/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6811/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6812/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6813/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6814/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6815/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6816/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6817/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6818/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6819/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6820/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6821/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6822/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6823/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6824/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6825/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6826/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6827/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6828/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6829/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6830/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6831/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6832/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6833/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6834/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6835/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6836/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6837/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6838/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6839/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6840/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6841/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6842/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6843/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6844/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6845/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6846/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6847/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6848/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6849/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6850/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6851/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6852/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6853/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6854/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6855/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6856/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6857/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6858/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6859/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6860/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6861/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6862/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6863/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6864/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6865/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6866/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6867/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6868/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6869/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6870/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6871/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6872/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6873/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6874/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6875/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6876/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6877/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6878/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6879/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6880/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6881/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6882/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6883/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6884/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6885/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6886/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6887/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6888/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6889/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6890/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6891/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6892/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6893/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6894/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6895/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6896/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6897/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6898/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6899/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6900/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6901/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6902/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6903/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6904/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6905/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6906/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6907/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6908/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6909/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6910/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6911/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6912/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6913/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6914/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6915/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6916/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6917/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6918/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6919/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6920/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6921/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6922/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6923/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6924/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6925/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6926/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6927/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6928/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6929/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6930/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6931/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6932/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6933/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6934/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6935/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6936/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6937/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6938/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6939/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6940/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6941/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6942/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6943/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6944/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6945/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6946/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6947/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6948/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6949/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6950/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6951/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6952/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6953/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6954/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6955/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6956/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6957/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6958/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6959/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6960/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6961/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6962/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6963/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6964/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6965/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6966/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6967/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6968/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6969/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6970/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6971/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6972/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6973/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6974/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6975/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6976/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6977/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6978/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6979/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6980/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6981/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6982/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6983/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6984/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6985/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6986/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6987/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6988/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6989/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6990/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6991/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6992/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6993/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6994/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6995/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6996/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6997/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6998/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 6999/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7000/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7001/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7002/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7003/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7004/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7005/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7006/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7007/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7008/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7009/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7010/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7011/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7012/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7013/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7014/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7015/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7016/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7017/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7018/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7019/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7020/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7021/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7022/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7023/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7024/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7025/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7026/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7027/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7028/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7029/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7030/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7031/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7032/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7033/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7034/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7035/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7036/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7037/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7038/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7039/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7040/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7041/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7042/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7043/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7044/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7045/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7046/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7047/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7048/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7049/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7050/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7051/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7052/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7053/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7054/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7055/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7056/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7057/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7058/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7059/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7060/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7061/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7062/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7063/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7064/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7065/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7066/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7067/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7068/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7069/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7070/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7071/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7072/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7073/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7074/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7075/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7076/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7077/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7078/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7079/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7080/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7081/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7082/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7083/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7084/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7085/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7086/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7087/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7088/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7089/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7090/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7091/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7092/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7093/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7094/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7095/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7096/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7097/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7098/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7099/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7100/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7101/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7102/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7103/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7104/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7105/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7106/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7107/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7108/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7109/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7110/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7111/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7112/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7113/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7114/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7115/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7116/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7117/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7118/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7119/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7120/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7121/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7122/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7123/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7124/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7125/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7126/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7127/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7128/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7129/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7130/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7131/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7132/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7133/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7134/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7135/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7136/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7137/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7138/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7139/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7140/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7141/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7142/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7143/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7144/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7145/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7146/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7147/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7148/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7149/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7150/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7151/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7152/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7153/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7154/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7155/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7156/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7157/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7158/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7159/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7160/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7161/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7162/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7163/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7164/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7165/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7166/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7167/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7168/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7169/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7170/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7171/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7172/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7173/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7174/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7175/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7176/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7177/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7178/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7179/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7180/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7181/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7182/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7183/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7184/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7185/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7186/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7187/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7188/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7189/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7190/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7191/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7192/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7193/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7194/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7195/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7196/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7197/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7198/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7199/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7200/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7201/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7202/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7203/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7204/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7205/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7206/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7207/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7208/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7209/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7210/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7211/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7212/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7213/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7214/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7215/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7216/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7217/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7218/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7219/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7220/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7221/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7222/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7223/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7224/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7225/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7226/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7227/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7228/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7229/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7230/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7231/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7232/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7233/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7234/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7235/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7236/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7237/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7238/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7239/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7240/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7241/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7242/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7243/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7244/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7245/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7246/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7247/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7248/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7249/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7250/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7251/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7252/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7253/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7254/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7255/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7256/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7257/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7258/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7259/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7260/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7261/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7262/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7263/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7264/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7265/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7266/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7267/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7268/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7269/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7270/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7271/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7272/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7273/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7274/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7275/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7276/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7277/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7278/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7279/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7280/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7281/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7282/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7283/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7284/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7285/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7286/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7287/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7288/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7289/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7290/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7291/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7292/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7293/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7294/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7295/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7296/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7297/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7298/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7299/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7300/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7301/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7302/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7303/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7304/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7305/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7306/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7307/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7308/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7309/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7310/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7311/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7312/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7313/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7314/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7315/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7316/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7317/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7318/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7319/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7320/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7321/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7322/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7323/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7324/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7325/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7326/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7327/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7328/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7329/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7330/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7331/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7332/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7333/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7334/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7335/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7336/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7337/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7338/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7339/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7340/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7341/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7342/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7343/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7344/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7345/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7346/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7347/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7348/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7349/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7350/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7351/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7352/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7353/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7354/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7355/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7356/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7357/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7358/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7359/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7360/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7361/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7362/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7363/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7364/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7365/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7366/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7367/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7368/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7369/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7370/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7371/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7372/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7373/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7374/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7375/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7376/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7377/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7378/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7379/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7380/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7381/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7382/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7383/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7384/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7385/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7386/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7387/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7388/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7389/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7390/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7391/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7392/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7393/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7394/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7395/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7396/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7397/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7398/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7399/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7400/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7401/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7402/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7403/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7404/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7405/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7406/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7407/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7408/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7409/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7410/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7411/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7412/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7413/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7414/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7415/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7416/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7417/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7418/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7419/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7420/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7421/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7422/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7423/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7424/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7425/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7426/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7427/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7428/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7429/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7430/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7431/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7432/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7433/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7434/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7435/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7436/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7437/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7438/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7439/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7440/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7441/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7442/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7443/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7444/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7445/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7446/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7447/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7448/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7449/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7450/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7451/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7452/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7453/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7454/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7455/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7456/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7457/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7458/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7459/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7460/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7461/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7462/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7463/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7464/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7465/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7466/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7467/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7468/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7469/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7470/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7471/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7472/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7473/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7474/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7475/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7476/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7477/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7478/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7479/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7480/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7481/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7482/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7483/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7484/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7485/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7486/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7487/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7488/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7489/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7490/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7491/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7492/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7493/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7494/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7495/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7496/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7497/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7498/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7499/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7500/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7501/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7502/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7503/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7504/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7505/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7506/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7507/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7508/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7509/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7510/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7511/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7512/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7513/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7514/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7515/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7516/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7517/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7518/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7519/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7520/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7521/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7522/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7523/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7524/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7525/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7526/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7527/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7528/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7529/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7530/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7531/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7532/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7533/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7534/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7535/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7536/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7537/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7538/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7539/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7540/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7541/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7542/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7543/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7544/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7545/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7546/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7547/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7548/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7549/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7550/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7551/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7552/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7553/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7554/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7555/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7556/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7557/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7558/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7559/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7560/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7561/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7562/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7563/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7564/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7565/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7566/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7567/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7568/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7569/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7570/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7571/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7572/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7573/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7574/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7575/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7576/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7577/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7578/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7579/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7580/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7581/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7582/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7583/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7584/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7585/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7586/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7587/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7588/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7589/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7590/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7591/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7592/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7593/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7594/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7595/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7596/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7597/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7598/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7599/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7600/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7601/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7602/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7603/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7604/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7605/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7606/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7607/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7608/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7609/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7610/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7611/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7612/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7613/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7614/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7615/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7616/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7617/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7618/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7619/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7620/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7621/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7622/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7623/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7624/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7625/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7626/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7627/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7628/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7629/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7630/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7631/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7632/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7633/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7634/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7635/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7636/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7637/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7638/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7639/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7640/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7641/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7642/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7643/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7644/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7645/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7646/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7647/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7648/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7649/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7650/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7651/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7652/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7653/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7654/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7655/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7656/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7657/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7658/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7659/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7660/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7661/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7662/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7663/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7664/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7665/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7666/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7667/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7668/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7669/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7670/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7671/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7672/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7673/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7674/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7675/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7676/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7677/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7678/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7679/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7680/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7681/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7682/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7683/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7684/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7685/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7686/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7687/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7688/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7689/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7690/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7691/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7692/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7693/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7694/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7695/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7696/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7697/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7698/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7699/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7700/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7701/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7702/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7703/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7704/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7705/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7706/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7707/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7708/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7709/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7710/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7711/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7712/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7713/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7714/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7715/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7716/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7717/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7718/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7719/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7720/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7721/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7722/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7723/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7724/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7725/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7726/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7727/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7728/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7729/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7730/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7731/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7732/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7733/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7734/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7735/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7736/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7737/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7738/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7739/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7740/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7741/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7742/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7743/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7744/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7745/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7746/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7747/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7748/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7749/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7750/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7751/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7752/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7753/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7754/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7755/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7756/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7757/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7758/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7759/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7760/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7761/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7762/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7763/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7764/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7765/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7766/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7767/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7768/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7769/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7770/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7771/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7772/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7773/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7774/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7775/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7776/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7777/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7778/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7779/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7780/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7781/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7782/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7783/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7784/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7785/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7786/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7787/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7788/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7789/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7790/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7791/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7792/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7793/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7794/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7795/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7796/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7797/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7798/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7799/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7800/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7801/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7802/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7803/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7804/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7805/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7806/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7807/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7808/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7809/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7810/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7811/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7812/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7813/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7814/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7815/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7816/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7817/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7818/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7819/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7820/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7821/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7822/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7823/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7824/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7825/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7826/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7827/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7828/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7829/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7830/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7831/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7832/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7833/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7834/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7835/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7836/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7837/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7838/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7839/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7840/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7841/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7842/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7843/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7844/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7845/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7846/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7847/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7848/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7849/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7850/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7851/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7852/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7853/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7854/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7855/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7856/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7857/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7858/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7859/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7860/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7861/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7862/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7863/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7864/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7865/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7866/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7867/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7868/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7869/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7870/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7871/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7872/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7873/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7874/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7875/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7876/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7877/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7878/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7879/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7880/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7881/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7882/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7883/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7884/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7885/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7886/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7887/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7888/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7889/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7890/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7891/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7892/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7893/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7894/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7895/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7896/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7897/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7898/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7899/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7900/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7901/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7902/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7903/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7904/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7905/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7906/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7907/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7908/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7909/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7910/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7911/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7912/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7913/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7914/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7915/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7916/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7917/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7918/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7919/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7920/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7921/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7922/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7923/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7924/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7925/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7926/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7927/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7928/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7929/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7930/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7931/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7932/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7933/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7934/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7935/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7936/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7937/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7938/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7939/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7940/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7941/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7942/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7943/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7944/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7945/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7946/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7947/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7948/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7949/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7950/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7951/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7952/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7953/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7954/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7955/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7956/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7957/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7958/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7959/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7960/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7961/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7962/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7963/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7964/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7965/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7966/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7967/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7968/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7969/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7970/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7971/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7972/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7973/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7974/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7975/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7976/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7977/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7978/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7979/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7980/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7981/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7982/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7983/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7984/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7985/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7986/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7987/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7988/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7989/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7990/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7991/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7992/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7993/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7994/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7995/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7996/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7997/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7998/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 7999/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n",
      "Epoch: 8000/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.4489\n"
     ]
    }
   ],
   "source": [
    "from LogisticRegression import LogisticRegression\n",
    "\n",
    "epochs = 8000\n",
    "alpha = 0.5\n",
    "logistic_reg2 = LogisticRegression(x=train_x_map,y=train_y_ex,val_x=val_x_map,val_y=val_y_ex,epoch=epochs,lr=alpha,scale=2,regularize=\"L2\")\n",
    "theta, loss, val_loss = logistic_reg2.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看精度，损失和F1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 75.00%\n",
      "My F1 Score: 0.7692\n"
     ]
    }
   ],
   "source": [
    "acc = logistic_reg2.test(val_x_map,val_y_ex)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(acc * 100))\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_true=val_y_ex,y_pred=logistic_reg2.predict(val_x_map))\n",
    "print(\"My F1 Score: {:.4f}\".format(f1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用库函数验证"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Accuracy: 70.83%\n",
      "Sklearn Val Loss: 0.4786\n",
      "Sklearn F1 Score: 0.6957\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sk_lr2 = LogisticRegression()\n",
    "sk_lr2.fit(train_x_map,train_y)\n",
    "sk_pred2 = sk_lr2.predict(val_x_map)\n",
    "count2 = np.sum(np.equal(sk_pred2,val_y))\n",
    "sk_acc2 = count2/val_y.shape[0]\n",
    "sk_prob2 = sk_lr2.predict_proba(val_x_map)\n",
    "\n",
    "from LogisticRegression import bce_loss\n",
    "sk_loss2 = bce_loss(sk_prob2[:,1], val_y_ex)\n",
    "sk_f12 = f1_score(y_true=val_y_ex,y_pred=sk_pred2)\n",
    "print(\"Sklearn Accuracy: {:.2f}%\".format(sk_acc2 * 100))\n",
    "print(\"Sklearn Val Loss: {:.4f}\".format(sk_loss2))\n",
    "print(\"Sklearn F1 Score: {:.4f}\".format(sk_f12))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可视化决策边界"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = np.linspace(-1, 1.5, 700)\n",
    "t2 = np.linspace(-1, 1.5, 700)\n",
    "\n",
    "coordinates = np.array([[x, y] for x in t1 for y in t2])\n",
    "\n",
    "mapped_cord_x = feature_mapping(np.array(coordinates), degree=6)  # this is a dataframe\n",
    "prob = logistic_reg2.get_inner_product(mapped_cord_x)\n",
    "sk_prob_coor = sk_lr2.predict_proba(mapped_cord_x)\n",
    "idx1 = np.where(abs(prob[0,:])<5e-3)\n",
    "idx2 = np.where(np.logical_and(sk_prob_coor[:,0] >= 0.495, sk_prob_coor[:,0] <= 0.505))\n",
    "my_bd = coordinates[idx1]\n",
    "sk_bd = coordinates[idx2]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=my_bd[:, 0], y=my_bd[:, 1], s=10, color=\"yellow\", label=\"My Decision Boundary\")\n",
    "ax.scatter(x=sk_bd[:, 0], y=sk_bd[:, 1], s=10, color=\"gray\", label=\"Sklearn Decision Boundary\")\n",
    "ax.scatter(x=positive_data[:, 0], y=positive_data[:, 1], s=10, color=\"red\",label=\"positive\")\n",
    "ax.scatter(x=negative_data[:, 0], y=negative_data[:, 1], s=10, label=\"negative\")\n",
    "ax.set_title('Train Set')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}