{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 逻辑回归\n",
    "### Logistic函数 (Sigmoid)\n",
    "### 为什么Sigmoid函数可以表示二分类概率？详见伯努利分布和指数分布族\n",
    "g 代表一个常用的逻辑函数（logistic function）为S形函数（Sigmoid function），公式为： $$g\\left( z \\right)=\\frac{1}{1+{{e}^{-z}}}$$\n",
    "合起来，我们得到逻辑回归模型的假设函数：\n",
    "$${{h}_{\\theta }}\\left( x \\right)=\\frac{1}{1+{{e}^{-{{\\theta}^{T}}X}}}$$\n",
    "### 损失函数\n",
    "### 关于交叉熵详见Liu II\n",
    "Binary Cross Entropy\n",
    "$$loss=-(y\\log{\\hat{y}}+(1-y)\\log{(1-\\hat{y})})$$\n",
    "$$J(\\theta)=-\\frac{1}{m}\\sum_{i=1}^{m}{(y\\log{h_{\\theta}(x)}-(1-y)\\log{(1-h_{\\theta}(x))})}$$\n",
    "### 梯度下降\n",
    "$$\\theta_{j}=\\theta_{j}-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}{(h_{\\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}}$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from LogisticRegression import sigmoid\n",
    "\n",
    "nums = np.arange(-5, 5, step=0.1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(nums, sigmoid(nums), 'r')\n",
    "ax.set_title(\"Sigmoid Function\")\n",
    "ax.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "加载数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[34.62365962, 78.02469282,  0.        ],\n       [30.28671077, 43.89499752,  0.        ],\n       [35.84740877, 72.90219803,  0.        ],\n       [60.18259939, 86.3085521 ,  1.        ],\n       [79.03273605, 75.34437644,  1.        ],\n       [45.08327748, 56.31637178,  0.        ],\n       [61.10666454, 96.51142588,  1.        ],\n       [75.02474557, 46.55401354,  1.        ],\n       [76.0987867 , 87.42056972,  1.        ],\n       [84.43281996, 43.53339331,  1.        ],\n       [95.86155507, 38.22527806,  0.        ],\n       [75.01365839, 30.60326323,  0.        ],\n       [82.30705337, 76.4819633 ,  1.        ],\n       [69.36458876, 97.71869196,  1.        ],\n       [39.53833914, 76.03681085,  0.        ],\n       [53.97105215, 89.20735014,  1.        ],\n       [69.07014406, 52.74046973,  1.        ],\n       [67.94685548, 46.67857411,  0.        ],\n       [70.66150955, 92.92713789,  1.        ],\n       [76.97878373, 47.57596365,  1.        ],\n       [67.37202755, 42.83843832,  0.        ],\n       [89.67677575, 65.79936593,  1.        ],\n       [50.53478829, 48.85581153,  0.        ],\n       [34.21206098, 44.2095286 ,  0.        ],\n       [77.92409145, 68.97235999,  1.        ],\n       [62.27101367, 69.95445795,  1.        ],\n       [80.19018075, 44.82162893,  1.        ],\n       [93.1143888 , 38.80067034,  0.        ],\n       [61.83020602, 50.25610789,  0.        ],\n       [38.7858038 , 64.99568096,  0.        ],\n       [61.37928945, 72.80788731,  1.        ],\n       [85.40451939, 57.05198398,  1.        ],\n       [52.10797973, 63.12762377,  0.        ],\n       [52.04540477, 69.43286012,  1.        ],\n       [40.23689374, 71.16774802,  0.        ],\n       [54.63510555, 52.21388588,  0.        ],\n       [33.91550011, 98.86943574,  0.        ],\n       [64.17698887, 80.90806059,  1.        ],\n       [74.78925296, 41.57341523,  0.        ],\n       [34.18364003, 75.23772034,  0.        ],\n       [83.90239366, 56.30804622,  1.        ],\n       [51.54772027, 46.85629026,  0.        ],\n       [94.44336777, 65.56892161,  1.        ],\n       [82.36875376, 40.61825516,  0.        ],\n       [51.04775177, 45.82270146,  0.        ],\n       [62.22267576, 52.06099195,  0.        ],\n       [77.19303493, 70.4582    ,  1.        ],\n       [97.77159928, 86.72782233,  1.        ],\n       [62.0730638 , 96.76882412,  1.        ],\n       [91.5649745 , 88.69629255,  1.        ],\n       [79.94481794, 74.16311935,  1.        ],\n       [99.27252693, 60.999031  ,  1.        ],\n       [90.54671411, 43.39060181,  1.        ],\n       [34.52451385, 60.39634246,  0.        ],\n       [50.28649612, 49.80453881,  0.        ],\n       [49.58667722, 59.80895099,  0.        ],\n       [97.64563396, 68.86157272,  1.        ],\n       [32.57720017, 95.59854761,  0.        ],\n       [74.24869137, 69.82457123,  1.        ],\n       [71.79646206, 78.45356225,  1.        ],\n       [75.39561147, 85.75993667,  1.        ],\n       [35.28611282, 47.02051395,  0.        ],\n       [56.2538175 , 39.26147251,  0.        ],\n       [30.05882245, 49.59297387,  0.        ],\n       [44.66826172, 66.45008615,  0.        ],\n       [66.56089447, 41.09209808,  0.        ],\n       [40.45755098, 97.53518549,  1.        ],\n       [49.07256322, 51.88321182,  0.        ],\n       [80.27957401, 92.11606081,  1.        ],\n       [66.74671857, 60.99139403,  1.        ],\n       [32.72283304, 43.30717306,  0.        ],\n       [64.03932042, 78.03168802,  1.        ],\n       [72.34649423, 96.22759297,  1.        ],\n       [60.45788574, 73.0949981 ,  1.        ],\n       [58.84095622, 75.85844831,  1.        ],\n       [99.8278578 , 72.36925193,  1.        ],\n       [47.26426911, 88.475865  ,  1.        ],\n       [50.4581598 , 75.80985953,  1.        ],\n       [60.45555629, 42.50840944,  0.        ],\n       [82.22666158, 42.71987854,  0.        ],\n       [88.91389642, 69.8037889 ,  1.        ],\n       [94.83450672, 45.6943068 ,  1.        ],\n       [67.31925747, 66.58935318,  1.        ],\n       [57.23870632, 59.51428198,  1.        ],\n       [80.366756  , 90.9601479 ,  1.        ],\n       [68.46852179, 85.5943071 ,  1.        ],\n       [42.07545454, 78.844786  ,  0.        ],\n       [75.47770201, 90.424539  ,  1.        ],\n       [78.63542435, 96.64742717,  1.        ],\n       [52.34800399, 60.76950526,  0.        ],\n       [94.09433113, 77.15910509,  1.        ],\n       [90.44855097, 87.50879176,  1.        ],\n       [55.48216114, 35.57070347,  0.        ],\n       [74.49269242, 84.84513685,  1.        ],\n       [89.84580671, 45.35828361,  1.        ],\n       [83.48916274, 48.3802858 ,  1.        ],\n       [42.26170081, 87.10385094,  1.        ],\n       [99.31500881, 68.77540947,  1.        ],\n       [55.34001756, 64.93193801,  1.        ],\n       [74.775893  , 89.5298129 ,  1.        ]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(fname='ex2data1.txt',delimiter=\",\")\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看数据集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "positive_data_idx= np.where(data[:,2]==1)\n",
    "positive_data = data[positive_data_idx]\n",
    "negative_data_idx= np.where(data[:, 2] == 0)\n",
    "negative_data = data[negative_data_idx]\n",
    "ax.scatter(x=positive_data[:, 0], y=positive_data[:, 1], s=10, color=\"red\",label=\"positive\")\n",
    "ax.scatter(x=negative_data[:, 0], y=negative_data[:, 1], s=10, label=\"negative\")\n",
    "ax.set_title(\"Dataset\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "划分训练集、验证集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y = train_test_split(data[:, :-1], data[:, -1], test_size=0.2)\n",
    "# train_x, val_x, train_y, val_y = data[:, :-1], data[:, :-1], data[:, -1], data[:, -1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=train_x[:,0], y=train_x[:,1], s=10, label=\"Train\")\n",
    "ax.scatter(x=val_x[:,0], y=val_x[:,1], s=10, color=\"red\", label=\"Validation\")\n",
    "ax.set_title('Dataset for Train and Validation')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看训练集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_train_data = train_x[np.where(train_y[:]==1)]\n",
    "negative_train_data = train_x[np.where(train_y[:]==0)]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=positive_train_data[:,0], y=positive_train_data[:,1], s=10, label=\"Positive\")\n",
    "ax.scatter(x=negative_train_data[:,0], y=negative_train_data[:,1], s=10, label=\"Negative\")\n",
    "ax.set_title('Train Set')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看验证集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_val_data = val_x[np.where(val_y[:]==1)]\n",
    "negative_val_data = val_x[np.where(val_y[:]==0)]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=positive_val_data[:,0], y=positive_val_data[:,1], s=10, label=\"Positive\")\n",
    "ax.scatter(x=negative_val_data[:,0], y=negative_val_data[:,1], s=10, label=\"Negative\")\n",
    "ax.legend(loc=2)\n",
    "ax.set_title('Validation Set')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "整理维度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(20, 1)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_ex = np.expand_dims(train_y,axis=1)\n",
    "val_y_ex = np.expand_dims(val_y,axis=1)\n",
    "val_y_ex.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "进行逻辑回归，查看参数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '，' (U+FF0C) (206114234.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn [1], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    进行逻辑回归，查看参数\u001B[0m\n\u001B[1;37m          ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid character '，' (U+FF0C)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5000, Train Loss: 0.4159\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4149\n",
      "Epoch: 2/5000, Train Loss: 0.4149\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4138\n",
      "Epoch: 3/5000, Train Loss: 0.4139\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4128\n",
      "Epoch: 4/5000, Train Loss: 0.4129\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4118\n",
      "Epoch: 5/5000, Train Loss: 0.4119\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4108\n",
      "Epoch: 6/5000, Train Loss: 0.4109\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4097\n",
      "Epoch: 7/5000, Train Loss: 0.4099\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4087\n",
      "Epoch: 8/5000, Train Loss: 0.4090\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4077\n",
      "Epoch: 9/5000, Train Loss: 0.4080\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4067\n",
      "Epoch: 10/5000, Train Loss: 0.4070\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4057\n",
      "Epoch: 11/5000, Train Loss: 0.4061\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4047\n",
      "Epoch: 12/5000, Train Loss: 0.4051\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4038\n",
      "Epoch: 13/5000, Train Loss: 0.4042\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4028\n",
      "Epoch: 14/5000, Train Loss: 0.4032\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4018\n",
      "Epoch: 15/5000, Train Loss: 0.4023\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.4008\n",
      "Epoch: 16/5000, Train Loss: 0.4013\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3999\n",
      "Epoch: 17/5000, Train Loss: 0.4004\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3989\n",
      "Epoch: 18/5000, Train Loss: 0.3995\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3979\n",
      "Epoch: 19/5000, Train Loss: 0.3986\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3970\n",
      "Epoch: 20/5000, Train Loss: 0.3976\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3960\n",
      "Epoch: 21/5000, Train Loss: 0.3967\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3951\n",
      "Epoch: 22/5000, Train Loss: 0.3958\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3942\n",
      "Epoch: 23/5000, Train Loss: 0.3949\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3932\n",
      "Epoch: 24/5000, Train Loss: 0.3940\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3923\n",
      "Epoch: 25/5000, Train Loss: 0.3931\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3914\n",
      "Epoch: 26/5000, Train Loss: 0.3922\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3905\n",
      "Epoch: 27/5000, Train Loss: 0.3913\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3895\n",
      "Epoch: 28/5000, Train Loss: 0.3905\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3886\n",
      "Epoch: 29/5000, Train Loss: 0.3896\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3877\n",
      "Epoch: 30/5000, Train Loss: 0.3887\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3868\n",
      "Epoch: 31/5000, Train Loss: 0.3878\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3859\n",
      "Epoch: 32/5000, Train Loss: 0.3870\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3850\n",
      "Epoch: 33/5000, Train Loss: 0.3861\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3841\n",
      "Epoch: 34/5000, Train Loss: 0.3853\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3832\n",
      "Epoch: 35/5000, Train Loss: 0.3844\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3824\n",
      "Epoch: 36/5000, Train Loss: 0.3836\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3815\n",
      "Epoch: 37/5000, Train Loss: 0.3827\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3806\n",
      "Epoch: 38/5000, Train Loss: 0.3819\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3797\n",
      "Epoch: 39/5000, Train Loss: 0.3811\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3789\n",
      "Epoch: 40/5000, Train Loss: 0.3802\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3780\n",
      "Epoch: 41/5000, Train Loss: 0.3794\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3771\n",
      "Epoch: 42/5000, Train Loss: 0.3786\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3763\n",
      "Epoch: 43/5000, Train Loss: 0.3778\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3754\n",
      "Epoch: 44/5000, Train Loss: 0.3770\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3746\n",
      "Epoch: 45/5000, Train Loss: 0.3762\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3737\n",
      "Epoch: 46/5000, Train Loss: 0.3753\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3729\n",
      "Epoch: 47/5000, Train Loss: 0.3745\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3721\n",
      "Epoch: 48/5000, Train Loss: 0.3738\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3712\n",
      "Epoch: 49/5000, Train Loss: 0.3730\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3704\n",
      "Epoch: 50/5000, Train Loss: 0.3722\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3696\n",
      "Epoch: 51/5000, Train Loss: 0.3714\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3688\n",
      "Epoch: 52/5000, Train Loss: 0.3706\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3680\n",
      "Epoch: 53/5000, Train Loss: 0.3698\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3671\n",
      "Epoch: 54/5000, Train Loss: 0.3691\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3663\n",
      "Epoch: 55/5000, Train Loss: 0.3683\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3655\n",
      "Epoch: 56/5000, Train Loss: 0.3675\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3647\n",
      "Epoch: 57/5000, Train Loss: 0.3668\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3639\n",
      "Epoch: 58/5000, Train Loss: 0.3660\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3631\n",
      "Epoch: 59/5000, Train Loss: 0.3652\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3623\n",
      "Epoch: 60/5000, Train Loss: 0.3645\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3616\n",
      "Epoch: 61/5000, Train Loss: 0.3638\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3608\n",
      "Epoch: 62/5000, Train Loss: 0.3630\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3600\n",
      "Epoch: 63/5000, Train Loss: 0.3623\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3592\n",
      "Epoch: 64/5000, Train Loss: 0.3615\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3585\n",
      "Epoch: 65/5000, Train Loss: 0.3608\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3577\n",
      "Epoch: 66/5000, Train Loss: 0.3601\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3569\n",
      "Epoch: 67/5000, Train Loss: 0.3594\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3562\n",
      "Epoch: 68/5000, Train Loss: 0.3586\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3554\n",
      "Epoch: 69/5000, Train Loss: 0.3579\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3546\n",
      "Epoch: 70/5000, Train Loss: 0.3572\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3539\n",
      "Epoch: 71/5000, Train Loss: 0.3565\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3531\n",
      "Epoch: 72/5000, Train Loss: 0.3558\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3524\n",
      "Epoch: 73/5000, Train Loss: 0.3551\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3517\n",
      "Epoch: 74/5000, Train Loss: 0.3544\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3509\n",
      "Epoch: 75/5000, Train Loss: 0.3537\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3502\n",
      "Epoch: 76/5000, Train Loss: 0.3530\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3495\n",
      "Epoch: 77/5000, Train Loss: 0.3523\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3487\n",
      "Epoch: 78/5000, Train Loss: 0.3516\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3480\n",
      "Epoch: 79/5000, Train Loss: 0.3509\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3473\n",
      "Epoch: 80/5000, Train Loss: 0.3503\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3466\n",
      "Epoch: 81/5000, Train Loss: 0.3496\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3459\n",
      "Epoch: 82/5000, Train Loss: 0.3489\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3451\n",
      "Epoch: 83/5000, Train Loss: 0.3482\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3444\n",
      "Epoch: 84/5000, Train Loss: 0.3476\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3437\n",
      "Epoch: 85/5000, Train Loss: 0.3469\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3430\n",
      "Epoch: 86/5000, Train Loss: 0.3462\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3423\n",
      "Epoch: 87/5000, Train Loss: 0.3456\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3416\n",
      "Epoch: 88/5000, Train Loss: 0.3449\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3409\n",
      "Epoch: 89/5000, Train Loss: 0.3443\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3403\n",
      "Epoch: 90/5000, Train Loss: 0.3436\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3396\n",
      "Epoch: 91/5000, Train Loss: 0.3430\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3389\n",
      "Epoch: 92/5000, Train Loss: 0.3424\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3382\n",
      "Epoch: 93/5000, Train Loss: 0.3417\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3375\n",
      "Epoch: 94/5000, Train Loss: 0.3411\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3369\n",
      "Epoch: 95/5000, Train Loss: 0.3405\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3362\n",
      "Epoch: 96/5000, Train Loss: 0.3398\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3355\n",
      "Epoch: 97/5000, Train Loss: 0.3392\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3349\n",
      "Epoch: 98/5000, Train Loss: 0.3386\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3342\n",
      "Epoch: 99/5000, Train Loss: 0.3380\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3335\n",
      "Epoch: 100/5000, Train Loss: 0.3373\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3329\n",
      "Epoch: 101/5000, Train Loss: 0.3367\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3322\n",
      "Epoch: 102/5000, Train Loss: 0.3361\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3316\n",
      "Epoch: 103/5000, Train Loss: 0.3355\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3309\n",
      "Epoch: 104/5000, Train Loss: 0.3349\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3303\n",
      "Epoch: 105/5000, Train Loss: 0.3343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3296\n",
      "Epoch: 106/5000, Train Loss: 0.3337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3290\n",
      "Epoch: 107/5000, Train Loss: 0.3331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3284\n",
      "Epoch: 108/5000, Train Loss: 0.3325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3277\n",
      "Epoch: 109/5000, Train Loss: 0.3319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3271\n",
      "Epoch: 110/5000, Train Loss: 0.3313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3265\n",
      "Epoch: 111/5000, Train Loss: 0.3307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3258\n",
      "Epoch: 112/5000, Train Loss: 0.3302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3252\n",
      "Epoch: 113/5000, Train Loss: 0.3296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3246\n",
      "Epoch: 114/5000, Train Loss: 0.3290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3240\n",
      "Epoch: 115/5000, Train Loss: 0.3284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3234\n",
      "Epoch: 116/5000, Train Loss: 0.3279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3228\n",
      "Epoch: 117/5000, Train Loss: 0.3273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3221\n",
      "Epoch: 118/5000, Train Loss: 0.3267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3215\n",
      "Epoch: 119/5000, Train Loss: 0.3262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3209\n",
      "Epoch: 120/5000, Train Loss: 0.3256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3203\n",
      "Epoch: 121/5000, Train Loss: 0.3250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3197\n",
      "Epoch: 122/5000, Train Loss: 0.3245\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3191\n",
      "Epoch: 123/5000, Train Loss: 0.3239\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3185\n",
      "Epoch: 124/5000, Train Loss: 0.3234\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3180\n",
      "Epoch: 125/5000, Train Loss: 0.3228\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3174\n",
      "Epoch: 126/5000, Train Loss: 0.3223\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3168\n",
      "Epoch: 127/5000, Train Loss: 0.3218\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3162\n",
      "Epoch: 128/5000, Train Loss: 0.3212\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3156\n",
      "Epoch: 129/5000, Train Loss: 0.3207\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3150\n",
      "Epoch: 130/5000, Train Loss: 0.3201\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3145\n",
      "Epoch: 131/5000, Train Loss: 0.3196\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3139\n",
      "Epoch: 132/5000, Train Loss: 0.3191\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3133\n",
      "Epoch: 133/5000, Train Loss: 0.3186\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3127\n",
      "Epoch: 134/5000, Train Loss: 0.3180\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3122\n",
      "Epoch: 135/5000, Train Loss: 0.3175\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3116\n",
      "Epoch: 136/5000, Train Loss: 0.3170\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3111\n",
      "Epoch: 137/5000, Train Loss: 0.3165\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3105\n",
      "Epoch: 138/5000, Train Loss: 0.3160\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3099\n",
      "Epoch: 139/5000, Train Loss: 0.3154\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3094\n",
      "Epoch: 140/5000, Train Loss: 0.3149\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3088\n",
      "Epoch: 141/5000, Train Loss: 0.3144\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3083\n",
      "Epoch: 142/5000, Train Loss: 0.3139\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3077\n",
      "Epoch: 143/5000, Train Loss: 0.3134\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3072\n",
      "Epoch: 144/5000, Train Loss: 0.3129\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3066\n",
      "Epoch: 145/5000, Train Loss: 0.3124\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3061\n",
      "Epoch: 146/5000, Train Loss: 0.3119\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3056\n",
      "Epoch: 147/5000, Train Loss: 0.3114\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3050\n",
      "Epoch: 148/5000, Train Loss: 0.3109\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3045\n",
      "Epoch: 149/5000, Train Loss: 0.3104\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3040\n",
      "Epoch: 150/5000, Train Loss: 0.3099\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3034\n",
      "Epoch: 151/5000, Train Loss: 0.3095\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3029\n",
      "Epoch: 152/5000, Train Loss: 0.3090\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3024\n",
      "Epoch: 153/5000, Train Loss: 0.3085\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3018\n",
      "Epoch: 154/5000, Train Loss: 0.3080\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3013\n",
      "Epoch: 155/5000, Train Loss: 0.3075\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3008\n",
      "Epoch: 156/5000, Train Loss: 0.3071\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.3003\n",
      "Epoch: 157/5000, Train Loss: 0.3066\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2998\n",
      "Epoch: 158/5000, Train Loss: 0.3061\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2993\n",
      "Epoch: 159/5000, Train Loss: 0.3057\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2988\n",
      "Epoch: 160/5000, Train Loss: 0.3052\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2982\n",
      "Epoch: 161/5000, Train Loss: 0.3047\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2977\n",
      "Epoch: 162/5000, Train Loss: 0.3043\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2972\n",
      "Epoch: 163/5000, Train Loss: 0.3038\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2967\n",
      "Epoch: 164/5000, Train Loss: 0.3033\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2962\n",
      "Epoch: 165/5000, Train Loss: 0.3029\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2957\n",
      "Epoch: 166/5000, Train Loss: 0.3024\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2952\n",
      "Epoch: 167/5000, Train Loss: 0.3020\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2947\n",
      "Epoch: 168/5000, Train Loss: 0.3015\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2942\n",
      "Epoch: 169/5000, Train Loss: 0.3011\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2938\n",
      "Epoch: 170/5000, Train Loss: 0.3006\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2933\n",
      "Epoch: 171/5000, Train Loss: 0.3002\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2928\n",
      "Epoch: 172/5000, Train Loss: 0.2997\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2923\n",
      "Epoch: 173/5000, Train Loss: 0.2993\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2918\n",
      "Epoch: 174/5000, Train Loss: 0.2989\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2913\n",
      "Epoch: 175/5000, Train Loss: 0.2984\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2909\n",
      "Epoch: 176/5000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2904\n",
      "Epoch: 177/5000, Train Loss: 0.2976\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2899\n",
      "Epoch: 178/5000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2894\n",
      "Epoch: 179/5000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2890\n",
      "Epoch: 180/5000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2885\n",
      "Epoch: 181/5000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2880\n",
      "Epoch: 182/5000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2876\n",
      "Epoch: 183/5000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2871\n",
      "Epoch: 184/5000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2866\n",
      "Epoch: 185/5000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2862\n",
      "Epoch: 186/5000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2857\n",
      "Epoch: 187/5000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2852\n",
      "Epoch: 188/5000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2848\n",
      "Epoch: 189/5000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2843\n",
      "Epoch: 190/5000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2839\n",
      "Epoch: 191/5000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2834\n",
      "Epoch: 192/5000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2830\n",
      "Epoch: 193/5000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2825\n",
      "Epoch: 194/5000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2821\n",
      "Epoch: 195/5000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2817\n",
      "Epoch: 196/5000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2812\n",
      "Epoch: 197/5000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2808\n",
      "Epoch: 198/5000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2803\n",
      "Epoch: 199/5000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2799\n",
      "Epoch: 200/5000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2795\n",
      "Epoch: 201/5000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2790\n",
      "Epoch: 202/5000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2786\n",
      "Epoch: 203/5000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2782\n",
      "Epoch: 204/5000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2777\n",
      "Epoch: 205/5000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2773\n",
      "Epoch: 206/5000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2769\n",
      "Epoch: 207/5000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2765\n",
      "Epoch: 208/5000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2760\n",
      "Epoch: 209/5000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2756\n",
      "Epoch: 210/5000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2752\n",
      "Epoch: 211/5000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2748\n",
      "Epoch: 212/5000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2744\n",
      "Epoch: 213/5000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2740\n",
      "Epoch: 214/5000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2735\n",
      "Epoch: 215/5000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2731\n",
      "Epoch: 216/5000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2727\n",
      "Epoch: 217/5000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2723\n",
      "Epoch: 218/5000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2719\n",
      "Epoch: 219/5000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2715\n",
      "Epoch: 220/5000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2711\n",
      "Epoch: 221/5000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2707\n",
      "Epoch: 222/5000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2703\n",
      "Epoch: 223/5000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2699\n",
      "Epoch: 224/5000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2695\n",
      "Epoch: 225/5000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2691\n",
      "Epoch: 226/5000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2687\n",
      "Epoch: 227/5000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2683\n",
      "Epoch: 228/5000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2679\n",
      "Epoch: 229/5000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2675\n",
      "Epoch: 230/5000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2672\n",
      "Epoch: 231/5000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2668\n",
      "Epoch: 232/5000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2664\n",
      "Epoch: 233/5000, Train Loss: 0.2761\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2660\n",
      "Epoch: 234/5000, Train Loss: 0.2757\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2656\n",
      "Epoch: 235/5000, Train Loss: 0.2754\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2652\n",
      "Epoch: 236/5000, Train Loss: 0.2750\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2649\n",
      "Epoch: 237/5000, Train Loss: 0.2747\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2645\n",
      "Epoch: 238/5000, Train Loss: 0.2744\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2641\n",
      "Epoch: 239/5000, Train Loss: 0.2740\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2637\n",
      "Epoch: 240/5000, Train Loss: 0.2737\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2633\n",
      "Epoch: 241/5000, Train Loss: 0.2734\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2630\n",
      "Epoch: 242/5000, Train Loss: 0.2730\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2626\n",
      "Epoch: 243/5000, Train Loss: 0.2727\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2622\n",
      "Epoch: 244/5000, Train Loss: 0.2724\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2619\n",
      "Epoch: 245/5000, Train Loss: 0.2721\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2615\n",
      "Epoch: 246/5000, Train Loss: 0.2717\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2611\n",
      "Epoch: 247/5000, Train Loss: 0.2714\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2608\n",
      "Epoch: 248/5000, Train Loss: 0.2711\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2604\n",
      "Epoch: 249/5000, Train Loss: 0.2708\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2600\n",
      "Epoch: 250/5000, Train Loss: 0.2705\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2597\n",
      "Epoch: 251/5000, Train Loss: 0.2701\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2593\n",
      "Epoch: 252/5000, Train Loss: 0.2698\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2589\n",
      "Epoch: 253/5000, Train Loss: 0.2695\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2586\n",
      "Epoch: 254/5000, Train Loss: 0.2692\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2582\n",
      "Epoch: 255/5000, Train Loss: 0.2689\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2579\n",
      "Epoch: 256/5000, Train Loss: 0.2686\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2575\n",
      "Epoch: 257/5000, Train Loss: 0.2683\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2572\n",
      "Epoch: 258/5000, Train Loss: 0.2679\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2568\n",
      "Epoch: 259/5000, Train Loss: 0.2676\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2565\n",
      "Epoch: 260/5000, Train Loss: 0.2673\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2561\n",
      "Epoch: 261/5000, Train Loss: 0.2670\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2558\n",
      "Epoch: 262/5000, Train Loss: 0.2667\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2554\n",
      "Epoch: 263/5000, Train Loss: 0.2664\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2551\n",
      "Epoch: 264/5000, Train Loss: 0.2661\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2547\n",
      "Epoch: 265/5000, Train Loss: 0.2658\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2544\n",
      "Epoch: 266/5000, Train Loss: 0.2655\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2540\n",
      "Epoch: 267/5000, Train Loss: 0.2652\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2537\n",
      "Epoch: 268/5000, Train Loss: 0.2649\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2534\n",
      "Epoch: 269/5000, Train Loss: 0.2646\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2530\n",
      "Epoch: 270/5000, Train Loss: 0.2643\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2527\n",
      "Epoch: 271/5000, Train Loss: 0.2640\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2524\n",
      "Epoch: 272/5000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2520\n",
      "Epoch: 273/5000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2517\n",
      "Epoch: 274/5000, Train Loss: 0.2631\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2513\n",
      "Epoch: 275/5000, Train Loss: 0.2629\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 276/5000, Train Loss: 0.2626\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 277/5000, Train Loss: 0.2623\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 278/5000, Train Loss: 0.2620\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 279/5000, Train Loss: 0.2617\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 280/5000, Train Loss: 0.2614\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 281/5000, Train Loss: 0.2611\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 282/5000, Train Loss: 0.2609\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 283/5000, Train Loss: 0.2606\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 284/5000, Train Loss: 0.2603\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 285/5000, Train Loss: 0.2600\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 286/5000, Train Loss: 0.2597\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 287/5000, Train Loss: 0.2595\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 288/5000, Train Loss: 0.2592\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 289/5000, Train Loss: 0.2589\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 290/5000, Train Loss: 0.2586\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 291/5000, Train Loss: 0.2584\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 292/5000, Train Loss: 0.2581\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 293/5000, Train Loss: 0.2578\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 294/5000, Train Loss: 0.2576\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 295/5000, Train Loss: 0.2573\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 296/5000, Train Loss: 0.2570\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 297/5000, Train Loss: 0.2567\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 298/5000, Train Loss: 0.2565\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 299/5000, Train Loss: 0.2562\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2434\n",
      "Epoch: 300/5000, Train Loss: 0.2560\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2431\n",
      "Epoch: 301/5000, Train Loss: 0.2557\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2428\n",
      "Epoch: 302/5000, Train Loss: 0.2554\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2425\n",
      "Epoch: 303/5000, Train Loss: 0.2552\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2422\n",
      "Epoch: 304/5000, Train Loss: 0.2549\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2419\n",
      "Epoch: 305/5000, Train Loss: 0.2546\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2416\n",
      "Epoch: 306/5000, Train Loss: 0.2544\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2413\n",
      "Epoch: 307/5000, Train Loss: 0.2541\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2410\n",
      "Epoch: 308/5000, Train Loss: 0.2539\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2407\n",
      "Epoch: 309/5000, Train Loss: 0.2536\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2404\n",
      "Epoch: 310/5000, Train Loss: 0.2534\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2401\n",
      "Epoch: 311/5000, Train Loss: 0.2531\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2398\n",
      "Epoch: 312/5000, Train Loss: 0.2529\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2395\n",
      "Epoch: 313/5000, Train Loss: 0.2526\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2392\n",
      "Epoch: 314/5000, Train Loss: 0.2524\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2389\n",
      "Epoch: 315/5000, Train Loss: 0.2521\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2386\n",
      "Epoch: 316/5000, Train Loss: 0.2519\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2383\n",
      "Epoch: 317/5000, Train Loss: 0.2516\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2380\n",
      "Epoch: 318/5000, Train Loss: 0.2514\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2377\n",
      "Epoch: 319/5000, Train Loss: 0.2511\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2374\n",
      "Epoch: 320/5000, Train Loss: 0.2509\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2372\n",
      "Epoch: 321/5000, Train Loss: 0.2506\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2369\n",
      "Epoch: 322/5000, Train Loss: 0.2504\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2366\n",
      "Epoch: 323/5000, Train Loss: 0.2501\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2363\n",
      "Epoch: 324/5000, Train Loss: 0.2499\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2360\n",
      "Epoch: 325/5000, Train Loss: 0.2496\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2357\n",
      "Epoch: 326/5000, Train Loss: 0.2494\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2355\n",
      "Epoch: 327/5000, Train Loss: 0.2492\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2352\n",
      "Epoch: 328/5000, Train Loss: 0.2489\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2349\n",
      "Epoch: 329/5000, Train Loss: 0.2487\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2346\n",
      "Epoch: 330/5000, Train Loss: 0.2485\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2343\n",
      "Epoch: 331/5000, Train Loss: 0.2482\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2341\n",
      "Epoch: 332/5000, Train Loss: 0.2480\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2338\n",
      "Epoch: 333/5000, Train Loss: 0.2477\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2335\n",
      "Epoch: 334/5000, Train Loss: 0.2475\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2332\n",
      "Epoch: 335/5000, Train Loss: 0.2473\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2330\n",
      "Epoch: 336/5000, Train Loss: 0.2470\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2327\n",
      "Epoch: 337/5000, Train Loss: 0.2468\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2324\n",
      "Epoch: 338/5000, Train Loss: 0.2466\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2321\n",
      "Epoch: 339/5000, Train Loss: 0.2464\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2319\n",
      "Epoch: 340/5000, Train Loss: 0.2461\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2316\n",
      "Epoch: 341/5000, Train Loss: 0.2459\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2313\n",
      "Epoch: 342/5000, Train Loss: 0.2457\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2311\n",
      "Epoch: 343/5000, Train Loss: 0.2454\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2308\n",
      "Epoch: 344/5000, Train Loss: 0.2452\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2305\n",
      "Epoch: 345/5000, Train Loss: 0.2450\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2303\n",
      "Epoch: 346/5000, Train Loss: 0.2448\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2300\n",
      "Epoch: 347/5000, Train Loss: 0.2445\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2297\n",
      "Epoch: 348/5000, Train Loss: 0.2443\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2295\n",
      "Epoch: 349/5000, Train Loss: 0.2441\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2292\n",
      "Epoch: 350/5000, Train Loss: 0.2439\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2289\n",
      "Epoch: 351/5000, Train Loss: 0.2437\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2287\n",
      "Epoch: 352/5000, Train Loss: 0.2434\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2284\n",
      "Epoch: 353/5000, Train Loss: 0.2432\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2282\n",
      "Epoch: 354/5000, Train Loss: 0.2430\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2279\n",
      "Epoch: 355/5000, Train Loss: 0.2428\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2277\n",
      "Epoch: 356/5000, Train Loss: 0.2426\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2274\n",
      "Epoch: 357/5000, Train Loss: 0.2423\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2271\n",
      "Epoch: 358/5000, Train Loss: 0.2421\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2269\n",
      "Epoch: 359/5000, Train Loss: 0.2419\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2266\n",
      "Epoch: 360/5000, Train Loss: 0.2417\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2264\n",
      "Epoch: 361/5000, Train Loss: 0.2415\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2261\n",
      "Epoch: 362/5000, Train Loss: 0.2413\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2259\n",
      "Epoch: 363/5000, Train Loss: 0.2411\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2256\n",
      "Epoch: 364/5000, Train Loss: 0.2409\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2254\n",
      "Epoch: 365/5000, Train Loss: 0.2406\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2251\n",
      "Epoch: 366/5000, Train Loss: 0.2404\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2249\n",
      "Epoch: 367/5000, Train Loss: 0.2402\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2246\n",
      "Epoch: 368/5000, Train Loss: 0.2400\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2244\n",
      "Epoch: 369/5000, Train Loss: 0.2398\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2241\n",
      "Epoch: 370/5000, Train Loss: 0.2396\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2239\n",
      "Epoch: 371/5000, Train Loss: 0.2394\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2236\n",
      "Epoch: 372/5000, Train Loss: 0.2392\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2234\n",
      "Epoch: 373/5000, Train Loss: 0.2390\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2231\n",
      "Epoch: 374/5000, Train Loss: 0.2388\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2229\n",
      "Epoch: 375/5000, Train Loss: 0.2386\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2227\n",
      "Epoch: 376/5000, Train Loss: 0.2384\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2224\n",
      "Epoch: 377/5000, Train Loss: 0.2382\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2222\n",
      "Epoch: 378/5000, Train Loss: 0.2380\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2219\n",
      "Epoch: 379/5000, Train Loss: 0.2378\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2217\n",
      "Epoch: 380/5000, Train Loss: 0.2376\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2214\n",
      "Epoch: 381/5000, Train Loss: 0.2374\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2212\n",
      "Epoch: 382/5000, Train Loss: 0.2372\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2210\n",
      "Epoch: 383/5000, Train Loss: 0.2370\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2207\n",
      "Epoch: 384/5000, Train Loss: 0.2368\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2205\n",
      "Epoch: 385/5000, Train Loss: 0.2366\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2203\n",
      "Epoch: 386/5000, Train Loss: 0.2364\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2200\n",
      "Epoch: 387/5000, Train Loss: 0.2362\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2198\n",
      "Epoch: 388/5000, Train Loss: 0.2360\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2196\n",
      "Epoch: 389/5000, Train Loss: 0.2358\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2193\n",
      "Epoch: 390/5000, Train Loss: 0.2356\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2191\n",
      "Epoch: 391/5000, Train Loss: 0.2354\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2189\n",
      "Epoch: 392/5000, Train Loss: 0.2352\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2186\n",
      "Epoch: 393/5000, Train Loss: 0.2350\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2184\n",
      "Epoch: 394/5000, Train Loss: 0.2348\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2182\n",
      "Epoch: 395/5000, Train Loss: 0.2346\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2179\n",
      "Epoch: 396/5000, Train Loss: 0.2344\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2177\n",
      "Epoch: 397/5000, Train Loss: 0.2343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2175\n",
      "Epoch: 398/5000, Train Loss: 0.2341\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2172\n",
      "Epoch: 399/5000, Train Loss: 0.2339\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2170\n",
      "Epoch: 400/5000, Train Loss: 0.2337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2168\n",
      "Epoch: 401/5000, Train Loss: 0.2335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2166\n",
      "Epoch: 402/5000, Train Loss: 0.2333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2163\n",
      "Epoch: 403/5000, Train Loss: 0.2331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2161\n",
      "Epoch: 404/5000, Train Loss: 0.2329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2159\n",
      "Epoch: 405/5000, Train Loss: 0.2328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2157\n",
      "Epoch: 406/5000, Train Loss: 0.2326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2154\n",
      "Epoch: 407/5000, Train Loss: 0.2324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2152\n",
      "Epoch: 408/5000, Train Loss: 0.2322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2150\n",
      "Epoch: 409/5000, Train Loss: 0.2320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2148\n",
      "Epoch: 410/5000, Train Loss: 0.2318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2146\n",
      "Epoch: 411/5000, Train Loss: 0.2317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2143\n",
      "Epoch: 412/5000, Train Loss: 0.2315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2141\n",
      "Epoch: 413/5000, Train Loss: 0.2313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2139\n",
      "Epoch: 414/5000, Train Loss: 0.2311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2137\n",
      "Epoch: 415/5000, Train Loss: 0.2309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2135\n",
      "Epoch: 416/5000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2132\n",
      "Epoch: 417/5000, Train Loss: 0.2306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2130\n",
      "Epoch: 418/5000, Train Loss: 0.2304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2128\n",
      "Epoch: 419/5000, Train Loss: 0.2302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2126\n",
      "Epoch: 420/5000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2124\n",
      "Epoch: 421/5000, Train Loss: 0.2299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2122\n",
      "Epoch: 422/5000, Train Loss: 0.2297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2120\n",
      "Epoch: 423/5000, Train Loss: 0.2295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2117\n",
      "Epoch: 424/5000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2115\n",
      "Epoch: 425/5000, Train Loss: 0.2292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2113\n",
      "Epoch: 426/5000, Train Loss: 0.2290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2111\n",
      "Epoch: 427/5000, Train Loss: 0.2288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2109\n",
      "Epoch: 428/5000, Train Loss: 0.2287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2107\n",
      "Epoch: 429/5000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2105\n",
      "Epoch: 430/5000, Train Loss: 0.2283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2103\n",
      "Epoch: 431/5000, Train Loss: 0.2281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2101\n",
      "Epoch: 432/5000, Train Loss: 0.2280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2099\n",
      "Epoch: 433/5000, Train Loss: 0.2278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2096\n",
      "Epoch: 434/5000, Train Loss: 0.2276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2094\n",
      "Epoch: 435/5000, Train Loss: 0.2275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2092\n",
      "Epoch: 436/5000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2090\n",
      "Epoch: 437/5000, Train Loss: 0.2271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2088\n",
      "Epoch: 438/5000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2086\n",
      "Epoch: 439/5000, Train Loss: 0.2268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2084\n",
      "Epoch: 440/5000, Train Loss: 0.2266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2082\n",
      "Epoch: 441/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2080\n",
      "Epoch: 442/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2078\n",
      "Epoch: 443/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2076\n",
      "Epoch: 444/5000, Train Loss: 0.2260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2074\n",
      "Epoch: 445/5000, Train Loss: 0.2258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2072\n",
      "Epoch: 446/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2070\n",
      "Epoch: 447/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2068\n",
      "Epoch: 448/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2066\n",
      "Epoch: 449/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2064\n",
      "Epoch: 450/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2062\n",
      "Epoch: 451/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2060\n",
      "Epoch: 452/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2058\n",
      "Epoch: 453/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2056\n",
      "Epoch: 454/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2054\n",
      "Epoch: 455/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2052\n",
      "Epoch: 456/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2050\n",
      "Epoch: 457/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2048\n",
      "Epoch: 458/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2046\n",
      "Epoch: 459/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2044\n",
      "Epoch: 460/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2042\n",
      "Epoch: 461/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2041\n",
      "Epoch: 462/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2039\n",
      "Epoch: 463/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2037\n",
      "Epoch: 464/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2035\n",
      "Epoch: 465/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2033\n",
      "Epoch: 466/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2031\n",
      "Epoch: 467/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2029\n",
      "Epoch: 468/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2027\n",
      "Epoch: 469/5000, Train Loss: 0.2220\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2025\n",
      "Epoch: 470/5000, Train Loss: 0.2219\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2023\n",
      "Epoch: 471/5000, Train Loss: 0.2217\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2021\n",
      "Epoch: 472/5000, Train Loss: 0.2216\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2020\n",
      "Epoch: 473/5000, Train Loss: 0.2214\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2018\n",
      "Epoch: 474/5000, Train Loss: 0.2213\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2016\n",
      "Epoch: 475/5000, Train Loss: 0.2211\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2014\n",
      "Epoch: 476/5000, Train Loss: 0.2210\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2012\n",
      "Epoch: 477/5000, Train Loss: 0.2208\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2010\n",
      "Epoch: 478/5000, Train Loss: 0.2207\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2008\n",
      "Epoch: 479/5000, Train Loss: 0.2205\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2007\n",
      "Epoch: 480/5000, Train Loss: 0.2204\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2005\n",
      "Epoch: 481/5000, Train Loss: 0.2202\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2003\n",
      "Epoch: 482/5000, Train Loss: 0.2201\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.2001\n",
      "Epoch: 483/5000, Train Loss: 0.2199\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1999\n",
      "Epoch: 484/5000, Train Loss: 0.2198\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1997\n",
      "Epoch: 485/5000, Train Loss: 0.2196\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1996\n",
      "Epoch: 486/5000, Train Loss: 0.2195\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1994\n",
      "Epoch: 487/5000, Train Loss: 0.2193\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1992\n",
      "Epoch: 488/5000, Train Loss: 0.2192\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1990\n",
      "Epoch: 489/5000, Train Loss: 0.2191\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1988\n",
      "Epoch: 490/5000, Train Loss: 0.2189\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1987\n",
      "Epoch: 491/5000, Train Loss: 0.2188\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1985\n",
      "Epoch: 492/5000, Train Loss: 0.2186\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1983\n",
      "Epoch: 493/5000, Train Loss: 0.2185\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1981\n",
      "Epoch: 494/5000, Train Loss: 0.2183\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1979\n",
      "Epoch: 495/5000, Train Loss: 0.2182\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1978\n",
      "Epoch: 496/5000, Train Loss: 0.2181\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1976\n",
      "Epoch: 497/5000, Train Loss: 0.2179\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1974\n",
      "Epoch: 498/5000, Train Loss: 0.2178\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1972\n",
      "Epoch: 499/5000, Train Loss: 0.2176\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1971\n",
      "Epoch: 500/5000, Train Loss: 0.2175\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1969\n",
      "Epoch: 501/5000, Train Loss: 0.2173\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1967\n",
      "Epoch: 502/5000, Train Loss: 0.2172\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1965\n",
      "Epoch: 503/5000, Train Loss: 0.2171\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1964\n",
      "Epoch: 504/5000, Train Loss: 0.2169\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1962\n",
      "Epoch: 505/5000, Train Loss: 0.2168\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1960\n",
      "Epoch: 506/5000, Train Loss: 0.2167\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1958\n",
      "Epoch: 507/5000, Train Loss: 0.2165\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1957\n",
      "Epoch: 508/5000, Train Loss: 0.2164\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1955\n",
      "Epoch: 509/5000, Train Loss: 0.2162\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1953\n",
      "Epoch: 510/5000, Train Loss: 0.2161\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1952\n",
      "Epoch: 511/5000, Train Loss: 0.2160\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1950\n",
      "Epoch: 512/5000, Train Loss: 0.2158\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1948\n",
      "Epoch: 513/5000, Train Loss: 0.2157\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1946\n",
      "Epoch: 514/5000, Train Loss: 0.2156\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1945\n",
      "Epoch: 515/5000, Train Loss: 0.2154\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1943\n",
      "Epoch: 516/5000, Train Loss: 0.2153\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1941\n",
      "Epoch: 517/5000, Train Loss: 0.2152\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1940\n",
      "Epoch: 518/5000, Train Loss: 0.2150\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1938\n",
      "Epoch: 519/5000, Train Loss: 0.2149\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1936\n",
      "Epoch: 520/5000, Train Loss: 0.2148\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1935\n",
      "Epoch: 521/5000, Train Loss: 0.2146\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1933\n",
      "Epoch: 522/5000, Train Loss: 0.2145\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1931\n",
      "Epoch: 523/5000, Train Loss: 0.2144\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1930\n",
      "Epoch: 524/5000, Train Loss: 0.2142\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1928\n",
      "Epoch: 525/5000, Train Loss: 0.2141\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1926\n",
      "Epoch: 526/5000, Train Loss: 0.2140\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1925\n",
      "Epoch: 527/5000, Train Loss: 0.2138\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1923\n",
      "Epoch: 528/5000, Train Loss: 0.2137\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1921\n",
      "Epoch: 529/5000, Train Loss: 0.2136\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1920\n",
      "Epoch: 530/5000, Train Loss: 0.2135\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1918\n",
      "Epoch: 531/5000, Train Loss: 0.2133\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1916\n",
      "Epoch: 532/5000, Train Loss: 0.2132\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1915\n",
      "Epoch: 533/5000, Train Loss: 0.2131\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1913\n",
      "Epoch: 534/5000, Train Loss: 0.2129\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1912\n",
      "Epoch: 535/5000, Train Loss: 0.2128\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1910\n",
      "Epoch: 536/5000, Train Loss: 0.2127\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1908\n",
      "Epoch: 537/5000, Train Loss: 0.2126\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1907\n",
      "Epoch: 538/5000, Train Loss: 0.2124\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1905\n",
      "Epoch: 539/5000, Train Loss: 0.2123\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1904\n",
      "Epoch: 540/5000, Train Loss: 0.2122\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1902\n",
      "Epoch: 541/5000, Train Loss: 0.2121\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1900\n",
      "Epoch: 542/5000, Train Loss: 0.2119\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1899\n",
      "Epoch: 543/5000, Train Loss: 0.2118\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1897\n",
      "Epoch: 544/5000, Train Loss: 0.2117\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1896\n",
      "Epoch: 545/5000, Train Loss: 0.2116\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1894\n",
      "Epoch: 546/5000, Train Loss: 0.2114\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1892\n",
      "Epoch: 547/5000, Train Loss: 0.2113\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1891\n",
      "Epoch: 548/5000, Train Loss: 0.2112\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1889\n",
      "Epoch: 549/5000, Train Loss: 0.2111\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1888\n",
      "Epoch: 550/5000, Train Loss: 0.2109\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1886\n",
      "Epoch: 551/5000, Train Loss: 0.2108\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1885\n",
      "Epoch: 552/5000, Train Loss: 0.2107\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1883\n",
      "Epoch: 553/5000, Train Loss: 0.2106\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1881\n",
      "Epoch: 554/5000, Train Loss: 0.2105\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1880\n",
      "Epoch: 555/5000, Train Loss: 0.2103\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1878\n",
      "Epoch: 556/5000, Train Loss: 0.2102\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1877\n",
      "Epoch: 557/5000, Train Loss: 0.2101\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1875\n",
      "Epoch: 558/5000, Train Loss: 0.2100\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1874\n",
      "Epoch: 559/5000, Train Loss: 0.2099\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1872\n",
      "Epoch: 560/5000, Train Loss: 0.2097\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1871\n",
      "Epoch: 561/5000, Train Loss: 0.2096\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1869\n",
      "Epoch: 562/5000, Train Loss: 0.2095\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1868\n",
      "Epoch: 563/5000, Train Loss: 0.2094\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1866\n",
      "Epoch: 564/5000, Train Loss: 0.2093\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1865\n",
      "Epoch: 565/5000, Train Loss: 0.2091\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1863\n",
      "Epoch: 566/5000, Train Loss: 0.2090\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1862\n",
      "Epoch: 567/5000, Train Loss: 0.2089\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1860\n",
      "Epoch: 568/5000, Train Loss: 0.2088\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1859\n",
      "Epoch: 569/5000, Train Loss: 0.2087\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1857\n",
      "Epoch: 570/5000, Train Loss: 0.2086\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1856\n",
      "Epoch: 571/5000, Train Loss: 0.2084\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1854\n",
      "Epoch: 572/5000, Train Loss: 0.2083\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1853\n",
      "Epoch: 573/5000, Train Loss: 0.2082\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1851\n",
      "Epoch: 574/5000, Train Loss: 0.2081\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1850\n",
      "Epoch: 575/5000, Train Loss: 0.2080\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1848\n",
      "Epoch: 576/5000, Train Loss: 0.2079\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1847\n",
      "Epoch: 577/5000, Train Loss: 0.2078\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1845\n",
      "Epoch: 578/5000, Train Loss: 0.2076\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1844\n",
      "Epoch: 579/5000, Train Loss: 0.2075\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1842\n",
      "Epoch: 580/5000, Train Loss: 0.2074\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1841\n",
      "Epoch: 581/5000, Train Loss: 0.2073\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1839\n",
      "Epoch: 582/5000, Train Loss: 0.2072\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1838\n",
      "Epoch: 583/5000, Train Loss: 0.2071\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1836\n",
      "Epoch: 584/5000, Train Loss: 0.2070\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1835\n",
      "Epoch: 585/5000, Train Loss: 0.2069\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1834\n",
      "Epoch: 586/5000, Train Loss: 0.2067\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1832\n",
      "Epoch: 587/5000, Train Loss: 0.2066\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1831\n",
      "Epoch: 588/5000, Train Loss: 0.2065\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1829\n",
      "Epoch: 589/5000, Train Loss: 0.2064\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1828\n",
      "Epoch: 590/5000, Train Loss: 0.2063\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1826\n",
      "Epoch: 591/5000, Train Loss: 0.2062\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1825\n",
      "Epoch: 592/5000, Train Loss: 0.2061\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1823\n",
      "Epoch: 593/5000, Train Loss: 0.2060\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1822\n",
      "Epoch: 594/5000, Train Loss: 0.2059\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1821\n",
      "Epoch: 595/5000, Train Loss: 0.2057\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1819\n",
      "Epoch: 596/5000, Train Loss: 0.2056\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1818\n",
      "Epoch: 597/5000, Train Loss: 0.2055\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1816\n",
      "Epoch: 598/5000, Train Loss: 0.2054\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1815\n",
      "Epoch: 599/5000, Train Loss: 0.2053\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1814\n",
      "Epoch: 600/5000, Train Loss: 0.2052\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1812\n",
      "Epoch: 601/5000, Train Loss: 0.2051\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1811\n",
      "Epoch: 602/5000, Train Loss: 0.2050\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1809\n",
      "Epoch: 603/5000, Train Loss: 0.2049\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1808\n",
      "Epoch: 604/5000, Train Loss: 0.2048\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1807\n",
      "Epoch: 605/5000, Train Loss: 0.2047\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1805\n",
      "Epoch: 606/5000, Train Loss: 0.2046\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1804\n",
      "Epoch: 607/5000, Train Loss: 0.2045\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1802\n",
      "Epoch: 608/5000, Train Loss: 0.2043\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1801\n",
      "Epoch: 609/5000, Train Loss: 0.2042\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1800\n",
      "Epoch: 610/5000, Train Loss: 0.2041\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1798\n",
      "Epoch: 611/5000, Train Loss: 0.2040\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1797\n",
      "Epoch: 612/5000, Train Loss: 0.2039\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1796\n",
      "Epoch: 613/5000, Train Loss: 0.2038\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1794\n",
      "Epoch: 614/5000, Train Loss: 0.2037\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1793\n",
      "Epoch: 615/5000, Train Loss: 0.2036\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1791\n",
      "Epoch: 616/5000, Train Loss: 0.2035\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1790\n",
      "Epoch: 617/5000, Train Loss: 0.2034\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1789\n",
      "Epoch: 618/5000, Train Loss: 0.2033\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1787\n",
      "Epoch: 619/5000, Train Loss: 0.2032\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1786\n",
      "Epoch: 620/5000, Train Loss: 0.2031\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1785\n",
      "Epoch: 621/5000, Train Loss: 0.2030\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1783\n",
      "Epoch: 622/5000, Train Loss: 0.2029\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1782\n",
      "Epoch: 623/5000, Train Loss: 0.2028\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1781\n",
      "Epoch: 624/5000, Train Loss: 0.2027\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1779\n",
      "Epoch: 625/5000, Train Loss: 0.2026\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1778\n",
      "Epoch: 626/5000, Train Loss: 0.2025\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1777\n",
      "Epoch: 627/5000, Train Loss: 0.2024\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1775\n",
      "Epoch: 628/5000, Train Loss: 0.2023\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1774\n",
      "Epoch: 629/5000, Train Loss: 0.2022\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1773\n",
      "Epoch: 630/5000, Train Loss: 0.2021\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1771\n",
      "Epoch: 631/5000, Train Loss: 0.2020\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1770\n",
      "Epoch: 632/5000, Train Loss: 0.2019\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1769\n",
      "Epoch: 633/5000, Train Loss: 0.2018\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1767\n",
      "Epoch: 634/5000, Train Loss: 0.2017\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1766\n",
      "Epoch: 635/5000, Train Loss: 0.2016\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1765\n",
      "Epoch: 636/5000, Train Loss: 0.2015\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1763\n",
      "Epoch: 637/5000, Train Loss: 0.2014\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1762\n",
      "Epoch: 638/5000, Train Loss: 0.2013\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1761\n",
      "Epoch: 639/5000, Train Loss: 0.2012\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1760\n",
      "Epoch: 640/5000, Train Loss: 0.2011\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1758\n",
      "Epoch: 641/5000, Train Loss: 0.2010\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1757\n",
      "Epoch: 642/5000, Train Loss: 0.2009\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1756\n",
      "Epoch: 643/5000, Train Loss: 0.2008\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1754\n",
      "Epoch: 644/5000, Train Loss: 0.2007\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1753\n",
      "Epoch: 645/5000, Train Loss: 0.2006\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1752\n",
      "Epoch: 646/5000, Train Loss: 0.2005\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1751\n",
      "Epoch: 647/5000, Train Loss: 0.2004\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1749\n",
      "Epoch: 648/5000, Train Loss: 0.2003\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1748\n",
      "Epoch: 649/5000, Train Loss: 0.2002\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1747\n",
      "Epoch: 650/5000, Train Loss: 0.2001\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1745\n",
      "Epoch: 651/5000, Train Loss: 0.2000\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1744\n",
      "Epoch: 652/5000, Train Loss: 0.1999\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1743\n",
      "Epoch: 653/5000, Train Loss: 0.1998\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1742\n",
      "Epoch: 654/5000, Train Loss: 0.1997\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1740\n",
      "Epoch: 655/5000, Train Loss: 0.1996\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1739\n",
      "Epoch: 656/5000, Train Loss: 0.1995\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1738\n",
      "Epoch: 657/5000, Train Loss: 0.1994\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1737\n",
      "Epoch: 658/5000, Train Loss: 0.1993\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1735\n",
      "Epoch: 659/5000, Train Loss: 0.1992\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1734\n",
      "Epoch: 660/5000, Train Loss: 0.1992\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1733\n",
      "Epoch: 661/5000, Train Loss: 0.1991\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1732\n",
      "Epoch: 662/5000, Train Loss: 0.1990\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1730\n",
      "Epoch: 663/5000, Train Loss: 0.1989\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1729\n",
      "Epoch: 664/5000, Train Loss: 0.1988\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1728\n",
      "Epoch: 665/5000, Train Loss: 0.1987\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1727\n",
      "Epoch: 666/5000, Train Loss: 0.1986\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1725\n",
      "Epoch: 667/5000, Train Loss: 0.1985\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1724\n",
      "Epoch: 668/5000, Train Loss: 0.1984\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1723\n",
      "Epoch: 669/5000, Train Loss: 0.1983\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1722\n",
      "Epoch: 670/5000, Train Loss: 0.1982\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1721\n",
      "Epoch: 671/5000, Train Loss: 0.1981\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1719\n",
      "Epoch: 672/5000, Train Loss: 0.1980\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1718\n",
      "Epoch: 673/5000, Train Loss: 0.1980\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1717\n",
      "Epoch: 674/5000, Train Loss: 0.1979\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1716\n",
      "Epoch: 675/5000, Train Loss: 0.1978\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1714\n",
      "Epoch: 676/5000, Train Loss: 0.1977\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1713\n",
      "Epoch: 677/5000, Train Loss: 0.1976\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1712\n",
      "Epoch: 678/5000, Train Loss: 0.1975\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1711\n",
      "Epoch: 679/5000, Train Loss: 0.1974\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1710\n",
      "Epoch: 680/5000, Train Loss: 0.1973\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1708\n",
      "Epoch: 681/5000, Train Loss: 0.1972\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1707\n",
      "Epoch: 682/5000, Train Loss: 0.1971\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1706\n",
      "Epoch: 683/5000, Train Loss: 0.1970\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1705\n",
      "Epoch: 684/5000, Train Loss: 0.1970\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1704\n",
      "Epoch: 685/5000, Train Loss: 0.1969\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1702\n",
      "Epoch: 686/5000, Train Loss: 0.1968\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1701\n",
      "Epoch: 687/5000, Train Loss: 0.1967\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1700\n",
      "Epoch: 688/5000, Train Loss: 0.1966\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1699\n",
      "Epoch: 689/5000, Train Loss: 0.1965\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1698\n",
      "Epoch: 690/5000, Train Loss: 0.1964\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1697\n",
      "Epoch: 691/5000, Train Loss: 0.1963\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1695\n",
      "Epoch: 692/5000, Train Loss: 0.1963\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1694\n",
      "Epoch: 693/5000, Train Loss: 0.1962\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1693\n",
      "Epoch: 694/5000, Train Loss: 0.1961\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1692\n",
      "Epoch: 695/5000, Train Loss: 0.1960\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1691\n",
      "Epoch: 696/5000, Train Loss: 0.1959\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1690\n",
      "Epoch: 697/5000, Train Loss: 0.1958\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1688\n",
      "Epoch: 698/5000, Train Loss: 0.1957\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1687\n",
      "Epoch: 699/5000, Train Loss: 0.1956\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1686\n",
      "Epoch: 700/5000, Train Loss: 0.1956\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1685\n",
      "Epoch: 701/5000, Train Loss: 0.1955\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1684\n",
      "Epoch: 702/5000, Train Loss: 0.1954\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1683\n",
      "Epoch: 703/5000, Train Loss: 0.1953\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1681\n",
      "Epoch: 704/5000, Train Loss: 0.1952\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1680\n",
      "Epoch: 705/5000, Train Loss: 0.1951\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1679\n",
      "Epoch: 706/5000, Train Loss: 0.1950\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1678\n",
      "Epoch: 707/5000, Train Loss: 0.1950\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1677\n",
      "Epoch: 708/5000, Train Loss: 0.1949\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1676\n",
      "Epoch: 709/5000, Train Loss: 0.1948\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1675\n",
      "Epoch: 710/5000, Train Loss: 0.1947\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1673\n",
      "Epoch: 711/5000, Train Loss: 0.1946\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1672\n",
      "Epoch: 712/5000, Train Loss: 0.1945\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1671\n",
      "Epoch: 713/5000, Train Loss: 0.1945\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1670\n",
      "Epoch: 714/5000, Train Loss: 0.1944\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1669\n",
      "Epoch: 715/5000, Train Loss: 0.1943\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1668\n",
      "Epoch: 716/5000, Train Loss: 0.1942\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1667\n",
      "Epoch: 717/5000, Train Loss: 0.1941\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1666\n",
      "Epoch: 718/5000, Train Loss: 0.1940\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1664\n",
      "Epoch: 719/5000, Train Loss: 0.1940\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1663\n",
      "Epoch: 720/5000, Train Loss: 0.1939\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1662\n",
      "Epoch: 721/5000, Train Loss: 0.1938\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1661\n",
      "Epoch: 722/5000, Train Loss: 0.1937\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1660\n",
      "Epoch: 723/5000, Train Loss: 0.1936\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1659\n",
      "Epoch: 724/5000, Train Loss: 0.1935\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1658\n",
      "Epoch: 725/5000, Train Loss: 0.1935\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1657\n",
      "Epoch: 726/5000, Train Loss: 0.1934\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1656\n",
      "Epoch: 727/5000, Train Loss: 0.1933\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1655\n",
      "Epoch: 728/5000, Train Loss: 0.1932\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1653\n",
      "Epoch: 729/5000, Train Loss: 0.1931\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1652\n",
      "Epoch: 730/5000, Train Loss: 0.1931\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1651\n",
      "Epoch: 731/5000, Train Loss: 0.1930\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1650\n",
      "Epoch: 732/5000, Train Loss: 0.1929\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1649\n",
      "Epoch: 733/5000, Train Loss: 0.1928\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1648\n",
      "Epoch: 734/5000, Train Loss: 0.1927\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1647\n",
      "Epoch: 735/5000, Train Loss: 0.1927\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1646\n",
      "Epoch: 736/5000, Train Loss: 0.1926\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1645\n",
      "Epoch: 737/5000, Train Loss: 0.1925\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1644\n",
      "Epoch: 738/5000, Train Loss: 0.1924\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1643\n",
      "Epoch: 739/5000, Train Loss: 0.1923\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1641\n",
      "Epoch: 740/5000, Train Loss: 0.1923\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1640\n",
      "Epoch: 741/5000, Train Loss: 0.1922\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1639\n",
      "Epoch: 742/5000, Train Loss: 0.1921\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1638\n",
      "Epoch: 743/5000, Train Loss: 0.1920\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1637\n",
      "Epoch: 744/5000, Train Loss: 0.1919\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1636\n",
      "Epoch: 745/5000, Train Loss: 0.1919\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1635\n",
      "Epoch: 746/5000, Train Loss: 0.1918\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1634\n",
      "Epoch: 747/5000, Train Loss: 0.1917\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1633\n",
      "Epoch: 748/5000, Train Loss: 0.1916\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1632\n",
      "Epoch: 749/5000, Train Loss: 0.1916\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1631\n",
      "Epoch: 750/5000, Train Loss: 0.1915\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1630\n",
      "Epoch: 751/5000, Train Loss: 0.1914\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1629\n",
      "Epoch: 752/5000, Train Loss: 0.1913\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1628\n",
      "Epoch: 753/5000, Train Loss: 0.1912\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1627\n",
      "Epoch: 754/5000, Train Loss: 0.1912\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1626\n",
      "Epoch: 755/5000, Train Loss: 0.1911\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1624\n",
      "Epoch: 756/5000, Train Loss: 0.1910\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1623\n",
      "Epoch: 757/5000, Train Loss: 0.1909\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1622\n",
      "Epoch: 758/5000, Train Loss: 0.1909\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1621\n",
      "Epoch: 759/5000, Train Loss: 0.1908\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1620\n",
      "Epoch: 760/5000, Train Loss: 0.1907\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1619\n",
      "Epoch: 761/5000, Train Loss: 0.1906\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1618\n",
      "Epoch: 762/5000, Train Loss: 0.1906\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1617\n",
      "Epoch: 763/5000, Train Loss: 0.1905\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1616\n",
      "Epoch: 764/5000, Train Loss: 0.1904\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1615\n",
      "Epoch: 765/5000, Train Loss: 0.1903\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1614\n",
      "Epoch: 766/5000, Train Loss: 0.1903\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1613\n",
      "Epoch: 767/5000, Train Loss: 0.1902\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1612\n",
      "Epoch: 768/5000, Train Loss: 0.1901\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1611\n",
      "Epoch: 769/5000, Train Loss: 0.1900\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1610\n",
      "Epoch: 770/5000, Train Loss: 0.1900\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1609\n",
      "Epoch: 771/5000, Train Loss: 0.1899\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1608\n",
      "Epoch: 772/5000, Train Loss: 0.1898\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1607\n",
      "Epoch: 773/5000, Train Loss: 0.1897\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1606\n",
      "Epoch: 774/5000, Train Loss: 0.1897\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1605\n",
      "Epoch: 775/5000, Train Loss: 0.1896\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1604\n",
      "Epoch: 776/5000, Train Loss: 0.1895\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1603\n",
      "Epoch: 777/5000, Train Loss: 0.1894\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1602\n",
      "Epoch: 778/5000, Train Loss: 0.1894\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1601\n",
      "Epoch: 779/5000, Train Loss: 0.1893\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1600\n",
      "Epoch: 780/5000, Train Loss: 0.1892\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1599\n",
      "Epoch: 781/5000, Train Loss: 0.1891\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1598\n",
      "Epoch: 782/5000, Train Loss: 0.1891\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1597\n",
      "Epoch: 783/5000, Train Loss: 0.1890\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1596\n",
      "Epoch: 784/5000, Train Loss: 0.1889\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1595\n",
      "Epoch: 785/5000, Train Loss: 0.1889\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1594\n",
      "Epoch: 786/5000, Train Loss: 0.1888\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1593\n",
      "Epoch: 787/5000, Train Loss: 0.1887\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1592\n",
      "Epoch: 788/5000, Train Loss: 0.1886\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1591\n",
      "Epoch: 789/5000, Train Loss: 0.1886\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1590\n",
      "Epoch: 790/5000, Train Loss: 0.1885\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1589\n",
      "Epoch: 791/5000, Train Loss: 0.1884\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1588\n",
      "Epoch: 792/5000, Train Loss: 0.1883\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1587\n",
      "Epoch: 793/5000, Train Loss: 0.1883\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1586\n",
      "Epoch: 794/5000, Train Loss: 0.1882\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1585\n",
      "Epoch: 795/5000, Train Loss: 0.1881\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1584\n",
      "Epoch: 796/5000, Train Loss: 0.1881\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1583\n",
      "Epoch: 797/5000, Train Loss: 0.1880\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1582\n",
      "Epoch: 798/5000, Train Loss: 0.1879\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1581\n",
      "Epoch: 799/5000, Train Loss: 0.1879\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1580\n",
      "Epoch: 800/5000, Train Loss: 0.1878\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1579\n",
      "Epoch: 801/5000, Train Loss: 0.1877\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1578\n",
      "Epoch: 802/5000, Train Loss: 0.1876\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1577\n",
      "Epoch: 803/5000, Train Loss: 0.1876\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1576\n",
      "Epoch: 804/5000, Train Loss: 0.1875\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1575\n",
      "Epoch: 805/5000, Train Loss: 0.1874\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1574\n",
      "Epoch: 806/5000, Train Loss: 0.1874\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1573\n",
      "Epoch: 807/5000, Train Loss: 0.1873\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1572\n",
      "Epoch: 808/5000, Train Loss: 0.1872\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1571\n",
      "Epoch: 809/5000, Train Loss: 0.1872\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1570\n",
      "Epoch: 810/5000, Train Loss: 0.1871\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1570\n",
      "Epoch: 811/5000, Train Loss: 0.1870\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1569\n",
      "Epoch: 812/5000, Train Loss: 0.1869\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1568\n",
      "Epoch: 813/5000, Train Loss: 0.1869\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1567\n",
      "Epoch: 814/5000, Train Loss: 0.1868\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1566\n",
      "Epoch: 815/5000, Train Loss: 0.1867\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1565\n",
      "Epoch: 816/5000, Train Loss: 0.1867\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1564\n",
      "Epoch: 817/5000, Train Loss: 0.1866\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1563\n",
      "Epoch: 818/5000, Train Loss: 0.1865\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1562\n",
      "Epoch: 819/5000, Train Loss: 0.1865\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1561\n",
      "Epoch: 820/5000, Train Loss: 0.1864\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1560\n",
      "Epoch: 821/5000, Train Loss: 0.1863\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1559\n",
      "Epoch: 822/5000, Train Loss: 0.1863\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1558\n",
      "Epoch: 823/5000, Train Loss: 0.1862\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1557\n",
      "Epoch: 824/5000, Train Loss: 0.1861\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1556\n",
      "Epoch: 825/5000, Train Loss: 0.1861\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1555\n",
      "Epoch: 826/5000, Train Loss: 0.1860\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1554\n",
      "Epoch: 827/5000, Train Loss: 0.1859\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1553\n",
      "Epoch: 828/5000, Train Loss: 0.1859\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1553\n",
      "Epoch: 829/5000, Train Loss: 0.1858\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1552\n",
      "Epoch: 830/5000, Train Loss: 0.1857\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1551\n",
      "Epoch: 831/5000, Train Loss: 0.1857\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1550\n",
      "Epoch: 832/5000, Train Loss: 0.1856\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1549\n",
      "Epoch: 833/5000, Train Loss: 0.1855\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1548\n",
      "Epoch: 834/5000, Train Loss: 0.1855\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1547\n",
      "Epoch: 835/5000, Train Loss: 0.1854\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1546\n",
      "Epoch: 836/5000, Train Loss: 0.1853\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1545\n",
      "Epoch: 837/5000, Train Loss: 0.1853\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1544\n",
      "Epoch: 838/5000, Train Loss: 0.1852\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1543\n",
      "Epoch: 839/5000, Train Loss: 0.1851\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1542\n",
      "Epoch: 840/5000, Train Loss: 0.1851\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1542\n",
      "Epoch: 841/5000, Train Loss: 0.1850\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1541\n",
      "Epoch: 842/5000, Train Loss: 0.1849\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1540\n",
      "Epoch: 843/5000, Train Loss: 0.1849\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1539\n",
      "Epoch: 844/5000, Train Loss: 0.1848\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1538\n",
      "Epoch: 845/5000, Train Loss: 0.1848\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1537\n",
      "Epoch: 846/5000, Train Loss: 0.1847\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1536\n",
      "Epoch: 847/5000, Train Loss: 0.1846\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1535\n",
      "Epoch: 848/5000, Train Loss: 0.1846\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1534\n",
      "Epoch: 849/5000, Train Loss: 0.1845\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1533\n",
      "Epoch: 850/5000, Train Loss: 0.1844\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1533\n",
      "Epoch: 851/5000, Train Loss: 0.1844\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1532\n",
      "Epoch: 852/5000, Train Loss: 0.1843\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1531\n",
      "Epoch: 853/5000, Train Loss: 0.1842\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1530\n",
      "Epoch: 854/5000, Train Loss: 0.1842\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1529\n",
      "Epoch: 855/5000, Train Loss: 0.1841\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1528\n",
      "Epoch: 856/5000, Train Loss: 0.1840\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1527\n",
      "Epoch: 857/5000, Train Loss: 0.1840\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1526\n",
      "Epoch: 858/5000, Train Loss: 0.1839\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1525\n",
      "Epoch: 859/5000, Train Loss: 0.1839\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1525\n",
      "Epoch: 860/5000, Train Loss: 0.1838\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1524\n",
      "Epoch: 861/5000, Train Loss: 0.1837\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1523\n",
      "Epoch: 862/5000, Train Loss: 0.1837\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1522\n",
      "Epoch: 863/5000, Train Loss: 0.1836\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1521\n",
      "Epoch: 864/5000, Train Loss: 0.1835\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1520\n",
      "Epoch: 865/5000, Train Loss: 0.1835\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1519\n",
      "Epoch: 866/5000, Train Loss: 0.1834\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1518\n",
      "Epoch: 867/5000, Train Loss: 0.1834\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1517\n",
      "Epoch: 868/5000, Train Loss: 0.1833\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1517\n",
      "Epoch: 869/5000, Train Loss: 0.1832\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1516\n",
      "Epoch: 870/5000, Train Loss: 0.1832\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1515\n",
      "Epoch: 871/5000, Train Loss: 0.1831\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1514\n",
      "Epoch: 872/5000, Train Loss: 0.1830\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1513\n",
      "Epoch: 873/5000, Train Loss: 0.1830\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1512\n",
      "Epoch: 874/5000, Train Loss: 0.1829\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1511\n",
      "Epoch: 875/5000, Train Loss: 0.1829\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1511\n",
      "Epoch: 876/5000, Train Loss: 0.1828\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1510\n",
      "Epoch: 877/5000, Train Loss: 0.1827\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1509\n",
      "Epoch: 878/5000, Train Loss: 0.1827\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1508\n",
      "Epoch: 879/5000, Train Loss: 0.1826\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1507\n",
      "Epoch: 880/5000, Train Loss: 0.1826\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1506\n",
      "Epoch: 881/5000, Train Loss: 0.1825\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1505\n",
      "Epoch: 882/5000, Train Loss: 0.1824\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1505\n",
      "Epoch: 883/5000, Train Loss: 0.1824\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1504\n",
      "Epoch: 884/5000, Train Loss: 0.1823\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1503\n",
      "Epoch: 885/5000, Train Loss: 0.1823\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1502\n",
      "Epoch: 886/5000, Train Loss: 0.1822\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1501\n",
      "Epoch: 887/5000, Train Loss: 0.1821\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1500\n",
      "Epoch: 888/5000, Train Loss: 0.1821\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1499\n",
      "Epoch: 889/5000, Train Loss: 0.1820\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1499\n",
      "Epoch: 890/5000, Train Loss: 0.1820\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1498\n",
      "Epoch: 891/5000, Train Loss: 0.1819\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1497\n",
      "Epoch: 892/5000, Train Loss: 0.1818\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1496\n",
      "Epoch: 893/5000, Train Loss: 0.1818\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1495\n",
      "Epoch: 894/5000, Train Loss: 0.1817\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1494\n",
      "Epoch: 895/5000, Train Loss: 0.1817\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1494\n",
      "Epoch: 896/5000, Train Loss: 0.1816\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1493\n",
      "Epoch: 897/5000, Train Loss: 0.1815\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1492\n",
      "Epoch: 898/5000, Train Loss: 0.1815\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1491\n",
      "Epoch: 899/5000, Train Loss: 0.1814\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1490\n",
      "Epoch: 900/5000, Train Loss: 0.1814\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1489\n",
      "Epoch: 901/5000, Train Loss: 0.1813\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1489\n",
      "Epoch: 902/5000, Train Loss: 0.1813\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1488\n",
      "Epoch: 903/5000, Train Loss: 0.1812\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1487\n",
      "Epoch: 904/5000, Train Loss: 0.1811\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1486\n",
      "Epoch: 905/5000, Train Loss: 0.1811\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1485\n",
      "Epoch: 906/5000, Train Loss: 0.1810\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1484\n",
      "Epoch: 907/5000, Train Loss: 0.1810\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1484\n",
      "Epoch: 908/5000, Train Loss: 0.1809\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1483\n",
      "Epoch: 909/5000, Train Loss: 0.1808\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1482\n",
      "Epoch: 910/5000, Train Loss: 0.1808\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1481\n",
      "Epoch: 911/5000, Train Loss: 0.1807\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1480\n",
      "Epoch: 912/5000, Train Loss: 0.1807\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1480\n",
      "Epoch: 913/5000, Train Loss: 0.1806\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1479\n",
      "Epoch: 914/5000, Train Loss: 0.1806\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1478\n",
      "Epoch: 915/5000, Train Loss: 0.1805\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1477\n",
      "Epoch: 916/5000, Train Loss: 0.1804\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1476\n",
      "Epoch: 917/5000, Train Loss: 0.1804\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1475\n",
      "Epoch: 918/5000, Train Loss: 0.1803\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1475\n",
      "Epoch: 919/5000, Train Loss: 0.1803\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1474\n",
      "Epoch: 920/5000, Train Loss: 0.1802\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1473\n",
      "Epoch: 921/5000, Train Loss: 0.1802\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1472\n",
      "Epoch: 922/5000, Train Loss: 0.1801\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1471\n",
      "Epoch: 923/5000, Train Loss: 0.1800\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1471\n",
      "Epoch: 924/5000, Train Loss: 0.1800\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1470\n",
      "Epoch: 925/5000, Train Loss: 0.1799\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1469\n",
      "Epoch: 926/5000, Train Loss: 0.1799\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1468\n",
      "Epoch: 927/5000, Train Loss: 0.1798\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1467\n",
      "Epoch: 928/5000, Train Loss: 0.1798\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1467\n",
      "Epoch: 929/5000, Train Loss: 0.1797\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1466\n",
      "Epoch: 930/5000, Train Loss: 0.1797\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1465\n",
      "Epoch: 931/5000, Train Loss: 0.1796\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1464\n",
      "Epoch: 932/5000, Train Loss: 0.1795\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1463\n",
      "Epoch: 933/5000, Train Loss: 0.1795\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1463\n",
      "Epoch: 934/5000, Train Loss: 0.1794\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1462\n",
      "Epoch: 935/5000, Train Loss: 0.1794\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1461\n",
      "Epoch: 936/5000, Train Loss: 0.1793\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1460\n",
      "Epoch: 937/5000, Train Loss: 0.1793\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1459\n",
      "Epoch: 938/5000, Train Loss: 0.1792\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1459\n",
      "Epoch: 939/5000, Train Loss: 0.1792\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1458\n",
      "Epoch: 940/5000, Train Loss: 0.1791\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1457\n",
      "Epoch: 941/5000, Train Loss: 0.1790\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1456\n",
      "Epoch: 942/5000, Train Loss: 0.1790\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1456\n",
      "Epoch: 943/5000, Train Loss: 0.1789\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1455\n",
      "Epoch: 944/5000, Train Loss: 0.1789\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1454\n",
      "Epoch: 945/5000, Train Loss: 0.1788\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1453\n",
      "Epoch: 946/5000, Train Loss: 0.1788\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1452\n",
      "Epoch: 947/5000, Train Loss: 0.1787\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1452\n",
      "Epoch: 948/5000, Train Loss: 0.1787\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1451\n",
      "Epoch: 949/5000, Train Loss: 0.1786\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1450\n",
      "Epoch: 950/5000, Train Loss: 0.1786\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1449\n",
      "Epoch: 951/5000, Train Loss: 0.1785\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1449\n",
      "Epoch: 952/5000, Train Loss: 0.1785\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1448\n",
      "Epoch: 953/5000, Train Loss: 0.1784\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1447\n",
      "Epoch: 954/5000, Train Loss: 0.1783\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1446\n",
      "Epoch: 955/5000, Train Loss: 0.1783\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1445\n",
      "Epoch: 956/5000, Train Loss: 0.1782\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1445\n",
      "Epoch: 957/5000, Train Loss: 0.1782\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1444\n",
      "Epoch: 958/5000, Train Loss: 0.1781\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1443\n",
      "Epoch: 959/5000, Train Loss: 0.1781\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1442\n",
      "Epoch: 960/5000, Train Loss: 0.1780\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1442\n",
      "Epoch: 961/5000, Train Loss: 0.1780\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1441\n",
      "Epoch: 962/5000, Train Loss: 0.1779\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1440\n",
      "Epoch: 963/5000, Train Loss: 0.1779\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1439\n",
      "Epoch: 964/5000, Train Loss: 0.1778\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1439\n",
      "Epoch: 965/5000, Train Loss: 0.1778\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1438\n",
      "Epoch: 966/5000, Train Loss: 0.1777\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1437\n",
      "Epoch: 967/5000, Train Loss: 0.1777\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1436\n",
      "Epoch: 968/5000, Train Loss: 0.1776\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1436\n",
      "Epoch: 969/5000, Train Loss: 0.1776\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1435\n",
      "Epoch: 970/5000, Train Loss: 0.1775\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1434\n",
      "Epoch: 971/5000, Train Loss: 0.1774\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1433\n",
      "Epoch: 972/5000, Train Loss: 0.1774\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1433\n",
      "Epoch: 973/5000, Train Loss: 0.1773\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1432\n",
      "Epoch: 974/5000, Train Loss: 0.1773\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1431\n",
      "Epoch: 975/5000, Train Loss: 0.1772\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1430\n",
      "Epoch: 976/5000, Train Loss: 0.1772\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1430\n",
      "Epoch: 977/5000, Train Loss: 0.1771\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1429\n",
      "Epoch: 978/5000, Train Loss: 0.1771\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1428\n",
      "Epoch: 979/5000, Train Loss: 0.1770\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1427\n",
      "Epoch: 980/5000, Train Loss: 0.1770\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1427\n",
      "Epoch: 981/5000, Train Loss: 0.1769\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1426\n",
      "Epoch: 982/5000, Train Loss: 0.1769\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1425\n",
      "Epoch: 983/5000, Train Loss: 0.1768\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1424\n",
      "Epoch: 984/5000, Train Loss: 0.1768\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1424\n",
      "Epoch: 985/5000, Train Loss: 0.1767\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1423\n",
      "Epoch: 986/5000, Train Loss: 0.1767\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1422\n",
      "Epoch: 987/5000, Train Loss: 0.1766\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1421\n",
      "Epoch: 988/5000, Train Loss: 0.1766\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1421\n",
      "Epoch: 989/5000, Train Loss: 0.1765\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1420\n",
      "Epoch: 990/5000, Train Loss: 0.1765\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1419\n",
      "Epoch: 991/5000, Train Loss: 0.1764\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1419\n",
      "Epoch: 992/5000, Train Loss: 0.1764\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1418\n",
      "Epoch: 993/5000, Train Loss: 0.1763\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1417\n",
      "Epoch: 994/5000, Train Loss: 0.1763\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1416\n",
      "Epoch: 995/5000, Train Loss: 0.1762\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1416\n",
      "Epoch: 996/5000, Train Loss: 0.1762\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1415\n",
      "Epoch: 997/5000, Train Loss: 0.1761\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1414\n",
      "Epoch: 998/5000, Train Loss: 0.1761\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1413\n",
      "Epoch: 999/5000, Train Loss: 0.1760\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1413\n",
      "Epoch: 1000/5000, Train Loss: 0.1760\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1412\n",
      "Epoch: 1001/5000, Train Loss: 0.1759\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1411\n",
      "Epoch: 1002/5000, Train Loss: 0.1759\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1411\n",
      "Epoch: 1003/5000, Train Loss: 0.1758\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1410\n",
      "Epoch: 1004/5000, Train Loss: 0.1758\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1409\n",
      "Epoch: 1005/5000, Train Loss: 0.1757\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1408\n",
      "Epoch: 1006/5000, Train Loss: 0.1757\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1408\n",
      "Epoch: 1007/5000, Train Loss: 0.1756\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1407\n",
      "Epoch: 1008/5000, Train Loss: 0.1756\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1406\n",
      "Epoch: 1009/5000, Train Loss: 0.1755\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1406\n",
      "Epoch: 1010/5000, Train Loss: 0.1755\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1405\n",
      "Epoch: 1011/5000, Train Loss: 0.1754\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1404\n",
      "Epoch: 1012/5000, Train Loss: 0.1754\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1403\n",
      "Epoch: 1013/5000, Train Loss: 0.1753\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1403\n",
      "Epoch: 1014/5000, Train Loss: 0.1753\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1402\n",
      "Epoch: 1015/5000, Train Loss: 0.1752\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1401\n",
      "Epoch: 1016/5000, Train Loss: 0.1752\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1401\n",
      "Epoch: 1017/5000, Train Loss: 0.1751\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1400\n",
      "Epoch: 1018/5000, Train Loss: 0.1751\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1399\n",
      "Epoch: 1019/5000, Train Loss: 0.1750\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1399\n",
      "Epoch: 1020/5000, Train Loss: 0.1750\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1398\n",
      "Epoch: 1021/5000, Train Loss: 0.1749\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1397\n",
      "Epoch: 1022/5000, Train Loss: 0.1749\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1396\n",
      "Epoch: 1023/5000, Train Loss: 0.1749\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1396\n",
      "Epoch: 1024/5000, Train Loss: 0.1748\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1395\n",
      "Epoch: 1025/5000, Train Loss: 0.1748\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1394\n",
      "Epoch: 1026/5000, Train Loss: 0.1747\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1394\n",
      "Epoch: 1027/5000, Train Loss: 0.1747\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1393\n",
      "Epoch: 1028/5000, Train Loss: 0.1746\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1392\n",
      "Epoch: 1029/5000, Train Loss: 0.1746\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1392\n",
      "Epoch: 1030/5000, Train Loss: 0.1745\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1391\n",
      "Epoch: 1031/5000, Train Loss: 0.1745\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1390\n",
      "Epoch: 1032/5000, Train Loss: 0.1744\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1389\n",
      "Epoch: 1033/5000, Train Loss: 0.1744\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1389\n",
      "Epoch: 1034/5000, Train Loss: 0.1743\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1388\n",
      "Epoch: 1035/5000, Train Loss: 0.1743\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1387\n",
      "Epoch: 1036/5000, Train Loss: 0.1742\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1387\n",
      "Epoch: 1037/5000, Train Loss: 0.1742\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1386\n",
      "Epoch: 1038/5000, Train Loss: 0.1741\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1385\n",
      "Epoch: 1039/5000, Train Loss: 0.1741\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1385\n",
      "Epoch: 1040/5000, Train Loss: 0.1740\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1384\n",
      "Epoch: 1041/5000, Train Loss: 0.1740\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1383\n",
      "Epoch: 1042/5000, Train Loss: 0.1740\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1383\n",
      "Epoch: 1043/5000, Train Loss: 0.1739\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1382\n",
      "Epoch: 1044/5000, Train Loss: 0.1739\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1381\n",
      "Epoch: 1045/5000, Train Loss: 0.1738\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1381\n",
      "Epoch: 1046/5000, Train Loss: 0.1738\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1380\n",
      "Epoch: 1047/5000, Train Loss: 0.1737\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1379\n",
      "Epoch: 1048/5000, Train Loss: 0.1737\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1379\n",
      "Epoch: 1049/5000, Train Loss: 0.1736\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1378\n",
      "Epoch: 1050/5000, Train Loss: 0.1736\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1377\n",
      "Epoch: 1051/5000, Train Loss: 0.1735\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1376\n",
      "Epoch: 1052/5000, Train Loss: 0.1735\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1376\n",
      "Epoch: 1053/5000, Train Loss: 0.1734\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1375\n",
      "Epoch: 1054/5000, Train Loss: 0.1734\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1374\n",
      "Epoch: 1055/5000, Train Loss: 0.1734\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1374\n",
      "Epoch: 1056/5000, Train Loss: 0.1733\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1373\n",
      "Epoch: 1057/5000, Train Loss: 0.1733\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1372\n",
      "Epoch: 1058/5000, Train Loss: 0.1732\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1372\n",
      "Epoch: 1059/5000, Train Loss: 0.1732\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1371\n",
      "Epoch: 1060/5000, Train Loss: 0.1731\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1370\n",
      "Epoch: 1061/5000, Train Loss: 0.1731\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1370\n",
      "Epoch: 1062/5000, Train Loss: 0.1730\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1369\n",
      "Epoch: 1063/5000, Train Loss: 0.1730\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1368\n",
      "Epoch: 1064/5000, Train Loss: 0.1729\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1368\n",
      "Epoch: 1065/5000, Train Loss: 0.1729\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1367\n",
      "Epoch: 1066/5000, Train Loss: 0.1729\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1366\n",
      "Epoch: 1067/5000, Train Loss: 0.1728\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1366\n",
      "Epoch: 1068/5000, Train Loss: 0.1728\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1365\n",
      "Epoch: 1069/5000, Train Loss: 0.1727\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1364\n",
      "Epoch: 1070/5000, Train Loss: 0.1727\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1364\n",
      "Epoch: 1071/5000, Train Loss: 0.1726\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1363\n",
      "Epoch: 1072/5000, Train Loss: 0.1726\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1363\n",
      "Epoch: 1073/5000, Train Loss: 0.1725\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1362\n",
      "Epoch: 1074/5000, Train Loss: 0.1725\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1361\n",
      "Epoch: 1075/5000, Train Loss: 0.1725\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1361\n",
      "Epoch: 1076/5000, Train Loss: 0.1724\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1360\n",
      "Epoch: 1077/5000, Train Loss: 0.1724\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1359\n",
      "Epoch: 1078/5000, Train Loss: 0.1723\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1359\n",
      "Epoch: 1079/5000, Train Loss: 0.1723\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1358\n",
      "Epoch: 1080/5000, Train Loss: 0.1722\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1357\n",
      "Epoch: 1081/5000, Train Loss: 0.1722\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1357\n",
      "Epoch: 1082/5000, Train Loss: 0.1721\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1356\n",
      "Epoch: 1083/5000, Train Loss: 0.1721\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1355\n",
      "Epoch: 1084/5000, Train Loss: 0.1721\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1355\n",
      "Epoch: 1085/5000, Train Loss: 0.1720\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1354\n",
      "Epoch: 1086/5000, Train Loss: 0.1720\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1353\n",
      "Epoch: 1087/5000, Train Loss: 0.1719\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1353\n",
      "Epoch: 1088/5000, Train Loss: 0.1719\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1352\n",
      "Epoch: 1089/5000, Train Loss: 0.1718\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1351\n",
      "Epoch: 1090/5000, Train Loss: 0.1718\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1351\n",
      "Epoch: 1091/5000, Train Loss: 0.1718\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1350\n",
      "Epoch: 1092/5000, Train Loss: 0.1717\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1350\n",
      "Epoch: 1093/5000, Train Loss: 0.1717\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1349\n",
      "Epoch: 1094/5000, Train Loss: 0.1716\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1348\n",
      "Epoch: 1095/5000, Train Loss: 0.1716\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1348\n",
      "Epoch: 1096/5000, Train Loss: 0.1715\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1347\n",
      "Epoch: 1097/5000, Train Loss: 0.1715\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1346\n",
      "Epoch: 1098/5000, Train Loss: 0.1714\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1346\n",
      "Epoch: 1099/5000, Train Loss: 0.1714\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1345\n",
      "Epoch: 1100/5000, Train Loss: 0.1714\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1344\n",
      "Epoch: 1101/5000, Train Loss: 0.1713\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1344\n",
      "Epoch: 1102/5000, Train Loss: 0.1713\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1343\n",
      "Epoch: 1103/5000, Train Loss: 0.1712\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1343\n",
      "Epoch: 1104/5000, Train Loss: 0.1712\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1342\n",
      "Epoch: 1105/5000, Train Loss: 0.1712\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1341\n",
      "Epoch: 1106/5000, Train Loss: 0.1711\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1341\n",
      "Epoch: 1107/5000, Train Loss: 0.1711\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1340\n",
      "Epoch: 1108/5000, Train Loss: 0.1710\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1339\n",
      "Epoch: 1109/5000, Train Loss: 0.1710\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1339\n",
      "Epoch: 1110/5000, Train Loss: 0.1709\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1338\n",
      "Epoch: 1111/5000, Train Loss: 0.1709\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1338\n",
      "Epoch: 1112/5000, Train Loss: 0.1709\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1337\n",
      "Epoch: 1113/5000, Train Loss: 0.1708\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1336\n",
      "Epoch: 1114/5000, Train Loss: 0.1708\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1336\n",
      "Epoch: 1115/5000, Train Loss: 0.1707\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1335\n",
      "Epoch: 1116/5000, Train Loss: 0.1707\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1334\n",
      "Epoch: 1117/5000, Train Loss: 0.1706\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1334\n",
      "Epoch: 1118/5000, Train Loss: 0.1706\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1333\n",
      "Epoch: 1119/5000, Train Loss: 0.1706\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1333\n",
      "Epoch: 1120/5000, Train Loss: 0.1705\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1332\n",
      "Epoch: 1121/5000, Train Loss: 0.1705\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1331\n",
      "Epoch: 1122/5000, Train Loss: 0.1704\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1331\n",
      "Epoch: 1123/5000, Train Loss: 0.1704\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1330\n",
      "Epoch: 1124/5000, Train Loss: 0.1704\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1329\n",
      "Epoch: 1125/5000, Train Loss: 0.1703\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1329\n",
      "Epoch: 1126/5000, Train Loss: 0.1703\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1328\n",
      "Epoch: 1127/5000, Train Loss: 0.1702\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1328\n",
      "Epoch: 1128/5000, Train Loss: 0.1702\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1327\n",
      "Epoch: 1129/5000, Train Loss: 0.1701\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1326\n",
      "Epoch: 1130/5000, Train Loss: 0.1701\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1326\n",
      "Epoch: 1131/5000, Train Loss: 0.1701\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1325\n",
      "Epoch: 1132/5000, Train Loss: 0.1700\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1325\n",
      "Epoch: 1133/5000, Train Loss: 0.1700\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1324\n",
      "Epoch: 1134/5000, Train Loss: 0.1699\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1323\n",
      "Epoch: 1135/5000, Train Loss: 0.1699\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1323\n",
      "Epoch: 1136/5000, Train Loss: 0.1699\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1322\n",
      "Epoch: 1137/5000, Train Loss: 0.1698\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1322\n",
      "Epoch: 1138/5000, Train Loss: 0.1698\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1321\n",
      "Epoch: 1139/5000, Train Loss: 0.1697\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1320\n",
      "Epoch: 1140/5000, Train Loss: 0.1697\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1320\n",
      "Epoch: 1141/5000, Train Loss: 0.1697\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1319\n",
      "Epoch: 1142/5000, Train Loss: 0.1696\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1319\n",
      "Epoch: 1143/5000, Train Loss: 0.1696\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1318\n",
      "Epoch: 1144/5000, Train Loss: 0.1695\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1317\n",
      "Epoch: 1145/5000, Train Loss: 0.1695\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1317\n",
      "Epoch: 1146/5000, Train Loss: 0.1695\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1316\n",
      "Epoch: 1147/5000, Train Loss: 0.1694\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1316\n",
      "Epoch: 1148/5000, Train Loss: 0.1694\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1315\n",
      "Epoch: 1149/5000, Train Loss: 0.1693\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1314\n",
      "Epoch: 1150/5000, Train Loss: 0.1693\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1314\n",
      "Epoch: 1151/5000, Train Loss: 0.1693\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1313\n",
      "Epoch: 1152/5000, Train Loss: 0.1692\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1313\n",
      "Epoch: 1153/5000, Train Loss: 0.1692\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1312\n",
      "Epoch: 1154/5000, Train Loss: 0.1691\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1311\n",
      "Epoch: 1155/5000, Train Loss: 0.1691\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1311\n",
      "Epoch: 1156/5000, Train Loss: 0.1691\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1310\n",
      "Epoch: 1157/5000, Train Loss: 0.1690\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1310\n",
      "Epoch: 1158/5000, Train Loss: 0.1690\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1309\n",
      "Epoch: 1159/5000, Train Loss: 0.1689\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1308\n",
      "Epoch: 1160/5000, Train Loss: 0.1689\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1308\n",
      "Epoch: 1161/5000, Train Loss: 0.1689\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1307\n",
      "Epoch: 1162/5000, Train Loss: 0.1688\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1307\n",
      "Epoch: 1163/5000, Train Loss: 0.1688\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1306\n",
      "Epoch: 1164/5000, Train Loss: 0.1687\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1305\n",
      "Epoch: 1165/5000, Train Loss: 0.1687\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1305\n",
      "Epoch: 1166/5000, Train Loss: 0.1687\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1304\n",
      "Epoch: 1167/5000, Train Loss: 0.1686\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1304\n",
      "Epoch: 1168/5000, Train Loss: 0.1686\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1303\n",
      "Epoch: 1169/5000, Train Loss: 0.1686\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1303\n",
      "Epoch: 1170/5000, Train Loss: 0.1685\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1302\n",
      "Epoch: 1171/5000, Train Loss: 0.1685\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1301\n",
      "Epoch: 1172/5000, Train Loss: 0.1684\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1301\n",
      "Epoch: 1173/5000, Train Loss: 0.1684\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1300\n",
      "Epoch: 1174/5000, Train Loss: 0.1684\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1300\n",
      "Epoch: 1175/5000, Train Loss: 0.1683\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1299\n",
      "Epoch: 1176/5000, Train Loss: 0.1683\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1298\n",
      "Epoch: 1177/5000, Train Loss: 0.1682\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1298\n",
      "Epoch: 1178/5000, Train Loss: 0.1682\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1297\n",
      "Epoch: 1179/5000, Train Loss: 0.1682\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1297\n",
      "Epoch: 1180/5000, Train Loss: 0.1681\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1296\n",
      "Epoch: 1181/5000, Train Loss: 0.1681\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1296\n",
      "Epoch: 1182/5000, Train Loss: 0.1681\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1295\n",
      "Epoch: 1183/5000, Train Loss: 0.1680\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1294\n",
      "Epoch: 1184/5000, Train Loss: 0.1680\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1294\n",
      "Epoch: 1185/5000, Train Loss: 0.1679\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1293\n",
      "Epoch: 1186/5000, Train Loss: 0.1679\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1293\n",
      "Epoch: 1187/5000, Train Loss: 0.1679\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1292\n",
      "Epoch: 1188/5000, Train Loss: 0.1678\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1292\n",
      "Epoch: 1189/5000, Train Loss: 0.1678\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1291\n",
      "Epoch: 1190/5000, Train Loss: 0.1677\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1290\n",
      "Epoch: 1191/5000, Train Loss: 0.1677\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1290\n",
      "Epoch: 1192/5000, Train Loss: 0.1677\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1289\n",
      "Epoch: 1193/5000, Train Loss: 0.1676\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1289\n",
      "Epoch: 1194/5000, Train Loss: 0.1676\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1288\n",
      "Epoch: 1195/5000, Train Loss: 0.1676\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1288\n",
      "Epoch: 1196/5000, Train Loss: 0.1675\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1287\n",
      "Epoch: 1197/5000, Train Loss: 0.1675\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1286\n",
      "Epoch: 1198/5000, Train Loss: 0.1674\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1286\n",
      "Epoch: 1199/5000, Train Loss: 0.1674\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1285\n",
      "Epoch: 1200/5000, Train Loss: 0.1674\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1285\n",
      "Epoch: 1201/5000, Train Loss: 0.1673\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1284\n",
      "Epoch: 1202/5000, Train Loss: 0.1673\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1284\n",
      "Epoch: 1203/5000, Train Loss: 0.1673\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1283\n",
      "Epoch: 1204/5000, Train Loss: 0.1672\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1283\n",
      "Epoch: 1205/5000, Train Loss: 0.1672\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1282\n",
      "Epoch: 1206/5000, Train Loss: 0.1672\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1281\n",
      "Epoch: 1207/5000, Train Loss: 0.1671\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1281\n",
      "Epoch: 1208/5000, Train Loss: 0.1671\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1280\n",
      "Epoch: 1209/5000, Train Loss: 0.1670\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1280\n",
      "Epoch: 1210/5000, Train Loss: 0.1670\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1279\n",
      "Epoch: 1211/5000, Train Loss: 0.1670\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1279\n",
      "Epoch: 1212/5000, Train Loss: 0.1669\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1278\n",
      "Epoch: 1213/5000, Train Loss: 0.1669\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1278\n",
      "Epoch: 1214/5000, Train Loss: 0.1669\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1277\n",
      "Epoch: 1215/5000, Train Loss: 0.1668\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1276\n",
      "Epoch: 1216/5000, Train Loss: 0.1668\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1276\n",
      "Epoch: 1217/5000, Train Loss: 0.1667\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1275\n",
      "Epoch: 1218/5000, Train Loss: 0.1667\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1275\n",
      "Epoch: 1219/5000, Train Loss: 0.1667\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1274\n",
      "Epoch: 1220/5000, Train Loss: 0.1666\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1274\n",
      "Epoch: 1221/5000, Train Loss: 0.1666\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1273\n",
      "Epoch: 1222/5000, Train Loss: 0.1666\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1273\n",
      "Epoch: 1223/5000, Train Loss: 0.1665\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1272\n",
      "Epoch: 1224/5000, Train Loss: 0.1665\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1271\n",
      "Epoch: 1225/5000, Train Loss: 0.1665\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1271\n",
      "Epoch: 1226/5000, Train Loss: 0.1664\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1270\n",
      "Epoch: 1227/5000, Train Loss: 0.1664\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1270\n",
      "Epoch: 1228/5000, Train Loss: 0.1663\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1269\n",
      "Epoch: 1229/5000, Train Loss: 0.1663\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1269\n",
      "Epoch: 1230/5000, Train Loss: 0.1663\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1268\n",
      "Epoch: 1231/5000, Train Loss: 0.1662\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1268\n",
      "Epoch: 1232/5000, Train Loss: 0.1662\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1267\n",
      "Epoch: 1233/5000, Train Loss: 0.1662\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1267\n",
      "Epoch: 1234/5000, Train Loss: 0.1661\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1266\n",
      "Epoch: 1235/5000, Train Loss: 0.1661\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1266\n",
      "Epoch: 1236/5000, Train Loss: 0.1661\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1265\n",
      "Epoch: 1237/5000, Train Loss: 0.1660\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1264\n",
      "Epoch: 1238/5000, Train Loss: 0.1660\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1264\n",
      "Epoch: 1239/5000, Train Loss: 0.1660\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1263\n",
      "Epoch: 1240/5000, Train Loss: 0.1659\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1263\n",
      "Epoch: 1241/5000, Train Loss: 0.1659\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1262\n",
      "Epoch: 1242/5000, Train Loss: 0.1659\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1262\n",
      "Epoch: 1243/5000, Train Loss: 0.1658\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1261\n",
      "Epoch: 1244/5000, Train Loss: 0.1658\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1261\n",
      "Epoch: 1245/5000, Train Loss: 0.1657\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1260\n",
      "Epoch: 1246/5000, Train Loss: 0.1657\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1260\n",
      "Epoch: 1247/5000, Train Loss: 0.1657\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1259\n",
      "Epoch: 1248/5000, Train Loss: 0.1656\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1259\n",
      "Epoch: 1249/5000, Train Loss: 0.1656\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1258\n",
      "Epoch: 1250/5000, Train Loss: 0.1656\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1257\n",
      "Epoch: 1251/5000, Train Loss: 0.1655\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1257\n",
      "Epoch: 1252/5000, Train Loss: 0.1655\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1256\n",
      "Epoch: 1253/5000, Train Loss: 0.1655\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1256\n",
      "Epoch: 1254/5000, Train Loss: 0.1654\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1255\n",
      "Epoch: 1255/5000, Train Loss: 0.1654\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1255\n",
      "Epoch: 1256/5000, Train Loss: 0.1654\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1254\n",
      "Epoch: 1257/5000, Train Loss: 0.1653\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1254\n",
      "Epoch: 1258/5000, Train Loss: 0.1653\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1253\n",
      "Epoch: 1259/5000, Train Loss: 0.1653\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1253\n",
      "Epoch: 1260/5000, Train Loss: 0.1652\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1252\n",
      "Epoch: 1261/5000, Train Loss: 0.1652\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1252\n",
      "Epoch: 1262/5000, Train Loss: 0.1652\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1251\n",
      "Epoch: 1263/5000, Train Loss: 0.1651\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1251\n",
      "Epoch: 1264/5000, Train Loss: 0.1651\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1250\n",
      "Epoch: 1265/5000, Train Loss: 0.1651\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1250\n",
      "Epoch: 1266/5000, Train Loss: 0.1650\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1249\n",
      "Epoch: 1267/5000, Train Loss: 0.1650\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1249\n",
      "Epoch: 1268/5000, Train Loss: 0.1649\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1248\n",
      "Epoch: 1269/5000, Train Loss: 0.1649\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1247\n",
      "Epoch: 1270/5000, Train Loss: 0.1649\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1247\n",
      "Epoch: 1271/5000, Train Loss: 0.1648\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1246\n",
      "Epoch: 1272/5000, Train Loss: 0.1648\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1246\n",
      "Epoch: 1273/5000, Train Loss: 0.1648\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1245\n",
      "Epoch: 1274/5000, Train Loss: 0.1647\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1245\n",
      "Epoch: 1275/5000, Train Loss: 0.1647\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1244\n",
      "Epoch: 1276/5000, Train Loss: 0.1647\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1244\n",
      "Epoch: 1277/5000, Train Loss: 0.1646\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1243\n",
      "Epoch: 1278/5000, Train Loss: 0.1646\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1243\n",
      "Epoch: 1279/5000, Train Loss: 0.1646\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1242\n",
      "Epoch: 1280/5000, Train Loss: 0.1645\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1242\n",
      "Epoch: 1281/5000, Train Loss: 0.1645\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1241\n",
      "Epoch: 1282/5000, Train Loss: 0.1645\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1241\n",
      "Epoch: 1283/5000, Train Loss: 0.1644\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1240\n",
      "Epoch: 1284/5000, Train Loss: 0.1644\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1240\n",
      "Epoch: 1285/5000, Train Loss: 0.1644\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1239\n",
      "Epoch: 1286/5000, Train Loss: 0.1643\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1239\n",
      "Epoch: 1287/5000, Train Loss: 0.1643\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1238\n",
      "Epoch: 1288/5000, Train Loss: 0.1643\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1238\n",
      "Epoch: 1289/5000, Train Loss: 0.1642\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1237\n",
      "Epoch: 1290/5000, Train Loss: 0.1642\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1237\n",
      "Epoch: 1291/5000, Train Loss: 0.1642\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1236\n",
      "Epoch: 1292/5000, Train Loss: 0.1641\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1236\n",
      "Epoch: 1293/5000, Train Loss: 0.1641\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1235\n",
      "Epoch: 1294/5000, Train Loss: 0.1641\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1235\n",
      "Epoch: 1295/5000, Train Loss: 0.1640\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1234\n",
      "Epoch: 1296/5000, Train Loss: 0.1640\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1234\n",
      "Epoch: 1297/5000, Train Loss: 0.1640\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1233\n",
      "Epoch: 1298/5000, Train Loss: 0.1639\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1233\n",
      "Epoch: 1299/5000, Train Loss: 0.1639\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1232\n",
      "Epoch: 1300/5000, Train Loss: 0.1639\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1232\n",
      "Epoch: 1301/5000, Train Loss: 0.1638\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1231\n",
      "Epoch: 1302/5000, Train Loss: 0.1638\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1231\n",
      "Epoch: 1303/5000, Train Loss: 0.1638\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1230\n",
      "Epoch: 1304/5000, Train Loss: 0.1637\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1230\n",
      "Epoch: 1305/5000, Train Loss: 0.1637\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1229\n",
      "Epoch: 1306/5000, Train Loss: 0.1637\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1229\n",
      "Epoch: 1307/5000, Train Loss: 0.1636\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1228\n",
      "Epoch: 1308/5000, Train Loss: 0.1636\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1228\n",
      "Epoch: 1309/5000, Train Loss: 0.1636\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1227\n",
      "Epoch: 1310/5000, Train Loss: 0.1636\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1227\n",
      "Epoch: 1311/5000, Train Loss: 0.1635\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1226\n",
      "Epoch: 1312/5000, Train Loss: 0.1635\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1226\n",
      "Epoch: 1313/5000, Train Loss: 0.1635\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1225\n",
      "Epoch: 1314/5000, Train Loss: 0.1634\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1225\n",
      "Epoch: 1315/5000, Train Loss: 0.1634\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1224\n",
      "Epoch: 1316/5000, Train Loss: 0.1634\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1224\n",
      "Epoch: 1317/5000, Train Loss: 0.1633\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1223\n",
      "Epoch: 1318/5000, Train Loss: 0.1633\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1223\n",
      "Epoch: 1319/5000, Train Loss: 0.1633\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1222\n",
      "Epoch: 1320/5000, Train Loss: 0.1632\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1222\n",
      "Epoch: 1321/5000, Train Loss: 0.1632\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1221\n",
      "Epoch: 1322/5000, Train Loss: 0.1632\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1221\n",
      "Epoch: 1323/5000, Train Loss: 0.1631\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1220\n",
      "Epoch: 1324/5000, Train Loss: 0.1631\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1220\n",
      "Epoch: 1325/5000, Train Loss: 0.1631\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1219\n",
      "Epoch: 1326/5000, Train Loss: 0.1630\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1219\n",
      "Epoch: 1327/5000, Train Loss: 0.1630\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1218\n",
      "Epoch: 1328/5000, Train Loss: 0.1630\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1218\n",
      "Epoch: 1329/5000, Train Loss: 0.1629\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1217\n",
      "Epoch: 1330/5000, Train Loss: 0.1629\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1217\n",
      "Epoch: 1331/5000, Train Loss: 0.1629\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1216\n",
      "Epoch: 1332/5000, Train Loss: 0.1628\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1216\n",
      "Epoch: 1333/5000, Train Loss: 0.1628\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1215\n",
      "Epoch: 1334/5000, Train Loss: 0.1628\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1215\n",
      "Epoch: 1335/5000, Train Loss: 0.1628\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1214\n",
      "Epoch: 1336/5000, Train Loss: 0.1627\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1214\n",
      "Epoch: 1337/5000, Train Loss: 0.1627\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1213\n",
      "Epoch: 1338/5000, Train Loss: 0.1627\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1213\n",
      "Epoch: 1339/5000, Train Loss: 0.1626\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1212\n",
      "Epoch: 1340/5000, Train Loss: 0.1626\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1212\n",
      "Epoch: 1341/5000, Train Loss: 0.1626\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1211\n",
      "Epoch: 1342/5000, Train Loss: 0.1625\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1211\n",
      "Epoch: 1343/5000, Train Loss: 0.1625\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1210\n",
      "Epoch: 1344/5000, Train Loss: 0.1625\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1210\n",
      "Epoch: 1345/5000, Train Loss: 0.1624\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1209\n",
      "Epoch: 1346/5000, Train Loss: 0.1624\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1209\n",
      "Epoch: 1347/5000, Train Loss: 0.1624\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1209\n",
      "Epoch: 1348/5000, Train Loss: 0.1623\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1208\n",
      "Epoch: 1349/5000, Train Loss: 0.1623\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1208\n",
      "Epoch: 1350/5000, Train Loss: 0.1623\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1207\n",
      "Epoch: 1351/5000, Train Loss: 0.1623\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1207\n",
      "Epoch: 1352/5000, Train Loss: 0.1622\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1206\n",
      "Epoch: 1353/5000, Train Loss: 0.1622\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1206\n",
      "Epoch: 1354/5000, Train Loss: 0.1622\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1205\n",
      "Epoch: 1355/5000, Train Loss: 0.1621\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1205\n",
      "Epoch: 1356/5000, Train Loss: 0.1621\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1204\n",
      "Epoch: 1357/5000, Train Loss: 0.1621\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1204\n",
      "Epoch: 1358/5000, Train Loss: 0.1620\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1203\n",
      "Epoch: 1359/5000, Train Loss: 0.1620\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1203\n",
      "Epoch: 1360/5000, Train Loss: 0.1620\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1202\n",
      "Epoch: 1361/5000, Train Loss: 0.1619\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1202\n",
      "Epoch: 1362/5000, Train Loss: 0.1619\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1201\n",
      "Epoch: 1363/5000, Train Loss: 0.1619\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1201\n",
      "Epoch: 1364/5000, Train Loss: 0.1619\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1200\n",
      "Epoch: 1365/5000, Train Loss: 0.1618\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1200\n",
      "Epoch: 1366/5000, Train Loss: 0.1618\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1200\n",
      "Epoch: 1367/5000, Train Loss: 0.1618\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1199\n",
      "Epoch: 1368/5000, Train Loss: 0.1617\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1199\n",
      "Epoch: 1369/5000, Train Loss: 0.1617\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1198\n",
      "Epoch: 1370/5000, Train Loss: 0.1617\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1198\n",
      "Epoch: 1371/5000, Train Loss: 0.1616\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1197\n",
      "Epoch: 1372/5000, Train Loss: 0.1616\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1197\n",
      "Epoch: 1373/5000, Train Loss: 0.1616\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1196\n",
      "Epoch: 1374/5000, Train Loss: 0.1616\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1196\n",
      "Epoch: 1375/5000, Train Loss: 0.1615\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1195\n",
      "Epoch: 1376/5000, Train Loss: 0.1615\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1195\n",
      "Epoch: 1377/5000, Train Loss: 0.1615\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1194\n",
      "Epoch: 1378/5000, Train Loss: 0.1614\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1194\n",
      "Epoch: 1379/5000, Train Loss: 0.1614\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1193\n",
      "Epoch: 1380/5000, Train Loss: 0.1614\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1193\n",
      "Epoch: 1381/5000, Train Loss: 0.1613\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1193\n",
      "Epoch: 1382/5000, Train Loss: 0.1613\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1192\n",
      "Epoch: 1383/5000, Train Loss: 0.1613\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1192\n",
      "Epoch: 1384/5000, Train Loss: 0.1613\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1191\n",
      "Epoch: 1385/5000, Train Loss: 0.1612\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1191\n",
      "Epoch: 1386/5000, Train Loss: 0.1612\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1190\n",
      "Epoch: 1387/5000, Train Loss: 0.1612\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1190\n",
      "Epoch: 1388/5000, Train Loss: 0.1611\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1189\n",
      "Epoch: 1389/5000, Train Loss: 0.1611\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1189\n",
      "Epoch: 1390/5000, Train Loss: 0.1611\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1188\n",
      "Epoch: 1391/5000, Train Loss: 0.1610\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1188\n",
      "Epoch: 1392/5000, Train Loss: 0.1610\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1187\n",
      "Epoch: 1393/5000, Train Loss: 0.1610\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1187\n",
      "Epoch: 1394/5000, Train Loss: 0.1610\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1187\n",
      "Epoch: 1395/5000, Train Loss: 0.1609\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1186\n",
      "Epoch: 1396/5000, Train Loss: 0.1609\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1186\n",
      "Epoch: 1397/5000, Train Loss: 0.1609\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1185\n",
      "Epoch: 1398/5000, Train Loss: 0.1608\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1185\n",
      "Epoch: 1399/5000, Train Loss: 0.1608\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1184\n",
      "Epoch: 1400/5000, Train Loss: 0.1608\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1184\n",
      "Epoch: 1401/5000, Train Loss: 0.1608\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1183\n",
      "Epoch: 1402/5000, Train Loss: 0.1607\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1183\n",
      "Epoch: 1403/5000, Train Loss: 0.1607\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1182\n",
      "Epoch: 1404/5000, Train Loss: 0.1607\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1182\n",
      "Epoch: 1405/5000, Train Loss: 0.1606\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1182\n",
      "Epoch: 1406/5000, Train Loss: 0.1606\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1181\n",
      "Epoch: 1407/5000, Train Loss: 0.1606\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1181\n",
      "Epoch: 1408/5000, Train Loss: 0.1606\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1180\n",
      "Epoch: 1409/5000, Train Loss: 0.1605\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1180\n",
      "Epoch: 1410/5000, Train Loss: 0.1605\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1179\n",
      "Epoch: 1411/5000, Train Loss: 0.1605\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1179\n",
      "Epoch: 1412/5000, Train Loss: 0.1604\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1178\n",
      "Epoch: 1413/5000, Train Loss: 0.1604\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1178\n",
      "Epoch: 1414/5000, Train Loss: 0.1604\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1178\n",
      "Epoch: 1415/5000, Train Loss: 0.1604\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1177\n",
      "Epoch: 1416/5000, Train Loss: 0.1603\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1177\n",
      "Epoch: 1417/5000, Train Loss: 0.1603\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1176\n",
      "Epoch: 1418/5000, Train Loss: 0.1603\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1176\n",
      "Epoch: 1419/5000, Train Loss: 0.1602\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1175\n",
      "Epoch: 1420/5000, Train Loss: 0.1602\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1175\n",
      "Epoch: 1421/5000, Train Loss: 0.1602\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1174\n",
      "Epoch: 1422/5000, Train Loss: 0.1602\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1174\n",
      "Epoch: 1423/5000, Train Loss: 0.1601\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1173\n",
      "Epoch: 1424/5000, Train Loss: 0.1601\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1173\n",
      "Epoch: 1425/5000, Train Loss: 0.1601\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1173\n",
      "Epoch: 1426/5000, Train Loss: 0.1600\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1172\n",
      "Epoch: 1427/5000, Train Loss: 0.1600\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1172\n",
      "Epoch: 1428/5000, Train Loss: 0.1600\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1171\n",
      "Epoch: 1429/5000, Train Loss: 0.1600\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1171\n",
      "Epoch: 1430/5000, Train Loss: 0.1599\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1170\n",
      "Epoch: 1431/5000, Train Loss: 0.1599\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1170\n",
      "Epoch: 1432/5000, Train Loss: 0.1599\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1170\n",
      "Epoch: 1433/5000, Train Loss: 0.1598\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1169\n",
      "Epoch: 1434/5000, Train Loss: 0.1598\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1169\n",
      "Epoch: 1435/5000, Train Loss: 0.1598\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1168\n",
      "Epoch: 1436/5000, Train Loss: 0.1598\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1168\n",
      "Epoch: 1437/5000, Train Loss: 0.1597\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1167\n",
      "Epoch: 1438/5000, Train Loss: 0.1597\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1167\n",
      "Epoch: 1439/5000, Train Loss: 0.1597\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1166\n",
      "Epoch: 1440/5000, Train Loss: 0.1596\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1166\n",
      "Epoch: 1441/5000, Train Loss: 0.1596\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1166\n",
      "Epoch: 1442/5000, Train Loss: 0.1596\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1165\n",
      "Epoch: 1443/5000, Train Loss: 0.1596\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1165\n",
      "Epoch: 1444/5000, Train Loss: 0.1595\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1164\n",
      "Epoch: 1445/5000, Train Loss: 0.1595\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1164\n",
      "Epoch: 1446/5000, Train Loss: 0.1595\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1163\n",
      "Epoch: 1447/5000, Train Loss: 0.1595\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1163\n",
      "Epoch: 1448/5000, Train Loss: 0.1594\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1163\n",
      "Epoch: 1449/5000, Train Loss: 0.1594\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1162\n",
      "Epoch: 1450/5000, Train Loss: 0.1594\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1162\n",
      "Epoch: 1451/5000, Train Loss: 0.1593\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1161\n",
      "Epoch: 1452/5000, Train Loss: 0.1593\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1161\n",
      "Epoch: 1453/5000, Train Loss: 0.1593\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1160\n",
      "Epoch: 1454/5000, Train Loss: 0.1593\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1160\n",
      "Epoch: 1455/5000, Train Loss: 0.1592\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1160\n",
      "Epoch: 1456/5000, Train Loss: 0.1592\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1159\n",
      "Epoch: 1457/5000, Train Loss: 0.1592\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1159\n",
      "Epoch: 1458/5000, Train Loss: 0.1591\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1158\n",
      "Epoch: 1459/5000, Train Loss: 0.1591\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1158\n",
      "Epoch: 1460/5000, Train Loss: 0.1591\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1157\n",
      "Epoch: 1461/5000, Train Loss: 0.1591\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1157\n",
      "Epoch: 1462/5000, Train Loss: 0.1590\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1157\n",
      "Epoch: 1463/5000, Train Loss: 0.1590\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1156\n",
      "Epoch: 1464/5000, Train Loss: 0.1590\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1156\n",
      "Epoch: 1465/5000, Train Loss: 0.1590\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1155\n",
      "Epoch: 1466/5000, Train Loss: 0.1589\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1155\n",
      "Epoch: 1467/5000, Train Loss: 0.1589\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1154\n",
      "Epoch: 1468/5000, Train Loss: 0.1589\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1154\n",
      "Epoch: 1469/5000, Train Loss: 0.1588\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1154\n",
      "Epoch: 1470/5000, Train Loss: 0.1588\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1153\n",
      "Epoch: 1471/5000, Train Loss: 0.1588\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1153\n",
      "Epoch: 1472/5000, Train Loss: 0.1588\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1152\n",
      "Epoch: 1473/5000, Train Loss: 0.1587\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1152\n",
      "Epoch: 1474/5000, Train Loss: 0.1587\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1151\n",
      "Epoch: 1475/5000, Train Loss: 0.1587\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1151\n",
      "Epoch: 1476/5000, Train Loss: 0.1587\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1151\n",
      "Epoch: 1477/5000, Train Loss: 0.1586\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1150\n",
      "Epoch: 1478/5000, Train Loss: 0.1586\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1150\n",
      "Epoch: 1479/5000, Train Loss: 0.1586\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1149\n",
      "Epoch: 1480/5000, Train Loss: 0.1586\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1149\n",
      "Epoch: 1481/5000, Train Loss: 0.1585\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1148\n",
      "Epoch: 1482/5000, Train Loss: 0.1585\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1148\n",
      "Epoch: 1483/5000, Train Loss: 0.1585\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1148\n",
      "Epoch: 1484/5000, Train Loss: 0.1584\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1147\n",
      "Epoch: 1485/5000, Train Loss: 0.1584\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1147\n",
      "Epoch: 1486/5000, Train Loss: 0.1584\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1146\n",
      "Epoch: 1487/5000, Train Loss: 0.1584\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1146\n",
      "Epoch: 1488/5000, Train Loss: 0.1583\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1146\n",
      "Epoch: 1489/5000, Train Loss: 0.1583\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1145\n",
      "Epoch: 1490/5000, Train Loss: 0.1583\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1145\n",
      "Epoch: 1491/5000, Train Loss: 0.1583\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1144\n",
      "Epoch: 1492/5000, Train Loss: 0.1582\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1144\n",
      "Epoch: 1493/5000, Train Loss: 0.1582\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1143\n",
      "Epoch: 1494/5000, Train Loss: 0.1582\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1143\n",
      "Epoch: 1495/5000, Train Loss: 0.1582\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1143\n",
      "Epoch: 1496/5000, Train Loss: 0.1581\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1142\n",
      "Epoch: 1497/5000, Train Loss: 0.1581\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1142\n",
      "Epoch: 1498/5000, Train Loss: 0.1581\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1141\n",
      "Epoch: 1499/5000, Train Loss: 0.1581\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1141\n",
      "Epoch: 1500/5000, Train Loss: 0.1580\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1141\n",
      "Epoch: 1501/5000, Train Loss: 0.1580\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1140\n",
      "Epoch: 1502/5000, Train Loss: 0.1580\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1140\n",
      "Epoch: 1503/5000, Train Loss: 0.1579\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1139\n",
      "Epoch: 1504/5000, Train Loss: 0.1579\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1139\n",
      "Epoch: 1505/5000, Train Loss: 0.1579\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1138\n",
      "Epoch: 1506/5000, Train Loss: 0.1579\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1138\n",
      "Epoch: 1507/5000, Train Loss: 0.1578\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1138\n",
      "Epoch: 1508/5000, Train Loss: 0.1578\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1137\n",
      "Epoch: 1509/5000, Train Loss: 0.1578\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1137\n",
      "Epoch: 1510/5000, Train Loss: 0.1578\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1136\n",
      "Epoch: 1511/5000, Train Loss: 0.1577\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1136\n",
      "Epoch: 1512/5000, Train Loss: 0.1577\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1136\n",
      "Epoch: 1513/5000, Train Loss: 0.1577\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1135\n",
      "Epoch: 1514/5000, Train Loss: 0.1577\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1135\n",
      "Epoch: 1515/5000, Train Loss: 0.1576\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1134\n",
      "Epoch: 1516/5000, Train Loss: 0.1576\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1134\n",
      "Epoch: 1517/5000, Train Loss: 0.1576\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1134\n",
      "Epoch: 1518/5000, Train Loss: 0.1576\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1133\n",
      "Epoch: 1519/5000, Train Loss: 0.1575\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1133\n",
      "Epoch: 1520/5000, Train Loss: 0.1575\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1132\n",
      "Epoch: 1521/5000, Train Loss: 0.1575\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1132\n",
      "Epoch: 1522/5000, Train Loss: 0.1575\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1132\n",
      "Epoch: 1523/5000, Train Loss: 0.1574\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1131\n",
      "Epoch: 1524/5000, Train Loss: 0.1574\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1131\n",
      "Epoch: 1525/5000, Train Loss: 0.1574\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1130\n",
      "Epoch: 1526/5000, Train Loss: 0.1574\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1130\n",
      "Epoch: 1527/5000, Train Loss: 0.1573\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1130\n",
      "Epoch: 1528/5000, Train Loss: 0.1573\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1129\n",
      "Epoch: 1529/5000, Train Loss: 0.1573\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1129\n",
      "Epoch: 1530/5000, Train Loss: 0.1573\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1128\n",
      "Epoch: 1531/5000, Train Loss: 0.1572\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1128\n",
      "Epoch: 1532/5000, Train Loss: 0.1572\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1128\n",
      "Epoch: 1533/5000, Train Loss: 0.1572\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1127\n",
      "Epoch: 1534/5000, Train Loss: 0.1572\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1127\n",
      "Epoch: 1535/5000, Train Loss: 0.1571\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1126\n",
      "Epoch: 1536/5000, Train Loss: 0.1571\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1126\n",
      "Epoch: 1537/5000, Train Loss: 0.1571\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1126\n",
      "Epoch: 1538/5000, Train Loss: 0.1571\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1125\n",
      "Epoch: 1539/5000, Train Loss: 0.1570\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1125\n",
      "Epoch: 1540/5000, Train Loss: 0.1570\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1124\n",
      "Epoch: 1541/5000, Train Loss: 0.1570\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1124\n",
      "Epoch: 1542/5000, Train Loss: 0.1570\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1124\n",
      "Epoch: 1543/5000, Train Loss: 0.1569\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1123\n",
      "Epoch: 1544/5000, Train Loss: 0.1569\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1123\n",
      "Epoch: 1545/5000, Train Loss: 0.1569\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1122\n",
      "Epoch: 1546/5000, Train Loss: 0.1569\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1122\n",
      "Epoch: 1547/5000, Train Loss: 0.1568\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1122\n",
      "Epoch: 1548/5000, Train Loss: 0.1568\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1121\n",
      "Epoch: 1549/5000, Train Loss: 0.1568\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1121\n",
      "Epoch: 1550/5000, Train Loss: 0.1568\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1120\n",
      "Epoch: 1551/5000, Train Loss: 0.1567\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1120\n",
      "Epoch: 1552/5000, Train Loss: 0.1567\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1120\n",
      "Epoch: 1553/5000, Train Loss: 0.1567\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1119\n",
      "Epoch: 1554/5000, Train Loss: 0.1567\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1119\n",
      "Epoch: 1555/5000, Train Loss: 0.1566\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1118\n",
      "Epoch: 1556/5000, Train Loss: 0.1566\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1118\n",
      "Epoch: 1557/5000, Train Loss: 0.1566\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1118\n",
      "Epoch: 1558/5000, Train Loss: 0.1566\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1117\n",
      "Epoch: 1559/5000, Train Loss: 0.1565\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1117\n",
      "Epoch: 1560/5000, Train Loss: 0.1565\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1116\n",
      "Epoch: 1561/5000, Train Loss: 0.1565\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1116\n",
      "Epoch: 1562/5000, Train Loss: 0.1565\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1116\n",
      "Epoch: 1563/5000, Train Loss: 0.1564\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1115\n",
      "Epoch: 1564/5000, Train Loss: 0.1564\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1115\n",
      "Epoch: 1565/5000, Train Loss: 0.1564\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1115\n",
      "Epoch: 1566/5000, Train Loss: 0.1564\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1114\n",
      "Epoch: 1567/5000, Train Loss: 0.1563\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1114\n",
      "Epoch: 1568/5000, Train Loss: 0.1563\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1113\n",
      "Epoch: 1569/5000, Train Loss: 0.1563\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1113\n",
      "Epoch: 1570/5000, Train Loss: 0.1563\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1113\n",
      "Epoch: 1571/5000, Train Loss: 0.1562\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1112\n",
      "Epoch: 1572/5000, Train Loss: 0.1562\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1112\n",
      "Epoch: 1573/5000, Train Loss: 0.1562\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1111\n",
      "Epoch: 1574/5000, Train Loss: 0.1562\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1111\n",
      "Epoch: 1575/5000, Train Loss: 0.1561\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1111\n",
      "Epoch: 1576/5000, Train Loss: 0.1561\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1110\n",
      "Epoch: 1577/5000, Train Loss: 0.1561\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1110\n",
      "Epoch: 1578/5000, Train Loss: 0.1561\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1110\n",
      "Epoch: 1579/5000, Train Loss: 0.1560\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1109\n",
      "Epoch: 1580/5000, Train Loss: 0.1560\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1109\n",
      "Epoch: 1581/5000, Train Loss: 0.1560\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1108\n",
      "Epoch: 1582/5000, Train Loss: 0.1560\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1108\n",
      "Epoch: 1583/5000, Train Loss: 0.1559\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1108\n",
      "Epoch: 1584/5000, Train Loss: 0.1559\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1107\n",
      "Epoch: 1585/5000, Train Loss: 0.1559\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1107\n",
      "Epoch: 1586/5000, Train Loss: 0.1559\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1106\n",
      "Epoch: 1587/5000, Train Loss: 0.1559\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1106\n",
      "Epoch: 1588/5000, Train Loss: 0.1558\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1106\n",
      "Epoch: 1589/5000, Train Loss: 0.1558\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1105\n",
      "Epoch: 1590/5000, Train Loss: 0.1558\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1105\n",
      "Epoch: 1591/5000, Train Loss: 0.1558\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1105\n",
      "Epoch: 1592/5000, Train Loss: 0.1557\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1104\n",
      "Epoch: 1593/5000, Train Loss: 0.1557\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1104\n",
      "Epoch: 1594/5000, Train Loss: 0.1557\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1103\n",
      "Epoch: 1595/5000, Train Loss: 0.1557\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1103\n",
      "Epoch: 1596/5000, Train Loss: 0.1556\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1103\n",
      "Epoch: 1597/5000, Train Loss: 0.1556\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1102\n",
      "Epoch: 1598/5000, Train Loss: 0.1556\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1102\n",
      "Epoch: 1599/5000, Train Loss: 0.1556\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1102\n",
      "Epoch: 1600/5000, Train Loss: 0.1555\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1101\n",
      "Epoch: 1601/5000, Train Loss: 0.1555\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1101\n",
      "Epoch: 1602/5000, Train Loss: 0.1555\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1100\n",
      "Epoch: 1603/5000, Train Loss: 0.1555\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1100\n",
      "Epoch: 1604/5000, Train Loss: 0.1555\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1100\n",
      "Epoch: 1605/5000, Train Loss: 0.1554\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1099\n",
      "Epoch: 1606/5000, Train Loss: 0.1554\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1099\n",
      "Epoch: 1607/5000, Train Loss: 0.1554\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1099\n",
      "Epoch: 1608/5000, Train Loss: 0.1554\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1098\n",
      "Epoch: 1609/5000, Train Loss: 0.1553\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1098\n",
      "Epoch: 1610/5000, Train Loss: 0.1553\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1097\n",
      "Epoch: 1611/5000, Train Loss: 0.1553\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1097\n",
      "Epoch: 1612/5000, Train Loss: 0.1553\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1097\n",
      "Epoch: 1613/5000, Train Loss: 0.1552\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1096\n",
      "Epoch: 1614/5000, Train Loss: 0.1552\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1096\n",
      "Epoch: 1615/5000, Train Loss: 0.1552\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1096\n",
      "Epoch: 1616/5000, Train Loss: 0.1552\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1095\n",
      "Epoch: 1617/5000, Train Loss: 0.1551\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1095\n",
      "Epoch: 1618/5000, Train Loss: 0.1551\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1094\n",
      "Epoch: 1619/5000, Train Loss: 0.1551\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1094\n",
      "Epoch: 1620/5000, Train Loss: 0.1551\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1094\n",
      "Epoch: 1621/5000, Train Loss: 0.1551\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1093\n",
      "Epoch: 1622/5000, Train Loss: 0.1550\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1093\n",
      "Epoch: 1623/5000, Train Loss: 0.1550\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1093\n",
      "Epoch: 1624/5000, Train Loss: 0.1550\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1092\n",
      "Epoch: 1625/5000, Train Loss: 0.1550\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1092\n",
      "Epoch: 1626/5000, Train Loss: 0.1549\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1091\n",
      "Epoch: 1627/5000, Train Loss: 0.1549\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1091\n",
      "Epoch: 1628/5000, Train Loss: 0.1549\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1091\n",
      "Epoch: 1629/5000, Train Loss: 0.1549\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1090\n",
      "Epoch: 1630/5000, Train Loss: 0.1548\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1090\n",
      "Epoch: 1631/5000, Train Loss: 0.1548\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1090\n",
      "Epoch: 1632/5000, Train Loss: 0.1548\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1089\n",
      "Epoch: 1633/5000, Train Loss: 0.1548\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1089\n",
      "Epoch: 1634/5000, Train Loss: 0.1548\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1089\n",
      "Epoch: 1635/5000, Train Loss: 0.1547\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1088\n",
      "Epoch: 1636/5000, Train Loss: 0.1547\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1088\n",
      "Epoch: 1637/5000, Train Loss: 0.1547\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1087\n",
      "Epoch: 1638/5000, Train Loss: 0.1547\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1087\n",
      "Epoch: 1639/5000, Train Loss: 0.1546\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1087\n",
      "Epoch: 1640/5000, Train Loss: 0.1546\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1086\n",
      "Epoch: 1641/5000, Train Loss: 0.1546\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1086\n",
      "Epoch: 1642/5000, Train Loss: 0.1546\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1086\n",
      "Epoch: 1643/5000, Train Loss: 0.1546\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1085\n",
      "Epoch: 1644/5000, Train Loss: 0.1545\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1085\n",
      "Epoch: 1645/5000, Train Loss: 0.1545\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1085\n",
      "Epoch: 1646/5000, Train Loss: 0.1545\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1084\n",
      "Epoch: 1647/5000, Train Loss: 0.1545\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1084\n",
      "Epoch: 1648/5000, Train Loss: 0.1544\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1083\n",
      "Epoch: 1649/5000, Train Loss: 0.1544\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1083\n",
      "Epoch: 1650/5000, Train Loss: 0.1544\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1083\n",
      "Epoch: 1651/5000, Train Loss: 0.1544\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1082\n",
      "Epoch: 1652/5000, Train Loss: 0.1544\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1082\n",
      "Epoch: 1653/5000, Train Loss: 0.1543\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1082\n",
      "Epoch: 1654/5000, Train Loss: 0.1543\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1081\n",
      "Epoch: 1655/5000, Train Loss: 0.1543\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1081\n",
      "Epoch: 1656/5000, Train Loss: 0.1543\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1081\n",
      "Epoch: 1657/5000, Train Loss: 0.1542\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1080\n",
      "Epoch: 1658/5000, Train Loss: 0.1542\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1080\n",
      "Epoch: 1659/5000, Train Loss: 0.1542\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1080\n",
      "Epoch: 1660/5000, Train Loss: 0.1542\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1079\n",
      "Epoch: 1661/5000, Train Loss: 0.1542\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1079\n",
      "Epoch: 1662/5000, Train Loss: 0.1541\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1078\n",
      "Epoch: 1663/5000, Train Loss: 0.1541\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1078\n",
      "Epoch: 1664/5000, Train Loss: 0.1541\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1078\n",
      "Epoch: 1665/5000, Train Loss: 0.1541\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1077\n",
      "Epoch: 1666/5000, Train Loss: 0.1540\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1077\n",
      "Epoch: 1667/5000, Train Loss: 0.1540\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1077\n",
      "Epoch: 1668/5000, Train Loss: 0.1540\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1076\n",
      "Epoch: 1669/5000, Train Loss: 0.1540\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1076\n",
      "Epoch: 1670/5000, Train Loss: 0.1540\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1076\n",
      "Epoch: 1671/5000, Train Loss: 0.1539\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1075\n",
      "Epoch: 1672/5000, Train Loss: 0.1539\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1075\n",
      "Epoch: 1673/5000, Train Loss: 0.1539\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1075\n",
      "Epoch: 1674/5000, Train Loss: 0.1539\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1074\n",
      "Epoch: 1675/5000, Train Loss: 0.1538\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1074\n",
      "Epoch: 1676/5000, Train Loss: 0.1538\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1073\n",
      "Epoch: 1677/5000, Train Loss: 0.1538\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1073\n",
      "Epoch: 1678/5000, Train Loss: 0.1538\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1073\n",
      "Epoch: 1679/5000, Train Loss: 0.1538\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1072\n",
      "Epoch: 1680/5000, Train Loss: 0.1537\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1072\n",
      "Epoch: 1681/5000, Train Loss: 0.1537\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1072\n",
      "Epoch: 1682/5000, Train Loss: 0.1537\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1071\n",
      "Epoch: 1683/5000, Train Loss: 0.1537\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1071\n",
      "Epoch: 1684/5000, Train Loss: 0.1536\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1071\n",
      "Epoch: 1685/5000, Train Loss: 0.1536\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1070\n",
      "Epoch: 1686/5000, Train Loss: 0.1536\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1070\n",
      "Epoch: 1687/5000, Train Loss: 0.1536\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1070\n",
      "Epoch: 1688/5000, Train Loss: 0.1536\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1069\n",
      "Epoch: 1689/5000, Train Loss: 0.1535\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1069\n",
      "Epoch: 1690/5000, Train Loss: 0.1535\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1069\n",
      "Epoch: 1691/5000, Train Loss: 0.1535\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1068\n",
      "Epoch: 1692/5000, Train Loss: 0.1535\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1068\n",
      "Epoch: 1693/5000, Train Loss: 0.1535\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1068\n",
      "Epoch: 1694/5000, Train Loss: 0.1534\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1067\n",
      "Epoch: 1695/5000, Train Loss: 0.1534\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1067\n",
      "Epoch: 1696/5000, Train Loss: 0.1534\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1067\n",
      "Epoch: 1697/5000, Train Loss: 0.1534\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1066\n",
      "Epoch: 1698/5000, Train Loss: 0.1533\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1066\n",
      "Epoch: 1699/5000, Train Loss: 0.1533\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1065\n",
      "Epoch: 1700/5000, Train Loss: 0.1533\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1065\n",
      "Epoch: 1701/5000, Train Loss: 0.1533\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1065\n",
      "Epoch: 1702/5000, Train Loss: 0.1533\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1064\n",
      "Epoch: 1703/5000, Train Loss: 0.1532\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1064\n",
      "Epoch: 1704/5000, Train Loss: 0.1532\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1064\n",
      "Epoch: 1705/5000, Train Loss: 0.1532\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1063\n",
      "Epoch: 1706/5000, Train Loss: 0.1532\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1063\n",
      "Epoch: 1707/5000, Train Loss: 0.1532\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1063\n",
      "Epoch: 1708/5000, Train Loss: 0.1531\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1062\n",
      "Epoch: 1709/5000, Train Loss: 0.1531\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1062\n",
      "Epoch: 1710/5000, Train Loss: 0.1531\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1062\n",
      "Epoch: 1711/5000, Train Loss: 0.1531\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1061\n",
      "Epoch: 1712/5000, Train Loss: 0.1530\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1061\n",
      "Epoch: 1713/5000, Train Loss: 0.1530\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1061\n",
      "Epoch: 1714/5000, Train Loss: 0.1530\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1060\n",
      "Epoch: 1715/5000, Train Loss: 0.1530\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1060\n",
      "Epoch: 1716/5000, Train Loss: 0.1530\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1060\n",
      "Epoch: 1717/5000, Train Loss: 0.1529\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1059\n",
      "Epoch: 1718/5000, Train Loss: 0.1529\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1059\n",
      "Epoch: 1719/5000, Train Loss: 0.1529\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1059\n",
      "Epoch: 1720/5000, Train Loss: 0.1529\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1058\n",
      "Epoch: 1721/5000, Train Loss: 0.1529\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1058\n",
      "Epoch: 1722/5000, Train Loss: 0.1528\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1058\n",
      "Epoch: 1723/5000, Train Loss: 0.1528\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1057\n",
      "Epoch: 1724/5000, Train Loss: 0.1528\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1057\n",
      "Epoch: 1725/5000, Train Loss: 0.1528\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1057\n",
      "Epoch: 1726/5000, Train Loss: 0.1528\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1056\n",
      "Epoch: 1727/5000, Train Loss: 0.1527\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1056\n",
      "Epoch: 1728/5000, Train Loss: 0.1527\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1056\n",
      "Epoch: 1729/5000, Train Loss: 0.1527\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1055\n",
      "Epoch: 1730/5000, Train Loss: 0.1527\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1055\n",
      "Epoch: 1731/5000, Train Loss: 0.1526\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1055\n",
      "Epoch: 1732/5000, Train Loss: 0.1526\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1054\n",
      "Epoch: 1733/5000, Train Loss: 0.1526\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1054\n",
      "Epoch: 1734/5000, Train Loss: 0.1526\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1054\n",
      "Epoch: 1735/5000, Train Loss: 0.1526\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1053\n",
      "Epoch: 1736/5000, Train Loss: 0.1525\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1053\n",
      "Epoch: 1737/5000, Train Loss: 0.1525\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1053\n",
      "Epoch: 1738/5000, Train Loss: 0.1525\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1052\n",
      "Epoch: 1739/5000, Train Loss: 0.1525\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1052\n",
      "Epoch: 1740/5000, Train Loss: 0.1525\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1052\n",
      "Epoch: 1741/5000, Train Loss: 0.1524\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1051\n",
      "Epoch: 1742/5000, Train Loss: 0.1524\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1051\n",
      "Epoch: 1743/5000, Train Loss: 0.1524\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1051\n",
      "Epoch: 1744/5000, Train Loss: 0.1524\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1050\n",
      "Epoch: 1745/5000, Train Loss: 0.1524\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1050\n",
      "Epoch: 1746/5000, Train Loss: 0.1523\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1050\n",
      "Epoch: 1747/5000, Train Loss: 0.1523\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1049\n",
      "Epoch: 1748/5000, Train Loss: 0.1523\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1049\n",
      "Epoch: 1749/5000, Train Loss: 0.1523\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1049\n",
      "Epoch: 1750/5000, Train Loss: 0.1523\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1048\n",
      "Epoch: 1751/5000, Train Loss: 0.1522\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1048\n",
      "Epoch: 1752/5000, Train Loss: 0.1522\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1048\n",
      "Epoch: 1753/5000, Train Loss: 0.1522\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1047\n",
      "Epoch: 1754/5000, Train Loss: 0.1522\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1047\n",
      "Epoch: 1755/5000, Train Loss: 0.1522\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1047\n",
      "Epoch: 1756/5000, Train Loss: 0.1521\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1046\n",
      "Epoch: 1757/5000, Train Loss: 0.1521\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1046\n",
      "Epoch: 1758/5000, Train Loss: 0.1521\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1046\n",
      "Epoch: 1759/5000, Train Loss: 0.1521\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1045\n",
      "Epoch: 1760/5000, Train Loss: 0.1521\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1045\n",
      "Epoch: 1761/5000, Train Loss: 0.1520\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1045\n",
      "Epoch: 1762/5000, Train Loss: 0.1520\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1044\n",
      "Epoch: 1763/5000, Train Loss: 0.1520\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1044\n",
      "Epoch: 1764/5000, Train Loss: 0.1520\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1044\n",
      "Epoch: 1765/5000, Train Loss: 0.1520\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1043\n",
      "Epoch: 1766/5000, Train Loss: 0.1519\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1043\n",
      "Epoch: 1767/5000, Train Loss: 0.1519\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1043\n",
      "Epoch: 1768/5000, Train Loss: 0.1519\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1042\n",
      "Epoch: 1769/5000, Train Loss: 0.1519\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1042\n",
      "Epoch: 1770/5000, Train Loss: 0.1519\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1042\n",
      "Epoch: 1771/5000, Train Loss: 0.1518\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1041\n",
      "Epoch: 1772/5000, Train Loss: 0.1518\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1041\n",
      "Epoch: 1773/5000, Train Loss: 0.1518\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1041\n",
      "Epoch: 1774/5000, Train Loss: 0.1518\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1040\n",
      "Epoch: 1775/5000, Train Loss: 0.1518\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1040\n",
      "Epoch: 1776/5000, Train Loss: 0.1517\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1040\n",
      "Epoch: 1777/5000, Train Loss: 0.1517\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1039\n",
      "Epoch: 1778/5000, Train Loss: 0.1517\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1039\n",
      "Epoch: 1779/5000, Train Loss: 0.1517\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1039\n",
      "Epoch: 1780/5000, Train Loss: 0.1517\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1038\n",
      "Epoch: 1781/5000, Train Loss: 0.1516\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1038\n",
      "Epoch: 1782/5000, Train Loss: 0.1516\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1038\n",
      "Epoch: 1783/5000, Train Loss: 0.1516\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1037\n",
      "Epoch: 1784/5000, Train Loss: 0.1516\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1037\n",
      "Epoch: 1785/5000, Train Loss: 0.1516\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1037\n",
      "Epoch: 1786/5000, Train Loss: 0.1515\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1036\n",
      "Epoch: 1787/5000, Train Loss: 0.1515\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1036\n",
      "Epoch: 1788/5000, Train Loss: 0.1515\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1036\n",
      "Epoch: 1789/5000, Train Loss: 0.1515\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1035\n",
      "Epoch: 1790/5000, Train Loss: 0.1515\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1035\n",
      "Epoch: 1791/5000, Train Loss: 0.1514\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1035\n",
      "Epoch: 1792/5000, Train Loss: 0.1514\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1035\n",
      "Epoch: 1793/5000, Train Loss: 0.1514\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1034\n",
      "Epoch: 1794/5000, Train Loss: 0.1514\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1034\n",
      "Epoch: 1795/5000, Train Loss: 0.1514\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1034\n",
      "Epoch: 1796/5000, Train Loss: 0.1513\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1033\n",
      "Epoch: 1797/5000, Train Loss: 0.1513\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1033\n",
      "Epoch: 1798/5000, Train Loss: 0.1513\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1033\n",
      "Epoch: 1799/5000, Train Loss: 0.1513\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1032\n",
      "Epoch: 1800/5000, Train Loss: 0.1513\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1032\n",
      "Epoch: 1801/5000, Train Loss: 0.1512\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1032\n",
      "Epoch: 1802/5000, Train Loss: 0.1512\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1031\n",
      "Epoch: 1803/5000, Train Loss: 0.1512\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1031\n",
      "Epoch: 1804/5000, Train Loss: 0.1512\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1031\n",
      "Epoch: 1805/5000, Train Loss: 0.1512\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1030\n",
      "Epoch: 1806/5000, Train Loss: 0.1511\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1030\n",
      "Epoch: 1807/5000, Train Loss: 0.1511\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1030\n",
      "Epoch: 1808/5000, Train Loss: 0.1511\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1029\n",
      "Epoch: 1809/5000, Train Loss: 0.1511\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1029\n",
      "Epoch: 1810/5000, Train Loss: 0.1511\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1029\n",
      "Epoch: 1811/5000, Train Loss: 0.1510\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1028\n",
      "Epoch: 1812/5000, Train Loss: 0.1510\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1028\n",
      "Epoch: 1813/5000, Train Loss: 0.1510\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1028\n",
      "Epoch: 1814/5000, Train Loss: 0.1510\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1028\n",
      "Epoch: 1815/5000, Train Loss: 0.1510\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1027\n",
      "Epoch: 1816/5000, Train Loss: 0.1509\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1027\n",
      "Epoch: 1817/5000, Train Loss: 0.1509\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1027\n",
      "Epoch: 1818/5000, Train Loss: 0.1509\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1026\n",
      "Epoch: 1819/5000, Train Loss: 0.1509\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1026\n",
      "Epoch: 1820/5000, Train Loss: 0.1509\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1026\n",
      "Epoch: 1821/5000, Train Loss: 0.1509\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1025\n",
      "Epoch: 1822/5000, Train Loss: 0.1508\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1025\n",
      "Epoch: 1823/5000, Train Loss: 0.1508\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1025\n",
      "Epoch: 1824/5000, Train Loss: 0.1508\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1024\n",
      "Epoch: 1825/5000, Train Loss: 0.1508\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1024\n",
      "Epoch: 1826/5000, Train Loss: 0.1508\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1024\n",
      "Epoch: 1827/5000, Train Loss: 0.1507\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1023\n",
      "Epoch: 1828/5000, Train Loss: 0.1507\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1023\n",
      "Epoch: 1829/5000, Train Loss: 0.1507\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1023\n",
      "Epoch: 1830/5000, Train Loss: 0.1507\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1023\n",
      "Epoch: 1831/5000, Train Loss: 0.1507\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1022\n",
      "Epoch: 1832/5000, Train Loss: 0.1506\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1022\n",
      "Epoch: 1833/5000, Train Loss: 0.1506\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1022\n",
      "Epoch: 1834/5000, Train Loss: 0.1506\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1021\n",
      "Epoch: 1835/5000, Train Loss: 0.1506\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1021\n",
      "Epoch: 1836/5000, Train Loss: 0.1506\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1021\n",
      "Epoch: 1837/5000, Train Loss: 0.1505\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1020\n",
      "Epoch: 1838/5000, Train Loss: 0.1505\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1020\n",
      "Epoch: 1839/5000, Train Loss: 0.1505\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1020\n",
      "Epoch: 1840/5000, Train Loss: 0.1505\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1019\n",
      "Epoch: 1841/5000, Train Loss: 0.1505\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1019\n",
      "Epoch: 1842/5000, Train Loss: 0.1505\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1019\n",
      "Epoch: 1843/5000, Train Loss: 0.1504\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1019\n",
      "Epoch: 1844/5000, Train Loss: 0.1504\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1018\n",
      "Epoch: 1845/5000, Train Loss: 0.1504\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1018\n",
      "Epoch: 1846/5000, Train Loss: 0.1504\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1018\n",
      "Epoch: 1847/5000, Train Loss: 0.1504\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1017\n",
      "Epoch: 1848/5000, Train Loss: 0.1503\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1017\n",
      "Epoch: 1849/5000, Train Loss: 0.1503\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1017\n",
      "Epoch: 1850/5000, Train Loss: 0.1503\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1016\n",
      "Epoch: 1851/5000, Train Loss: 0.1503\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1016\n",
      "Epoch: 1852/5000, Train Loss: 0.1503\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1016\n",
      "Epoch: 1853/5000, Train Loss: 0.1502\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1015\n",
      "Epoch: 1854/5000, Train Loss: 0.1502\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1015\n",
      "Epoch: 1855/5000, Train Loss: 0.1502\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1015\n",
      "Epoch: 1856/5000, Train Loss: 0.1502\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1015\n",
      "Epoch: 1857/5000, Train Loss: 0.1502\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1014\n",
      "Epoch: 1858/5000, Train Loss: 0.1502\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1014\n",
      "Epoch: 1859/5000, Train Loss: 0.1501\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1014\n",
      "Epoch: 1860/5000, Train Loss: 0.1501\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1013\n",
      "Epoch: 1861/5000, Train Loss: 0.1501\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1013\n",
      "Epoch: 1862/5000, Train Loss: 0.1501\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1013\n",
      "Epoch: 1863/5000, Train Loss: 0.1501\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1012\n",
      "Epoch: 1864/5000, Train Loss: 0.1500\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1012\n",
      "Epoch: 1865/5000, Train Loss: 0.1500\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1012\n",
      "Epoch: 1866/5000, Train Loss: 0.1500\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1012\n",
      "Epoch: 1867/5000, Train Loss: 0.1500\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1011\n",
      "Epoch: 1868/5000, Train Loss: 0.1500\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1011\n",
      "Epoch: 1869/5000, Train Loss: 0.1500\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1011\n",
      "Epoch: 1870/5000, Train Loss: 0.1499\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1010\n",
      "Epoch: 1871/5000, Train Loss: 0.1499\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1010\n",
      "Epoch: 1872/5000, Train Loss: 0.1499\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1010\n",
      "Epoch: 1873/5000, Train Loss: 0.1499\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1009\n",
      "Epoch: 1874/5000, Train Loss: 0.1499\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1009\n",
      "Epoch: 1875/5000, Train Loss: 0.1498\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1009\n",
      "Epoch: 1876/5000, Train Loss: 0.1498\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1008\n",
      "Epoch: 1877/5000, Train Loss: 0.1498\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1008\n",
      "Epoch: 1878/5000, Train Loss: 0.1498\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1008\n",
      "Epoch: 1879/5000, Train Loss: 0.1498\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1008\n",
      "Epoch: 1880/5000, Train Loss: 0.1497\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1007\n",
      "Epoch: 1881/5000, Train Loss: 0.1497\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1007\n",
      "Epoch: 1882/5000, Train Loss: 0.1497\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1007\n",
      "Epoch: 1883/5000, Train Loss: 0.1497\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1006\n",
      "Epoch: 1884/5000, Train Loss: 0.1497\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1006\n",
      "Epoch: 1885/5000, Train Loss: 0.1497\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1006\n",
      "Epoch: 1886/5000, Train Loss: 0.1496\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1006\n",
      "Epoch: 1887/5000, Train Loss: 0.1496\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1005\n",
      "Epoch: 1888/5000, Train Loss: 0.1496\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1005\n",
      "Epoch: 1889/5000, Train Loss: 0.1496\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1005\n",
      "Epoch: 1890/5000, Train Loss: 0.1496\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1004\n",
      "Epoch: 1891/5000, Train Loss: 0.1495\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1004\n",
      "Epoch: 1892/5000, Train Loss: 0.1495\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1004\n",
      "Epoch: 1893/5000, Train Loss: 0.1495\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1003\n",
      "Epoch: 1894/5000, Train Loss: 0.1495\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1003\n",
      "Epoch: 1895/5000, Train Loss: 0.1495\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1003\n",
      "Epoch: 1896/5000, Train Loss: 0.1495\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1003\n",
      "Epoch: 1897/5000, Train Loss: 0.1494\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1002\n",
      "Epoch: 1898/5000, Train Loss: 0.1494\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1002\n",
      "Epoch: 1899/5000, Train Loss: 0.1494\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1002\n",
      "Epoch: 1900/5000, Train Loss: 0.1494\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1001\n",
      "Epoch: 1901/5000, Train Loss: 0.1494\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1001\n",
      "Epoch: 1902/5000, Train Loss: 0.1494\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1001\n",
      "Epoch: 1903/5000, Train Loss: 0.1493\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1000\n",
      "Epoch: 1904/5000, Train Loss: 0.1493\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1000\n",
      "Epoch: 1905/5000, Train Loss: 0.1493\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1000\n",
      "Epoch: 1906/5000, Train Loss: 0.1493\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.1000\n",
      "Epoch: 1907/5000, Train Loss: 0.1493\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0999\n",
      "Epoch: 1908/5000, Train Loss: 0.1492\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0999\n",
      "Epoch: 1909/5000, Train Loss: 0.1492\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0999\n",
      "Epoch: 1910/5000, Train Loss: 0.1492\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0998\n",
      "Epoch: 1911/5000, Train Loss: 0.1492\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0998\n",
      "Epoch: 1912/5000, Train Loss: 0.1492\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0998\n",
      "Epoch: 1913/5000, Train Loss: 0.1492\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0998\n",
      "Epoch: 1914/5000, Train Loss: 0.1491\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0997\n",
      "Epoch: 1915/5000, Train Loss: 0.1491\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0997\n",
      "Epoch: 1916/5000, Train Loss: 0.1491\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0997\n",
      "Epoch: 1917/5000, Train Loss: 0.1491\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0996\n",
      "Epoch: 1918/5000, Train Loss: 0.1491\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0996\n",
      "Epoch: 1919/5000, Train Loss: 0.1490\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0996\n",
      "Epoch: 1920/5000, Train Loss: 0.1490\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0996\n",
      "Epoch: 1921/5000, Train Loss: 0.1490\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0995\n",
      "Epoch: 1922/5000, Train Loss: 0.1490\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0995\n",
      "Epoch: 1923/5000, Train Loss: 0.1490\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0995\n",
      "Epoch: 1924/5000, Train Loss: 0.1490\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0994\n",
      "Epoch: 1925/5000, Train Loss: 0.1489\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0994\n",
      "Epoch: 1926/5000, Train Loss: 0.1489\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0994\n",
      "Epoch: 1927/5000, Train Loss: 0.1489\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0993\n",
      "Epoch: 1928/5000, Train Loss: 0.1489\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0993\n",
      "Epoch: 1929/5000, Train Loss: 0.1489\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0993\n",
      "Epoch: 1930/5000, Train Loss: 0.1489\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0993\n",
      "Epoch: 1931/5000, Train Loss: 0.1488\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0992\n",
      "Epoch: 1932/5000, Train Loss: 0.1488\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0992\n",
      "Epoch: 1933/5000, Train Loss: 0.1488\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0992\n",
      "Epoch: 1934/5000, Train Loss: 0.1488\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0991\n",
      "Epoch: 1935/5000, Train Loss: 0.1488\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0991\n",
      "Epoch: 1936/5000, Train Loss: 0.1488\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0991\n",
      "Epoch: 1937/5000, Train Loss: 0.1487\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0991\n",
      "Epoch: 1938/5000, Train Loss: 0.1487\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0990\n",
      "Epoch: 1939/5000, Train Loss: 0.1487\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0990\n",
      "Epoch: 1940/5000, Train Loss: 0.1487\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0990\n",
      "Epoch: 1941/5000, Train Loss: 0.1487\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0989\n",
      "Epoch: 1942/5000, Train Loss: 0.1486\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0989\n",
      "Epoch: 1943/5000, Train Loss: 0.1486\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0989\n",
      "Epoch: 1944/5000, Train Loss: 0.1486\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0989\n",
      "Epoch: 1945/5000, Train Loss: 0.1486\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0988\n",
      "Epoch: 1946/5000, Train Loss: 0.1486\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0988\n",
      "Epoch: 1947/5000, Train Loss: 0.1486\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0988\n",
      "Epoch: 1948/5000, Train Loss: 0.1485\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0987\n",
      "Epoch: 1949/5000, Train Loss: 0.1485\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0987\n",
      "Epoch: 1950/5000, Train Loss: 0.1485\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0987\n",
      "Epoch: 1951/5000, Train Loss: 0.1485\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0987\n",
      "Epoch: 1952/5000, Train Loss: 0.1485\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0986\n",
      "Epoch: 1953/5000, Train Loss: 0.1485\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0986\n",
      "Epoch: 1954/5000, Train Loss: 0.1484\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0986\n",
      "Epoch: 1955/5000, Train Loss: 0.1484\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0986\n",
      "Epoch: 1956/5000, Train Loss: 0.1484\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0985\n",
      "Epoch: 1957/5000, Train Loss: 0.1484\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0985\n",
      "Epoch: 1958/5000, Train Loss: 0.1484\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0985\n",
      "Epoch: 1959/5000, Train Loss: 0.1484\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0984\n",
      "Epoch: 1960/5000, Train Loss: 0.1483\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0984\n",
      "Epoch: 1961/5000, Train Loss: 0.1483\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0984\n",
      "Epoch: 1962/5000, Train Loss: 0.1483\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0984\n",
      "Epoch: 1963/5000, Train Loss: 0.1483\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0983\n",
      "Epoch: 1964/5000, Train Loss: 0.1483\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0983\n",
      "Epoch: 1965/5000, Train Loss: 0.1483\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0983\n",
      "Epoch: 1966/5000, Train Loss: 0.1482\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0982\n",
      "Epoch: 1967/5000, Train Loss: 0.1482\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0982\n",
      "Epoch: 1968/5000, Train Loss: 0.1482\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0982\n",
      "Epoch: 1969/5000, Train Loss: 0.1482\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0982\n",
      "Epoch: 1970/5000, Train Loss: 0.1482\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0981\n",
      "Epoch: 1971/5000, Train Loss: 0.1482\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0981\n",
      "Epoch: 1972/5000, Train Loss: 0.1481\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0981\n",
      "Epoch: 1973/5000, Train Loss: 0.1481\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0980\n",
      "Epoch: 1974/5000, Train Loss: 0.1481\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0980\n",
      "Epoch: 1975/5000, Train Loss: 0.1481\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0980\n",
      "Epoch: 1976/5000, Train Loss: 0.1481\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0980\n",
      "Epoch: 1977/5000, Train Loss: 0.1481\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0979\n",
      "Epoch: 1978/5000, Train Loss: 0.1480\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0979\n",
      "Epoch: 1979/5000, Train Loss: 0.1480\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0979\n",
      "Epoch: 1980/5000, Train Loss: 0.1480\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0979\n",
      "Epoch: 1981/5000, Train Loss: 0.1480\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0978\n",
      "Epoch: 1982/5000, Train Loss: 0.1480\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0978\n",
      "Epoch: 1983/5000, Train Loss: 0.1480\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0978\n",
      "Epoch: 1984/5000, Train Loss: 0.1479\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0977\n",
      "Epoch: 1985/5000, Train Loss: 0.1479\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0977\n",
      "Epoch: 1986/5000, Train Loss: 0.1479\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0977\n",
      "Epoch: 1987/5000, Train Loss: 0.1479\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0977\n",
      "Epoch: 1988/5000, Train Loss: 0.1479\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0976\n",
      "Epoch: 1989/5000, Train Loss: 0.1479\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0976\n",
      "Epoch: 1990/5000, Train Loss: 0.1478\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0976\n",
      "Epoch: 1991/5000, Train Loss: 0.1478\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0975\n",
      "Epoch: 1992/5000, Train Loss: 0.1478\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0975\n",
      "Epoch: 1993/5000, Train Loss: 0.1478\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0975\n",
      "Epoch: 1994/5000, Train Loss: 0.1478\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0975\n",
      "Epoch: 1995/5000, Train Loss: 0.1478\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0974\n",
      "Epoch: 1996/5000, Train Loss: 0.1477\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0974\n",
      "Epoch: 1997/5000, Train Loss: 0.1477\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0974\n",
      "Epoch: 1998/5000, Train Loss: 0.1477\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0974\n",
      "Epoch: 1999/5000, Train Loss: 0.1477\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0973\n",
      "Epoch: 2000/5000, Train Loss: 0.1477\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0973\n",
      "Epoch: 2001/5000, Train Loss: 0.1477\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0973\n",
      "Epoch: 2002/5000, Train Loss: 0.1476\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0972\n",
      "Epoch: 2003/5000, Train Loss: 0.1476\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0972\n",
      "Epoch: 2004/5000, Train Loss: 0.1476\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0972\n",
      "Epoch: 2005/5000, Train Loss: 0.1476\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0972\n",
      "Epoch: 2006/5000, Train Loss: 0.1476\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0971\n",
      "Epoch: 2007/5000, Train Loss: 0.1476\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0971\n",
      "Epoch: 2008/5000, Train Loss: 0.1475\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0971\n",
      "Epoch: 2009/5000, Train Loss: 0.1475\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0971\n",
      "Epoch: 2010/5000, Train Loss: 0.1475\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0970\n",
      "Epoch: 2011/5000, Train Loss: 0.1475\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0970\n",
      "Epoch: 2012/5000, Train Loss: 0.1475\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0970\n",
      "Epoch: 2013/5000, Train Loss: 0.1475\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0969\n",
      "Epoch: 2014/5000, Train Loss: 0.1474\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0969\n",
      "Epoch: 2015/5000, Train Loss: 0.1474\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0969\n",
      "Epoch: 2016/5000, Train Loss: 0.1474\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0969\n",
      "Epoch: 2017/5000, Train Loss: 0.1474\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0968\n",
      "Epoch: 2018/5000, Train Loss: 0.1474\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0968\n",
      "Epoch: 2019/5000, Train Loss: 0.1474\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0968\n",
      "Epoch: 2020/5000, Train Loss: 0.1473\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0968\n",
      "Epoch: 2021/5000, Train Loss: 0.1473\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0967\n",
      "Epoch: 2022/5000, Train Loss: 0.1473\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0967\n",
      "Epoch: 2023/5000, Train Loss: 0.1473\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0967\n",
      "Epoch: 2024/5000, Train Loss: 0.1473\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0966\n",
      "Epoch: 2025/5000, Train Loss: 0.1473\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0966\n",
      "Epoch: 2026/5000, Train Loss: 0.1472\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0966\n",
      "Epoch: 2027/5000, Train Loss: 0.1472\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0966\n",
      "Epoch: 2028/5000, Train Loss: 0.1472\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0965\n",
      "Epoch: 2029/5000, Train Loss: 0.1472\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0965\n",
      "Epoch: 2030/5000, Train Loss: 0.1472\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0965\n",
      "Epoch: 2031/5000, Train Loss: 0.1472\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0965\n",
      "Epoch: 2032/5000, Train Loss: 0.1471\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0964\n",
      "Epoch: 2033/5000, Train Loss: 0.1471\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0964\n",
      "Epoch: 2034/5000, Train Loss: 0.1471\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0964\n",
      "Epoch: 2035/5000, Train Loss: 0.1471\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0964\n",
      "Epoch: 2036/5000, Train Loss: 0.1471\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0963\n",
      "Epoch: 2037/5000, Train Loss: 0.1471\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0963\n",
      "Epoch: 2038/5000, Train Loss: 0.1471\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0963\n",
      "Epoch: 2039/5000, Train Loss: 0.1470\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0962\n",
      "Epoch: 2040/5000, Train Loss: 0.1470\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0962\n",
      "Epoch: 2041/5000, Train Loss: 0.1470\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0962\n",
      "Epoch: 2042/5000, Train Loss: 0.1470\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0962\n",
      "Epoch: 2043/5000, Train Loss: 0.1470\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0961\n",
      "Epoch: 2044/5000, Train Loss: 0.1470\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0961\n",
      "Epoch: 2045/5000, Train Loss: 0.1469\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0961\n",
      "Epoch: 2046/5000, Train Loss: 0.1469\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0961\n",
      "Epoch: 2047/5000, Train Loss: 0.1469\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0960\n",
      "Epoch: 2048/5000, Train Loss: 0.1469\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0960\n",
      "Epoch: 2049/5000, Train Loss: 0.1469\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0960\n",
      "Epoch: 2050/5000, Train Loss: 0.1469\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0960\n",
      "Epoch: 2051/5000, Train Loss: 0.1468\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0959\n",
      "Epoch: 2052/5000, Train Loss: 0.1468\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0959\n",
      "Epoch: 2053/5000, Train Loss: 0.1468\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0959\n",
      "Epoch: 2054/5000, Train Loss: 0.1468\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0959\n",
      "Epoch: 2055/5000, Train Loss: 0.1468\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0958\n",
      "Epoch: 2056/5000, Train Loss: 0.1468\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0958\n",
      "Epoch: 2057/5000, Train Loss: 0.1467\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0958\n",
      "Epoch: 2058/5000, Train Loss: 0.1467\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0957\n",
      "Epoch: 2059/5000, Train Loss: 0.1467\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0957\n",
      "Epoch: 2060/5000, Train Loss: 0.1467\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0957\n",
      "Epoch: 2061/5000, Train Loss: 0.1467\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0957\n",
      "Epoch: 2062/5000, Train Loss: 0.1467\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0956\n",
      "Epoch: 2063/5000, Train Loss: 0.1467\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0956\n",
      "Epoch: 2064/5000, Train Loss: 0.1466\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0956\n",
      "Epoch: 2065/5000, Train Loss: 0.1466\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0956\n",
      "Epoch: 2066/5000, Train Loss: 0.1466\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0955\n",
      "Epoch: 2067/5000, Train Loss: 0.1466\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0955\n",
      "Epoch: 2068/5000, Train Loss: 0.1466\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0955\n",
      "Epoch: 2069/5000, Train Loss: 0.1466\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0955\n",
      "Epoch: 2070/5000, Train Loss: 0.1465\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0954\n",
      "Epoch: 2071/5000, Train Loss: 0.1465\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0954\n",
      "Epoch: 2072/5000, Train Loss: 0.1465\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0954\n",
      "Epoch: 2073/5000, Train Loss: 0.1465\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0954\n",
      "Epoch: 2074/5000, Train Loss: 0.1465\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0953\n",
      "Epoch: 2075/5000, Train Loss: 0.1465\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0953\n",
      "Epoch: 2076/5000, Train Loss: 0.1465\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0953\n",
      "Epoch: 2077/5000, Train Loss: 0.1464\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0953\n",
      "Epoch: 2078/5000, Train Loss: 0.1464\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0952\n",
      "Epoch: 2079/5000, Train Loss: 0.1464\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0952\n",
      "Epoch: 2080/5000, Train Loss: 0.1464\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0952\n",
      "Epoch: 2081/5000, Train Loss: 0.1464\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0951\n",
      "Epoch: 2082/5000, Train Loss: 0.1464\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0951\n",
      "Epoch: 2083/5000, Train Loss: 0.1463\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0951\n",
      "Epoch: 2084/5000, Train Loss: 0.1463\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0951\n",
      "Epoch: 2085/5000, Train Loss: 0.1463\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0950\n",
      "Epoch: 2086/5000, Train Loss: 0.1463\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0950\n",
      "Epoch: 2087/5000, Train Loss: 0.1463\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0950\n",
      "Epoch: 2088/5000, Train Loss: 0.1463\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0950\n",
      "Epoch: 2089/5000, Train Loss: 0.1463\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0949\n",
      "Epoch: 2090/5000, Train Loss: 0.1462\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0949\n",
      "Epoch: 2091/5000, Train Loss: 0.1462\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0949\n",
      "Epoch: 2092/5000, Train Loss: 0.1462\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0949\n",
      "Epoch: 2093/5000, Train Loss: 0.1462\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0948\n",
      "Epoch: 2094/5000, Train Loss: 0.1462\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0948\n",
      "Epoch: 2095/5000, Train Loss: 0.1462\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0948\n",
      "Epoch: 2096/5000, Train Loss: 0.1461\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0948\n",
      "Epoch: 2097/5000, Train Loss: 0.1461\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0947\n",
      "Epoch: 2098/5000, Train Loss: 0.1461\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0947\n",
      "Epoch: 2099/5000, Train Loss: 0.1461\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0947\n",
      "Epoch: 2100/5000, Train Loss: 0.1461\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0947\n",
      "Epoch: 2101/5000, Train Loss: 0.1461\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0946\n",
      "Epoch: 2102/5000, Train Loss: 0.1461\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0946\n",
      "Epoch: 2103/5000, Train Loss: 0.1460\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0946\n",
      "Epoch: 2104/5000, Train Loss: 0.1460\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0946\n",
      "Epoch: 2105/5000, Train Loss: 0.1460\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0945\n",
      "Epoch: 2106/5000, Train Loss: 0.1460\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0945\n",
      "Epoch: 2107/5000, Train Loss: 0.1460\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0945\n",
      "Epoch: 2108/5000, Train Loss: 0.1460\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0945\n",
      "Epoch: 2109/5000, Train Loss: 0.1459\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0944\n",
      "Epoch: 2110/5000, Train Loss: 0.1459\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0944\n",
      "Epoch: 2111/5000, Train Loss: 0.1459\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0944\n",
      "Epoch: 2112/5000, Train Loss: 0.1459\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0944\n",
      "Epoch: 2113/5000, Train Loss: 0.1459\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0943\n",
      "Epoch: 2114/5000, Train Loss: 0.1459\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0943\n",
      "Epoch: 2115/5000, Train Loss: 0.1459\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0943\n",
      "Epoch: 2116/5000, Train Loss: 0.1458\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0943\n",
      "Epoch: 2117/5000, Train Loss: 0.1458\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0942\n",
      "Epoch: 2118/5000, Train Loss: 0.1458\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0942\n",
      "Epoch: 2119/5000, Train Loss: 0.1458\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0942\n",
      "Epoch: 2120/5000, Train Loss: 0.1458\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0942\n",
      "Epoch: 2121/5000, Train Loss: 0.1458\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0941\n",
      "Epoch: 2122/5000, Train Loss: 0.1457\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0941\n",
      "Epoch: 2123/5000, Train Loss: 0.1457\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0941\n",
      "Epoch: 2124/5000, Train Loss: 0.1457\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0941\n",
      "Epoch: 2125/5000, Train Loss: 0.1457\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0940\n",
      "Epoch: 2126/5000, Train Loss: 0.1457\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0940\n",
      "Epoch: 2127/5000, Train Loss: 0.1457\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0940\n",
      "Epoch: 2128/5000, Train Loss: 0.1457\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0940\n",
      "Epoch: 2129/5000, Train Loss: 0.1456\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0939\n",
      "Epoch: 2130/5000, Train Loss: 0.1456\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0939\n",
      "Epoch: 2131/5000, Train Loss: 0.1456\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0939\n",
      "Epoch: 2132/5000, Train Loss: 0.1456\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0939\n",
      "Epoch: 2133/5000, Train Loss: 0.1456\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0938\n",
      "Epoch: 2134/5000, Train Loss: 0.1456\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0938\n",
      "Epoch: 2135/5000, Train Loss: 0.1456\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0938\n",
      "Epoch: 2136/5000, Train Loss: 0.1455\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0938\n",
      "Epoch: 2137/5000, Train Loss: 0.1455\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0937\n",
      "Epoch: 2138/5000, Train Loss: 0.1455\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0937\n",
      "Epoch: 2139/5000, Train Loss: 0.1455\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0937\n",
      "Epoch: 2140/5000, Train Loss: 0.1455\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0937\n",
      "Epoch: 2141/5000, Train Loss: 0.1455\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0936\n",
      "Epoch: 2142/5000, Train Loss: 0.1455\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0936\n",
      "Epoch: 2143/5000, Train Loss: 0.1454\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0936\n",
      "Epoch: 2144/5000, Train Loss: 0.1454\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0936\n",
      "Epoch: 2145/5000, Train Loss: 0.1454\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0935\n",
      "Epoch: 2146/5000, Train Loss: 0.1454\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0935\n",
      "Epoch: 2147/5000, Train Loss: 0.1454\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0935\n",
      "Epoch: 2148/5000, Train Loss: 0.1454\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0935\n",
      "Epoch: 2149/5000, Train Loss: 0.1453\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0934\n",
      "Epoch: 2150/5000, Train Loss: 0.1453\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0934\n",
      "Epoch: 2151/5000, Train Loss: 0.1453\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0934\n",
      "Epoch: 2152/5000, Train Loss: 0.1453\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0934\n",
      "Epoch: 2153/5000, Train Loss: 0.1453\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0933\n",
      "Epoch: 2154/5000, Train Loss: 0.1453\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0933\n",
      "Epoch: 2155/5000, Train Loss: 0.1453\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0933\n",
      "Epoch: 2156/5000, Train Loss: 0.1452\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0933\n",
      "Epoch: 2157/5000, Train Loss: 0.1452\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0932\n",
      "Epoch: 2158/5000, Train Loss: 0.1452\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0932\n",
      "Epoch: 2159/5000, Train Loss: 0.1452\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0932\n",
      "Epoch: 2160/5000, Train Loss: 0.1452\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0932\n",
      "Epoch: 2161/5000, Train Loss: 0.1452\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0931\n",
      "Epoch: 2162/5000, Train Loss: 0.1452\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0931\n",
      "Epoch: 2163/5000, Train Loss: 0.1451\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0931\n",
      "Epoch: 2164/5000, Train Loss: 0.1451\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0931\n",
      "Epoch: 2165/5000, Train Loss: 0.1451\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0930\n",
      "Epoch: 2166/5000, Train Loss: 0.1451\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0930\n",
      "Epoch: 2167/5000, Train Loss: 0.1451\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0930\n",
      "Epoch: 2168/5000, Train Loss: 0.1451\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0930\n",
      "Epoch: 2169/5000, Train Loss: 0.1451\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0929\n",
      "Epoch: 2170/5000, Train Loss: 0.1450\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0929\n",
      "Epoch: 2171/5000, Train Loss: 0.1450\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0929\n",
      "Epoch: 2172/5000, Train Loss: 0.1450\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0929\n",
      "Epoch: 2173/5000, Train Loss: 0.1450\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0928\n",
      "Epoch: 2174/5000, Train Loss: 0.1450\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0928\n",
      "Epoch: 2175/5000, Train Loss: 0.1450\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0928\n",
      "Epoch: 2176/5000, Train Loss: 0.1450\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0928\n",
      "Epoch: 2177/5000, Train Loss: 0.1449\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0928\n",
      "Epoch: 2178/5000, Train Loss: 0.1449\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0927\n",
      "Epoch: 2179/5000, Train Loss: 0.1449\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0927\n",
      "Epoch: 2180/5000, Train Loss: 0.1449\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0927\n",
      "Epoch: 2181/5000, Train Loss: 0.1449\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0927\n",
      "Epoch: 2182/5000, Train Loss: 0.1449\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0926\n",
      "Epoch: 2183/5000, Train Loss: 0.1449\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0926\n",
      "Epoch: 2184/5000, Train Loss: 0.1448\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0926\n",
      "Epoch: 2185/5000, Train Loss: 0.1448\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0926\n",
      "Epoch: 2186/5000, Train Loss: 0.1448\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0925\n",
      "Epoch: 2187/5000, Train Loss: 0.1448\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0925\n",
      "Epoch: 2188/5000, Train Loss: 0.1448\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0925\n",
      "Epoch: 2189/5000, Train Loss: 0.1448\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0925\n",
      "Epoch: 2190/5000, Train Loss: 0.1448\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0924\n",
      "Epoch: 2191/5000, Train Loss: 0.1447\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0924\n",
      "Epoch: 2192/5000, Train Loss: 0.1447\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0924\n",
      "Epoch: 2193/5000, Train Loss: 0.1447\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0924\n",
      "Epoch: 2194/5000, Train Loss: 0.1447\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0923\n",
      "Epoch: 2195/5000, Train Loss: 0.1447\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0923\n",
      "Epoch: 2196/5000, Train Loss: 0.1447\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0923\n",
      "Epoch: 2197/5000, Train Loss: 0.1447\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0923\n",
      "Epoch: 2198/5000, Train Loss: 0.1446\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0922\n",
      "Epoch: 2199/5000, Train Loss: 0.1446\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0922\n",
      "Epoch: 2200/5000, Train Loss: 0.1446\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0922\n",
      "Epoch: 2201/5000, Train Loss: 0.1446\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0922\n",
      "Epoch: 2202/5000, Train Loss: 0.1446\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0922\n",
      "Epoch: 2203/5000, Train Loss: 0.1446\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0921\n",
      "Epoch: 2204/5000, Train Loss: 0.1446\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0921\n",
      "Epoch: 2205/5000, Train Loss: 0.1445\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0921\n",
      "Epoch: 2206/5000, Train Loss: 0.1445\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0921\n",
      "Epoch: 2207/5000, Train Loss: 0.1445\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0920\n",
      "Epoch: 2208/5000, Train Loss: 0.1445\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0920\n",
      "Epoch: 2209/5000, Train Loss: 0.1445\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0920\n",
      "Epoch: 2210/5000, Train Loss: 0.1445\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0920\n",
      "Epoch: 2211/5000, Train Loss: 0.1445\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0919\n",
      "Epoch: 2212/5000, Train Loss: 0.1444\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0919\n",
      "Epoch: 2213/5000, Train Loss: 0.1444\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0919\n",
      "Epoch: 2214/5000, Train Loss: 0.1444\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0919\n",
      "Epoch: 2215/5000, Train Loss: 0.1444\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0918\n",
      "Epoch: 2216/5000, Train Loss: 0.1444\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0918\n",
      "Epoch: 2217/5000, Train Loss: 0.1444\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0918\n",
      "Epoch: 2218/5000, Train Loss: 0.1444\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0918\n",
      "Epoch: 2219/5000, Train Loss: 0.1443\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0918\n",
      "Epoch: 2220/5000, Train Loss: 0.1443\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0917\n",
      "Epoch: 2221/5000, Train Loss: 0.1443\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0917\n",
      "Epoch: 2222/5000, Train Loss: 0.1443\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0917\n",
      "Epoch: 2223/5000, Train Loss: 0.1443\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0917\n",
      "Epoch: 2224/5000, Train Loss: 0.1443\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0916\n",
      "Epoch: 2225/5000, Train Loss: 0.1443\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0916\n",
      "Epoch: 2226/5000, Train Loss: 0.1442\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0916\n",
      "Epoch: 2227/5000, Train Loss: 0.1442\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0916\n",
      "Epoch: 2228/5000, Train Loss: 0.1442\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0915\n",
      "Epoch: 2229/5000, Train Loss: 0.1442\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0915\n",
      "Epoch: 2230/5000, Train Loss: 0.1442\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0915\n",
      "Epoch: 2231/5000, Train Loss: 0.1442\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0915\n",
      "Epoch: 2232/5000, Train Loss: 0.1442\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0914\n",
      "Epoch: 2233/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0914\n",
      "Epoch: 2234/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0914\n",
      "Epoch: 2235/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0914\n",
      "Epoch: 2236/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0914\n",
      "Epoch: 2237/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0913\n",
      "Epoch: 2238/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0913\n",
      "Epoch: 2239/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0913\n",
      "Epoch: 2240/5000, Train Loss: 0.1441\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0913\n",
      "Epoch: 2241/5000, Train Loss: 0.1440\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0912\n",
      "Epoch: 2242/5000, Train Loss: 0.1440\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0912\n",
      "Epoch: 2243/5000, Train Loss: 0.1440\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0912\n",
      "Epoch: 2244/5000, Train Loss: 0.1440\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0912\n",
      "Epoch: 2245/5000, Train Loss: 0.1440\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0911\n",
      "Epoch: 2246/5000, Train Loss: 0.1440\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0911\n",
      "Epoch: 2247/5000, Train Loss: 0.1440\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0911\n",
      "Epoch: 2248/5000, Train Loss: 0.1439\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0911\n",
      "Epoch: 2249/5000, Train Loss: 0.1439\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0911\n",
      "Epoch: 2250/5000, Train Loss: 0.1439\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0910\n",
      "Epoch: 2251/5000, Train Loss: 0.1439\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0910\n",
      "Epoch: 2252/5000, Train Loss: 0.1439\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0910\n",
      "Epoch: 2253/5000, Train Loss: 0.1439\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0910\n",
      "Epoch: 2254/5000, Train Loss: 0.1439\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0909\n",
      "Epoch: 2255/5000, Train Loss: 0.1438\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0909\n",
      "Epoch: 2256/5000, Train Loss: 0.1438\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0909\n",
      "Epoch: 2257/5000, Train Loss: 0.1438\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0909\n",
      "Epoch: 2258/5000, Train Loss: 0.1438\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0908\n",
      "Epoch: 2259/5000, Train Loss: 0.1438\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0908\n",
      "Epoch: 2260/5000, Train Loss: 0.1438\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0908\n",
      "Epoch: 2261/5000, Train Loss: 0.1438\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0908\n",
      "Epoch: 2262/5000, Train Loss: 0.1438\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0908\n",
      "Epoch: 2263/5000, Train Loss: 0.1437\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0907\n",
      "Epoch: 2264/5000, Train Loss: 0.1437\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0907\n",
      "Epoch: 2265/5000, Train Loss: 0.1437\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0907\n",
      "Epoch: 2266/5000, Train Loss: 0.1437\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0907\n",
      "Epoch: 2267/5000, Train Loss: 0.1437\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0906\n",
      "Epoch: 2268/5000, Train Loss: 0.1437\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0906\n",
      "Epoch: 2269/5000, Train Loss: 0.1437\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0906\n",
      "Epoch: 2270/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0906\n",
      "Epoch: 2271/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0905\n",
      "Epoch: 2272/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0905\n",
      "Epoch: 2273/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0905\n",
      "Epoch: 2274/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0905\n",
      "Epoch: 2275/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0905\n",
      "Epoch: 2276/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0904\n",
      "Epoch: 2277/5000, Train Loss: 0.1436\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0904\n",
      "Epoch: 2278/5000, Train Loss: 0.1435\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0904\n",
      "Epoch: 2279/5000, Train Loss: 0.1435\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0904\n",
      "Epoch: 2280/5000, Train Loss: 0.1435\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0903\n",
      "Epoch: 2281/5000, Train Loss: 0.1435\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0903\n",
      "Epoch: 2282/5000, Train Loss: 0.1435\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0903\n",
      "Epoch: 2283/5000, Train Loss: 0.1435\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0903\n",
      "Epoch: 2284/5000, Train Loss: 0.1435\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0903\n",
      "Epoch: 2285/5000, Train Loss: 0.1434\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0902\n",
      "Epoch: 2286/5000, Train Loss: 0.1434\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0902\n",
      "Epoch: 2287/5000, Train Loss: 0.1434\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0902\n",
      "Epoch: 2288/5000, Train Loss: 0.1434\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0902\n",
      "Epoch: 2289/5000, Train Loss: 0.1434\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0901\n",
      "Epoch: 2290/5000, Train Loss: 0.1434\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0901\n",
      "Epoch: 2291/5000, Train Loss: 0.1434\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0901\n",
      "Epoch: 2292/5000, Train Loss: 0.1434\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0901\n",
      "Epoch: 2293/5000, Train Loss: 0.1433\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0901\n",
      "Epoch: 2294/5000, Train Loss: 0.1433\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0900\n",
      "Epoch: 2295/5000, Train Loss: 0.1433\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0900\n",
      "Epoch: 2296/5000, Train Loss: 0.1433\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0900\n",
      "Epoch: 2297/5000, Train Loss: 0.1433\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0900\n",
      "Epoch: 2298/5000, Train Loss: 0.1433\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0899\n",
      "Epoch: 2299/5000, Train Loss: 0.1433\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0899\n",
      "Epoch: 2300/5000, Train Loss: 0.1432\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0899\n",
      "Epoch: 2301/5000, Train Loss: 0.1432\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0899\n",
      "Epoch: 2302/5000, Train Loss: 0.1432\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0899\n",
      "Epoch: 2303/5000, Train Loss: 0.1432\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0898\n",
      "Epoch: 2304/5000, Train Loss: 0.1432\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0898\n",
      "Epoch: 2305/5000, Train Loss: 0.1432\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0898\n",
      "Epoch: 2306/5000, Train Loss: 0.1432\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0898\n",
      "Epoch: 2307/5000, Train Loss: 0.1432\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0897\n",
      "Epoch: 2308/5000, Train Loss: 0.1431\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0897\n",
      "Epoch: 2309/5000, Train Loss: 0.1431\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0897\n",
      "Epoch: 2310/5000, Train Loss: 0.1431\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0897\n",
      "Epoch: 2311/5000, Train Loss: 0.1431\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0897\n",
      "Epoch: 2312/5000, Train Loss: 0.1431\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0896\n",
      "Epoch: 2313/5000, Train Loss: 0.1431\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0896\n",
      "Epoch: 2314/5000, Train Loss: 0.1431\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0896\n",
      "Epoch: 2315/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0896\n",
      "Epoch: 2316/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0895\n",
      "Epoch: 2317/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0895\n",
      "Epoch: 2318/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0895\n",
      "Epoch: 2319/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0895\n",
      "Epoch: 2320/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0895\n",
      "Epoch: 2321/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0894\n",
      "Epoch: 2322/5000, Train Loss: 0.1430\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0894\n",
      "Epoch: 2323/5000, Train Loss: 0.1429\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0894\n",
      "Epoch: 2324/5000, Train Loss: 0.1429\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0894\n",
      "Epoch: 2325/5000, Train Loss: 0.1429\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0893\n",
      "Epoch: 2326/5000, Train Loss: 0.1429\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0893\n",
      "Epoch: 2327/5000, Train Loss: 0.1429\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0893\n",
      "Epoch: 2328/5000, Train Loss: 0.1429\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0893\n",
      "Epoch: 2329/5000, Train Loss: 0.1429\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0893\n",
      "Epoch: 2330/5000, Train Loss: 0.1429\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0892\n",
      "Epoch: 2331/5000, Train Loss: 0.1428\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0892\n",
      "Epoch: 2332/5000, Train Loss: 0.1428\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0892\n",
      "Epoch: 2333/5000, Train Loss: 0.1428\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0892\n",
      "Epoch: 2334/5000, Train Loss: 0.1428\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0891\n",
      "Epoch: 2335/5000, Train Loss: 0.1428\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0891\n",
      "Epoch: 2336/5000, Train Loss: 0.1428\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0891\n",
      "Epoch: 2337/5000, Train Loss: 0.1428\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0891\n",
      "Epoch: 2338/5000, Train Loss: 0.1427\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0891\n",
      "Epoch: 2339/5000, Train Loss: 0.1427\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0890\n",
      "Epoch: 2340/5000, Train Loss: 0.1427\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0890\n",
      "Epoch: 2341/5000, Train Loss: 0.1427\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0890\n",
      "Epoch: 2342/5000, Train Loss: 0.1427\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0890\n",
      "Epoch: 2343/5000, Train Loss: 0.1427\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0890\n",
      "Epoch: 2344/5000, Train Loss: 0.1427\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0889\n",
      "Epoch: 2345/5000, Train Loss: 0.1427\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0889\n",
      "Epoch: 2346/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0889\n",
      "Epoch: 2347/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0889\n",
      "Epoch: 2348/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0888\n",
      "Epoch: 2349/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0888\n",
      "Epoch: 2350/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0888\n",
      "Epoch: 2351/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0888\n",
      "Epoch: 2352/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0888\n",
      "Epoch: 2353/5000, Train Loss: 0.1426\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0887\n",
      "Epoch: 2354/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0887\n",
      "Epoch: 2355/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0887\n",
      "Epoch: 2356/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0887\n",
      "Epoch: 2357/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0886\n",
      "Epoch: 2358/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0886\n",
      "Epoch: 2359/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0886\n",
      "Epoch: 2360/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0886\n",
      "Epoch: 2361/5000, Train Loss: 0.1425\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0886\n",
      "Epoch: 2362/5000, Train Loss: 0.1424\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0885\n",
      "Epoch: 2363/5000, Train Loss: 0.1424\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0885\n",
      "Epoch: 2364/5000, Train Loss: 0.1424\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0885\n",
      "Epoch: 2365/5000, Train Loss: 0.1424\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0885\n",
      "Epoch: 2366/5000, Train Loss: 0.1424\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0885\n",
      "Epoch: 2367/5000, Train Loss: 0.1424\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0884\n",
      "Epoch: 2368/5000, Train Loss: 0.1424\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0884\n",
      "Epoch: 2369/5000, Train Loss: 0.1424\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0884\n",
      "Epoch: 2370/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0884\n",
      "Epoch: 2371/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0883\n",
      "Epoch: 2372/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0883\n",
      "Epoch: 2373/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0883\n",
      "Epoch: 2374/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0883\n",
      "Epoch: 2375/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0883\n",
      "Epoch: 2376/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0882\n",
      "Epoch: 2377/5000, Train Loss: 0.1423\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0882\n",
      "Epoch: 2378/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0882\n",
      "Epoch: 2379/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0882\n",
      "Epoch: 2380/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0882\n",
      "Epoch: 2381/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0881\n",
      "Epoch: 2382/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0881\n",
      "Epoch: 2383/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0881\n",
      "Epoch: 2384/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0881\n",
      "Epoch: 2385/5000, Train Loss: 0.1422\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0881\n",
      "Epoch: 2386/5000, Train Loss: 0.1421\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0880\n",
      "Epoch: 2387/5000, Train Loss: 0.1421\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0880\n",
      "Epoch: 2388/5000, Train Loss: 0.1421\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0880\n",
      "Epoch: 2389/5000, Train Loss: 0.1421\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0880\n",
      "Epoch: 2390/5000, Train Loss: 0.1421\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0879\n",
      "Epoch: 2391/5000, Train Loss: 0.1421\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0879\n",
      "Epoch: 2392/5000, Train Loss: 0.1421\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0879\n",
      "Epoch: 2393/5000, Train Loss: 0.1421\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0879\n",
      "Epoch: 2394/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0879\n",
      "Epoch: 2395/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0878\n",
      "Epoch: 2396/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0878\n",
      "Epoch: 2397/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0878\n",
      "Epoch: 2398/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0878\n",
      "Epoch: 2399/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0878\n",
      "Epoch: 2400/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0877\n",
      "Epoch: 2401/5000, Train Loss: 0.1420\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0877\n",
      "Epoch: 2402/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0877\n",
      "Epoch: 2403/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0877\n",
      "Epoch: 2404/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0877\n",
      "Epoch: 2405/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0876\n",
      "Epoch: 2406/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0876\n",
      "Epoch: 2407/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0876\n",
      "Epoch: 2408/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0876\n",
      "Epoch: 2409/5000, Train Loss: 0.1419\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0875\n",
      "Epoch: 2410/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0875\n",
      "Epoch: 2411/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0875\n",
      "Epoch: 2412/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0875\n",
      "Epoch: 2413/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0875\n",
      "Epoch: 2414/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0874\n",
      "Epoch: 2415/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0874\n",
      "Epoch: 2416/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0874\n",
      "Epoch: 2417/5000, Train Loss: 0.1418\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0874\n",
      "Epoch: 2418/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0874\n",
      "Epoch: 2419/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0873\n",
      "Epoch: 2420/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0873\n",
      "Epoch: 2421/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0873\n",
      "Epoch: 2422/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0873\n",
      "Epoch: 2423/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0873\n",
      "Epoch: 2424/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0872\n",
      "Epoch: 2425/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0872\n",
      "Epoch: 2426/5000, Train Loss: 0.1417\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0872\n",
      "Epoch: 2427/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0872\n",
      "Epoch: 2428/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0872\n",
      "Epoch: 2429/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0871\n",
      "Epoch: 2430/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0871\n",
      "Epoch: 2431/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0871\n",
      "Epoch: 2432/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0871\n",
      "Epoch: 2433/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0871\n",
      "Epoch: 2434/5000, Train Loss: 0.1416\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0870\n",
      "Epoch: 2435/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0870\n",
      "Epoch: 2436/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0870\n",
      "Epoch: 2437/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0870\n",
      "Epoch: 2438/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0870\n",
      "Epoch: 2439/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0869\n",
      "Epoch: 2440/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0869\n",
      "Epoch: 2441/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0869\n",
      "Epoch: 2442/5000, Train Loss: 0.1415\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0869\n",
      "Epoch: 2443/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0868\n",
      "Epoch: 2444/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0868\n",
      "Epoch: 2445/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0868\n",
      "Epoch: 2446/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0868\n",
      "Epoch: 2447/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0868\n",
      "Epoch: 2448/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0867\n",
      "Epoch: 2449/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0867\n",
      "Epoch: 2450/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0867\n",
      "Epoch: 2451/5000, Train Loss: 0.1414\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0867\n",
      "Epoch: 2452/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0867\n",
      "Epoch: 2453/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0866\n",
      "Epoch: 2454/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0866\n",
      "Epoch: 2455/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0866\n",
      "Epoch: 2456/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0866\n",
      "Epoch: 2457/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0866\n",
      "Epoch: 2458/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0865\n",
      "Epoch: 2459/5000, Train Loss: 0.1413\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0865\n",
      "Epoch: 2460/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0865\n",
      "Epoch: 2461/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0865\n",
      "Epoch: 2462/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0865\n",
      "Epoch: 2463/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0864\n",
      "Epoch: 2464/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0864\n",
      "Epoch: 2465/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0864\n",
      "Epoch: 2466/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0864\n",
      "Epoch: 2467/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0864\n",
      "Epoch: 2468/5000, Train Loss: 0.1412\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0863\n",
      "Epoch: 2469/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0863\n",
      "Epoch: 2470/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0863\n",
      "Epoch: 2471/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0863\n",
      "Epoch: 2472/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0863\n",
      "Epoch: 2473/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0862\n",
      "Epoch: 2474/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0862\n",
      "Epoch: 2475/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0862\n",
      "Epoch: 2476/5000, Train Loss: 0.1411\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0862\n",
      "Epoch: 2477/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0862\n",
      "Epoch: 2478/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0861\n",
      "Epoch: 2479/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0861\n",
      "Epoch: 2480/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0861\n",
      "Epoch: 2481/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0861\n",
      "Epoch: 2482/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0861\n",
      "Epoch: 2483/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0860\n",
      "Epoch: 2484/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0860\n",
      "Epoch: 2485/5000, Train Loss: 0.1410\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0860\n",
      "Epoch: 2486/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0860\n",
      "Epoch: 2487/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0860\n",
      "Epoch: 2488/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0859\n",
      "Epoch: 2489/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0859\n",
      "Epoch: 2490/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0859\n",
      "Epoch: 2491/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0859\n",
      "Epoch: 2492/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0859\n",
      "Epoch: 2493/5000, Train Loss: 0.1409\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0858\n",
      "Epoch: 2494/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0858\n",
      "Epoch: 2495/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0858\n",
      "Epoch: 2496/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0858\n",
      "Epoch: 2497/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0858\n",
      "Epoch: 2498/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0857\n",
      "Epoch: 2499/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0857\n",
      "Epoch: 2500/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0857\n",
      "Epoch: 2501/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0857\n",
      "Epoch: 2502/5000, Train Loss: 0.1408\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0857\n",
      "Epoch: 2503/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0856\n",
      "Epoch: 2504/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0856\n",
      "Epoch: 2505/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0856\n",
      "Epoch: 2506/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0856\n",
      "Epoch: 2507/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0856\n",
      "Epoch: 2508/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0855\n",
      "Epoch: 2509/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0855\n",
      "Epoch: 2510/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0855\n",
      "Epoch: 2511/5000, Train Loss: 0.1407\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0855\n",
      "Epoch: 2512/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0855\n",
      "Epoch: 2513/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0855\n",
      "Epoch: 2514/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0854\n",
      "Epoch: 2515/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0854\n",
      "Epoch: 2516/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0854\n",
      "Epoch: 2517/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0854\n",
      "Epoch: 2518/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0854\n",
      "Epoch: 2519/5000, Train Loss: 0.1406\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0853\n",
      "Epoch: 2520/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0853\n",
      "Epoch: 2521/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0853\n",
      "Epoch: 2522/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0853\n",
      "Epoch: 2523/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0853\n",
      "Epoch: 2524/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0852\n",
      "Epoch: 2525/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0852\n",
      "Epoch: 2526/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0852\n",
      "Epoch: 2527/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0852\n",
      "Epoch: 2528/5000, Train Loss: 0.1405\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0852\n",
      "Epoch: 2529/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0851\n",
      "Epoch: 2530/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0851\n",
      "Epoch: 2531/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0851\n",
      "Epoch: 2532/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0851\n",
      "Epoch: 2533/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0851\n",
      "Epoch: 2534/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0850\n",
      "Epoch: 2535/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0850\n",
      "Epoch: 2536/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0850\n",
      "Epoch: 2537/5000, Train Loss: 0.1404\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0850\n",
      "Epoch: 2538/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0850\n",
      "Epoch: 2539/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0849\n",
      "Epoch: 2540/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0849\n",
      "Epoch: 2541/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0849\n",
      "Epoch: 2542/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0849\n",
      "Epoch: 2543/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0849\n",
      "Epoch: 2544/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0849\n",
      "Epoch: 2545/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0848\n",
      "Epoch: 2546/5000, Train Loss: 0.1403\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0848\n",
      "Epoch: 2547/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0848\n",
      "Epoch: 2548/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0848\n",
      "Epoch: 2549/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0848\n",
      "Epoch: 2550/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0847\n",
      "Epoch: 2551/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0847\n",
      "Epoch: 2552/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0847\n",
      "Epoch: 2553/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0847\n",
      "Epoch: 2554/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0847\n",
      "Epoch: 2555/5000, Train Loss: 0.1402\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0846\n",
      "Epoch: 2556/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0846\n",
      "Epoch: 2557/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0846\n",
      "Epoch: 2558/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0846\n",
      "Epoch: 2559/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0846\n",
      "Epoch: 2560/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0845\n",
      "Epoch: 2561/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0845\n",
      "Epoch: 2562/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0845\n",
      "Epoch: 2563/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0845\n",
      "Epoch: 2564/5000, Train Loss: 0.1401\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0845\n",
      "Epoch: 2565/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0845\n",
      "Epoch: 2566/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0844\n",
      "Epoch: 2567/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0844\n",
      "Epoch: 2568/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0844\n",
      "Epoch: 2569/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0844\n",
      "Epoch: 2570/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0844\n",
      "Epoch: 2571/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0843\n",
      "Epoch: 2572/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0843\n",
      "Epoch: 2573/5000, Train Loss: 0.1400\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0843\n",
      "Epoch: 2574/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0843\n",
      "Epoch: 2575/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0843\n",
      "Epoch: 2576/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0842\n",
      "Epoch: 2577/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0842\n",
      "Epoch: 2578/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0842\n",
      "Epoch: 2579/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0842\n",
      "Epoch: 2580/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0842\n",
      "Epoch: 2581/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0841\n",
      "Epoch: 2582/5000, Train Loss: 0.1399\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0841\n",
      "Epoch: 2583/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0841\n",
      "Epoch: 2584/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0841\n",
      "Epoch: 2585/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0841\n",
      "Epoch: 2586/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0841\n",
      "Epoch: 2587/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0840\n",
      "Epoch: 2588/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0840\n",
      "Epoch: 2589/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0840\n",
      "Epoch: 2590/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0840\n",
      "Epoch: 2591/5000, Train Loss: 0.1398\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0840\n",
      "Epoch: 2592/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0839\n",
      "Epoch: 2593/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0839\n",
      "Epoch: 2594/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0839\n",
      "Epoch: 2595/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0839\n",
      "Epoch: 2596/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0839\n",
      "Epoch: 2597/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0838\n",
      "Epoch: 2598/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0838\n",
      "Epoch: 2599/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0838\n",
      "Epoch: 2600/5000, Train Loss: 0.1397\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0838\n",
      "Epoch: 2601/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0838\n",
      "Epoch: 2602/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0838\n",
      "Epoch: 2603/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0837\n",
      "Epoch: 2604/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0837\n",
      "Epoch: 2605/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0837\n",
      "Epoch: 2606/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0837\n",
      "Epoch: 2607/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0837\n",
      "Epoch: 2608/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0836\n",
      "Epoch: 2609/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0836\n",
      "Epoch: 2610/5000, Train Loss: 0.1396\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0836\n",
      "Epoch: 2611/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0836\n",
      "Epoch: 2612/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0836\n",
      "Epoch: 2613/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0836\n",
      "Epoch: 2614/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0835\n",
      "Epoch: 2615/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0835\n",
      "Epoch: 2616/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0835\n",
      "Epoch: 2617/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0835\n",
      "Epoch: 2618/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0835\n",
      "Epoch: 2619/5000, Train Loss: 0.1395\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0834\n",
      "Epoch: 2620/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0834\n",
      "Epoch: 2621/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0834\n",
      "Epoch: 2622/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0834\n",
      "Epoch: 2623/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0834\n",
      "Epoch: 2624/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0834\n",
      "Epoch: 2625/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0833\n",
      "Epoch: 2626/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0833\n",
      "Epoch: 2627/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0833\n",
      "Epoch: 2628/5000, Train Loss: 0.1394\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0833\n",
      "Epoch: 2629/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0833\n",
      "Epoch: 2630/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0832\n",
      "Epoch: 2631/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0832\n",
      "Epoch: 2632/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0832\n",
      "Epoch: 2633/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0832\n",
      "Epoch: 2634/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0832\n",
      "Epoch: 2635/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0832\n",
      "Epoch: 2636/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0831\n",
      "Epoch: 2637/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0831\n",
      "Epoch: 2638/5000, Train Loss: 0.1393\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0831\n",
      "Epoch: 2639/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0831\n",
      "Epoch: 2640/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0831\n",
      "Epoch: 2641/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0830\n",
      "Epoch: 2642/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0830\n",
      "Epoch: 2643/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0830\n",
      "Epoch: 2644/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0830\n",
      "Epoch: 2645/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0830\n",
      "Epoch: 2646/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0830\n",
      "Epoch: 2647/5000, Train Loss: 0.1392\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0829\n",
      "Epoch: 2648/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0829\n",
      "Epoch: 2649/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0829\n",
      "Epoch: 2650/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0829\n",
      "Epoch: 2651/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0829\n",
      "Epoch: 2652/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0828\n",
      "Epoch: 2653/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0828\n",
      "Epoch: 2654/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0828\n",
      "Epoch: 2655/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0828\n",
      "Epoch: 2656/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0828\n",
      "Epoch: 2657/5000, Train Loss: 0.1391\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0828\n",
      "Epoch: 2658/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0827\n",
      "Epoch: 2659/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0827\n",
      "Epoch: 2660/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0827\n",
      "Epoch: 2661/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0827\n",
      "Epoch: 2662/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0827\n",
      "Epoch: 2663/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0826\n",
      "Epoch: 2664/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0826\n",
      "Epoch: 2665/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0826\n",
      "Epoch: 2666/5000, Train Loss: 0.1390\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0826\n",
      "Epoch: 2667/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0826\n",
      "Epoch: 2668/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0826\n",
      "Epoch: 2669/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0825\n",
      "Epoch: 2670/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0825\n",
      "Epoch: 2671/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0825\n",
      "Epoch: 2672/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0825\n",
      "Epoch: 2673/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0825\n",
      "Epoch: 2674/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0824\n",
      "Epoch: 2675/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0824\n",
      "Epoch: 2676/5000, Train Loss: 0.1389\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0824\n",
      "Epoch: 2677/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0824\n",
      "Epoch: 2678/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0824\n",
      "Epoch: 2679/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0824\n",
      "Epoch: 2680/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0823\n",
      "Epoch: 2681/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0823\n",
      "Epoch: 2682/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0823\n",
      "Epoch: 2683/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0823\n",
      "Epoch: 2684/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0823\n",
      "Epoch: 2685/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0823\n",
      "Epoch: 2686/5000, Train Loss: 0.1388\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0822\n",
      "Epoch: 2687/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0822\n",
      "Epoch: 2688/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0822\n",
      "Epoch: 2689/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0822\n",
      "Epoch: 2690/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0822\n",
      "Epoch: 2691/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0821\n",
      "Epoch: 2692/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0821\n",
      "Epoch: 2693/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0821\n",
      "Epoch: 2694/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0821\n",
      "Epoch: 2695/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0821\n",
      "Epoch: 2696/5000, Train Loss: 0.1387\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0821\n",
      "Epoch: 2697/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0820\n",
      "Epoch: 2698/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0820\n",
      "Epoch: 2699/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0820\n",
      "Epoch: 2700/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0820\n",
      "Epoch: 2701/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0820\n",
      "Epoch: 2702/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0820\n",
      "Epoch: 2703/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0819\n",
      "Epoch: 2704/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0819\n",
      "Epoch: 2705/5000, Train Loss: 0.1386\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0819\n",
      "Epoch: 2706/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0819\n",
      "Epoch: 2707/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0819\n",
      "Epoch: 2708/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0818\n",
      "Epoch: 2709/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0818\n",
      "Epoch: 2710/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0818\n",
      "Epoch: 2711/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0818\n",
      "Epoch: 2712/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0818\n",
      "Epoch: 2713/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0818\n",
      "Epoch: 2714/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0817\n",
      "Epoch: 2715/5000, Train Loss: 0.1385\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0817\n",
      "Epoch: 2716/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0817\n",
      "Epoch: 2717/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0817\n",
      "Epoch: 2718/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0817\n",
      "Epoch: 2719/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0817\n",
      "Epoch: 2720/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0816\n",
      "Epoch: 2721/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0816\n",
      "Epoch: 2722/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0816\n",
      "Epoch: 2723/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0816\n",
      "Epoch: 2724/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0816\n",
      "Epoch: 2725/5000, Train Loss: 0.1384\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0816\n",
      "Epoch: 2726/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0815\n",
      "Epoch: 2727/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0815\n",
      "Epoch: 2728/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0815\n",
      "Epoch: 2729/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0815\n",
      "Epoch: 2730/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0815\n",
      "Epoch: 2731/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0814\n",
      "Epoch: 2732/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0814\n",
      "Epoch: 2733/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0814\n",
      "Epoch: 2734/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0814\n",
      "Epoch: 2735/5000, Train Loss: 0.1383\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0814\n",
      "Epoch: 2736/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0814\n",
      "Epoch: 2737/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0813\n",
      "Epoch: 2738/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0813\n",
      "Epoch: 2739/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0813\n",
      "Epoch: 2740/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0813\n",
      "Epoch: 2741/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0813\n",
      "Epoch: 2742/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0813\n",
      "Epoch: 2743/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0812\n",
      "Epoch: 2744/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0812\n",
      "Epoch: 2745/5000, Train Loss: 0.1382\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0812\n",
      "Epoch: 2746/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0812\n",
      "Epoch: 2747/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0812\n",
      "Epoch: 2748/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0812\n",
      "Epoch: 2749/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0811\n",
      "Epoch: 2750/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0811\n",
      "Epoch: 2751/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0811\n",
      "Epoch: 2752/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0811\n",
      "Epoch: 2753/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0811\n",
      "Epoch: 2754/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0811\n",
      "Epoch: 2755/5000, Train Loss: 0.1381\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0810\n",
      "Epoch: 2756/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0810\n",
      "Epoch: 2757/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0810\n",
      "Epoch: 2758/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0810\n",
      "Epoch: 2759/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0810\n",
      "Epoch: 2760/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0810\n",
      "Epoch: 2761/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0809\n",
      "Epoch: 2762/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0809\n",
      "Epoch: 2763/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0809\n",
      "Epoch: 2764/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0809\n",
      "Epoch: 2765/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0809\n",
      "Epoch: 2766/5000, Train Loss: 0.1380\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0809\n",
      "Epoch: 2767/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0808\n",
      "Epoch: 2768/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0808\n",
      "Epoch: 2769/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0808\n",
      "Epoch: 2770/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0808\n",
      "Epoch: 2771/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0808\n",
      "Epoch: 2772/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0807\n",
      "Epoch: 2773/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0807\n",
      "Epoch: 2774/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0807\n",
      "Epoch: 2775/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0807\n",
      "Epoch: 2776/5000, Train Loss: 0.1379\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0807\n",
      "Epoch: 2777/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0807\n",
      "Epoch: 2778/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0806\n",
      "Epoch: 2779/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0806\n",
      "Epoch: 2780/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0806\n",
      "Epoch: 2781/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0806\n",
      "Epoch: 2782/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0806\n",
      "Epoch: 2783/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0806\n",
      "Epoch: 2784/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0805\n",
      "Epoch: 2785/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0805\n",
      "Epoch: 2786/5000, Train Loss: 0.1378\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0805\n",
      "Epoch: 2787/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0805\n",
      "Epoch: 2788/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0805\n",
      "Epoch: 2789/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0805\n",
      "Epoch: 2790/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0804\n",
      "Epoch: 2791/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0804\n",
      "Epoch: 2792/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0804\n",
      "Epoch: 2793/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0804\n",
      "Epoch: 2794/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0804\n",
      "Epoch: 2795/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0804\n",
      "Epoch: 2796/5000, Train Loss: 0.1377\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0803\n",
      "Epoch: 2797/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0803\n",
      "Epoch: 2798/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0803\n",
      "Epoch: 2799/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0803\n",
      "Epoch: 2800/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0803\n",
      "Epoch: 2801/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0803\n",
      "Epoch: 2802/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0802\n",
      "Epoch: 2803/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0802\n",
      "Epoch: 2804/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0802\n",
      "Epoch: 2805/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0802\n",
      "Epoch: 2806/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0802\n",
      "Epoch: 2807/5000, Train Loss: 0.1376\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0802\n",
      "Epoch: 2808/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0801\n",
      "Epoch: 2809/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0801\n",
      "Epoch: 2810/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0801\n",
      "Epoch: 2811/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0801\n",
      "Epoch: 2812/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0801\n",
      "Epoch: 2813/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0801\n",
      "Epoch: 2814/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0800\n",
      "Epoch: 2815/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0800\n",
      "Epoch: 2816/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0800\n",
      "Epoch: 2817/5000, Train Loss: 0.1375\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0800\n",
      "Epoch: 2818/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0800\n",
      "Epoch: 2819/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0800\n",
      "Epoch: 2820/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0800\n",
      "Epoch: 2821/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0799\n",
      "Epoch: 2822/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0799\n",
      "Epoch: 2823/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0799\n",
      "Epoch: 2824/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0799\n",
      "Epoch: 2825/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0799\n",
      "Epoch: 2826/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0799\n",
      "Epoch: 2827/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0798\n",
      "Epoch: 2828/5000, Train Loss: 0.1374\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0798\n",
      "Epoch: 2829/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0798\n",
      "Epoch: 2830/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0798\n",
      "Epoch: 2831/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0798\n",
      "Epoch: 2832/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0798\n",
      "Epoch: 2833/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0797\n",
      "Epoch: 2834/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0797\n",
      "Epoch: 2835/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0797\n",
      "Epoch: 2836/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0797\n",
      "Epoch: 2837/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0797\n",
      "Epoch: 2838/5000, Train Loss: 0.1373\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0797\n",
      "Epoch: 2839/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0796\n",
      "Epoch: 2840/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0796\n",
      "Epoch: 2841/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0796\n",
      "Epoch: 2842/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0796\n",
      "Epoch: 2843/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0796\n",
      "Epoch: 2844/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0796\n",
      "Epoch: 2845/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0795\n",
      "Epoch: 2846/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0795\n",
      "Epoch: 2847/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0795\n",
      "Epoch: 2848/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0795\n",
      "Epoch: 2849/5000, Train Loss: 0.1372\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0795\n",
      "Epoch: 2850/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0795\n",
      "Epoch: 2851/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0794\n",
      "Epoch: 2852/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0794\n",
      "Epoch: 2853/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0794\n",
      "Epoch: 2854/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0794\n",
      "Epoch: 2855/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0794\n",
      "Epoch: 2856/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0794\n",
      "Epoch: 2857/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0793\n",
      "Epoch: 2858/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0793\n",
      "Epoch: 2859/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0793\n",
      "Epoch: 2860/5000, Train Loss: 0.1371\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0793\n",
      "Epoch: 2861/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0793\n",
      "Epoch: 2862/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0793\n",
      "Epoch: 2863/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0793\n",
      "Epoch: 2864/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0792\n",
      "Epoch: 2865/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0792\n",
      "Epoch: 2866/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0792\n",
      "Epoch: 2867/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0792\n",
      "Epoch: 2868/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0792\n",
      "Epoch: 2869/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0792\n",
      "Epoch: 2870/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0791\n",
      "Epoch: 2871/5000, Train Loss: 0.1370\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0791\n",
      "Epoch: 2872/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0791\n",
      "Epoch: 2873/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0791\n",
      "Epoch: 2874/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0791\n",
      "Epoch: 2875/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0791\n",
      "Epoch: 2876/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0790\n",
      "Epoch: 2877/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0790\n",
      "Epoch: 2878/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0790\n",
      "Epoch: 2879/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0790\n",
      "Epoch: 2880/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0790\n",
      "Epoch: 2881/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0790\n",
      "Epoch: 2882/5000, Train Loss: 0.1369\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0789\n",
      "Epoch: 2883/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0789\n",
      "Epoch: 2884/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0789\n",
      "Epoch: 2885/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0789\n",
      "Epoch: 2886/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0789\n",
      "Epoch: 2887/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0789\n",
      "Epoch: 2888/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0789\n",
      "Epoch: 2889/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0788\n",
      "Epoch: 2890/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0788\n",
      "Epoch: 2891/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0788\n",
      "Epoch: 2892/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0788\n",
      "Epoch: 2893/5000, Train Loss: 0.1368\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0788\n",
      "Epoch: 2894/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0788\n",
      "Epoch: 2895/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0787\n",
      "Epoch: 2896/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0787\n",
      "Epoch: 2897/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0787\n",
      "Epoch: 2898/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0787\n",
      "Epoch: 2899/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0787\n",
      "Epoch: 2900/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0787\n",
      "Epoch: 2901/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0786\n",
      "Epoch: 2902/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0786\n",
      "Epoch: 2903/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0786\n",
      "Epoch: 2904/5000, Train Loss: 0.1367\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0786\n",
      "Epoch: 2905/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0786\n",
      "Epoch: 2906/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0786\n",
      "Epoch: 2907/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0786\n",
      "Epoch: 2908/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0785\n",
      "Epoch: 2909/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0785\n",
      "Epoch: 2910/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0785\n",
      "Epoch: 2911/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0785\n",
      "Epoch: 2912/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0785\n",
      "Epoch: 2913/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0785\n",
      "Epoch: 2914/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0784\n",
      "Epoch: 2915/5000, Train Loss: 0.1366\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0784\n",
      "Epoch: 2916/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0784\n",
      "Epoch: 2917/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0784\n",
      "Epoch: 2918/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0784\n",
      "Epoch: 2919/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0784\n",
      "Epoch: 2920/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0783\n",
      "Epoch: 2921/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0783\n",
      "Epoch: 2922/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0783\n",
      "Epoch: 2923/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0783\n",
      "Epoch: 2924/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0783\n",
      "Epoch: 2925/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0783\n",
      "Epoch: 2926/5000, Train Loss: 0.1365\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0783\n",
      "Epoch: 2927/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0782\n",
      "Epoch: 2928/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0782\n",
      "Epoch: 2929/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0782\n",
      "Epoch: 2930/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0782\n",
      "Epoch: 2931/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0782\n",
      "Epoch: 2932/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0782\n",
      "Epoch: 2933/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0781\n",
      "Epoch: 2934/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0781\n",
      "Epoch: 2935/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0781\n",
      "Epoch: 2936/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0781\n",
      "Epoch: 2937/5000, Train Loss: 0.1364\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0781\n",
      "Epoch: 2938/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0781\n",
      "Epoch: 2939/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0781\n",
      "Epoch: 2940/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0780\n",
      "Epoch: 2941/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0780\n",
      "Epoch: 2942/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0780\n",
      "Epoch: 2943/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0780\n",
      "Epoch: 2944/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0780\n",
      "Epoch: 2945/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0780\n",
      "Epoch: 2946/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0779\n",
      "Epoch: 2947/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0779\n",
      "Epoch: 2948/5000, Train Loss: 0.1363\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0779\n",
      "Epoch: 2949/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0779\n",
      "Epoch: 2950/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0779\n",
      "Epoch: 2951/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0779\n",
      "Epoch: 2952/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0779\n",
      "Epoch: 2953/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0778\n",
      "Epoch: 2954/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0778\n",
      "Epoch: 2955/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0778\n",
      "Epoch: 2956/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0778\n",
      "Epoch: 2957/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0778\n",
      "Epoch: 2958/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0778\n",
      "Epoch: 2959/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0777\n",
      "Epoch: 2960/5000, Train Loss: 0.1362\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0777\n",
      "Epoch: 2961/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0777\n",
      "Epoch: 2962/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0777\n",
      "Epoch: 2963/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0777\n",
      "Epoch: 2964/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0777\n",
      "Epoch: 2965/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0777\n",
      "Epoch: 2966/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0776\n",
      "Epoch: 2967/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0776\n",
      "Epoch: 2968/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0776\n",
      "Epoch: 2969/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0776\n",
      "Epoch: 2970/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0776\n",
      "Epoch: 2971/5000, Train Loss: 0.1361\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0776\n",
      "Epoch: 2972/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0775\n",
      "Epoch: 2973/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0775\n",
      "Epoch: 2974/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0775\n",
      "Epoch: 2975/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0775\n",
      "Epoch: 2976/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0775\n",
      "Epoch: 2977/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0775\n",
      "Epoch: 2978/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0775\n",
      "Epoch: 2979/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0774\n",
      "Epoch: 2980/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0774\n",
      "Epoch: 2981/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0774\n",
      "Epoch: 2982/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0774\n",
      "Epoch: 2983/5000, Train Loss: 0.1360\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0774\n",
      "Epoch: 2984/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0774\n",
      "Epoch: 2985/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0774\n",
      "Epoch: 2986/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0773\n",
      "Epoch: 2987/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0773\n",
      "Epoch: 2988/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0773\n",
      "Epoch: 2989/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0773\n",
      "Epoch: 2990/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0773\n",
      "Epoch: 2991/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0773\n",
      "Epoch: 2992/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0772\n",
      "Epoch: 2993/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0772\n",
      "Epoch: 2994/5000, Train Loss: 0.1359\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0772\n",
      "Epoch: 2995/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0772\n",
      "Epoch: 2996/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0772\n",
      "Epoch: 2997/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0772\n",
      "Epoch: 2998/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0772\n",
      "Epoch: 2999/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0771\n",
      "Epoch: 3000/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0771\n",
      "Epoch: 3001/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0771\n",
      "Epoch: 3002/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0771\n",
      "Epoch: 3003/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0771\n",
      "Epoch: 3004/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0771\n",
      "Epoch: 3005/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0771\n",
      "Epoch: 3006/5000, Train Loss: 0.1358\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0770\n",
      "Epoch: 3007/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0770\n",
      "Epoch: 3008/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0770\n",
      "Epoch: 3009/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0770\n",
      "Epoch: 3010/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0770\n",
      "Epoch: 3011/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0770\n",
      "Epoch: 3012/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0769\n",
      "Epoch: 3013/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0769\n",
      "Epoch: 3014/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0769\n",
      "Epoch: 3015/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0769\n",
      "Epoch: 3016/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0769\n",
      "Epoch: 3017/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0769\n",
      "Epoch: 3018/5000, Train Loss: 0.1357\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0769\n",
      "Epoch: 3019/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0768\n",
      "Epoch: 3020/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0768\n",
      "Epoch: 3021/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0768\n",
      "Epoch: 3022/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0768\n",
      "Epoch: 3023/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0768\n",
      "Epoch: 3024/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0768\n",
      "Epoch: 3025/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0768\n",
      "Epoch: 3026/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0767\n",
      "Epoch: 3027/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0767\n",
      "Epoch: 3028/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0767\n",
      "Epoch: 3029/5000, Train Loss: 0.1356\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0767\n",
      "Epoch: 3030/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0767\n",
      "Epoch: 3031/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0767\n",
      "Epoch: 3032/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0767\n",
      "Epoch: 3033/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0766\n",
      "Epoch: 3034/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0766\n",
      "Epoch: 3035/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0766\n",
      "Epoch: 3036/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0766\n",
      "Epoch: 3037/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0766\n",
      "Epoch: 3038/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0766\n",
      "Epoch: 3039/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0766\n",
      "Epoch: 3040/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0765\n",
      "Epoch: 3041/5000, Train Loss: 0.1355\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0765\n",
      "Epoch: 3042/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0765\n",
      "Epoch: 3043/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0765\n",
      "Epoch: 3044/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0765\n",
      "Epoch: 3045/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0765\n",
      "Epoch: 3046/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0764\n",
      "Epoch: 3047/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0764\n",
      "Epoch: 3048/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0764\n",
      "Epoch: 3049/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0764\n",
      "Epoch: 3050/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0764\n",
      "Epoch: 3051/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0764\n",
      "Epoch: 3052/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0764\n",
      "Epoch: 3053/5000, Train Loss: 0.1354\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0763\n",
      "Epoch: 3054/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0763\n",
      "Epoch: 3055/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0763\n",
      "Epoch: 3056/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0763\n",
      "Epoch: 3057/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0763\n",
      "Epoch: 3058/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0763\n",
      "Epoch: 3059/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0763\n",
      "Epoch: 3060/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0762\n",
      "Epoch: 3061/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0762\n",
      "Epoch: 3062/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0762\n",
      "Epoch: 3063/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0762\n",
      "Epoch: 3064/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0762\n",
      "Epoch: 3065/5000, Train Loss: 0.1353\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0762\n",
      "Epoch: 3066/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0762\n",
      "Epoch: 3067/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0761\n",
      "Epoch: 3068/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0761\n",
      "Epoch: 3069/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0761\n",
      "Epoch: 3070/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0761\n",
      "Epoch: 3071/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0761\n",
      "Epoch: 3072/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0761\n",
      "Epoch: 3073/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0761\n",
      "Epoch: 3074/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0760\n",
      "Epoch: 3075/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0760\n",
      "Epoch: 3076/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0760\n",
      "Epoch: 3077/5000, Train Loss: 0.1352\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0760\n",
      "Epoch: 3078/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0760\n",
      "Epoch: 3079/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0760\n",
      "Epoch: 3080/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0760\n",
      "Epoch: 3081/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0759\n",
      "Epoch: 3082/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0759\n",
      "Epoch: 3083/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0759\n",
      "Epoch: 3084/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0759\n",
      "Epoch: 3085/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0759\n",
      "Epoch: 3086/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0759\n",
      "Epoch: 3087/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0759\n",
      "Epoch: 3088/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0758\n",
      "Epoch: 3089/5000, Train Loss: 0.1351\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0758\n",
      "Epoch: 3090/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0758\n",
      "Epoch: 3091/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0758\n",
      "Epoch: 3092/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0758\n",
      "Epoch: 3093/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0758\n",
      "Epoch: 3094/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0758\n",
      "Epoch: 3095/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0757\n",
      "Epoch: 3096/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0757\n",
      "Epoch: 3097/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0757\n",
      "Epoch: 3098/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0757\n",
      "Epoch: 3099/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0757\n",
      "Epoch: 3100/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0757\n",
      "Epoch: 3101/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0757\n",
      "Epoch: 3102/5000, Train Loss: 0.1350\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0756\n",
      "Epoch: 3103/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0756\n",
      "Epoch: 3104/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0756\n",
      "Epoch: 3105/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0756\n",
      "Epoch: 3106/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0756\n",
      "Epoch: 3107/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0756\n",
      "Epoch: 3108/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0756\n",
      "Epoch: 3109/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0755\n",
      "Epoch: 3110/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0755\n",
      "Epoch: 3111/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0755\n",
      "Epoch: 3112/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0755\n",
      "Epoch: 3113/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0755\n",
      "Epoch: 3114/5000, Train Loss: 0.1349\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0755\n",
      "Epoch: 3115/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0755\n",
      "Epoch: 3116/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0754\n",
      "Epoch: 3117/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0754\n",
      "Epoch: 3118/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0754\n",
      "Epoch: 3119/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0754\n",
      "Epoch: 3120/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0754\n",
      "Epoch: 3121/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0754\n",
      "Epoch: 3122/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0754\n",
      "Epoch: 3123/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0753\n",
      "Epoch: 3124/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0753\n",
      "Epoch: 3125/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0753\n",
      "Epoch: 3126/5000, Train Loss: 0.1348\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0753\n",
      "Epoch: 3127/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0753\n",
      "Epoch: 3128/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0753\n",
      "Epoch: 3129/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0753\n",
      "Epoch: 3130/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0752\n",
      "Epoch: 3131/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0752\n",
      "Epoch: 3132/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0752\n",
      "Epoch: 3133/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0752\n",
      "Epoch: 3134/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0752\n",
      "Epoch: 3135/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0752\n",
      "Epoch: 3136/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0752\n",
      "Epoch: 3137/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0751\n",
      "Epoch: 3138/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0751\n",
      "Epoch: 3139/5000, Train Loss: 0.1347\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0751\n",
      "Epoch: 3140/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0751\n",
      "Epoch: 3141/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0751\n",
      "Epoch: 3142/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0751\n",
      "Epoch: 3143/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0751\n",
      "Epoch: 3144/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0750\n",
      "Epoch: 3145/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0750\n",
      "Epoch: 3146/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0750\n",
      "Epoch: 3147/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0750\n",
      "Epoch: 3148/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0750\n",
      "Epoch: 3149/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0750\n",
      "Epoch: 3150/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0750\n",
      "Epoch: 3151/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0750\n",
      "Epoch: 3152/5000, Train Loss: 0.1346\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0749\n",
      "Epoch: 3153/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0749\n",
      "Epoch: 3154/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0749\n",
      "Epoch: 3155/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0749\n",
      "Epoch: 3156/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0749\n",
      "Epoch: 3157/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0749\n",
      "Epoch: 3158/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0749\n",
      "Epoch: 3159/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0748\n",
      "Epoch: 3160/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0748\n",
      "Epoch: 3161/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0748\n",
      "Epoch: 3162/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0748\n",
      "Epoch: 3163/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0748\n",
      "Epoch: 3164/5000, Train Loss: 0.1345\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0748\n",
      "Epoch: 3165/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0748\n",
      "Epoch: 3166/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0747\n",
      "Epoch: 3167/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0747\n",
      "Epoch: 3168/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0747\n",
      "Epoch: 3169/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0747\n",
      "Epoch: 3170/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0747\n",
      "Epoch: 3171/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0747\n",
      "Epoch: 3172/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0747\n",
      "Epoch: 3173/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0746\n",
      "Epoch: 3174/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0746\n",
      "Epoch: 3175/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0746\n",
      "Epoch: 3176/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0746\n",
      "Epoch: 3177/5000, Train Loss: 0.1344\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0746\n",
      "Epoch: 3178/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0746\n",
      "Epoch: 3179/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0746\n",
      "Epoch: 3180/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0746\n",
      "Epoch: 3181/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0745\n",
      "Epoch: 3182/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0745\n",
      "Epoch: 3183/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0745\n",
      "Epoch: 3184/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0745\n",
      "Epoch: 3185/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0745\n",
      "Epoch: 3186/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0745\n",
      "Epoch: 3187/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0745\n",
      "Epoch: 3188/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0744\n",
      "Epoch: 3189/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0744\n",
      "Epoch: 3190/5000, Train Loss: 0.1343\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0744\n",
      "Epoch: 3191/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0744\n",
      "Epoch: 3192/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0744\n",
      "Epoch: 3193/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0744\n",
      "Epoch: 3194/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0744\n",
      "Epoch: 3195/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0743\n",
      "Epoch: 3196/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0743\n",
      "Epoch: 3197/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0743\n",
      "Epoch: 3198/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0743\n",
      "Epoch: 3199/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0743\n",
      "Epoch: 3200/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0743\n",
      "Epoch: 3201/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0743\n",
      "Epoch: 3202/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0743\n",
      "Epoch: 3203/5000, Train Loss: 0.1342\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0742\n",
      "Epoch: 3204/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0742\n",
      "Epoch: 3205/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0742\n",
      "Epoch: 3206/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0742\n",
      "Epoch: 3207/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0742\n",
      "Epoch: 3208/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0742\n",
      "Epoch: 3209/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0742\n",
      "Epoch: 3210/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0741\n",
      "Epoch: 3211/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0741\n",
      "Epoch: 3212/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0741\n",
      "Epoch: 3213/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0741\n",
      "Epoch: 3214/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0741\n",
      "Epoch: 3215/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0741\n",
      "Epoch: 3216/5000, Train Loss: 0.1341\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0741\n",
      "Epoch: 3217/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0741\n",
      "Epoch: 3218/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0740\n",
      "Epoch: 3219/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0740\n",
      "Epoch: 3220/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0740\n",
      "Epoch: 3221/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0740\n",
      "Epoch: 3222/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0740\n",
      "Epoch: 3223/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0740\n",
      "Epoch: 3224/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0740\n",
      "Epoch: 3225/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0739\n",
      "Epoch: 3226/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0739\n",
      "Epoch: 3227/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0739\n",
      "Epoch: 3228/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0739\n",
      "Epoch: 3229/5000, Train Loss: 0.1340\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0739\n",
      "Epoch: 3230/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0739\n",
      "Epoch: 3231/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0739\n",
      "Epoch: 3232/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0739\n",
      "Epoch: 3233/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0738\n",
      "Epoch: 3234/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0738\n",
      "Epoch: 3235/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0738\n",
      "Epoch: 3236/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0738\n",
      "Epoch: 3237/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0738\n",
      "Epoch: 3238/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0738\n",
      "Epoch: 3239/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0738\n",
      "Epoch: 3240/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0737\n",
      "Epoch: 3241/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0737\n",
      "Epoch: 3242/5000, Train Loss: 0.1339\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0737\n",
      "Epoch: 3243/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0737\n",
      "Epoch: 3244/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0737\n",
      "Epoch: 3245/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0737\n",
      "Epoch: 3246/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0737\n",
      "Epoch: 3247/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0737\n",
      "Epoch: 3248/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0736\n",
      "Epoch: 3249/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0736\n",
      "Epoch: 3250/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0736\n",
      "Epoch: 3251/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0736\n",
      "Epoch: 3252/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0736\n",
      "Epoch: 3253/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0736\n",
      "Epoch: 3254/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0736\n",
      "Epoch: 3255/5000, Train Loss: 0.1338\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0735\n",
      "Epoch: 3256/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0735\n",
      "Epoch: 3257/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0735\n",
      "Epoch: 3258/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0735\n",
      "Epoch: 3259/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0735\n",
      "Epoch: 3260/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0735\n",
      "Epoch: 3261/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0735\n",
      "Epoch: 3262/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0735\n",
      "Epoch: 3263/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0734\n",
      "Epoch: 3264/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0734\n",
      "Epoch: 3265/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0734\n",
      "Epoch: 3266/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0734\n",
      "Epoch: 3267/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0734\n",
      "Epoch: 3268/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0734\n",
      "Epoch: 3269/5000, Train Loss: 0.1337\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0734\n",
      "Epoch: 3270/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0733\n",
      "Epoch: 3271/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0733\n",
      "Epoch: 3272/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0733\n",
      "Epoch: 3273/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0733\n",
      "Epoch: 3274/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0733\n",
      "Epoch: 3275/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0733\n",
      "Epoch: 3276/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0733\n",
      "Epoch: 3277/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0733\n",
      "Epoch: 3278/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0732\n",
      "Epoch: 3279/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0732\n",
      "Epoch: 3280/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0732\n",
      "Epoch: 3281/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0732\n",
      "Epoch: 3282/5000, Train Loss: 0.1336\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0732\n",
      "Epoch: 3283/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0732\n",
      "Epoch: 3284/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0732\n",
      "Epoch: 3285/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0732\n",
      "Epoch: 3286/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0731\n",
      "Epoch: 3287/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0731\n",
      "Epoch: 3288/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0731\n",
      "Epoch: 3289/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0731\n",
      "Epoch: 3290/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0731\n",
      "Epoch: 3291/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0731\n",
      "Epoch: 3292/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0731\n",
      "Epoch: 3293/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0730\n",
      "Epoch: 3294/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0730\n",
      "Epoch: 3295/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0730\n",
      "Epoch: 3296/5000, Train Loss: 0.1335\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0730\n",
      "Epoch: 3297/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0730\n",
      "Epoch: 3298/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0730\n",
      "Epoch: 3299/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0730\n",
      "Epoch: 3300/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0730\n",
      "Epoch: 3301/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0729\n",
      "Epoch: 3302/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0729\n",
      "Epoch: 3303/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0729\n",
      "Epoch: 3304/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0729\n",
      "Epoch: 3305/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0729\n",
      "Epoch: 3306/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0729\n",
      "Epoch: 3307/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0729\n",
      "Epoch: 3308/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0729\n",
      "Epoch: 3309/5000, Train Loss: 0.1334\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0728\n",
      "Epoch: 3310/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0728\n",
      "Epoch: 3311/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0728\n",
      "Epoch: 3312/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0728\n",
      "Epoch: 3313/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0728\n",
      "Epoch: 3314/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0728\n",
      "Epoch: 3315/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0728\n",
      "Epoch: 3316/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0728\n",
      "Epoch: 3317/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0727\n",
      "Epoch: 3318/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0727\n",
      "Epoch: 3319/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0727\n",
      "Epoch: 3320/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0727\n",
      "Epoch: 3321/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0727\n",
      "Epoch: 3322/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0727\n",
      "Epoch: 3323/5000, Train Loss: 0.1333\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0727\n",
      "Epoch: 3324/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0726\n",
      "Epoch: 3325/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0726\n",
      "Epoch: 3326/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0726\n",
      "Epoch: 3327/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0726\n",
      "Epoch: 3328/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0726\n",
      "Epoch: 3329/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0726\n",
      "Epoch: 3330/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0726\n",
      "Epoch: 3331/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0726\n",
      "Epoch: 3332/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0725\n",
      "Epoch: 3333/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0725\n",
      "Epoch: 3334/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0725\n",
      "Epoch: 3335/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0725\n",
      "Epoch: 3336/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0725\n",
      "Epoch: 3337/5000, Train Loss: 0.1332\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0725\n",
      "Epoch: 3338/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0725\n",
      "Epoch: 3339/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0725\n",
      "Epoch: 3340/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0724\n",
      "Epoch: 3341/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0724\n",
      "Epoch: 3342/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0724\n",
      "Epoch: 3343/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0724\n",
      "Epoch: 3344/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0724\n",
      "Epoch: 3345/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0724\n",
      "Epoch: 3346/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0724\n",
      "Epoch: 3347/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0724\n",
      "Epoch: 3348/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0723\n",
      "Epoch: 3349/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0723\n",
      "Epoch: 3350/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0723\n",
      "Epoch: 3351/5000, Train Loss: 0.1331\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0723\n",
      "Epoch: 3352/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0723\n",
      "Epoch: 3353/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0723\n",
      "Epoch: 3354/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0723\n",
      "Epoch: 3355/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0723\n",
      "Epoch: 3356/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0722\n",
      "Epoch: 3357/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0722\n",
      "Epoch: 3358/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0722\n",
      "Epoch: 3359/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0722\n",
      "Epoch: 3360/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0722\n",
      "Epoch: 3361/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0722\n",
      "Epoch: 3362/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0722\n",
      "Epoch: 3363/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0722\n",
      "Epoch: 3364/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0721\n",
      "Epoch: 3365/5000, Train Loss: 0.1330\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0721\n",
      "Epoch: 3366/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0721\n",
      "Epoch: 3367/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0721\n",
      "Epoch: 3368/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0721\n",
      "Epoch: 3369/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0721\n",
      "Epoch: 3370/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0721\n",
      "Epoch: 3371/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0721\n",
      "Epoch: 3372/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0720\n",
      "Epoch: 3373/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0720\n",
      "Epoch: 3374/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0720\n",
      "Epoch: 3375/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0720\n",
      "Epoch: 3376/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0720\n",
      "Epoch: 3377/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0720\n",
      "Epoch: 3378/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0720\n",
      "Epoch: 3379/5000, Train Loss: 0.1329\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0720\n",
      "Epoch: 3380/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0719\n",
      "Epoch: 3381/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0719\n",
      "Epoch: 3382/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0719\n",
      "Epoch: 3383/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0719\n",
      "Epoch: 3384/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0719\n",
      "Epoch: 3385/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0719\n",
      "Epoch: 3386/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0719\n",
      "Epoch: 3387/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0719\n",
      "Epoch: 3388/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0718\n",
      "Epoch: 3389/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0718\n",
      "Epoch: 3390/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0718\n",
      "Epoch: 3391/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0718\n",
      "Epoch: 3392/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0718\n",
      "Epoch: 3393/5000, Train Loss: 0.1328\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0718\n",
      "Epoch: 3394/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0718\n",
      "Epoch: 3395/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0718\n",
      "Epoch: 3396/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0717\n",
      "Epoch: 3397/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0717\n",
      "Epoch: 3398/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0717\n",
      "Epoch: 3399/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0717\n",
      "Epoch: 3400/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0717\n",
      "Epoch: 3401/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0717\n",
      "Epoch: 3402/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0717\n",
      "Epoch: 3403/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0717\n",
      "Epoch: 3404/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0716\n",
      "Epoch: 3405/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0716\n",
      "Epoch: 3406/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0716\n",
      "Epoch: 3407/5000, Train Loss: 0.1327\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0716\n",
      "Epoch: 3408/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0716\n",
      "Epoch: 3409/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0716\n",
      "Epoch: 3410/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0716\n",
      "Epoch: 3411/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0716\n",
      "Epoch: 3412/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0715\n",
      "Epoch: 3413/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0715\n",
      "Epoch: 3414/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0715\n",
      "Epoch: 3415/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0715\n",
      "Epoch: 3416/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0715\n",
      "Epoch: 3417/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0715\n",
      "Epoch: 3418/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0715\n",
      "Epoch: 3419/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0715\n",
      "Epoch: 3420/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0714\n",
      "Epoch: 3421/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0714\n",
      "Epoch: 3422/5000, Train Loss: 0.1326\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0714\n",
      "Epoch: 3423/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0714\n",
      "Epoch: 3424/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0714\n",
      "Epoch: 3425/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0714\n",
      "Epoch: 3426/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0714\n",
      "Epoch: 3427/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0714\n",
      "Epoch: 3428/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0714\n",
      "Epoch: 3429/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0713\n",
      "Epoch: 3430/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0713\n",
      "Epoch: 3431/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0713\n",
      "Epoch: 3432/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0713\n",
      "Epoch: 3433/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0713\n",
      "Epoch: 3434/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0713\n",
      "Epoch: 3435/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0713\n",
      "Epoch: 3436/5000, Train Loss: 0.1325\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0713\n",
      "Epoch: 3437/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0712\n",
      "Epoch: 3438/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0712\n",
      "Epoch: 3439/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0712\n",
      "Epoch: 3440/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0712\n",
      "Epoch: 3441/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0712\n",
      "Epoch: 3442/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0712\n",
      "Epoch: 3443/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0712\n",
      "Epoch: 3444/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0712\n",
      "Epoch: 3445/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0711\n",
      "Epoch: 3446/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0711\n",
      "Epoch: 3447/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0711\n",
      "Epoch: 3448/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0711\n",
      "Epoch: 3449/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0711\n",
      "Epoch: 3450/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0711\n",
      "Epoch: 3451/5000, Train Loss: 0.1324\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0711\n",
      "Epoch: 3452/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0711\n",
      "Epoch: 3453/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0710\n",
      "Epoch: 3454/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0710\n",
      "Epoch: 3455/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0710\n",
      "Epoch: 3456/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0710\n",
      "Epoch: 3457/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0710\n",
      "Epoch: 3458/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0710\n",
      "Epoch: 3459/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0710\n",
      "Epoch: 3460/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0710\n",
      "Epoch: 3461/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0710\n",
      "Epoch: 3462/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0709\n",
      "Epoch: 3463/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0709\n",
      "Epoch: 3464/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0709\n",
      "Epoch: 3465/5000, Train Loss: 0.1323\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0709\n",
      "Epoch: 3466/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0709\n",
      "Epoch: 3467/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0709\n",
      "Epoch: 3468/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0709\n",
      "Epoch: 3469/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0709\n",
      "Epoch: 3470/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0708\n",
      "Epoch: 3471/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0708\n",
      "Epoch: 3472/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0708\n",
      "Epoch: 3473/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0708\n",
      "Epoch: 3474/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0708\n",
      "Epoch: 3475/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0708\n",
      "Epoch: 3476/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0708\n",
      "Epoch: 3477/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0708\n",
      "Epoch: 3478/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0708\n",
      "Epoch: 3479/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0707\n",
      "Epoch: 3480/5000, Train Loss: 0.1322\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0707\n",
      "Epoch: 3481/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0707\n",
      "Epoch: 3482/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0707\n",
      "Epoch: 3483/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0707\n",
      "Epoch: 3484/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0707\n",
      "Epoch: 3485/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0707\n",
      "Epoch: 3486/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0707\n",
      "Epoch: 3487/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0706\n",
      "Epoch: 3488/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0706\n",
      "Epoch: 3489/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0706\n",
      "Epoch: 3490/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0706\n",
      "Epoch: 3491/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0706\n",
      "Epoch: 3492/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0706\n",
      "Epoch: 3493/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0706\n",
      "Epoch: 3494/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0706\n",
      "Epoch: 3495/5000, Train Loss: 0.1321\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0705\n",
      "Epoch: 3496/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0705\n",
      "Epoch: 3497/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0705\n",
      "Epoch: 3498/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0705\n",
      "Epoch: 3499/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0705\n",
      "Epoch: 3500/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0705\n",
      "Epoch: 3501/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0705\n",
      "Epoch: 3502/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0705\n",
      "Epoch: 3503/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0705\n",
      "Epoch: 3504/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0704\n",
      "Epoch: 3505/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0704\n",
      "Epoch: 3506/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0704\n",
      "Epoch: 3507/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0704\n",
      "Epoch: 3508/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0704\n",
      "Epoch: 3509/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0704\n",
      "Epoch: 3510/5000, Train Loss: 0.1320\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0704\n",
      "Epoch: 3511/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0704\n",
      "Epoch: 3512/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0703\n",
      "Epoch: 3513/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0703\n",
      "Epoch: 3514/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0703\n",
      "Epoch: 3515/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0703\n",
      "Epoch: 3516/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0703\n",
      "Epoch: 3517/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0703\n",
      "Epoch: 3518/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0703\n",
      "Epoch: 3519/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0703\n",
      "Epoch: 3520/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0703\n",
      "Epoch: 3521/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0702\n",
      "Epoch: 3522/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0702\n",
      "Epoch: 3523/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0702\n",
      "Epoch: 3524/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0702\n",
      "Epoch: 3525/5000, Train Loss: 0.1319\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0702\n",
      "Epoch: 3526/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0702\n",
      "Epoch: 3527/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0702\n",
      "Epoch: 3528/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0702\n",
      "Epoch: 3529/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0701\n",
      "Epoch: 3530/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0701\n",
      "Epoch: 3531/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0701\n",
      "Epoch: 3532/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0701\n",
      "Epoch: 3533/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0701\n",
      "Epoch: 3534/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0701\n",
      "Epoch: 3535/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0701\n",
      "Epoch: 3536/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0701\n",
      "Epoch: 3537/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0701\n",
      "Epoch: 3538/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0700\n",
      "Epoch: 3539/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0700\n",
      "Epoch: 3540/5000, Train Loss: 0.1318\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0700\n",
      "Epoch: 3541/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0700\n",
      "Epoch: 3542/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0700\n",
      "Epoch: 3543/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0700\n",
      "Epoch: 3544/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0700\n",
      "Epoch: 3545/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0700\n",
      "Epoch: 3546/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0700\n",
      "Epoch: 3547/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0699\n",
      "Epoch: 3548/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0699\n",
      "Epoch: 3549/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0699\n",
      "Epoch: 3550/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0699\n",
      "Epoch: 3551/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0699\n",
      "Epoch: 3552/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0699\n",
      "Epoch: 3553/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0699\n",
      "Epoch: 3554/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0699\n",
      "Epoch: 3555/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0698\n",
      "Epoch: 3556/5000, Train Loss: 0.1317\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0698\n",
      "Epoch: 3557/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0698\n",
      "Epoch: 3558/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0698\n",
      "Epoch: 3559/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0698\n",
      "Epoch: 3560/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0698\n",
      "Epoch: 3561/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0698\n",
      "Epoch: 3562/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0698\n",
      "Epoch: 3563/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0698\n",
      "Epoch: 3564/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0697\n",
      "Epoch: 3565/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0697\n",
      "Epoch: 3566/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0697\n",
      "Epoch: 3567/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0697\n",
      "Epoch: 3568/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0697\n",
      "Epoch: 3569/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0697\n",
      "Epoch: 3570/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0697\n",
      "Epoch: 3571/5000, Train Loss: 0.1316\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0697\n",
      "Epoch: 3572/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0697\n",
      "Epoch: 3573/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0696\n",
      "Epoch: 3574/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0696\n",
      "Epoch: 3575/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0696\n",
      "Epoch: 3576/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0696\n",
      "Epoch: 3577/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0696\n",
      "Epoch: 3578/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0696\n",
      "Epoch: 3579/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0696\n",
      "Epoch: 3580/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0696\n",
      "Epoch: 3581/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0696\n",
      "Epoch: 3582/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0695\n",
      "Epoch: 3583/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0695\n",
      "Epoch: 3584/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0695\n",
      "Epoch: 3585/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0695\n",
      "Epoch: 3586/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0695\n",
      "Epoch: 3587/5000, Train Loss: 0.1315\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0695\n",
      "Epoch: 3588/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0695\n",
      "Epoch: 3589/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0695\n",
      "Epoch: 3590/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0694\n",
      "Epoch: 3591/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0694\n",
      "Epoch: 3592/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0694\n",
      "Epoch: 3593/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0694\n",
      "Epoch: 3594/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0694\n",
      "Epoch: 3595/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0694\n",
      "Epoch: 3596/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0694\n",
      "Epoch: 3597/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0694\n",
      "Epoch: 3598/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0694\n",
      "Epoch: 3599/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0693\n",
      "Epoch: 3600/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0693\n",
      "Epoch: 3601/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0693\n",
      "Epoch: 3602/5000, Train Loss: 0.1314\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0693\n",
      "Epoch: 3603/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0693\n",
      "Epoch: 3604/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0693\n",
      "Epoch: 3605/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0693\n",
      "Epoch: 3606/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0693\n",
      "Epoch: 3607/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0693\n",
      "Epoch: 3608/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0692\n",
      "Epoch: 3609/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0692\n",
      "Epoch: 3610/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0692\n",
      "Epoch: 3611/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0692\n",
      "Epoch: 3612/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0692\n",
      "Epoch: 3613/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0692\n",
      "Epoch: 3614/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0692\n",
      "Epoch: 3615/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0692\n",
      "Epoch: 3616/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0692\n",
      "Epoch: 3617/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0691\n",
      "Epoch: 3618/5000, Train Loss: 0.1313\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0691\n",
      "Epoch: 3619/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0691\n",
      "Epoch: 3620/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0691\n",
      "Epoch: 3621/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0691\n",
      "Epoch: 3622/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0691\n",
      "Epoch: 3623/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0691\n",
      "Epoch: 3624/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0691\n",
      "Epoch: 3625/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0691\n",
      "Epoch: 3626/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0690\n",
      "Epoch: 3627/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0690\n",
      "Epoch: 3628/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0690\n",
      "Epoch: 3629/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0690\n",
      "Epoch: 3630/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0690\n",
      "Epoch: 3631/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0690\n",
      "Epoch: 3632/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0690\n",
      "Epoch: 3633/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0690\n",
      "Epoch: 3634/5000, Train Loss: 0.1312\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0690\n",
      "Epoch: 3635/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0689\n",
      "Epoch: 3636/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0689\n",
      "Epoch: 3637/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0689\n",
      "Epoch: 3638/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0689\n",
      "Epoch: 3639/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0689\n",
      "Epoch: 3640/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0689\n",
      "Epoch: 3641/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0689\n",
      "Epoch: 3642/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0689\n",
      "Epoch: 3643/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0689\n",
      "Epoch: 3644/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0688\n",
      "Epoch: 3645/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0688\n",
      "Epoch: 3646/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0688\n",
      "Epoch: 3647/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0688\n",
      "Epoch: 3648/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0688\n",
      "Epoch: 3649/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0688\n",
      "Epoch: 3650/5000, Train Loss: 0.1311\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0688\n",
      "Epoch: 3651/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0688\n",
      "Epoch: 3652/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0688\n",
      "Epoch: 3653/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0687\n",
      "Epoch: 3654/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0687\n",
      "Epoch: 3655/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0687\n",
      "Epoch: 3656/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0687\n",
      "Epoch: 3657/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0687\n",
      "Epoch: 3658/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0687\n",
      "Epoch: 3659/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0687\n",
      "Epoch: 3660/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0687\n",
      "Epoch: 3661/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0687\n",
      "Epoch: 3662/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0686\n",
      "Epoch: 3663/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0686\n",
      "Epoch: 3664/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0686\n",
      "Epoch: 3665/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0686\n",
      "Epoch: 3666/5000, Train Loss: 0.1310\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0686\n",
      "Epoch: 3667/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0686\n",
      "Epoch: 3668/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0686\n",
      "Epoch: 3669/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0686\n",
      "Epoch: 3670/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0686\n",
      "Epoch: 3671/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0685\n",
      "Epoch: 3672/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0685\n",
      "Epoch: 3673/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0685\n",
      "Epoch: 3674/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0685\n",
      "Epoch: 3675/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0685\n",
      "Epoch: 3676/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0685\n",
      "Epoch: 3677/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0685\n",
      "Epoch: 3678/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0685\n",
      "Epoch: 3679/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0685\n",
      "Epoch: 3680/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0684\n",
      "Epoch: 3681/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0684\n",
      "Epoch: 3682/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0684\n",
      "Epoch: 3683/5000, Train Loss: 0.1309\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0684\n",
      "Epoch: 3684/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0684\n",
      "Epoch: 3685/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0684\n",
      "Epoch: 3686/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0684\n",
      "Epoch: 3687/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0684\n",
      "Epoch: 3688/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0684\n",
      "Epoch: 3689/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0684\n",
      "Epoch: 3690/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0683\n",
      "Epoch: 3691/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0683\n",
      "Epoch: 3692/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0683\n",
      "Epoch: 3693/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0683\n",
      "Epoch: 3694/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0683\n",
      "Epoch: 3695/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0683\n",
      "Epoch: 3696/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0683\n",
      "Epoch: 3697/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0683\n",
      "Epoch: 3698/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0683\n",
      "Epoch: 3699/5000, Train Loss: 0.1308\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0682\n",
      "Epoch: 3700/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0682\n",
      "Epoch: 3701/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0682\n",
      "Epoch: 3702/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0682\n",
      "Epoch: 3703/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0682\n",
      "Epoch: 3704/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0682\n",
      "Epoch: 3705/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0682\n",
      "Epoch: 3706/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0682\n",
      "Epoch: 3707/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0682\n",
      "Epoch: 3708/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0681\n",
      "Epoch: 3709/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0681\n",
      "Epoch: 3710/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0681\n",
      "Epoch: 3711/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0681\n",
      "Epoch: 3712/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0681\n",
      "Epoch: 3713/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0681\n",
      "Epoch: 3714/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0681\n",
      "Epoch: 3715/5000, Train Loss: 0.1307\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0681\n",
      "Epoch: 3716/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0681\n",
      "Epoch: 3717/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0680\n",
      "Epoch: 3718/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0680\n",
      "Epoch: 3719/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0680\n",
      "Epoch: 3720/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0680\n",
      "Epoch: 3721/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0680\n",
      "Epoch: 3722/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0680\n",
      "Epoch: 3723/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0680\n",
      "Epoch: 3724/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0680\n",
      "Epoch: 3725/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0680\n",
      "Epoch: 3726/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0680\n",
      "Epoch: 3727/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0679\n",
      "Epoch: 3728/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0679\n",
      "Epoch: 3729/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0679\n",
      "Epoch: 3730/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0679\n",
      "Epoch: 3731/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0679\n",
      "Epoch: 3732/5000, Train Loss: 0.1306\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0679\n",
      "Epoch: 3733/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0679\n",
      "Epoch: 3734/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0679\n",
      "Epoch: 3735/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0679\n",
      "Epoch: 3736/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0678\n",
      "Epoch: 3737/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0678\n",
      "Epoch: 3738/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0678\n",
      "Epoch: 3739/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0678\n",
      "Epoch: 3740/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0678\n",
      "Epoch: 3741/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0678\n",
      "Epoch: 3742/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0678\n",
      "Epoch: 3743/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0678\n",
      "Epoch: 3744/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0678\n",
      "Epoch: 3745/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0678\n",
      "Epoch: 3746/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0677\n",
      "Epoch: 3747/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0677\n",
      "Epoch: 3748/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0677\n",
      "Epoch: 3749/5000, Train Loss: 0.1305\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0677\n",
      "Epoch: 3750/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0677\n",
      "Epoch: 3751/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0677\n",
      "Epoch: 3752/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0677\n",
      "Epoch: 3753/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0677\n",
      "Epoch: 3754/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0677\n",
      "Epoch: 3755/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0676\n",
      "Epoch: 3756/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0676\n",
      "Epoch: 3757/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0676\n",
      "Epoch: 3758/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0676\n",
      "Epoch: 3759/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0676\n",
      "Epoch: 3760/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0676\n",
      "Epoch: 3761/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0676\n",
      "Epoch: 3762/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0676\n",
      "Epoch: 3763/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0676\n",
      "Epoch: 3764/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0676\n",
      "Epoch: 3765/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0675\n",
      "Epoch: 3766/5000, Train Loss: 0.1304\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0675\n",
      "Epoch: 3767/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0675\n",
      "Epoch: 3768/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0675\n",
      "Epoch: 3769/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0675\n",
      "Epoch: 3770/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0675\n",
      "Epoch: 3771/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0675\n",
      "Epoch: 3772/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0675\n",
      "Epoch: 3773/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0675\n",
      "Epoch: 3774/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0674\n",
      "Epoch: 3775/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0674\n",
      "Epoch: 3776/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0674\n",
      "Epoch: 3777/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0674\n",
      "Epoch: 3778/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0674\n",
      "Epoch: 3779/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0674\n",
      "Epoch: 3780/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0674\n",
      "Epoch: 3781/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0674\n",
      "Epoch: 3782/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0674\n",
      "Epoch: 3783/5000, Train Loss: 0.1303\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0674\n",
      "Epoch: 3784/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0673\n",
      "Epoch: 3785/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0673\n",
      "Epoch: 3786/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0673\n",
      "Epoch: 3787/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0673\n",
      "Epoch: 3788/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0673\n",
      "Epoch: 3789/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0673\n",
      "Epoch: 3790/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0673\n",
      "Epoch: 3791/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0673\n",
      "Epoch: 3792/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0673\n",
      "Epoch: 3793/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0672\n",
      "Epoch: 3794/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0672\n",
      "Epoch: 3795/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0672\n",
      "Epoch: 3796/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0672\n",
      "Epoch: 3797/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0672\n",
      "Epoch: 3798/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0672\n",
      "Epoch: 3799/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0672\n",
      "Epoch: 3800/5000, Train Loss: 0.1302\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0672\n",
      "Epoch: 3801/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0672\n",
      "Epoch: 3802/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0672\n",
      "Epoch: 3803/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0671\n",
      "Epoch: 3804/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0671\n",
      "Epoch: 3805/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0671\n",
      "Epoch: 3806/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0671\n",
      "Epoch: 3807/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0671\n",
      "Epoch: 3808/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0671\n",
      "Epoch: 3809/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0671\n",
      "Epoch: 3810/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0671\n",
      "Epoch: 3811/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0671\n",
      "Epoch: 3812/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0671\n",
      "Epoch: 3813/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0670\n",
      "Epoch: 3814/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0670\n",
      "Epoch: 3815/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0670\n",
      "Epoch: 3816/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0670\n",
      "Epoch: 3817/5000, Train Loss: 0.1301\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0670\n",
      "Epoch: 3818/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0670\n",
      "Epoch: 3819/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0670\n",
      "Epoch: 3820/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0670\n",
      "Epoch: 3821/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0670\n",
      "Epoch: 3822/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0669\n",
      "Epoch: 3823/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0669\n",
      "Epoch: 3824/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0669\n",
      "Epoch: 3825/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0669\n",
      "Epoch: 3826/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0669\n",
      "Epoch: 3827/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0669\n",
      "Epoch: 3828/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0669\n",
      "Epoch: 3829/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0669\n",
      "Epoch: 3830/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0669\n",
      "Epoch: 3831/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0669\n",
      "Epoch: 3832/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0668\n",
      "Epoch: 3833/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0668\n",
      "Epoch: 3834/5000, Train Loss: 0.1300\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0668\n",
      "Epoch: 3835/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0668\n",
      "Epoch: 3836/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0668\n",
      "Epoch: 3837/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0668\n",
      "Epoch: 3838/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0668\n",
      "Epoch: 3839/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0668\n",
      "Epoch: 3840/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0668\n",
      "Epoch: 3841/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0668\n",
      "Epoch: 3842/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0667\n",
      "Epoch: 3843/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0667\n",
      "Epoch: 3844/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0667\n",
      "Epoch: 3845/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0667\n",
      "Epoch: 3846/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0667\n",
      "Epoch: 3847/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0667\n",
      "Epoch: 3848/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0667\n",
      "Epoch: 3849/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0667\n",
      "Epoch: 3850/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0667\n",
      "Epoch: 3851/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0667\n",
      "Epoch: 3852/5000, Train Loss: 0.1299\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0666\n",
      "Epoch: 3853/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0666\n",
      "Epoch: 3854/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0666\n",
      "Epoch: 3855/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0666\n",
      "Epoch: 3856/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0666\n",
      "Epoch: 3857/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0666\n",
      "Epoch: 3858/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0666\n",
      "Epoch: 3859/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0666\n",
      "Epoch: 3860/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0666\n",
      "Epoch: 3861/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0666\n",
      "Epoch: 3862/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0665\n",
      "Epoch: 3863/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0665\n",
      "Epoch: 3864/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0665\n",
      "Epoch: 3865/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0665\n",
      "Epoch: 3866/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0665\n",
      "Epoch: 3867/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0665\n",
      "Epoch: 3868/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0665\n",
      "Epoch: 3869/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0665\n",
      "Epoch: 3870/5000, Train Loss: 0.1298\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0665\n",
      "Epoch: 3871/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0664\n",
      "Epoch: 3872/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0664\n",
      "Epoch: 3873/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0664\n",
      "Epoch: 3874/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0664\n",
      "Epoch: 3875/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0664\n",
      "Epoch: 3876/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0664\n",
      "Epoch: 3877/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0664\n",
      "Epoch: 3878/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0664\n",
      "Epoch: 3879/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0664\n",
      "Epoch: 3880/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0664\n",
      "Epoch: 3881/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0663\n",
      "Epoch: 3882/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0663\n",
      "Epoch: 3883/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0663\n",
      "Epoch: 3884/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0663\n",
      "Epoch: 3885/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0663\n",
      "Epoch: 3886/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0663\n",
      "Epoch: 3887/5000, Train Loss: 0.1297\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0663\n",
      "Epoch: 3888/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0663\n",
      "Epoch: 3889/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0663\n",
      "Epoch: 3890/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0663\n",
      "Epoch: 3891/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0662\n",
      "Epoch: 3892/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0662\n",
      "Epoch: 3893/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0662\n",
      "Epoch: 3894/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0662\n",
      "Epoch: 3895/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0662\n",
      "Epoch: 3896/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0662\n",
      "Epoch: 3897/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0662\n",
      "Epoch: 3898/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0662\n",
      "Epoch: 3899/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0662\n",
      "Epoch: 3900/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0662\n",
      "Epoch: 3901/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0661\n",
      "Epoch: 3902/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0661\n",
      "Epoch: 3903/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0661\n",
      "Epoch: 3904/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0661\n",
      "Epoch: 3905/5000, Train Loss: 0.1296\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0661\n",
      "Epoch: 3906/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0661\n",
      "Epoch: 3907/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0661\n",
      "Epoch: 3908/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0661\n",
      "Epoch: 3909/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0661\n",
      "Epoch: 3910/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0661\n",
      "Epoch: 3911/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0661\n",
      "Epoch: 3912/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0660\n",
      "Epoch: 3913/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0660\n",
      "Epoch: 3914/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0660\n",
      "Epoch: 3915/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0660\n",
      "Epoch: 3916/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0660\n",
      "Epoch: 3917/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0660\n",
      "Epoch: 3918/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0660\n",
      "Epoch: 3919/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0660\n",
      "Epoch: 3920/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0660\n",
      "Epoch: 3921/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0660\n",
      "Epoch: 3922/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0659\n",
      "Epoch: 3923/5000, Train Loss: 0.1295\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0659\n",
      "Epoch: 3924/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0659\n",
      "Epoch: 3925/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0659\n",
      "Epoch: 3926/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0659\n",
      "Epoch: 3927/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0659\n",
      "Epoch: 3928/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0659\n",
      "Epoch: 3929/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0659\n",
      "Epoch: 3930/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0659\n",
      "Epoch: 3931/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0659\n",
      "Epoch: 3932/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0658\n",
      "Epoch: 3933/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0658\n",
      "Epoch: 3934/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0658\n",
      "Epoch: 3935/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0658\n",
      "Epoch: 3936/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0658\n",
      "Epoch: 3937/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0658\n",
      "Epoch: 3938/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0658\n",
      "Epoch: 3939/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0658\n",
      "Epoch: 3940/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0658\n",
      "Epoch: 3941/5000, Train Loss: 0.1294\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0658\n",
      "Epoch: 3942/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0657\n",
      "Epoch: 3943/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0657\n",
      "Epoch: 3944/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0657\n",
      "Epoch: 3945/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0657\n",
      "Epoch: 3946/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0657\n",
      "Epoch: 3947/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0657\n",
      "Epoch: 3948/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0657\n",
      "Epoch: 3949/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0657\n",
      "Epoch: 3950/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0657\n",
      "Epoch: 3951/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0657\n",
      "Epoch: 3952/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0656\n",
      "Epoch: 3953/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0656\n",
      "Epoch: 3954/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0656\n",
      "Epoch: 3955/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0656\n",
      "Epoch: 3956/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0656\n",
      "Epoch: 3957/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0656\n",
      "Epoch: 3958/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0656\n",
      "Epoch: 3959/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0656\n",
      "Epoch: 3960/5000, Train Loss: 0.1293\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0656\n",
      "Epoch: 3961/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0656\n",
      "Epoch: 3962/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0656\n",
      "Epoch: 3963/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0655\n",
      "Epoch: 3964/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0655\n",
      "Epoch: 3965/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0655\n",
      "Epoch: 3966/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0655\n",
      "Epoch: 3967/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0655\n",
      "Epoch: 3968/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0655\n",
      "Epoch: 3969/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0655\n",
      "Epoch: 3970/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0655\n",
      "Epoch: 3971/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0655\n",
      "Epoch: 3972/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0655\n",
      "Epoch: 3973/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0654\n",
      "Epoch: 3974/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0654\n",
      "Epoch: 3975/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0654\n",
      "Epoch: 3976/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0654\n",
      "Epoch: 3977/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0654\n",
      "Epoch: 3978/5000, Train Loss: 0.1292\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0654\n",
      "Epoch: 3979/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0654\n",
      "Epoch: 3980/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0654\n",
      "Epoch: 3981/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0654\n",
      "Epoch: 3982/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0654\n",
      "Epoch: 3983/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0653\n",
      "Epoch: 3984/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0653\n",
      "Epoch: 3985/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0653\n",
      "Epoch: 3986/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0653\n",
      "Epoch: 3987/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0653\n",
      "Epoch: 3988/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0653\n",
      "Epoch: 3989/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0653\n",
      "Epoch: 3990/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0653\n",
      "Epoch: 3991/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0653\n",
      "Epoch: 3992/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0653\n",
      "Epoch: 3993/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0653\n",
      "Epoch: 3994/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0652\n",
      "Epoch: 3995/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0652\n",
      "Epoch: 3996/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0652\n",
      "Epoch: 3997/5000, Train Loss: 0.1291\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0652\n",
      "Epoch: 3998/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0652\n",
      "Epoch: 3999/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0652\n",
      "Epoch: 4000/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0652\n",
      "Epoch: 4001/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0652\n",
      "Epoch: 4002/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0652\n",
      "Epoch: 4003/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0652\n",
      "Epoch: 4004/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0651\n",
      "Epoch: 4005/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0651\n",
      "Epoch: 4006/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0651\n",
      "Epoch: 4007/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0651\n",
      "Epoch: 4008/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0651\n",
      "Epoch: 4009/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0651\n",
      "Epoch: 4010/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0651\n",
      "Epoch: 4011/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0651\n",
      "Epoch: 4012/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0651\n",
      "Epoch: 4013/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0651\n",
      "Epoch: 4014/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0651\n",
      "Epoch: 4015/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0650\n",
      "Epoch: 4016/5000, Train Loss: 0.1290\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0650\n",
      "Epoch: 4017/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0650\n",
      "Epoch: 4018/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0650\n",
      "Epoch: 4019/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0650\n",
      "Epoch: 4020/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0650\n",
      "Epoch: 4021/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0650\n",
      "Epoch: 4022/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0650\n",
      "Epoch: 4023/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0650\n",
      "Epoch: 4024/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0650\n",
      "Epoch: 4025/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0649\n",
      "Epoch: 4026/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0649\n",
      "Epoch: 4027/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0649\n",
      "Epoch: 4028/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0649\n",
      "Epoch: 4029/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0649\n",
      "Epoch: 4030/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0649\n",
      "Epoch: 4031/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0649\n",
      "Epoch: 4032/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0649\n",
      "Epoch: 4033/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0649\n",
      "Epoch: 4034/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0649\n",
      "Epoch: 4035/5000, Train Loss: 0.1289\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0649\n",
      "Epoch: 4036/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0648\n",
      "Epoch: 4037/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0648\n",
      "Epoch: 4038/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0648\n",
      "Epoch: 4039/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0648\n",
      "Epoch: 4040/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0648\n",
      "Epoch: 4041/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0648\n",
      "Epoch: 4042/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0648\n",
      "Epoch: 4043/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0648\n",
      "Epoch: 4044/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0648\n",
      "Epoch: 4045/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0648\n",
      "Epoch: 4046/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0647\n",
      "Epoch: 4047/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0647\n",
      "Epoch: 4048/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0647\n",
      "Epoch: 4049/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0647\n",
      "Epoch: 4050/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0647\n",
      "Epoch: 4051/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0647\n",
      "Epoch: 4052/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0647\n",
      "Epoch: 4053/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0647\n",
      "Epoch: 4054/5000, Train Loss: 0.1288\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0647\n",
      "Epoch: 4055/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0647\n",
      "Epoch: 4056/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0647\n",
      "Epoch: 4057/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0646\n",
      "Epoch: 4058/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0646\n",
      "Epoch: 4059/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0646\n",
      "Epoch: 4060/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0646\n",
      "Epoch: 4061/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0646\n",
      "Epoch: 4062/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0646\n",
      "Epoch: 4063/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0646\n",
      "Epoch: 4064/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0646\n",
      "Epoch: 4065/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0646\n",
      "Epoch: 4066/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0646\n",
      "Epoch: 4067/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0646\n",
      "Epoch: 4068/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0645\n",
      "Epoch: 4069/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0645\n",
      "Epoch: 4070/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0645\n",
      "Epoch: 4071/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0645\n",
      "Epoch: 4072/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0645\n",
      "Epoch: 4073/5000, Train Loss: 0.1287\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0645\n",
      "Epoch: 4074/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0645\n",
      "Epoch: 4075/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0645\n",
      "Epoch: 4076/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0645\n",
      "Epoch: 4077/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0645\n",
      "Epoch: 4078/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0645\n",
      "Epoch: 4079/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0644\n",
      "Epoch: 4080/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0644\n",
      "Epoch: 4081/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0644\n",
      "Epoch: 4082/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0644\n",
      "Epoch: 4083/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0644\n",
      "Epoch: 4084/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0644\n",
      "Epoch: 4085/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0644\n",
      "Epoch: 4086/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0644\n",
      "Epoch: 4087/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0644\n",
      "Epoch: 4088/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0644\n",
      "Epoch: 4089/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0643\n",
      "Epoch: 4090/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0643\n",
      "Epoch: 4091/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0643\n",
      "Epoch: 4092/5000, Train Loss: 0.1286\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0643\n",
      "Epoch: 4093/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0643\n",
      "Epoch: 4094/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0643\n",
      "Epoch: 4095/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0643\n",
      "Epoch: 4096/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0643\n",
      "Epoch: 4097/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0643\n",
      "Epoch: 4098/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0643\n",
      "Epoch: 4099/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0643\n",
      "Epoch: 4100/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0642\n",
      "Epoch: 4101/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0642\n",
      "Epoch: 4102/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0642\n",
      "Epoch: 4103/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0642\n",
      "Epoch: 4104/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0642\n",
      "Epoch: 4105/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0642\n",
      "Epoch: 4106/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0642\n",
      "Epoch: 4107/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0642\n",
      "Epoch: 4108/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0642\n",
      "Epoch: 4109/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0642\n",
      "Epoch: 4110/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0642\n",
      "Epoch: 4111/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0641\n",
      "Epoch: 4112/5000, Train Loss: 0.1285\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0641\n",
      "Epoch: 4113/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0641\n",
      "Epoch: 4114/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0641\n",
      "Epoch: 4115/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0641\n",
      "Epoch: 4116/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0641\n",
      "Epoch: 4117/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0641\n",
      "Epoch: 4118/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0641\n",
      "Epoch: 4119/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0641\n",
      "Epoch: 4120/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0641\n",
      "Epoch: 4121/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0641\n",
      "Epoch: 4122/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0640\n",
      "Epoch: 4123/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0640\n",
      "Epoch: 4124/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0640\n",
      "Epoch: 4125/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0640\n",
      "Epoch: 4126/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0640\n",
      "Epoch: 4127/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0640\n",
      "Epoch: 4128/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0640\n",
      "Epoch: 4129/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0640\n",
      "Epoch: 4130/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0640\n",
      "Epoch: 4131/5000, Train Loss: 0.1284\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0640\n",
      "Epoch: 4132/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0640\n",
      "Epoch: 4133/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0639\n",
      "Epoch: 4134/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0639\n",
      "Epoch: 4135/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0639\n",
      "Epoch: 4136/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0639\n",
      "Epoch: 4137/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0639\n",
      "Epoch: 4138/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0639\n",
      "Epoch: 4139/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0639\n",
      "Epoch: 4140/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0639\n",
      "Epoch: 4141/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0639\n",
      "Epoch: 4142/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0639\n",
      "Epoch: 4143/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0639\n",
      "Epoch: 4144/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0638\n",
      "Epoch: 4145/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0638\n",
      "Epoch: 4146/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0638\n",
      "Epoch: 4147/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0638\n",
      "Epoch: 4148/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0638\n",
      "Epoch: 4149/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0638\n",
      "Epoch: 4150/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0638\n",
      "Epoch: 4151/5000, Train Loss: 0.1283\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0638\n",
      "Epoch: 4152/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0638\n",
      "Epoch: 4153/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0638\n",
      "Epoch: 4154/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0638\n",
      "Epoch: 4155/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0637\n",
      "Epoch: 4156/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0637\n",
      "Epoch: 4157/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0637\n",
      "Epoch: 4158/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0637\n",
      "Epoch: 4159/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0637\n",
      "Epoch: 4160/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0637\n",
      "Epoch: 4161/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0637\n",
      "Epoch: 4162/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0637\n",
      "Epoch: 4163/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0637\n",
      "Epoch: 4164/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0637\n",
      "Epoch: 4165/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0637\n",
      "Epoch: 4166/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0637\n",
      "Epoch: 4167/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0636\n",
      "Epoch: 4168/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0636\n",
      "Epoch: 4169/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0636\n",
      "Epoch: 4170/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0636\n",
      "Epoch: 4171/5000, Train Loss: 0.1282\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0636\n",
      "Epoch: 4172/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0636\n",
      "Epoch: 4173/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0636\n",
      "Epoch: 4174/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0636\n",
      "Epoch: 4175/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0636\n",
      "Epoch: 4176/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0636\n",
      "Epoch: 4177/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0636\n",
      "Epoch: 4178/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0635\n",
      "Epoch: 4179/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0635\n",
      "Epoch: 4180/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0635\n",
      "Epoch: 4181/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0635\n",
      "Epoch: 4182/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0635\n",
      "Epoch: 4183/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0635\n",
      "Epoch: 4184/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0635\n",
      "Epoch: 4185/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0635\n",
      "Epoch: 4186/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0635\n",
      "Epoch: 4187/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0635\n",
      "Epoch: 4188/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0635\n",
      "Epoch: 4189/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0634\n",
      "Epoch: 4190/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0634\n",
      "Epoch: 4191/5000, Train Loss: 0.1281\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0634\n",
      "Epoch: 4192/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0634\n",
      "Epoch: 4193/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0634\n",
      "Epoch: 4194/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0634\n",
      "Epoch: 4195/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0634\n",
      "Epoch: 4196/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0634\n",
      "Epoch: 4197/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0634\n",
      "Epoch: 4198/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0634\n",
      "Epoch: 4199/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0634\n",
      "Epoch: 4200/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0633\n",
      "Epoch: 4201/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0633\n",
      "Epoch: 4202/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0633\n",
      "Epoch: 4203/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0633\n",
      "Epoch: 4204/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0633\n",
      "Epoch: 4205/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0633\n",
      "Epoch: 4206/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0633\n",
      "Epoch: 4207/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0633\n",
      "Epoch: 4208/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0633\n",
      "Epoch: 4209/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0633\n",
      "Epoch: 4210/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0633\n",
      "Epoch: 4211/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0633\n",
      "Epoch: 4212/5000, Train Loss: 0.1280\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0632\n",
      "Epoch: 4213/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0632\n",
      "Epoch: 4214/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0632\n",
      "Epoch: 4215/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0632\n",
      "Epoch: 4216/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0632\n",
      "Epoch: 4217/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0632\n",
      "Epoch: 4218/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0632\n",
      "Epoch: 4219/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0632\n",
      "Epoch: 4220/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0632\n",
      "Epoch: 4221/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0632\n",
      "Epoch: 4222/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0632\n",
      "Epoch: 4223/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0631\n",
      "Epoch: 4224/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0631\n",
      "Epoch: 4225/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0631\n",
      "Epoch: 4226/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0631\n",
      "Epoch: 4227/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0631\n",
      "Epoch: 4228/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0631\n",
      "Epoch: 4229/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0631\n",
      "Epoch: 4230/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0631\n",
      "Epoch: 4231/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0631\n",
      "Epoch: 4232/5000, Train Loss: 0.1279\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0631\n",
      "Epoch: 4233/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0631\n",
      "Epoch: 4234/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0630\n",
      "Epoch: 4235/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0630\n",
      "Epoch: 4236/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0630\n",
      "Epoch: 4237/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0630\n",
      "Epoch: 4238/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0630\n",
      "Epoch: 4239/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0630\n",
      "Epoch: 4240/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0630\n",
      "Epoch: 4241/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0630\n",
      "Epoch: 4242/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0630\n",
      "Epoch: 4243/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0630\n",
      "Epoch: 4244/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0630\n",
      "Epoch: 4245/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0630\n",
      "Epoch: 4246/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0629\n",
      "Epoch: 4247/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0629\n",
      "Epoch: 4248/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0629\n",
      "Epoch: 4249/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0629\n",
      "Epoch: 4250/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0629\n",
      "Epoch: 4251/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0629\n",
      "Epoch: 4252/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0629\n",
      "Epoch: 4253/5000, Train Loss: 0.1278\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0629\n",
      "Epoch: 4254/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0629\n",
      "Epoch: 4255/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0629\n",
      "Epoch: 4256/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0629\n",
      "Epoch: 4257/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0628\n",
      "Epoch: 4258/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0628\n",
      "Epoch: 4259/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0628\n",
      "Epoch: 4260/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0628\n",
      "Epoch: 4261/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0628\n",
      "Epoch: 4262/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0628\n",
      "Epoch: 4263/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0628\n",
      "Epoch: 4264/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0628\n",
      "Epoch: 4265/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0628\n",
      "Epoch: 4266/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0628\n",
      "Epoch: 4267/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0628\n",
      "Epoch: 4268/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0628\n",
      "Epoch: 4269/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0627\n",
      "Epoch: 4270/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0627\n",
      "Epoch: 4271/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0627\n",
      "Epoch: 4272/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0627\n",
      "Epoch: 4273/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0627\n",
      "Epoch: 4274/5000, Train Loss: 0.1277\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0627\n",
      "Epoch: 4275/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0627\n",
      "Epoch: 4276/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0627\n",
      "Epoch: 4277/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0627\n",
      "Epoch: 4278/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0627\n",
      "Epoch: 4279/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0627\n",
      "Epoch: 4280/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0627\n",
      "Epoch: 4281/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0626\n",
      "Epoch: 4282/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0626\n",
      "Epoch: 4283/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0626\n",
      "Epoch: 4284/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0626\n",
      "Epoch: 4285/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0626\n",
      "Epoch: 4286/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0626\n",
      "Epoch: 4287/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0626\n",
      "Epoch: 4288/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0626\n",
      "Epoch: 4289/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0626\n",
      "Epoch: 4290/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0626\n",
      "Epoch: 4291/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0626\n",
      "Epoch: 4292/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0625\n",
      "Epoch: 4293/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0625\n",
      "Epoch: 4294/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0625\n",
      "Epoch: 4295/5000, Train Loss: 0.1276\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0625\n",
      "Epoch: 4296/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0625\n",
      "Epoch: 4297/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0625\n",
      "Epoch: 4298/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0625\n",
      "Epoch: 4299/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0625\n",
      "Epoch: 4300/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0625\n",
      "Epoch: 4301/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0625\n",
      "Epoch: 4302/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0625\n",
      "Epoch: 4303/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0625\n",
      "Epoch: 4304/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0624\n",
      "Epoch: 4305/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0624\n",
      "Epoch: 4306/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0624\n",
      "Epoch: 4307/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0624\n",
      "Epoch: 4308/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0624\n",
      "Epoch: 4309/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0624\n",
      "Epoch: 4310/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0624\n",
      "Epoch: 4311/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0624\n",
      "Epoch: 4312/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0624\n",
      "Epoch: 4313/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0624\n",
      "Epoch: 4314/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0624\n",
      "Epoch: 4315/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0624\n",
      "Epoch: 4316/5000, Train Loss: 0.1275\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0623\n",
      "Epoch: 4317/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0623\n",
      "Epoch: 4318/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0623\n",
      "Epoch: 4319/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0623\n",
      "Epoch: 4320/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0623\n",
      "Epoch: 4321/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0623\n",
      "Epoch: 4322/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0623\n",
      "Epoch: 4323/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0623\n",
      "Epoch: 4324/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0623\n",
      "Epoch: 4325/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0623\n",
      "Epoch: 4326/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0623\n",
      "Epoch: 4327/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0623\n",
      "Epoch: 4328/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0622\n",
      "Epoch: 4329/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0622\n",
      "Epoch: 4330/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0622\n",
      "Epoch: 4331/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0622\n",
      "Epoch: 4332/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0622\n",
      "Epoch: 4333/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0622\n",
      "Epoch: 4334/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0622\n",
      "Epoch: 4335/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0622\n",
      "Epoch: 4336/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0622\n",
      "Epoch: 4337/5000, Train Loss: 0.1274\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0622\n",
      "Epoch: 4338/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0622\n",
      "Epoch: 4339/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0622\n",
      "Epoch: 4340/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0621\n",
      "Epoch: 4341/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0621\n",
      "Epoch: 4342/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0621\n",
      "Epoch: 4343/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0621\n",
      "Epoch: 4344/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0621\n",
      "Epoch: 4345/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0621\n",
      "Epoch: 4346/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0621\n",
      "Epoch: 4347/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0621\n",
      "Epoch: 4348/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0621\n",
      "Epoch: 4349/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0621\n",
      "Epoch: 4350/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0621\n",
      "Epoch: 4351/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0621\n",
      "Epoch: 4352/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0620\n",
      "Epoch: 4353/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0620\n",
      "Epoch: 4354/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0620\n",
      "Epoch: 4355/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0620\n",
      "Epoch: 4356/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0620\n",
      "Epoch: 4357/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0620\n",
      "Epoch: 4358/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0620\n",
      "Epoch: 4359/5000, Train Loss: 0.1273\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0620\n",
      "Epoch: 4360/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0620\n",
      "Epoch: 4361/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0620\n",
      "Epoch: 4362/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0620\n",
      "Epoch: 4363/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0620\n",
      "Epoch: 4364/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0619\n",
      "Epoch: 4365/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0619\n",
      "Epoch: 4366/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0619\n",
      "Epoch: 4367/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0619\n",
      "Epoch: 4368/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0619\n",
      "Epoch: 4369/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0619\n",
      "Epoch: 4370/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0619\n",
      "Epoch: 4371/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0619\n",
      "Epoch: 4372/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0619\n",
      "Epoch: 4373/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0619\n",
      "Epoch: 4374/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0619\n",
      "Epoch: 4375/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0619\n",
      "Epoch: 4376/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0618\n",
      "Epoch: 4377/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0618\n",
      "Epoch: 4378/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0618\n",
      "Epoch: 4379/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0618\n",
      "Epoch: 4380/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0618\n",
      "Epoch: 4381/5000, Train Loss: 0.1272\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0618\n",
      "Epoch: 4382/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0618\n",
      "Epoch: 4383/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0618\n",
      "Epoch: 4384/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0618\n",
      "Epoch: 4385/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0618\n",
      "Epoch: 4386/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0618\n",
      "Epoch: 4387/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0618\n",
      "Epoch: 4388/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0617\n",
      "Epoch: 4389/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0617\n",
      "Epoch: 4390/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0617\n",
      "Epoch: 4391/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0617\n",
      "Epoch: 4392/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0617\n",
      "Epoch: 4393/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0617\n",
      "Epoch: 4394/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0617\n",
      "Epoch: 4395/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0617\n",
      "Epoch: 4396/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0617\n",
      "Epoch: 4397/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0617\n",
      "Epoch: 4398/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0617\n",
      "Epoch: 4399/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0617\n",
      "Epoch: 4400/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0616\n",
      "Epoch: 4401/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0616\n",
      "Epoch: 4402/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0616\n",
      "Epoch: 4403/5000, Train Loss: 0.1271\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0616\n",
      "Epoch: 4404/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0616\n",
      "Epoch: 4405/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0616\n",
      "Epoch: 4406/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0616\n",
      "Epoch: 4407/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0616\n",
      "Epoch: 4408/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0616\n",
      "Epoch: 4409/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0616\n",
      "Epoch: 4410/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0616\n",
      "Epoch: 4411/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0616\n",
      "Epoch: 4412/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0615\n",
      "Epoch: 4413/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0615\n",
      "Epoch: 4414/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0615\n",
      "Epoch: 4415/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0615\n",
      "Epoch: 4416/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0615\n",
      "Epoch: 4417/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0615\n",
      "Epoch: 4418/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0615\n",
      "Epoch: 4419/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0615\n",
      "Epoch: 4420/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0615\n",
      "Epoch: 4421/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0615\n",
      "Epoch: 4422/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0615\n",
      "Epoch: 4423/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0615\n",
      "Epoch: 4424/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0615\n",
      "Epoch: 4425/5000, Train Loss: 0.1270\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0614\n",
      "Epoch: 4426/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0614\n",
      "Epoch: 4427/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0614\n",
      "Epoch: 4428/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0614\n",
      "Epoch: 4429/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0614\n",
      "Epoch: 4430/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0614\n",
      "Epoch: 4431/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0614\n",
      "Epoch: 4432/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0614\n",
      "Epoch: 4433/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0614\n",
      "Epoch: 4434/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0614\n",
      "Epoch: 4435/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0614\n",
      "Epoch: 4436/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0614\n",
      "Epoch: 4437/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0613\n",
      "Epoch: 4438/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0613\n",
      "Epoch: 4439/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0613\n",
      "Epoch: 4440/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0613\n",
      "Epoch: 4441/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0613\n",
      "Epoch: 4442/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0613\n",
      "Epoch: 4443/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0613\n",
      "Epoch: 4444/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0613\n",
      "Epoch: 4445/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0613\n",
      "Epoch: 4446/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0613\n",
      "Epoch: 4447/5000, Train Loss: 0.1269\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0613\n",
      "Epoch: 4448/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0613\n",
      "Epoch: 4449/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0612\n",
      "Epoch: 4450/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0612\n",
      "Epoch: 4451/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0612\n",
      "Epoch: 4452/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0612\n",
      "Epoch: 4453/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0612\n",
      "Epoch: 4454/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0612\n",
      "Epoch: 4455/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0612\n",
      "Epoch: 4456/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0612\n",
      "Epoch: 4457/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0612\n",
      "Epoch: 4458/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0612\n",
      "Epoch: 4459/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0612\n",
      "Epoch: 4460/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0612\n",
      "Epoch: 4461/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0612\n",
      "Epoch: 4462/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0611\n",
      "Epoch: 4463/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0611\n",
      "Epoch: 4464/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0611\n",
      "Epoch: 4465/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0611\n",
      "Epoch: 4466/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0611\n",
      "Epoch: 4467/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0611\n",
      "Epoch: 4468/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0611\n",
      "Epoch: 4469/5000, Train Loss: 0.1268\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0611\n",
      "Epoch: 4470/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0611\n",
      "Epoch: 4471/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0611\n",
      "Epoch: 4472/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0611\n",
      "Epoch: 4473/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0611\n",
      "Epoch: 4474/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0610\n",
      "Epoch: 4475/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0610\n",
      "Epoch: 4476/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0610\n",
      "Epoch: 4477/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0610\n",
      "Epoch: 4478/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0610\n",
      "Epoch: 4479/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0610\n",
      "Epoch: 4480/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0610\n",
      "Epoch: 4481/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0610\n",
      "Epoch: 4482/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0610\n",
      "Epoch: 4483/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0610\n",
      "Epoch: 4484/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0610\n",
      "Epoch: 4485/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0610\n",
      "Epoch: 4486/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0610\n",
      "Epoch: 4487/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0609\n",
      "Epoch: 4488/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0609\n",
      "Epoch: 4489/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0609\n",
      "Epoch: 4490/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0609\n",
      "Epoch: 4491/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0609\n",
      "Epoch: 4492/5000, Train Loss: 0.1267\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0609\n",
      "Epoch: 4493/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0609\n",
      "Epoch: 4494/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0609\n",
      "Epoch: 4495/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0609\n",
      "Epoch: 4496/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0609\n",
      "Epoch: 4497/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0609\n",
      "Epoch: 4498/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0609\n",
      "Epoch: 4499/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0608\n",
      "Epoch: 4500/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0608\n",
      "Epoch: 4501/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0608\n",
      "Epoch: 4502/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0608\n",
      "Epoch: 4503/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0608\n",
      "Epoch: 4504/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0608\n",
      "Epoch: 4505/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0608\n",
      "Epoch: 4506/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0608\n",
      "Epoch: 4507/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0608\n",
      "Epoch: 4508/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0608\n",
      "Epoch: 4509/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0608\n",
      "Epoch: 4510/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0608\n",
      "Epoch: 4511/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0608\n",
      "Epoch: 4512/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0607\n",
      "Epoch: 4513/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0607\n",
      "Epoch: 4514/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0607\n",
      "Epoch: 4515/5000, Train Loss: 0.1266\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0607\n",
      "Epoch: 4516/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0607\n",
      "Epoch: 4517/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0607\n",
      "Epoch: 4518/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0607\n",
      "Epoch: 4519/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0607\n",
      "Epoch: 4520/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0607\n",
      "Epoch: 4521/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0607\n",
      "Epoch: 4522/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0607\n",
      "Epoch: 4523/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0607\n",
      "Epoch: 4524/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0607\n",
      "Epoch: 4525/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0606\n",
      "Epoch: 4526/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0606\n",
      "Epoch: 4527/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0606\n",
      "Epoch: 4528/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0606\n",
      "Epoch: 4529/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0606\n",
      "Epoch: 4530/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0606\n",
      "Epoch: 4531/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0606\n",
      "Epoch: 4532/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0606\n",
      "Epoch: 4533/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0606\n",
      "Epoch: 4534/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0606\n",
      "Epoch: 4535/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0606\n",
      "Epoch: 4536/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0606\n",
      "Epoch: 4537/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0606\n",
      "Epoch: 4538/5000, Train Loss: 0.1265\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0605\n",
      "Epoch: 4539/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0605\n",
      "Epoch: 4540/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0605\n",
      "Epoch: 4541/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0605\n",
      "Epoch: 4542/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0605\n",
      "Epoch: 4543/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0605\n",
      "Epoch: 4544/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0605\n",
      "Epoch: 4545/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0605\n",
      "Epoch: 4546/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0605\n",
      "Epoch: 4547/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0605\n",
      "Epoch: 4548/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0605\n",
      "Epoch: 4549/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0605\n",
      "Epoch: 4550/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0604\n",
      "Epoch: 4551/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0604\n",
      "Epoch: 4552/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0604\n",
      "Epoch: 4553/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0604\n",
      "Epoch: 4554/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0604\n",
      "Epoch: 4555/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0604\n",
      "Epoch: 4556/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0604\n",
      "Epoch: 4557/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0604\n",
      "Epoch: 4558/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0604\n",
      "Epoch: 4559/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0604\n",
      "Epoch: 4560/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0604\n",
      "Epoch: 4561/5000, Train Loss: 0.1264\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0604\n",
      "Epoch: 4562/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0604\n",
      "Epoch: 4563/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0603\n",
      "Epoch: 4564/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0603\n",
      "Epoch: 4565/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0603\n",
      "Epoch: 4566/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0603\n",
      "Epoch: 4567/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0603\n",
      "Epoch: 4568/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0603\n",
      "Epoch: 4569/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0603\n",
      "Epoch: 4570/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0603\n",
      "Epoch: 4571/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0603\n",
      "Epoch: 4572/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0603\n",
      "Epoch: 4573/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0603\n",
      "Epoch: 4574/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0603\n",
      "Epoch: 4575/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0603\n",
      "Epoch: 4576/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0602\n",
      "Epoch: 4577/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0602\n",
      "Epoch: 4578/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0602\n",
      "Epoch: 4579/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0602\n",
      "Epoch: 4580/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0602\n",
      "Epoch: 4581/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0602\n",
      "Epoch: 4582/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0602\n",
      "Epoch: 4583/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0602\n",
      "Epoch: 4584/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0602\n",
      "Epoch: 4585/5000, Train Loss: 0.1263\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0602\n",
      "Epoch: 4586/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0602\n",
      "Epoch: 4587/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0602\n",
      "Epoch: 4588/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0602\n",
      "Epoch: 4589/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0601\n",
      "Epoch: 4590/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0601\n",
      "Epoch: 4591/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0601\n",
      "Epoch: 4592/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0601\n",
      "Epoch: 4593/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0601\n",
      "Epoch: 4594/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0601\n",
      "Epoch: 4595/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0601\n",
      "Epoch: 4596/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0601\n",
      "Epoch: 4597/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0601\n",
      "Epoch: 4598/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0601\n",
      "Epoch: 4599/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0601\n",
      "Epoch: 4600/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0601\n",
      "Epoch: 4601/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0601\n",
      "Epoch: 4602/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0600\n",
      "Epoch: 4603/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0600\n",
      "Epoch: 4604/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0600\n",
      "Epoch: 4605/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0600\n",
      "Epoch: 4606/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0600\n",
      "Epoch: 4607/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0600\n",
      "Epoch: 4608/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0600\n",
      "Epoch: 4609/5000, Train Loss: 0.1262\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0600\n",
      "Epoch: 4610/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0600\n",
      "Epoch: 4611/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0600\n",
      "Epoch: 4612/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0600\n",
      "Epoch: 4613/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0600\n",
      "Epoch: 4614/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0600\n",
      "Epoch: 4615/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0600\n",
      "Epoch: 4616/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0599\n",
      "Epoch: 4617/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0599\n",
      "Epoch: 4618/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0599\n",
      "Epoch: 4619/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0599\n",
      "Epoch: 4620/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0599\n",
      "Epoch: 4621/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0599\n",
      "Epoch: 4622/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0599\n",
      "Epoch: 4623/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0599\n",
      "Epoch: 4624/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0599\n",
      "Epoch: 4625/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0599\n",
      "Epoch: 4626/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0599\n",
      "Epoch: 4627/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0599\n",
      "Epoch: 4628/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0599\n",
      "Epoch: 4629/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0598\n",
      "Epoch: 4630/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0598\n",
      "Epoch: 4631/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0598\n",
      "Epoch: 4632/5000, Train Loss: 0.1261\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0598\n",
      "Epoch: 4633/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0598\n",
      "Epoch: 4634/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0598\n",
      "Epoch: 4635/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0598\n",
      "Epoch: 4636/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0598\n",
      "Epoch: 4637/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0598\n",
      "Epoch: 4638/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0598\n",
      "Epoch: 4639/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0598\n",
      "Epoch: 4640/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0598\n",
      "Epoch: 4641/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0598\n",
      "Epoch: 4642/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0597\n",
      "Epoch: 4643/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0597\n",
      "Epoch: 4644/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0597\n",
      "Epoch: 4645/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0597\n",
      "Epoch: 4646/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0597\n",
      "Epoch: 4647/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0597\n",
      "Epoch: 4648/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0597\n",
      "Epoch: 4649/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0597\n",
      "Epoch: 4650/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0597\n",
      "Epoch: 4651/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0597\n",
      "Epoch: 4652/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0597\n",
      "Epoch: 4653/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0597\n",
      "Epoch: 4654/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0597\n",
      "Epoch: 4655/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0596\n",
      "Epoch: 4656/5000, Train Loss: 0.1260\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0596\n",
      "Epoch: 4657/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0596\n",
      "Epoch: 4658/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0596\n",
      "Epoch: 4659/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0596\n",
      "Epoch: 4660/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0596\n",
      "Epoch: 4661/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0596\n",
      "Epoch: 4662/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0596\n",
      "Epoch: 4663/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0596\n",
      "Epoch: 4664/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0596\n",
      "Epoch: 4665/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0596\n",
      "Epoch: 4666/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0596\n",
      "Epoch: 4667/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0596\n",
      "Epoch: 4668/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0596\n",
      "Epoch: 4669/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0595\n",
      "Epoch: 4670/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0595\n",
      "Epoch: 4671/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0595\n",
      "Epoch: 4672/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0595\n",
      "Epoch: 4673/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0595\n",
      "Epoch: 4674/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0595\n",
      "Epoch: 4675/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0595\n",
      "Epoch: 4676/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0595\n",
      "Epoch: 4677/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0595\n",
      "Epoch: 4678/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0595\n",
      "Epoch: 4679/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0595\n",
      "Epoch: 4680/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0595\n",
      "Epoch: 4681/5000, Train Loss: 0.1259\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0595\n",
      "Epoch: 4682/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0594\n",
      "Epoch: 4683/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0594\n",
      "Epoch: 4684/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0594\n",
      "Epoch: 4685/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0594\n",
      "Epoch: 4686/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0594\n",
      "Epoch: 4687/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0594\n",
      "Epoch: 4688/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0594\n",
      "Epoch: 4689/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0594\n",
      "Epoch: 4690/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0594\n",
      "Epoch: 4691/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0594\n",
      "Epoch: 4692/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0594\n",
      "Epoch: 4693/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0594\n",
      "Epoch: 4694/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0594\n",
      "Epoch: 4695/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0594\n",
      "Epoch: 4696/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0593\n",
      "Epoch: 4697/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0593\n",
      "Epoch: 4698/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0593\n",
      "Epoch: 4699/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0593\n",
      "Epoch: 4700/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0593\n",
      "Epoch: 4701/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0593\n",
      "Epoch: 4702/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0593\n",
      "Epoch: 4703/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0593\n",
      "Epoch: 4704/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0593\n",
      "Epoch: 4705/5000, Train Loss: 0.1258\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0593\n",
      "Epoch: 4706/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0593\n",
      "Epoch: 4707/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0593\n",
      "Epoch: 4708/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0593\n",
      "Epoch: 4709/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0592\n",
      "Epoch: 4710/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0592\n",
      "Epoch: 4711/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0592\n",
      "Epoch: 4712/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0592\n",
      "Epoch: 4713/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0592\n",
      "Epoch: 4714/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0592\n",
      "Epoch: 4715/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0592\n",
      "Epoch: 4716/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0592\n",
      "Epoch: 4717/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0592\n",
      "Epoch: 4718/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0592\n",
      "Epoch: 4719/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0592\n",
      "Epoch: 4720/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0592\n",
      "Epoch: 4721/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0592\n",
      "Epoch: 4722/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0592\n",
      "Epoch: 4723/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0591\n",
      "Epoch: 4724/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0591\n",
      "Epoch: 4725/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0591\n",
      "Epoch: 4726/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0591\n",
      "Epoch: 4727/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0591\n",
      "Epoch: 4728/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0591\n",
      "Epoch: 4729/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0591\n",
      "Epoch: 4730/5000, Train Loss: 0.1257\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0591\n",
      "Epoch: 4731/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0591\n",
      "Epoch: 4732/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0591\n",
      "Epoch: 4733/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0591\n",
      "Epoch: 4734/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0591\n",
      "Epoch: 4735/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0591\n",
      "Epoch: 4736/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0591\n",
      "Epoch: 4737/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0590\n",
      "Epoch: 4738/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0590\n",
      "Epoch: 4739/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0590\n",
      "Epoch: 4740/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0590\n",
      "Epoch: 4741/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0590\n",
      "Epoch: 4742/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0590\n",
      "Epoch: 4743/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0590\n",
      "Epoch: 4744/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0590\n",
      "Epoch: 4745/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0590\n",
      "Epoch: 4746/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0590\n",
      "Epoch: 4747/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0590\n",
      "Epoch: 4748/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0590\n",
      "Epoch: 4749/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0590\n",
      "Epoch: 4750/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0590\n",
      "Epoch: 4751/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0589\n",
      "Epoch: 4752/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0589\n",
      "Epoch: 4753/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0589\n",
      "Epoch: 4754/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0589\n",
      "Epoch: 4755/5000, Train Loss: 0.1256\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0589\n",
      "Epoch: 4756/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0589\n",
      "Epoch: 4757/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0589\n",
      "Epoch: 4758/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0589\n",
      "Epoch: 4759/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0589\n",
      "Epoch: 4760/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0589\n",
      "Epoch: 4761/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0589\n",
      "Epoch: 4762/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0589\n",
      "Epoch: 4763/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0589\n",
      "Epoch: 4764/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0588\n",
      "Epoch: 4765/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0588\n",
      "Epoch: 4766/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0588\n",
      "Epoch: 4767/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0588\n",
      "Epoch: 4768/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0588\n",
      "Epoch: 4769/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0588\n",
      "Epoch: 4770/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0588\n",
      "Epoch: 4771/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0588\n",
      "Epoch: 4772/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0588\n",
      "Epoch: 4773/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0588\n",
      "Epoch: 4774/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0588\n",
      "Epoch: 4775/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0588\n",
      "Epoch: 4776/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0588\n",
      "Epoch: 4777/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0588\n",
      "Epoch: 4778/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0587\n",
      "Epoch: 4779/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0587\n",
      "Epoch: 4780/5000, Train Loss: 0.1255\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0587\n",
      "Epoch: 4781/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0587\n",
      "Epoch: 4782/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0587\n",
      "Epoch: 4783/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0587\n",
      "Epoch: 4784/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0587\n",
      "Epoch: 4785/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0587\n",
      "Epoch: 4786/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0587\n",
      "Epoch: 4787/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0587\n",
      "Epoch: 4788/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0587\n",
      "Epoch: 4789/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0587\n",
      "Epoch: 4790/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0587\n",
      "Epoch: 4791/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0587\n",
      "Epoch: 4792/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0586\n",
      "Epoch: 4793/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0586\n",
      "Epoch: 4794/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0586\n",
      "Epoch: 4795/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0586\n",
      "Epoch: 4796/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0586\n",
      "Epoch: 4797/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0586\n",
      "Epoch: 4798/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0586\n",
      "Epoch: 4799/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0586\n",
      "Epoch: 4800/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0586\n",
      "Epoch: 4801/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0586\n",
      "Epoch: 4802/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0586\n",
      "Epoch: 4803/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0586\n",
      "Epoch: 4804/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0586\n",
      "Epoch: 4805/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0586\n",
      "Epoch: 4806/5000, Train Loss: 0.1254\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0585\n",
      "Epoch: 4807/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0585\n",
      "Epoch: 4808/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0585\n",
      "Epoch: 4809/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0585\n",
      "Epoch: 4810/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0585\n",
      "Epoch: 4811/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0585\n",
      "Epoch: 4812/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0585\n",
      "Epoch: 4813/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0585\n",
      "Epoch: 4814/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0585\n",
      "Epoch: 4815/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0585\n",
      "Epoch: 4816/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0585\n",
      "Epoch: 4817/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0585\n",
      "Epoch: 4818/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0585\n",
      "Epoch: 4819/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0585\n",
      "Epoch: 4820/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4821/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4822/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4823/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4824/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4825/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4826/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4827/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4828/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4829/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4830/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4831/5000, Train Loss: 0.1253\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4832/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4833/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4834/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0584\n",
      "Epoch: 4835/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0583\n",
      "Epoch: 4836/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0583\n",
      "Epoch: 4837/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0583\n",
      "Epoch: 4838/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0583\n",
      "Epoch: 4839/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0583\n",
      "Epoch: 4840/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0583\n",
      "Epoch: 4841/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0583\n",
      "Epoch: 4842/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0583\n",
      "Epoch: 4843/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0583\n",
      "Epoch: 4844/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0583\n",
      "Epoch: 4845/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0583\n",
      "Epoch: 4846/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0583\n",
      "Epoch: 4847/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0583\n",
      "Epoch: 4848/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0583\n",
      "Epoch: 4849/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0582\n",
      "Epoch: 4850/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0582\n",
      "Epoch: 4851/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0582\n",
      "Epoch: 4852/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0582\n",
      "Epoch: 4853/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0582\n",
      "Epoch: 4854/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0582\n",
      "Epoch: 4855/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0582\n",
      "Epoch: 4856/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0582\n",
      "Epoch: 4857/5000, Train Loss: 0.1252\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0582\n",
      "Epoch: 4858/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0582\n",
      "Epoch: 4859/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0582\n",
      "Epoch: 4860/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0582\n",
      "Epoch: 4861/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0582\n",
      "Epoch: 4862/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0582\n",
      "Epoch: 4863/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4864/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4865/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4866/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4867/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4868/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4869/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4870/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4871/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4872/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4873/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4874/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4875/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4876/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4877/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0581\n",
      "Epoch: 4878/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0580\n",
      "Epoch: 4879/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0580\n",
      "Epoch: 4880/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0580\n",
      "Epoch: 4881/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0580\n",
      "Epoch: 4882/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0580\n",
      "Epoch: 4883/5000, Train Loss: 0.1251\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0580\n",
      "Epoch: 4884/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0580\n",
      "Epoch: 4885/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0580\n",
      "Epoch: 4886/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0580\n",
      "Epoch: 4887/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0580\n",
      "Epoch: 4888/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0580\n",
      "Epoch: 4889/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0580\n",
      "Epoch: 4890/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0580\n",
      "Epoch: 4891/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0580\n",
      "Epoch: 4892/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4893/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4894/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4895/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4896/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4897/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4898/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4899/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4900/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4901/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4902/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4903/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4904/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4905/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4906/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0579\n",
      "Epoch: 4907/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0578\n",
      "Epoch: 4908/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0578\n",
      "Epoch: 4909/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0578\n",
      "Epoch: 4910/5000, Train Loss: 0.1250\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0578\n",
      "Epoch: 4911/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0578\n",
      "Epoch: 4912/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0578\n",
      "Epoch: 4913/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0578\n",
      "Epoch: 4914/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0578\n",
      "Epoch: 4915/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0578\n",
      "Epoch: 4916/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0578\n",
      "Epoch: 4917/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0578\n",
      "Epoch: 4918/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0578\n",
      "Epoch: 4919/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0578\n",
      "Epoch: 4920/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0578\n",
      "Epoch: 4921/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4922/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4923/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4924/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4925/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4926/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4927/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4928/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4929/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4930/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4931/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4932/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4933/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4934/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4935/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0577\n",
      "Epoch: 4936/5000, Train Loss: 0.1249\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4937/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4938/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4939/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4940/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4941/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4942/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4943/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4944/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4945/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4946/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4947/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4948/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4949/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4950/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0576\n",
      "Epoch: 4951/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0575\n",
      "Epoch: 4952/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0575\n",
      "Epoch: 4953/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0575\n",
      "Epoch: 4954/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0575\n",
      "Epoch: 4955/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0575\n",
      "Epoch: 4956/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0575\n",
      "Epoch: 4957/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0575\n",
      "Epoch: 4958/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0575\n",
      "Epoch: 4959/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0575\n",
      "Epoch: 4960/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0575\n",
      "Epoch: 4961/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0575\n",
      "Epoch: 4962/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0575\n",
      "Epoch: 4963/5000, Train Loss: 0.1248\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0575\n",
      "Epoch: 4964/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0575\n",
      "Epoch: 4965/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4966/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4967/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4968/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4969/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4970/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4971/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4972/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4973/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4974/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4975/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4976/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4977/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4978/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4979/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0574\n",
      "Epoch: 4980/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4981/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4982/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4983/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4984/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4985/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4986/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4987/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4988/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4989/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4990/5000, Train Loss: 0.1247\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4991/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4992/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4993/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4994/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0573\n",
      "Epoch: 4995/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0572\n",
      "Epoch: 4996/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0572\n",
      "Epoch: 4997/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0572\n",
      "Epoch: 4998/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0572\n",
      "Epoch: 4999/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0572\n",
      "Epoch: 5000/5000, Train Loss: 0.1246\n",
      "Accuracy on Val set: 100.00%\tLoss on Val set: 0.0572\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[-14.50455216,   0.1190008 ,   0.11370495]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from LogisticRegression import LogisticRegression\n",
    "\n",
    "epochs = 5000\n",
    "alpha = 0.01\n",
    "logistic_reg = LogisticRegression(x=train_x,y=train_y_ex,val_x=val_x,val_y=val_y_ex,epoch=epochs,lr=alpha)\n",
    "theta,train_loss,val_loss = logistic_reg.train()\n",
    "theta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看准确率、损失和F1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 100.00%\n",
      "My F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "acc = logistic_reg.test(val_x,val_y_ex)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(acc * 100))\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_true=val_y_ex,y_pred=logistic_reg.predict(val_x))\n",
    "print(\"My F1 Score: {:.4f}\".format(f1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "调用库函数验证"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Accuracy: 100.00%\n",
      "Sklearn Val Loss: 0.8861\n",
      "SKlearn Parameters:  [[-21.33415113   0.17389086   0.17020951]]\n",
      "Sklearn F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sk_lr = LogisticRegression(max_iter=50000)\n",
    "sk_lr.fit(train_x,train_y)\n",
    "sk_pred = sk_lr.predict(val_x)\n",
    "count = np.sum(np.equal(sk_pred,val_y))\n",
    "sk_acc = count/val_y.shape[0]\n",
    "sk_prob = sk_lr.predict_proba(val_x)\n",
    "\n",
    "from LogisticRegression import bce_loss\n",
    "sk_loss = bce_loss(sk_prob[:,1], val_y_ex)\n",
    "sk_theta = np.array([[sk_lr.intercept_[0],sk_lr.coef_[0,0],sk_lr.coef_[0,1]]])\n",
    "sk_f1 = f1_score(y_true=val_y_ex,y_pred=sk_pred)\n",
    "print(\"Sklearn Accuracy: {:.2f}%\".format(sk_acc * 100))\n",
    "print(\"Sklearn Val Loss: {:.4f}\".format(sk_loss))\n",
    "print(\"SKlearn Parameters: \",sk_theta)\n",
    "print(\"Sklearn F1 Score: {:.4f}\".format(sk_f1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "决策边界可视化"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[127.56306425  -1.04657537  -1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef = -(theta / theta[0,2])  # find the\n",
    "coef1 = -(sk_theta / sk_theta[0,2])\n",
    "print(coef)\n",
    "\n",
    "x = np.arange(data[:,0].min(), data[:,0].max(), step=1)\n",
    "y = coef[0,0] + coef[0,1]*x\n",
    "y1 = coef1[0,0] + coef[0,1]*x\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(x,y,label=\"My Prediction\")\n",
    "ax.plot(x,y1,label=\"Sklearn\")\n",
    "ax.scatter(x=positive_data[:, 0], y=positive_data[:, 1], s=10, color=\"red\",label=\"positive\")\n",
    "ax.scatter(x=negative_data[:, 0], y=negative_data[:, 1], s=10, color=\"blue\",label=\"negative\")\n",
    "ax.set_title(\"Decision Boundary\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "画出训练过程"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(np.arange(1,epochs+1), train_loss, 'r', label=\"Train Loss\")\n",
    "ax.plot(np.arange(1,epochs+1), val_loss, 'b', label=\"Val Loss\")\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Train Curve')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 正则化\n",
    "### regularized cost（正则化代价函数）\n",
    "$$J\\left( \\theta  \\right)=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[-{{y}^{(i)}}\\log \\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)-\\left( 1-{{y}^{(i)}} \\right)\\log \\left( 1-{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)]}+\\frac{\\lambda }{2m}\\sum\\limits_{j=1}^{n}{\\theta _{j}^{2}}$$\n",
    "正则化项实现了对参数的缩小，使得某些导致过拟合的特征的参数变小。\n",
    "从另一个角度来说，使得对损失不敏感的参数缩小较大，对损失敏感的参数缩小较小。详见Deep Learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.051267 ,  0.69956  ,  1.       ],\n       [-0.092742 ,  0.68494  ,  1.       ],\n       [-0.21371  ,  0.69225  ,  1.       ],\n       [-0.375    ,  0.50219  ,  1.       ],\n       [-0.51325  ,  0.46564  ,  1.       ],\n       [-0.52477  ,  0.2098   ,  1.       ],\n       [-0.39804  ,  0.034357 ,  1.       ],\n       [-0.30588  , -0.19225  ,  1.       ],\n       [ 0.016705 , -0.40424  ,  1.       ],\n       [ 0.13191  , -0.51389  ,  1.       ],\n       [ 0.38537  , -0.56506  ,  1.       ],\n       [ 0.52938  , -0.5212   ,  1.       ],\n       [ 0.63882  , -0.24342  ,  1.       ],\n       [ 0.73675  , -0.18494  ,  1.       ],\n       [ 0.54666  ,  0.48757  ,  1.       ],\n       [ 0.322    ,  0.5826   ,  1.       ],\n       [ 0.16647  ,  0.53874  ,  1.       ],\n       [-0.046659 ,  0.81652  ,  1.       ],\n       [-0.17339  ,  0.69956  ,  1.       ],\n       [-0.47869  ,  0.63377  ,  1.       ],\n       [-0.60541  ,  0.59722  ,  1.       ],\n       [-0.62846  ,  0.33406  ,  1.       ],\n       [-0.59389  ,  0.005117 ,  1.       ],\n       [-0.42108  , -0.27266  ,  1.       ],\n       [-0.11578  , -0.39693  ,  1.       ],\n       [ 0.20104  , -0.60161  ,  1.       ],\n       [ 0.46601  , -0.53582  ,  1.       ],\n       [ 0.67339  , -0.53582  ,  1.       ],\n       [-0.13882  ,  0.54605  ,  1.       ],\n       [-0.29435  ,  0.77997  ,  1.       ],\n       [-0.26555  ,  0.96272  ,  1.       ],\n       [-0.16187  ,  0.8019   ,  1.       ],\n       [-0.17339  ,  0.64839  ,  1.       ],\n       [-0.28283  ,  0.47295  ,  1.       ],\n       [-0.36348  ,  0.31213  ,  1.       ],\n       [-0.30012  ,  0.027047 ,  1.       ],\n       [-0.23675  , -0.21418  ,  1.       ],\n       [-0.06394  , -0.18494  ,  1.       ],\n       [ 0.062788 , -0.16301  ,  1.       ],\n       [ 0.22984  , -0.41155  ,  1.       ],\n       [ 0.2932   , -0.2288   ,  1.       ],\n       [ 0.48329  , -0.18494  ,  1.       ],\n       [ 0.64459  , -0.14108  ,  1.       ],\n       [ 0.46025  ,  0.012427 ,  1.       ],\n       [ 0.6273   ,  0.15863  ,  1.       ],\n       [ 0.57546  ,  0.26827  ,  1.       ],\n       [ 0.72523  ,  0.44371  ,  1.       ],\n       [ 0.22408  ,  0.52412  ,  1.       ],\n       [ 0.44297  ,  0.67032  ,  1.       ],\n       [ 0.322    ,  0.69225  ,  1.       ],\n       [ 0.13767  ,  0.57529  ,  1.       ],\n       [-0.0063364,  0.39985  ,  1.       ],\n       [-0.092742 ,  0.55336  ,  1.       ],\n       [-0.20795  ,  0.35599  ,  1.       ],\n       [-0.20795  ,  0.17325  ,  1.       ],\n       [-0.43836  ,  0.21711  ,  1.       ],\n       [-0.21947  , -0.016813 ,  1.       ],\n       [-0.13882  , -0.27266  ,  1.       ],\n       [ 0.18376  ,  0.93348  ,  0.       ],\n       [ 0.22408  ,  0.77997  ,  0.       ],\n       [ 0.29896  ,  0.61915  ,  0.       ],\n       [ 0.50634  ,  0.75804  ,  0.       ],\n       [ 0.61578  ,  0.7288   ,  0.       ],\n       [ 0.60426  ,  0.59722  ,  0.       ],\n       [ 0.76555  ,  0.50219  ,  0.       ],\n       [ 0.92684  ,  0.3633   ,  0.       ],\n       [ 0.82316  ,  0.27558  ,  0.       ],\n       [ 0.96141  ,  0.085526 ,  0.       ],\n       [ 0.93836  ,  0.012427 ,  0.       ],\n       [ 0.86348  , -0.082602 ,  0.       ],\n       [ 0.89804  , -0.20687  ,  0.       ],\n       [ 0.85196  , -0.36769  ,  0.       ],\n       [ 0.82892  , -0.5212   ,  0.       ],\n       [ 0.79435  , -0.55775  ,  0.       ],\n       [ 0.59274  , -0.7405   ,  0.       ],\n       [ 0.51786  , -0.5943   ,  0.       ],\n       [ 0.46601  , -0.41886  ,  0.       ],\n       [ 0.35081  , -0.57968  ,  0.       ],\n       [ 0.28744  , -0.76974  ,  0.       ],\n       [ 0.085829 , -0.75512  ,  0.       ],\n       [ 0.14919  , -0.57968  ,  0.       ],\n       [-0.13306  , -0.4481   ,  0.       ],\n       [-0.40956  , -0.41155  ,  0.       ],\n       [-0.39228  , -0.25804  ,  0.       ],\n       [-0.74366  , -0.25804  ,  0.       ],\n       [-0.69758  ,  0.041667 ,  0.       ],\n       [-0.75518  ,  0.2902   ,  0.       ],\n       [-0.69758  ,  0.68494  ,  0.       ],\n       [-0.4038   ,  0.70687  ,  0.       ],\n       [-0.38076  ,  0.91886  ,  0.       ],\n       [-0.50749  ,  0.90424  ,  0.       ],\n       [-0.54781  ,  0.70687  ,  0.       ],\n       [ 0.10311  ,  0.77997  ,  0.       ],\n       [ 0.057028 ,  0.91886  ,  0.       ],\n       [-0.10426  ,  0.99196  ,  0.       ],\n       [-0.081221 ,  1.1089   ,  0.       ],\n       [ 0.28744  ,  1.087    ,  0.       ],\n       [ 0.39689  ,  0.82383  ,  0.       ],\n       [ 0.63882  ,  0.88962  ,  0.       ],\n       [ 0.82316  ,  0.66301  ,  0.       ],\n       [ 0.67339  ,  0.64108  ,  0.       ],\n       [ 1.0709   ,  0.10015  ,  0.       ],\n       [-0.046659 , -0.57968  ,  0.       ],\n       [-0.23675  , -0.63816  ,  0.       ],\n       [-0.15035  , -0.36769  ,  0.       ],\n       [-0.49021  , -0.3019   ,  0.       ],\n       [-0.46717  , -0.13377  ,  0.       ],\n       [-0.28859  , -0.060673 ,  0.       ],\n       [-0.61118  , -0.067982 ,  0.       ],\n       [-0.66302  , -0.21418  ,  0.       ],\n       [-0.59965  , -0.41886  ,  0.       ],\n       [-0.72638  , -0.082602 ,  0.       ],\n       [-0.83007  ,  0.31213  ,  0.       ],\n       [-0.72062  ,  0.53874  ,  0.       ],\n       [-0.59389  ,  0.49488  ,  0.       ],\n       [-0.48445  ,  0.99927  ,  0.       ],\n       [-0.0063364,  0.99927  ,  0.       ],\n       [ 0.63265  , -0.030612 ,  0.       ]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt('ex2data2.txt', delimiter=',')\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看数据集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "positive_data_idx= np.where(data[:,2]==1)\n",
    "positive_data = data[positive_data_idx]\n",
    "negative_data_idx= np.where(data[:, 2] == 0)\n",
    "negative_data = data[negative_data_idx]\n",
    "ax.scatter(x=positive_data[:, 0], y=positive_data[:, 1], s=10, color=\"red\",label=\"positive\")\n",
    "ax.scatter(x=negative_data[:, 0], y=negative_data[:, 1], s=10, label=\"negative\")\n",
    "ax.set_title(\"Dataset\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "划分训练集和验证集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y = train_test_split(data[:, :-1], data[:, -1], test_size=0.2)\n",
    "# train_x, val_x, train_y, val_y = data[:, :-1], data[:, :-1], data[:, -1], data[:, -1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=train_x[:,0], y=train_x[:,1], s=10, label=\"Train\")\n",
    "ax.scatter(x=val_x[:,0], y=val_x[:,1], s=10, color=\"red\", label=\"Validation\")\n",
    "ax.set_title('Dataset for Train and Validation')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看训练集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_train_data = train_x[np.where(train_y[:]==1)]\n",
    "negative_train_data = train_x[np.where(train_y[:]==0)]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=positive_train_data[:,0], y=positive_train_data[:,1], s=10, label=\"Positive\")\n",
    "ax.scatter(x=negative_train_data[:,0], y=negative_train_data[:,1], s=10, label=\"Negative\")\n",
    "ax.set_title('Train Set')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看测试集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()\n",
    "positive_val_data = val_x[np.where(val_y[:] == 1)]\n",
    "negative_val_data = val_x[np.where(val_y[:] == 0)]\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.scatter(x=positive_val_data[:, 0], y=positive_val_data[:, 1], s=10, label=\"Positive\")\n",
    "ax.scatter(x=negative_val_data[:, 0], y=negative_val_data[:, 1], s=10, label=\"Negative\")\n",
    "ax.legend(loc=2)\n",
    "ax.set_title('Validation Set')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "整理维度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(24, 1)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_ex = np.expand_dims(train_y,axis=1)\n",
    "val_y_ex = np.expand_dims(val_y,axis=1)\n",
    "val_y_ex.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "特征映射\n",
    "$$\\mathbf{X}=[x_{1}, x_{2}, x_{1}^{2}, x_{1}x_{2}, x_{2}^{2}, x_{1}^{3}, x_{1}^{2}x_{2},\\cdots]$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 5.24120000e-01,  2.74701774e-01,  1.43976694e-01, ...,\n         5.64957111e-04,  2.96105321e-04,  1.26595589e-04],\n       [ 5.97220000e-01,  3.56671728e-01,  2.13011490e-01, ...,\n        -8.13294717e-02, -4.85715871e-02,  4.92376755e-02],\n       [ 4.16670000e-02,  1.73613889e-03,  7.23396991e-05, ...,\n        -1.65184808e-01, -6.88275540e-03,  1.15229618e-01],\n       ...,\n       [ 6.92250000e-01,  4.79210063e-01,  3.31733166e-01, ...,\n         3.46161974e-03,  2.39630626e-03,  1.11464156e-03],\n       [ 3.63300000e-01,  1.31986890e-01,  4.79508371e-02, ...,\n         6.83949195e-01,  2.48478743e-01,  6.33911472e-01],\n       [ 6.84940000e-01,  4.69142804e-01,  3.21334672e-01, ...,\n        -1.65184808e-01, -1.13141682e-01,  1.15229618e-01]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_mapping(x, degree):\n",
    "    feature = np.zeros([x.shape[0],1])\n",
    "    for i in range(0, 1 + degree):\n",
    "        for j in range(0, 1 + degree - i):\n",
    "            if i==0 and j==0: continue\n",
    "            feature=np.concatenate((feature, np.expand_dims(np.multiply(np.power(x[:, 0], i) , np.power(x[:, 1], j)), axis=1)),axis=1)\n",
    "    return feature[:,1:]\n",
    "\n",
    "train_x_map = feature_mapping(train_x,degree=6)\n",
    "val_x_map = feature_mapping(val_x,degree=6)\n",
    "train_x_map"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "训练逻辑回归"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/8000, Train Loss: 0.3392\n",
      "Accuracy on Val set: 70.83%\tLoss on Val set: 0.2981\n",
      "Epoch: 2/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.2848\n",
      "Epoch: 3/8000, Train Loss: 0.2616\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.2784\n",
      "Epoch: 4/8000, Train Loss: 0.2506\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.2752\n",
      "Epoch: 5/8000, Train Loss: 0.2435\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.2738\n",
      "Epoch: 6/8000, Train Loss: 0.2386\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.2737\n",
      "Epoch: 7/8000, Train Loss: 0.2349\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.2744\n",
      "Epoch: 8/8000, Train Loss: 0.2322\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.2756\n",
      "Epoch: 9/8000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.2772\n",
      "Epoch: 10/8000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 79.17%\tLoss on Val set: 0.2791\n",
      "Epoch: 11/8000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 79.17%\tLoss on Val set: 0.2812\n",
      "Epoch: 12/8000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 79.17%\tLoss on Val set: 0.2835\n",
      "Epoch: 13/8000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 79.17%\tLoss on Val set: 0.2859\n",
      "Epoch: 14/8000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.2885\n",
      "Epoch: 15/8000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.2911\n",
      "Epoch: 16/8000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.2937\n",
      "Epoch: 17/8000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.2963\n",
      "Epoch: 18/8000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.2990\n",
      "Epoch: 19/8000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3017\n",
      "Epoch: 20/8000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3043\n",
      "Epoch: 21/8000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3070\n",
      "Epoch: 22/8000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3096\n",
      "Epoch: 23/8000, Train Loss: 0.2275\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3122\n",
      "Epoch: 24/8000, Train Loss: 0.2281\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3148\n",
      "Epoch: 25/8000, Train Loss: 0.2288\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3174\n",
      "Epoch: 26/8000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3199\n",
      "Epoch: 27/8000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3223\n",
      "Epoch: 28/8000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3248\n",
      "Epoch: 29/8000, Train Loss: 0.2316\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3272\n",
      "Epoch: 30/8000, Train Loss: 0.2323\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3295\n",
      "Epoch: 31/8000, Train Loss: 0.2331\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3318\n",
      "Epoch: 32/8000, Train Loss: 0.2338\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3341\n",
      "Epoch: 33/8000, Train Loss: 0.2346\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3363\n",
      "Epoch: 34/8000, Train Loss: 0.2354\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3384\n",
      "Epoch: 35/8000, Train Loss: 0.2362\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3406\n",
      "Epoch: 36/8000, Train Loss: 0.2370\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3427\n",
      "Epoch: 37/8000, Train Loss: 0.2378\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3447\n",
      "Epoch: 38/8000, Train Loss: 0.2386\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3467\n",
      "Epoch: 39/8000, Train Loss: 0.2393\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3486\n",
      "Epoch: 40/8000, Train Loss: 0.2401\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3505\n",
      "Epoch: 41/8000, Train Loss: 0.2409\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3524\n",
      "Epoch: 42/8000, Train Loss: 0.2417\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3542\n",
      "Epoch: 43/8000, Train Loss: 0.2424\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3560\n",
      "Epoch: 44/8000, Train Loss: 0.2432\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3578\n",
      "Epoch: 45/8000, Train Loss: 0.2439\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3595\n",
      "Epoch: 46/8000, Train Loss: 0.2446\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3611\n",
      "Epoch: 47/8000, Train Loss: 0.2454\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3628\n",
      "Epoch: 48/8000, Train Loss: 0.2461\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3643\n",
      "Epoch: 49/8000, Train Loss: 0.2468\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3659\n",
      "Epoch: 50/8000, Train Loss: 0.2475\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3674\n",
      "Epoch: 51/8000, Train Loss: 0.2482\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3689\n",
      "Epoch: 52/8000, Train Loss: 0.2488\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3703\n",
      "Epoch: 53/8000, Train Loss: 0.2495\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3717\n",
      "Epoch: 54/8000, Train Loss: 0.2502\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3731\n",
      "Epoch: 55/8000, Train Loss: 0.2508\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3744\n",
      "Epoch: 56/8000, Train Loss: 0.2514\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3758\n",
      "Epoch: 57/8000, Train Loss: 0.2521\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3770\n",
      "Epoch: 58/8000, Train Loss: 0.2527\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3783\n",
      "Epoch: 59/8000, Train Loss: 0.2533\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3795\n",
      "Epoch: 60/8000, Train Loss: 0.2539\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3807\n",
      "Epoch: 61/8000, Train Loss: 0.2544\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3818\n",
      "Epoch: 62/8000, Train Loss: 0.2550\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3830\n",
      "Epoch: 63/8000, Train Loss: 0.2556\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3841\n",
      "Epoch: 64/8000, Train Loss: 0.2561\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3852\n",
      "Epoch: 65/8000, Train Loss: 0.2566\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3862\n",
      "Epoch: 66/8000, Train Loss: 0.2572\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3872\n",
      "Epoch: 67/8000, Train Loss: 0.2577\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3882\n",
      "Epoch: 68/8000, Train Loss: 0.2582\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3892\n",
      "Epoch: 69/8000, Train Loss: 0.2587\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3902\n",
      "Epoch: 70/8000, Train Loss: 0.2592\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3911\n",
      "Epoch: 71/8000, Train Loss: 0.2596\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3920\n",
      "Epoch: 72/8000, Train Loss: 0.2601\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3929\n",
      "Epoch: 73/8000, Train Loss: 0.2606\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3937\n",
      "Epoch: 74/8000, Train Loss: 0.2610\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3946\n",
      "Epoch: 75/8000, Train Loss: 0.2614\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3954\n",
      "Epoch: 76/8000, Train Loss: 0.2619\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3962\n",
      "Epoch: 77/8000, Train Loss: 0.2623\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3970\n",
      "Epoch: 78/8000, Train Loss: 0.2627\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3977\n",
      "Epoch: 79/8000, Train Loss: 0.2631\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3985\n",
      "Epoch: 80/8000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3992\n",
      "Epoch: 81/8000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3999\n",
      "Epoch: 82/8000, Train Loss: 0.2643\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4006\n",
      "Epoch: 83/8000, Train Loss: 0.2646\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4013\n",
      "Epoch: 84/8000, Train Loss: 0.2650\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4019\n",
      "Epoch: 85/8000, Train Loss: 0.2653\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4026\n",
      "Epoch: 86/8000, Train Loss: 0.2657\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4032\n",
      "Epoch: 87/8000, Train Loss: 0.2660\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4038\n",
      "Epoch: 88/8000, Train Loss: 0.2663\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4044\n",
      "Epoch: 89/8000, Train Loss: 0.2667\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4050\n",
      "Epoch: 90/8000, Train Loss: 0.2670\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4055\n",
      "Epoch: 91/8000, Train Loss: 0.2673\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4061\n",
      "Epoch: 92/8000, Train Loss: 0.2676\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4066\n",
      "Epoch: 93/8000, Train Loss: 0.2679\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4072\n",
      "Epoch: 94/8000, Train Loss: 0.2682\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4077\n",
      "Epoch: 95/8000, Train Loss: 0.2685\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4082\n",
      "Epoch: 96/8000, Train Loss: 0.2687\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4087\n",
      "Epoch: 97/8000, Train Loss: 0.2690\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4091\n",
      "Epoch: 98/8000, Train Loss: 0.2693\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4096\n",
      "Epoch: 99/8000, Train Loss: 0.2695\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4101\n",
      "Epoch: 100/8000, Train Loss: 0.2698\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4105\n",
      "Epoch: 101/8000, Train Loss: 0.2700\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4109\n",
      "Epoch: 102/8000, Train Loss: 0.2703\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4113\n",
      "Epoch: 103/8000, Train Loss: 0.2705\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4118\n",
      "Epoch: 104/8000, Train Loss: 0.2707\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4122\n",
      "Epoch: 105/8000, Train Loss: 0.2710\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4126\n",
      "Epoch: 106/8000, Train Loss: 0.2712\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4129\n",
      "Epoch: 107/8000, Train Loss: 0.2714\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4133\n",
      "Epoch: 108/8000, Train Loss: 0.2716\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4137\n",
      "Epoch: 109/8000, Train Loss: 0.2718\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4140\n",
      "Epoch: 110/8000, Train Loss: 0.2720\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4144\n",
      "Epoch: 111/8000, Train Loss: 0.2722\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4147\n",
      "Epoch: 112/8000, Train Loss: 0.2724\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4150\n",
      "Epoch: 113/8000, Train Loss: 0.2726\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4154\n",
      "Epoch: 114/8000, Train Loss: 0.2728\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4157\n",
      "Epoch: 115/8000, Train Loss: 0.2730\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4160\n",
      "Epoch: 116/8000, Train Loss: 0.2731\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4163\n",
      "Epoch: 117/8000, Train Loss: 0.2733\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4166\n",
      "Epoch: 118/8000, Train Loss: 0.2735\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4169\n",
      "Epoch: 119/8000, Train Loss: 0.2737\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4171\n",
      "Epoch: 120/8000, Train Loss: 0.2738\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4174\n",
      "Epoch: 121/8000, Train Loss: 0.2740\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4177\n",
      "Epoch: 122/8000, Train Loss: 0.2741\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4179\n",
      "Epoch: 123/8000, Train Loss: 0.2743\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4182\n",
      "Epoch: 124/8000, Train Loss: 0.2744\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4184\n",
      "Epoch: 125/8000, Train Loss: 0.2746\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4187\n",
      "Epoch: 126/8000, Train Loss: 0.2747\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4189\n",
      "Epoch: 127/8000, Train Loss: 0.2748\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4191\n",
      "Epoch: 128/8000, Train Loss: 0.2750\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4194\n",
      "Epoch: 129/8000, Train Loss: 0.2751\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4196\n",
      "Epoch: 130/8000, Train Loss: 0.2752\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4198\n",
      "Epoch: 131/8000, Train Loss: 0.2754\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4200\n",
      "Epoch: 132/8000, Train Loss: 0.2755\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4202\n",
      "Epoch: 133/8000, Train Loss: 0.2756\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4204\n",
      "Epoch: 134/8000, Train Loss: 0.2757\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4206\n",
      "Epoch: 135/8000, Train Loss: 0.2758\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4208\n",
      "Epoch: 136/8000, Train Loss: 0.2760\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4210\n",
      "Epoch: 137/8000, Train Loss: 0.2761\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4211\n",
      "Epoch: 138/8000, Train Loss: 0.2762\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4213\n",
      "Epoch: 139/8000, Train Loss: 0.2763\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4215\n",
      "Epoch: 140/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4217\n",
      "Epoch: 141/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4218\n",
      "Epoch: 142/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4220\n",
      "Epoch: 143/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4221\n",
      "Epoch: 144/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4223\n",
      "Epoch: 145/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4224\n",
      "Epoch: 146/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4226\n",
      "Epoch: 147/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4227\n",
      "Epoch: 148/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4229\n",
      "Epoch: 149/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4230\n",
      "Epoch: 150/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4231\n",
      "Epoch: 151/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4233\n",
      "Epoch: 152/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4234\n",
      "Epoch: 153/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4235\n",
      "Epoch: 154/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4236\n",
      "Epoch: 155/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4238\n",
      "Epoch: 156/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4239\n",
      "Epoch: 157/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4240\n",
      "Epoch: 158/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4241\n",
      "Epoch: 159/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4242\n",
      "Epoch: 160/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4243\n",
      "Epoch: 161/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4244\n",
      "Epoch: 162/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4245\n",
      "Epoch: 163/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4246\n",
      "Epoch: 164/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4247\n",
      "Epoch: 165/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4248\n",
      "Epoch: 166/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4249\n",
      "Epoch: 167/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4250\n",
      "Epoch: 168/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4251\n",
      "Epoch: 169/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4252\n",
      "Epoch: 170/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4252\n",
      "Epoch: 171/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4253\n",
      "Epoch: 172/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4254\n",
      "Epoch: 173/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4255\n",
      "Epoch: 174/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4256\n",
      "Epoch: 175/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4256\n",
      "Epoch: 176/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4257\n",
      "Epoch: 177/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4258\n",
      "Epoch: 178/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4258\n",
      "Epoch: 179/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4259\n",
      "Epoch: 180/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4260\n",
      "Epoch: 181/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4260\n",
      "Epoch: 182/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4261\n",
      "Epoch: 183/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4262\n",
      "Epoch: 184/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4262\n",
      "Epoch: 185/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4263\n",
      "Epoch: 186/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4264\n",
      "Epoch: 187/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4264\n",
      "Epoch: 188/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4265\n",
      "Epoch: 189/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4265\n",
      "Epoch: 190/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4266\n",
      "Epoch: 191/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4266\n",
      "Epoch: 192/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4267\n",
      "Epoch: 193/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4267\n",
      "Epoch: 194/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4268\n",
      "Epoch: 195/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4268\n",
      "Epoch: 196/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4269\n",
      "Epoch: 197/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4269\n",
      "Epoch: 198/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4270\n",
      "Epoch: 199/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4270\n",
      "Epoch: 200/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4270\n",
      "Epoch: 201/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4271\n",
      "Epoch: 202/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4271\n",
      "Epoch: 203/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4272\n",
      "Epoch: 204/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4272\n",
      "Epoch: 205/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4272\n",
      "Epoch: 206/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4273\n",
      "Epoch: 207/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4273\n",
      "Epoch: 208/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4274\n",
      "Epoch: 209/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4274\n",
      "Epoch: 210/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4274\n",
      "Epoch: 211/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4275\n",
      "Epoch: 212/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4275\n",
      "Epoch: 213/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4275\n",
      "Epoch: 214/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4276\n",
      "Epoch: 215/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4276\n",
      "Epoch: 216/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4276\n",
      "Epoch: 217/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4276\n",
      "Epoch: 218/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4277\n",
      "Epoch: 219/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4277\n",
      "Epoch: 220/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4277\n",
      "Epoch: 221/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4278\n",
      "Epoch: 222/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4278\n",
      "Epoch: 223/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4278\n",
      "Epoch: 224/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4278\n",
      "Epoch: 225/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4279\n",
      "Epoch: 226/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4279\n",
      "Epoch: 227/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4279\n",
      "Epoch: 228/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4279\n",
      "Epoch: 229/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4280\n",
      "Epoch: 230/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4280\n",
      "Epoch: 231/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4280\n",
      "Epoch: 232/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4280\n",
      "Epoch: 233/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4280\n",
      "Epoch: 234/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4281\n",
      "Epoch: 235/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4281\n",
      "Epoch: 236/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4281\n",
      "Epoch: 237/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4281\n",
      "Epoch: 238/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4281\n",
      "Epoch: 239/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4282\n",
      "Epoch: 240/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4282\n",
      "Epoch: 241/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4282\n",
      "Epoch: 242/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4282\n",
      "Epoch: 243/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4282\n",
      "Epoch: 244/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4282\n",
      "Epoch: 245/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4283\n",
      "Epoch: 246/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4283\n",
      "Epoch: 247/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4283\n",
      "Epoch: 248/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4283\n",
      "Epoch: 249/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4283\n",
      "Epoch: 250/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4283\n",
      "Epoch: 251/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4284\n",
      "Epoch: 252/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4284\n",
      "Epoch: 253/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4284\n",
      "Epoch: 254/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4284\n",
      "Epoch: 255/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4284\n",
      "Epoch: 256/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4284\n",
      "Epoch: 257/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4284\n",
      "Epoch: 258/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4285\n",
      "Epoch: 259/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4285\n",
      "Epoch: 260/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4285\n",
      "Epoch: 261/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4285\n",
      "Epoch: 262/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4285\n",
      "Epoch: 263/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4285\n",
      "Epoch: 264/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4285\n",
      "Epoch: 265/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4285\n",
      "Epoch: 266/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4285\n",
      "Epoch: 267/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4286\n",
      "Epoch: 268/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4286\n",
      "Epoch: 269/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4286\n",
      "Epoch: 270/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4286\n",
      "Epoch: 271/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4286\n",
      "Epoch: 272/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4286\n",
      "Epoch: 273/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4286\n",
      "Epoch: 274/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4286\n",
      "Epoch: 275/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4286\n",
      "Epoch: 276/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4286\n",
      "Epoch: 277/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4287\n",
      "Epoch: 278/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4287\n",
      "Epoch: 279/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4287\n",
      "Epoch: 280/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4287\n",
      "Epoch: 281/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4287\n",
      "Epoch: 282/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4287\n",
      "Epoch: 283/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4287\n",
      "Epoch: 284/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4287\n",
      "Epoch: 285/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4287\n",
      "Epoch: 286/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4287\n",
      "Epoch: 287/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4287\n",
      "Epoch: 288/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4287\n",
      "Epoch: 289/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4287\n",
      "Epoch: 290/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4287\n",
      "Epoch: 291/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 292/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 293/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 294/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 295/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 296/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 297/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 298/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 299/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 300/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 301/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 302/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 303/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 304/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 305/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 306/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 307/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4288\n",
      "Epoch: 308/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 309/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 310/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 311/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 312/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 313/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 314/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 315/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 316/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 317/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 318/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 319/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 320/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 321/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 322/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 323/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 324/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 325/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 326/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 327/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 328/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 329/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 330/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 331/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 332/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 333/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4289\n",
      "Epoch: 334/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 335/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 336/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 337/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 338/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 339/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 340/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 341/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 342/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 343/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 344/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 345/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 346/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 347/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 348/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 349/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 350/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 351/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 352/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 353/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 354/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 355/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 356/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 357/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 358/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 359/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 360/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 361/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 362/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 363/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 364/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 365/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 366/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 367/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 368/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 369/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 370/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 371/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 372/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 373/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 374/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 375/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 376/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 377/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 378/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 379/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 380/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 381/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 382/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 383/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4290\n",
      "Epoch: 384/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 385/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 386/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 387/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 388/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 389/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 390/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 391/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 392/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 393/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 394/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 395/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 396/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 397/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 398/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 399/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 400/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 401/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 402/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 403/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 404/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 405/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 406/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 407/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 408/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 409/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 410/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 411/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 412/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 413/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 414/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 415/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 416/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 417/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 418/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 419/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 420/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 421/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 422/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 423/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 424/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 425/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 426/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 427/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 428/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 429/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 430/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 431/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 432/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 433/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 434/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 435/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 436/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 437/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 438/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 439/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 440/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 441/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 442/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 443/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 444/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 445/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 446/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 447/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 448/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 449/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 450/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 451/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 452/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 453/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 454/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 455/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 456/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 457/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 458/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 459/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 460/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 461/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 462/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 463/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 464/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 465/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 466/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 467/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 468/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 469/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 470/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 471/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 472/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 473/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 474/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 475/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 476/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 477/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 478/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 479/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 480/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 481/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 482/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 483/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 484/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 485/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 486/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 487/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 488/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 489/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 490/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 491/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 492/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 493/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 494/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 495/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 496/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 497/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 498/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 499/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 500/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 501/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 502/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 503/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 504/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 505/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 506/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 507/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 508/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 509/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 510/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 511/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 512/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 513/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 514/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 515/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 516/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 517/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 518/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 519/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 520/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 521/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 522/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 523/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 524/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 525/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 526/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 527/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 528/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 529/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 530/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 531/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 532/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 533/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 534/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 535/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 536/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 537/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 538/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 539/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 540/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 541/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 542/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 543/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 544/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 545/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 546/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 547/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 548/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 549/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 550/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 551/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 552/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 553/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 554/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 555/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 556/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 557/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 558/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 559/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 560/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 561/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 562/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 563/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 564/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 565/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 566/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 567/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 568/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 569/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 570/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 571/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 572/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 573/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 574/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 575/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 576/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 577/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 578/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 579/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 580/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 581/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 582/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 583/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 584/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 585/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 586/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 587/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 588/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 589/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 590/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 591/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 592/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 593/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 594/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 595/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 596/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 597/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 598/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 599/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 600/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 601/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 602/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 603/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 604/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 605/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 606/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 607/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 608/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 609/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 610/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 611/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 612/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 613/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 614/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 615/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 616/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 617/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 618/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 619/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 620/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 621/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 622/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 623/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 624/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 625/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 626/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 627/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 628/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 629/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 630/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 631/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 632/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 633/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 634/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 635/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 636/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 637/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 638/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 639/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 640/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 641/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 642/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 643/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 644/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 645/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 646/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 647/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 648/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 649/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 650/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 651/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 652/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 653/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 654/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 655/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 656/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 657/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 658/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 659/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 660/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 661/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 662/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 663/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 664/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 665/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 666/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 667/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 668/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 669/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 670/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 671/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 672/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 673/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 674/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 675/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 676/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 677/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 678/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 679/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 680/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 681/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 682/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 683/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 684/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 685/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 686/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 687/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 688/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 689/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 690/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 691/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 692/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 693/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 694/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 695/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 696/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 697/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 698/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 699/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 700/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 701/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 702/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 703/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 704/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 705/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 706/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 707/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 708/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 709/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 710/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 711/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 712/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 713/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 714/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 715/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 716/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 717/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 718/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 719/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 720/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 721/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 722/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 723/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 724/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 725/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 726/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 727/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 728/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 729/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 730/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 731/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 732/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 733/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 734/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 735/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 736/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 737/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 738/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 739/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 740/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 741/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 742/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 743/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 744/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 745/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 746/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 747/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 748/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 749/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 750/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 751/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 752/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 753/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 754/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 755/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 756/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 757/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 758/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 759/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 760/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 761/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 762/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 763/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 764/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 765/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 766/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 767/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 768/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 769/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 770/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 771/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 772/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 773/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 774/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 775/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 776/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 777/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 778/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 779/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 780/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 781/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 782/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 783/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 784/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 785/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 786/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 787/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 788/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 789/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 790/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 791/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 792/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 793/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 794/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 795/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 796/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 797/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 798/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 799/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 800/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 801/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 802/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 803/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 804/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 805/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 806/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 807/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 808/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 809/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 810/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 811/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 812/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 813/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 814/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 815/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 816/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 817/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 818/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 819/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 820/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 821/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 822/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 823/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 824/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 825/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 826/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 827/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 828/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 829/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 830/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 831/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 832/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 833/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 834/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 835/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 836/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 837/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 838/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 839/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 840/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 841/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 842/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 843/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 844/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 845/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 846/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 847/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 848/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 849/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 850/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 851/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 852/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 853/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 854/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 855/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 856/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 857/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 858/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 859/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 860/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 861/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 862/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 863/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 864/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 865/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 866/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 867/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 868/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 869/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 870/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 871/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 872/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 873/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 874/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 875/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 876/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 877/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 878/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 879/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 880/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 881/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 882/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 883/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 884/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 885/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 886/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 887/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 888/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 889/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 890/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 891/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 892/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 893/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 894/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 895/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 896/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 897/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 898/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 899/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 900/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 901/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 902/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 903/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 904/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 905/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 906/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 907/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 908/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 909/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 910/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 911/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 912/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 913/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 914/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 915/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 916/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 917/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 918/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 919/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 920/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 921/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 922/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 923/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 924/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 925/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 926/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 927/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 928/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 929/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 930/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 931/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 932/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 933/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 934/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 935/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 936/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 937/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 938/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 939/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 940/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 941/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 942/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 943/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 944/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 945/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 946/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 947/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 948/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 949/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 950/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 951/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 952/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 953/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 954/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 955/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 956/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 957/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 958/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 959/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 960/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 961/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 962/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 963/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 964/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 965/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 966/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 967/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 968/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 969/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 970/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 971/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 972/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 973/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 974/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 975/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 976/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 977/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 978/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 979/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 980/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 981/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 982/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 983/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 984/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 985/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 986/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 987/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 988/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 989/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 990/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 991/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 992/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 993/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 994/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 995/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 996/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 997/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 998/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 999/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1000/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1001/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1002/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1003/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1004/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1005/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1006/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1007/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1008/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1009/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1010/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1011/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1012/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1013/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1014/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1015/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1016/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1017/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1018/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1019/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1020/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1021/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1022/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1023/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1024/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1025/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1026/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1027/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1028/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1029/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1030/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1031/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1032/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1033/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1034/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1035/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1036/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1037/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1038/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1039/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1040/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1041/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1042/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1043/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1044/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1045/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1046/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1047/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1048/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1049/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1050/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1051/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1052/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1053/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1054/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1055/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1056/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1057/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1058/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1059/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1060/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1061/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1062/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1063/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1064/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1065/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1066/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1067/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1068/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1069/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1070/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1071/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1072/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1073/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1074/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1075/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1076/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1077/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1078/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1079/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1080/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1081/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1082/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1083/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1084/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1085/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1086/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1087/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1088/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1089/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1090/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1091/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1092/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1093/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1094/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1095/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1096/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1097/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1098/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1099/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1100/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1101/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1102/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1103/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1104/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1105/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1106/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1107/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1108/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1109/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1110/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1111/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1112/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1113/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1114/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1115/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1116/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1117/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1118/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1119/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1120/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1121/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1122/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1123/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1124/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1125/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1126/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1127/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1128/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1129/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1130/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1131/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1132/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1133/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1134/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1135/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1136/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1137/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1138/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1139/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1140/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1141/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1142/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1143/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1144/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1145/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1146/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1147/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1148/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1149/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1150/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1151/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1152/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1153/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1154/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1155/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1156/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1157/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1158/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1159/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1160/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1161/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1162/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1163/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1164/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1165/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1166/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1167/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1168/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1169/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1170/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1171/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1172/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1173/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1174/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1175/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1176/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1177/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1178/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1179/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1180/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1181/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1182/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1183/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1184/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1185/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1186/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1187/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1188/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1189/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1190/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1191/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1192/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1193/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1194/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1195/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1196/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1197/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1198/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1199/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1200/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1201/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1202/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1203/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1204/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1205/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1206/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1207/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1208/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1209/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1210/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1211/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1212/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1213/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1214/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1215/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1216/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1217/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1218/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1219/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1220/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1221/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1222/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1223/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1224/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1225/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1226/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1227/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1228/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1229/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1230/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1231/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1232/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1233/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1234/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1235/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1236/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1237/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1238/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1239/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1240/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1241/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1242/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1243/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1244/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1245/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1246/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1247/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1248/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1249/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1250/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1251/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1252/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1253/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1254/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1255/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1256/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1257/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1258/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1259/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1260/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1261/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1262/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1263/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1264/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1265/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1266/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1267/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1268/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1269/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1270/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1271/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1272/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1273/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1274/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1275/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1276/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1277/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1278/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1279/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1280/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1281/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1282/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1283/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1284/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1285/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1286/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1287/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1288/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1289/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1290/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1291/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1292/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1293/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1294/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1295/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1296/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1297/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1298/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1299/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1300/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1301/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1302/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1303/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1304/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1305/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1306/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1307/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1308/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1309/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1310/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1311/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1312/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1313/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1314/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1315/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1316/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1317/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1318/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1319/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1320/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1321/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1322/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1323/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1324/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1325/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1326/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1327/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1328/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1329/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1330/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1331/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1332/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1333/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1334/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1335/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1336/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1337/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1338/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1339/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1340/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1341/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1342/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1343/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1344/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1345/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1346/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1347/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1348/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1349/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1350/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1351/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1352/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1353/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1354/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1355/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1356/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1357/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1358/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1359/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1360/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1361/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1362/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1363/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1364/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1365/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1366/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1367/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1368/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1369/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1370/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1371/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1372/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1373/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1374/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1375/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1376/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1377/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1378/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1379/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1380/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1381/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1382/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1383/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1384/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1385/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1386/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1387/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1388/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1389/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1390/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1391/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1392/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1393/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1394/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1395/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1396/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1397/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1398/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1399/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1400/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1401/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1402/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1403/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1404/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1405/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1406/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1407/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1408/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1409/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1410/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1411/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1412/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1413/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1414/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1415/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1416/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1417/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1418/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1419/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1420/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1421/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1422/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1423/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1424/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1425/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1426/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1427/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1428/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1429/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1430/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1431/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1432/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1433/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1434/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1435/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1436/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1437/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1438/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1439/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1440/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1441/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1442/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1443/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1444/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1445/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1446/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1447/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1448/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1449/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1450/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1451/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1452/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1453/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1454/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1455/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1456/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1457/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1458/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1459/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1460/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1461/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1462/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1463/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1464/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1465/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1466/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1467/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1468/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1469/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1470/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1471/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1472/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1473/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1474/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1475/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1476/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1477/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1478/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1479/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1480/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1481/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1482/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1483/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1484/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1485/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1486/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1487/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1488/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1489/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1490/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1491/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1492/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1493/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1494/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1495/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1496/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1497/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1498/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1499/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1500/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1501/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1502/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1503/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1504/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1505/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1506/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1507/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1508/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1509/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1510/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1511/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1512/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1513/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1514/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1515/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1516/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1517/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1518/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1519/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1520/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1521/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1522/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1523/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1524/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1525/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1526/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1527/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1528/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1529/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1530/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1531/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1532/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1533/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1534/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1535/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1536/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1537/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1538/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1539/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1540/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1541/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1542/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1543/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1544/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1545/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1546/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1547/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1548/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1549/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1550/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1551/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1552/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1553/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1554/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1555/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1556/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1557/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1558/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1559/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1560/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1561/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1562/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1563/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1564/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1565/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1566/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1567/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1568/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1569/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1570/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1571/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1572/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1573/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1574/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1575/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1576/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1577/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1578/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1579/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1580/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1581/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1582/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1583/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1584/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1585/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1586/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1587/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1588/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1589/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1590/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1591/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1592/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1593/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1594/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1595/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1596/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1597/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1598/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1599/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1600/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1601/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1602/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1603/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1604/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1605/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1606/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1607/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1608/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1609/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1610/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1611/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1612/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1613/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1614/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1615/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1616/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1617/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1618/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1619/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1620/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1621/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1622/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1623/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1624/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1625/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1626/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1627/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1628/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1629/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1630/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1631/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1632/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1633/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1634/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1635/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1636/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1637/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1638/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1639/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1640/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1641/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1642/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1643/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1644/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1645/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1646/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1647/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1648/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1649/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1650/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1651/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1652/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1653/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1654/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1655/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1656/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1657/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1658/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1659/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1660/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1661/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1662/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1663/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1664/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1665/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1666/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1667/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1668/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1669/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1670/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1671/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1672/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1673/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1674/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1675/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1676/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1677/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1678/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1679/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1680/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1681/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1682/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1683/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1684/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1685/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1686/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1687/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1688/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1689/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1690/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1691/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1692/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1693/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1694/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1695/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1696/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1697/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1698/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1699/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1700/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1701/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1702/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1703/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1704/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1705/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1706/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1707/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1708/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1709/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1710/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1711/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1712/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1713/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1714/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1715/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1716/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1717/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1718/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1719/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1720/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1721/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1722/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1723/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1724/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1725/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1726/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1727/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1728/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1729/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1730/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1731/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1732/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1733/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1734/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1735/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1736/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1737/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1738/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1739/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1740/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1741/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1742/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1743/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1744/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1745/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1746/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1747/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1748/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1749/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1750/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1751/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1752/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1753/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1754/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1755/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1756/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1757/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1758/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1759/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1760/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1761/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1762/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1763/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1764/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1765/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1766/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1767/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1768/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1769/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1770/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1771/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1772/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1773/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1774/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1775/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1776/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1777/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1778/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1779/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1780/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1781/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1782/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1783/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1784/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1785/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1786/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1787/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1788/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1789/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1790/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1791/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1792/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1793/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1794/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1795/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1796/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1797/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1798/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1799/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1800/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1801/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1802/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1803/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1804/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1805/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1806/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1807/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1808/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1809/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1810/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1811/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1812/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1813/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1814/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1815/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1816/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1817/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1818/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1819/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1820/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1821/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1822/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1823/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1824/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1825/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1826/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1827/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1828/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1829/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1830/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1831/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1832/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1833/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1834/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1835/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1836/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1837/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1838/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1839/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1840/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1841/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1842/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1843/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1844/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1845/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1846/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1847/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1848/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1849/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1850/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1851/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1852/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1853/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1854/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1855/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1856/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1857/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1858/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1859/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1860/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1861/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1862/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1863/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1864/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1865/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1866/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1867/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1868/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1869/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1870/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1871/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1872/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1873/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1874/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1875/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1876/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1877/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1878/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1879/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1880/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1881/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1882/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1883/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1884/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1885/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1886/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1887/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1888/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1889/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1890/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1891/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1892/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1893/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1894/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1895/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1896/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1897/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1898/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1899/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1900/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1901/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1902/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1903/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1904/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1905/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1906/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1907/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1908/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1909/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1910/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1911/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1912/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1913/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1914/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1915/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1916/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1917/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1918/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1919/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1920/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1921/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1922/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1923/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1924/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1925/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1926/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1927/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1928/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1929/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1930/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1931/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1932/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1933/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1934/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1935/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1936/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1937/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1938/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1939/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1940/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1941/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1942/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1943/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1944/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1945/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1946/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1947/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1948/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1949/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1950/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1951/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1952/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1953/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1954/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1955/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1956/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1957/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1958/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1959/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1960/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1961/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1962/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1963/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1964/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1965/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1966/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1967/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1968/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1969/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1970/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1971/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1972/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1973/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1974/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1975/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1976/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1977/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1978/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1979/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1980/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1981/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1982/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1983/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1984/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1985/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1986/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1987/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1988/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1989/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1990/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1991/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1992/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1993/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1994/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1995/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1996/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1997/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1998/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 1999/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2000/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2001/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2002/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2003/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2004/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2005/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2006/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2007/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2008/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2009/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2010/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2011/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2012/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2013/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2014/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2015/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2016/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2017/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2018/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2019/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2020/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2021/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2022/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2023/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2024/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2025/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2026/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2027/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2028/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2029/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2030/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2031/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2032/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2033/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2034/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2035/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2036/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2037/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2038/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2039/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2040/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2041/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2042/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2043/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2044/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2045/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2046/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2047/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2048/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2049/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2050/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2051/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2052/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2053/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2054/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2055/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2056/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2057/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2058/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2059/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2060/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2061/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2062/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2063/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2064/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2065/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2066/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2067/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2068/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2069/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2070/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2071/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2072/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2073/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2074/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2075/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2076/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2077/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2078/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2079/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2080/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2081/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2082/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2083/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2084/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2085/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2086/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2087/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2088/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2089/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2090/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2091/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2092/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2093/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2094/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2095/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2096/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2097/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2098/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2099/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2100/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2101/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2102/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2103/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2104/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2105/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2106/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2107/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2108/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2109/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2110/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2111/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2112/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2113/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2114/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2115/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2116/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2117/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2118/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2119/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2120/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2121/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2122/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2123/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2124/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2125/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2126/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2127/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2128/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2129/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2130/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2131/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2132/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2133/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2134/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2135/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2136/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2137/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2138/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2139/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2140/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2141/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2142/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2143/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2144/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2145/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2146/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2147/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2148/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2149/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2150/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2151/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2152/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2153/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2154/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2155/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2156/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2157/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2158/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2159/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2160/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2161/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2162/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2163/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2164/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2165/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2166/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2167/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2168/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2169/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2170/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2171/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2172/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2173/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2174/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2175/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2176/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2177/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2178/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2179/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2180/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2181/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2182/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2183/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2184/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2185/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2186/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2187/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2188/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2189/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2190/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2191/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2192/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2193/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2194/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2195/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2196/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2197/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2198/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2199/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2200/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2201/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2202/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2203/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2204/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2205/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2206/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2207/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2208/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2209/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2210/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2211/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2212/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2213/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2214/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2215/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2216/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2217/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2218/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2219/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2220/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2221/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2222/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2223/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2224/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2225/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2226/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2227/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2228/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2229/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2230/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2231/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2232/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2233/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2234/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2235/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2236/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2237/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2238/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2239/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2240/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2241/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2242/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2243/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2244/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2245/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2246/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2247/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2248/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2249/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2250/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2251/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2252/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2253/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2254/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2255/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2256/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2257/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2258/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2259/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2260/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2261/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2262/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2263/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2264/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2265/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2266/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2267/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2268/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2269/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2270/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2271/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2272/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2273/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2274/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2275/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2276/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2277/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2278/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2279/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2280/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2281/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2282/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2283/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2284/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2285/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2286/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2287/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2288/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2289/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2290/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2291/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2292/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2293/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2294/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2295/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2296/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2297/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2298/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2299/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2300/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2301/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2302/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2303/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2304/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2305/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2306/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2307/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2308/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2309/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2310/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2311/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2312/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2313/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2314/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2315/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2316/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2317/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2318/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2319/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2320/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2321/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2322/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2323/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2324/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2325/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2326/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2327/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2328/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2329/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2330/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2331/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2332/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2333/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2334/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2335/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2336/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2337/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2338/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2339/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2340/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2341/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2342/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2343/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2344/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2345/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2346/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2347/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2348/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2349/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2350/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2351/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2352/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2353/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2354/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2355/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2356/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2357/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2358/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2359/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2360/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2361/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2362/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2363/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2364/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2365/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2366/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2367/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2368/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2369/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2370/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2371/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2372/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2373/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2374/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2375/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2376/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2377/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2378/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2379/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2380/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2381/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2382/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2383/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2384/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2385/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2386/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2387/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2388/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2389/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2390/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2391/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2392/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2393/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2394/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2395/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2396/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2397/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2398/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2399/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2400/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2401/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2402/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2403/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2404/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2405/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2406/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2407/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2408/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2409/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2410/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2411/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2412/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2413/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2414/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2415/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2416/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2417/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2418/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2419/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2420/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2421/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2422/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2423/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2424/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2425/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2426/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2427/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2428/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2429/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2430/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2431/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2432/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2433/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2434/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2435/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2436/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2437/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2438/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2439/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2440/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2441/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2442/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2443/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2444/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2445/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2446/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2447/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2448/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2449/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2450/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2451/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2452/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2453/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2454/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2455/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2456/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2457/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2458/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2459/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2460/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2461/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2462/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2463/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2464/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2465/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2466/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2467/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2468/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2469/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2470/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2471/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2472/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2473/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2474/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2475/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2476/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2477/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2478/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2479/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2480/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2481/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2482/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2483/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2484/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2485/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2486/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2487/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2488/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2489/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2490/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2491/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2492/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2493/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2494/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2495/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2496/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2497/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2498/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2499/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2500/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2501/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2502/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2503/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2504/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2505/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2506/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2507/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2508/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2509/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2510/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2511/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2512/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2513/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2514/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2515/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2516/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2517/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2518/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2519/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2520/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2521/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2522/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2523/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2524/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2525/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2526/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2527/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2528/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2529/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2530/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2531/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2532/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2533/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2534/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2535/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2536/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2537/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2538/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2539/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2540/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2541/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2542/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2543/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2544/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2545/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2546/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2547/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2548/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2549/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2550/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2551/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2552/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2553/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2554/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2555/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2556/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2557/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2558/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2559/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2560/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2561/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2562/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2563/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2564/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2565/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2566/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2567/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2568/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2569/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2570/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2571/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2572/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2573/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2574/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2575/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2576/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2577/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2578/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2579/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2580/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2581/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2582/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2583/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2584/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2585/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2586/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2587/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2588/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2589/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2590/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2591/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2592/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2593/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2594/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2595/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2596/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2597/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2598/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2599/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2600/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2601/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2602/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2603/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2604/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2605/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2606/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2607/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2608/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2609/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2610/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2611/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2612/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2613/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2614/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2615/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2616/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2617/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2618/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2619/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2620/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2621/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2622/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2623/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2624/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2625/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2626/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2627/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2628/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2629/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2630/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2631/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2632/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2633/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2634/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2635/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2636/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2637/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2638/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2639/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2640/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2641/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2642/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2643/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2644/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2645/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2646/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2647/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2648/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2649/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2650/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2651/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2652/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2653/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2654/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2655/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2656/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2657/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2658/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2659/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2660/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2661/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2662/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2663/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2664/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2665/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2666/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2667/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2668/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2669/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2670/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2671/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2672/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2673/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2674/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2675/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2676/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2677/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2678/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2679/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2680/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2681/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2682/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2683/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2684/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2685/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2686/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2687/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2688/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2689/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2690/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2691/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2692/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2693/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2694/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2695/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2696/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2697/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2698/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2699/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2700/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2701/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2702/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2703/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2704/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2705/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2706/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2707/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2708/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2709/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2710/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2711/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2712/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2713/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2714/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2715/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2716/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2717/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2718/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2719/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2720/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2721/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2722/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2723/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2724/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2725/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2726/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2727/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2728/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2729/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2730/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2731/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2732/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2733/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2734/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2735/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2736/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2737/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2738/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2739/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2740/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2741/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2742/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2743/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2744/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2745/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2746/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2747/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2748/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2749/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2750/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2751/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2752/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2753/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2754/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2755/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2756/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2757/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2758/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2759/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2760/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2761/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2762/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2763/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2764/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2765/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2766/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2767/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2768/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2769/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2770/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2771/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2772/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2773/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2774/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2775/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2776/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2777/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2778/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2779/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2780/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2781/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2782/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2783/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2784/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2785/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2786/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2787/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2788/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2789/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2790/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2791/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2792/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2793/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2794/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2795/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2796/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2797/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2798/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2799/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2800/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2801/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2802/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2803/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2804/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2805/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2806/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2807/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2808/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2809/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2810/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2811/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2812/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2813/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2814/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2815/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2816/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2817/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2818/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2819/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2820/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2821/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2822/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2823/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2824/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2825/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2826/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2827/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2828/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2829/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2830/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2831/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2832/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2833/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2834/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2835/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2836/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2837/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2838/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2839/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2840/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2841/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2842/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2843/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2844/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2845/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2846/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2847/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2848/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2849/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2850/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2851/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2852/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2853/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2854/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2855/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2856/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2857/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2858/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2859/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2860/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2861/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2862/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2863/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2864/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2865/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2866/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2867/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2868/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2869/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2870/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2871/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2872/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2873/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2874/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2875/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2876/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2877/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2878/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2879/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2880/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2881/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2882/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2883/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2884/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2885/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2886/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2887/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2888/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2889/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2890/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2891/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2892/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2893/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2894/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2895/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2896/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2897/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2898/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2899/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2900/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2901/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2902/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2903/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2904/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2905/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2906/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2907/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2908/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2909/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2910/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2911/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2912/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2913/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2914/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2915/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2916/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2917/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2918/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2919/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2920/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2921/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2922/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2923/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2924/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2925/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2926/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2927/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2928/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2929/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2930/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2931/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2932/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2933/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2934/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2935/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2936/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2937/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2938/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2939/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2940/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2941/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2942/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2943/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2944/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2945/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2946/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2947/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2948/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2949/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2950/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2951/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2952/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2953/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2954/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2955/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2956/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2957/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2958/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2959/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2960/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2961/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2962/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2963/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2964/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2965/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2966/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2967/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2968/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2969/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2970/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2971/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2972/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2973/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2974/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2975/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2976/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2977/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2978/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2979/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2980/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2981/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2982/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2983/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2984/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2985/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2986/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2987/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2988/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2989/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2990/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2991/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2992/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2993/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2994/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2995/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2996/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2997/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2998/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 2999/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3000/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3001/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3002/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3003/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3004/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3005/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3006/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3007/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3008/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3009/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3010/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3011/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3012/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3013/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3014/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3015/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3016/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3017/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3018/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3019/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3020/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3021/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3022/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3023/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3024/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3025/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3026/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3027/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3028/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3029/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3030/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3031/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3032/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3033/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3034/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3035/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3036/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3037/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3038/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3039/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3040/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3041/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3042/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3043/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3044/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3045/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3046/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3047/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3048/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3049/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3050/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3051/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3052/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3053/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3054/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3055/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3056/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3057/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3058/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3059/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3060/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3061/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3062/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3063/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3064/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3065/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3066/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3067/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3068/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3069/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3070/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3071/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3072/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3073/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3074/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3075/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3076/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3077/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3078/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3079/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3080/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3081/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3082/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3083/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3084/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3085/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3086/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3087/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3088/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3089/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3090/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3091/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3092/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3093/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3094/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3095/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3096/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3097/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3098/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3099/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3100/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3101/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3102/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3103/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3104/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3105/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3106/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3107/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3108/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3109/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3110/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3111/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3112/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3113/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3114/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3115/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3116/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3117/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3118/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3119/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3120/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3121/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3122/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3123/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3124/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3125/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3126/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3127/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3128/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3129/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3130/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3131/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3132/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3133/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3134/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3135/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3136/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3137/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3138/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3139/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3140/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3141/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3142/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3143/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3144/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3145/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3146/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3147/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3148/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3149/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3150/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3151/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3152/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3153/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3154/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3155/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3156/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3157/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3158/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3159/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3160/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3161/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3162/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3163/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3164/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3165/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3166/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3167/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3168/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3169/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3170/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3171/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3172/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3173/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3174/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3175/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3176/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3177/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3178/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3179/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3180/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3181/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3182/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3183/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3184/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3185/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3186/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3187/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3188/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3189/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3190/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3191/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3192/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3193/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3194/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3195/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3196/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3197/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3198/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3199/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3200/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3201/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3202/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3203/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3204/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3205/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3206/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3207/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3208/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3209/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3210/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3211/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3212/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3213/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3214/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3215/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3216/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3217/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3218/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3219/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3220/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3221/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3222/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3223/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3224/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3225/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3226/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3227/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3228/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3229/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3230/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3231/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3232/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3233/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3234/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3235/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3236/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3237/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3238/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3239/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3240/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3241/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3242/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3243/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3244/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3245/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3246/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3247/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3248/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3249/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3250/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3251/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3252/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3253/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3254/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3255/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3256/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3257/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3258/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3259/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3260/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3261/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3262/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3263/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3264/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3265/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3266/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3267/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3268/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3269/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3270/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3271/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3272/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3273/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3274/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3275/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3276/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3277/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3278/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3279/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3280/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3281/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3282/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3283/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3284/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3285/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3286/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3287/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3288/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3289/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3290/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3291/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3292/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3293/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3294/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3295/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3296/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3297/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3298/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3299/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3300/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3301/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3302/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3303/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3304/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3305/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3306/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3307/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3308/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3309/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3310/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3311/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3312/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3313/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3314/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3315/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3316/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3317/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3318/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3319/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3320/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3321/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3322/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3323/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3324/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3325/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3326/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3327/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3328/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3329/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3330/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3331/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3332/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3333/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3334/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3335/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3336/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3337/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3338/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3339/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3340/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3341/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3342/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3343/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3344/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3345/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3346/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3347/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3348/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3349/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3350/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3351/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3352/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3353/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3354/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3355/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3356/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3357/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3358/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3359/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3360/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3361/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3362/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3363/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3364/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3365/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3366/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3367/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3368/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3369/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3370/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3371/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3372/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3373/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3374/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3375/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3376/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3377/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3378/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3379/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3380/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3381/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3382/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3383/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3384/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3385/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3386/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3387/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3388/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3389/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3390/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3391/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3392/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3393/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3394/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3395/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3396/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3397/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3398/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3399/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3400/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3401/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3402/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3403/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3404/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3405/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3406/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3407/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3408/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3409/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3410/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3411/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3412/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3413/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3414/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3415/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3416/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3417/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3418/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3419/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3420/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3421/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3422/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3423/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3424/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3425/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3426/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3427/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3428/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3429/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3430/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3431/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3432/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3433/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3434/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3435/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3436/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3437/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3438/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3439/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3440/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3441/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3442/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3443/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3444/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3445/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3446/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3447/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3448/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3449/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3450/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3451/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3452/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3453/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3454/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3455/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3456/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3457/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3458/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3459/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3460/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3461/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3462/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3463/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3464/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3465/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3466/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3467/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3468/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3469/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3470/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3471/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3472/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3473/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3474/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3475/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3476/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3477/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3478/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3479/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3480/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3481/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3482/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3483/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3484/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3485/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3486/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3487/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3488/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3489/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3490/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3491/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3492/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3493/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3494/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3495/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3496/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3497/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3498/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3499/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3500/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3501/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3502/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3503/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3504/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3505/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3506/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3507/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3508/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3509/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3510/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3511/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3512/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3513/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3514/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3515/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3516/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3517/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3518/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3519/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3520/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3521/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3522/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3523/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3524/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3525/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3526/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3527/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3528/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3529/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3530/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3531/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3532/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3533/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3534/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3535/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3536/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3537/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3538/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3539/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3540/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3541/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3542/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3543/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3544/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3545/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3546/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3547/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3548/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3549/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3550/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3551/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3552/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3553/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3554/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3555/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3556/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3557/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3558/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3559/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3560/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3561/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3562/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3563/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3564/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3565/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3566/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3567/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3568/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3569/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3570/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3571/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3572/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3573/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3574/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3575/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3576/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3577/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3578/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3579/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3580/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3581/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3582/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3583/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3584/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3585/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3586/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3587/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3588/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3589/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3590/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3591/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3592/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3593/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3594/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3595/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3596/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3597/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3598/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3599/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3600/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3601/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3602/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3603/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3604/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3605/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3606/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3607/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3608/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3609/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3610/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3611/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3612/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3613/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3614/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3615/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3616/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3617/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3618/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3619/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3620/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3621/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3622/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3623/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3624/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3625/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3626/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3627/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3628/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3629/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3630/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3631/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3632/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3633/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3634/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3635/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3636/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3637/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3638/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3639/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3640/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3641/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3642/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3643/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3644/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3645/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3646/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3647/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3648/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3649/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3650/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3651/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3652/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3653/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3654/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3655/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3656/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3657/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3658/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3659/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3660/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3661/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3662/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3663/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3664/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3665/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3666/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3667/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3668/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3669/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3670/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3671/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3672/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3673/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3674/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3675/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3676/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3677/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3678/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3679/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3680/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3681/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3682/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3683/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3684/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3685/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3686/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3687/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3688/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3689/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3690/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3691/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3692/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3693/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3694/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3695/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3696/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3697/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3698/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3699/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3700/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3701/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3702/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3703/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3704/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3705/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3706/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3707/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3708/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3709/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3710/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3711/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3712/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3713/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3714/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3715/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3716/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3717/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3718/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3719/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3720/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3721/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3722/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3723/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3724/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3725/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3726/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3727/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3728/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3729/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3730/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3731/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3732/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3733/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3734/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3735/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3736/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3737/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3738/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3739/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3740/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3741/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3742/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3743/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3744/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3745/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3746/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3747/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3748/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3749/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3750/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3751/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3752/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3753/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3754/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3755/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3756/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3757/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3758/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3759/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3760/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3761/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3762/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3763/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3764/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3765/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3766/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3767/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3768/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3769/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3770/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3771/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3772/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3773/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3774/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3775/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3776/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3777/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3778/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3779/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3780/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3781/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3782/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3783/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3784/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3785/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3786/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3787/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3788/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3789/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3790/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3791/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3792/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3793/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3794/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3795/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3796/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3797/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3798/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3799/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3800/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3801/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3802/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3803/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3804/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3805/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3806/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3807/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3808/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3809/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3810/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3811/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3812/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3813/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3814/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3815/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3816/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3817/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3818/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3819/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3820/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3821/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3822/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3823/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3824/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3825/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3826/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3827/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3828/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3829/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3830/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3831/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3832/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3833/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3834/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3835/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3836/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3837/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3838/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3839/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3840/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3841/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3842/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3843/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3844/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3845/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3846/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3847/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3848/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3849/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3850/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3851/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3852/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3853/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3854/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3855/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3856/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3857/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3858/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3859/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3860/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3861/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3862/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3863/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3864/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3865/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3866/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3867/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3868/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3869/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3870/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3871/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3872/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3873/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3874/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3875/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3876/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3877/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3878/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3879/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3880/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3881/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3882/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3883/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3884/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3885/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3886/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3887/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3888/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3889/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3890/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3891/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3892/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3893/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3894/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3895/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3896/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3897/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3898/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3899/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3900/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3901/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3902/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3903/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3904/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3905/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3906/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3907/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3908/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3909/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3910/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3911/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3912/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3913/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3914/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3915/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3916/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3917/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3918/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3919/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3920/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3921/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3922/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3923/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3924/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3925/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3926/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3927/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3928/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3929/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3930/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3931/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3932/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3933/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3934/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3935/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3936/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3937/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3938/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3939/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3940/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3941/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3942/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3943/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3944/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3945/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3946/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3947/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3948/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3949/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3950/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3951/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3952/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3953/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3954/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3955/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3956/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3957/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3958/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3959/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3960/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3961/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3962/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3963/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3964/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3965/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3966/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3967/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3968/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3969/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3970/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3971/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3972/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3973/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3974/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3975/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3976/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3977/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3978/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3979/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3980/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3981/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3982/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3983/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3984/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3985/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3986/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3987/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3988/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3989/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3990/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3991/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3992/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3993/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3994/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3995/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3996/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3997/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3998/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 3999/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4000/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4001/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4002/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4003/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4004/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4005/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4006/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4007/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4008/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4009/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4010/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4011/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4012/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4013/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4014/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4015/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4016/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4017/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4018/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4019/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4020/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4021/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4022/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4023/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4024/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4025/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4026/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4027/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4028/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4029/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4030/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4031/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4032/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4033/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4034/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4035/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4036/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4037/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4038/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4039/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4040/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4041/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4042/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4043/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4044/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4045/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4046/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4047/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4048/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4049/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4050/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4051/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4052/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4053/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4054/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4055/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4056/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4057/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4058/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4059/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4060/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4061/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4062/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4063/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4064/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4065/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4066/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4067/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4068/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4069/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4070/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4071/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4072/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4073/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4074/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4075/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4076/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4077/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4078/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4079/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4080/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4081/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4082/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4083/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4084/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4085/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4086/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4087/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4088/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4089/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4090/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4091/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4092/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4093/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4094/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4095/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4096/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4097/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4098/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4099/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4100/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4101/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4102/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4103/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4104/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4105/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4106/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4107/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4108/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4109/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4110/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4111/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4112/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4113/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4114/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4115/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4116/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4117/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4118/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4119/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4120/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4121/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4122/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4123/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4124/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4125/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4126/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4127/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4128/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4129/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4130/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4131/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4132/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4133/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4134/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4135/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4136/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4137/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4138/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4139/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4140/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4141/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4142/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4143/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4144/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4145/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4146/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4147/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4148/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4149/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4150/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4151/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4152/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4153/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4154/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4155/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4156/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4157/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4158/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4159/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4160/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4161/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4162/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4163/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4164/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4165/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4166/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4167/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4168/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4169/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4170/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4171/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4172/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4173/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4174/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4175/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4176/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4177/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4178/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4179/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4180/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4181/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4182/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4183/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4184/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4185/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4186/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4187/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4188/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4189/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4190/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4191/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4192/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4193/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4194/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4195/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4196/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4197/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4198/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4199/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4200/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4201/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4202/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4203/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4204/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4205/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4206/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4207/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4208/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4209/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4210/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4211/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4212/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4213/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4214/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4215/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4216/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4217/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4218/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4219/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4220/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4221/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4222/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4223/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4224/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4225/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4226/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4227/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4228/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4229/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4230/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4231/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4232/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4233/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4234/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4235/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4236/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4237/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4238/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4239/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4240/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4241/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4242/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4243/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4244/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4245/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4246/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4247/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4248/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4249/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4250/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4251/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4252/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4253/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4254/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4255/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4256/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4257/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4258/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4259/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4260/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4261/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4262/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4263/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4264/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4265/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4266/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4267/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4268/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4269/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4270/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4271/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4272/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4273/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4274/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4275/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4276/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4277/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4278/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4279/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4280/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4281/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4282/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4283/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4284/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4285/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4286/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4287/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4288/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4289/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4290/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4291/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4292/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4293/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4294/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4295/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4296/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4297/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4298/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4299/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4300/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4301/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4302/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4303/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4304/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4305/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4306/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4307/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4308/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4309/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4310/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4311/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4312/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4313/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4314/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4315/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4316/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4317/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4318/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4319/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4320/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4321/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4322/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4323/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4324/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4325/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4326/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4327/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4328/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4329/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4330/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4331/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4332/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4333/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4334/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4335/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4336/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4337/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4338/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4339/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4340/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4341/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4342/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4343/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4344/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4345/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4346/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4347/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4348/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4349/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4350/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4351/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4352/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4353/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4354/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4355/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4356/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4357/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4358/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4359/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4360/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4361/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4362/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4363/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4364/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4365/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4366/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4367/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4368/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4369/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4370/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4371/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4372/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4373/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4374/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4375/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4376/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4377/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4378/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4379/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4380/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4381/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4382/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4383/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4384/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4385/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4386/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4387/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4388/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4389/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4390/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4391/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4392/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4393/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4394/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4395/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4396/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4397/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4398/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4399/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4400/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4401/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4402/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4403/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4404/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4405/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4406/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4407/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4408/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4409/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4410/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4411/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4412/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4413/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4414/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4415/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4416/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4417/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4418/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4419/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4420/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4421/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4422/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4423/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4424/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4425/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4426/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4427/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4428/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4429/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4430/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4431/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4432/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4433/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4434/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4435/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4436/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4437/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4438/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4439/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4440/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4441/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4442/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4443/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4444/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4445/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4446/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4447/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4448/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4449/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4450/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4451/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4452/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4453/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4454/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4455/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4456/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4457/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4458/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4459/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4460/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4461/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4462/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4463/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4464/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4465/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4466/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4467/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4468/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4469/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4470/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4471/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4472/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4473/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4474/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4475/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4476/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4477/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4478/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4479/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4480/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4481/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4482/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4483/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4484/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4485/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4486/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4487/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4488/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4489/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4490/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4491/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4492/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4493/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4494/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4495/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4496/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4497/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4498/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4499/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4500/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4501/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4502/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4503/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4504/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4505/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4506/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4507/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4508/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4509/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4510/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4511/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4512/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4513/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4514/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4515/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4516/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4517/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4518/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4519/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4520/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4521/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4522/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4523/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4524/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4525/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4526/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4527/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4528/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4529/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4530/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4531/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4532/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4533/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4534/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4535/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4536/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4537/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4538/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4539/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4540/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4541/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4542/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4543/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4544/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4545/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4546/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4547/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4548/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4549/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4550/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4551/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4552/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4553/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4554/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4555/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4556/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4557/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4558/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4559/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4560/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4561/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4562/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4563/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4564/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4565/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4566/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4567/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4568/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4569/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4570/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4571/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4572/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4573/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4574/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4575/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4576/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4577/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4578/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4579/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4580/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4581/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4582/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4583/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4584/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4585/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4586/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4587/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4588/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4589/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4590/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4591/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4592/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4593/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4594/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4595/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4596/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4597/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4598/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4599/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4600/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4601/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4602/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4603/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4604/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4605/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4606/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4607/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4608/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4609/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4610/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4611/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4612/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4613/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4614/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4615/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4616/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4617/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4618/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4619/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4620/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4621/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4622/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4623/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4624/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4625/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4626/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4627/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4628/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4629/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4630/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4631/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4632/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4633/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4634/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4635/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4636/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4637/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4638/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4639/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4640/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4641/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4642/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4643/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4644/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4645/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4646/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4647/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4648/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4649/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4650/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4651/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4652/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4653/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4654/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4655/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4656/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4657/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4658/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4659/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4660/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4661/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4662/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4663/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4664/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4665/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4666/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4667/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4668/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4669/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4670/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4671/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4672/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4673/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4674/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4675/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4676/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4677/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4678/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4679/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4680/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4681/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4682/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4683/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4684/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4685/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4686/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4687/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4688/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4689/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4690/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4691/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4692/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4693/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4694/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4695/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4696/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4697/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4698/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4699/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4700/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4701/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4702/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4703/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4704/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4705/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4706/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4707/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4708/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4709/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4710/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4711/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4712/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4713/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4714/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4715/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4716/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4717/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4718/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4719/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4720/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4721/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4722/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4723/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4724/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4725/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4726/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4727/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4728/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4729/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4730/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4731/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4732/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4733/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4734/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4735/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4736/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4737/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4738/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4739/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4740/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4741/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4742/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4743/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4744/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4745/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4746/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4747/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4748/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4749/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4750/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4751/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4752/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4753/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4754/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4755/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4756/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4757/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4758/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4759/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4760/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4761/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4762/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4763/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4764/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4765/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4766/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4767/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4768/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4769/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4770/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4771/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4772/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4773/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4774/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4775/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4776/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4777/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4778/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4779/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4780/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4781/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4782/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4783/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4784/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4785/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4786/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4787/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4788/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4789/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4790/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4791/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4792/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4793/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4794/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4795/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4796/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4797/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4798/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4799/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4800/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4801/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4802/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4803/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4804/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4805/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4806/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4807/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4808/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4809/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4810/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4811/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4812/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4813/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4814/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4815/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4816/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4817/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4818/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4819/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4820/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4821/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4822/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4823/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4824/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4825/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4826/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4827/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4828/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4829/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4830/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4831/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4832/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4833/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4834/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4835/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4836/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4837/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4838/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4839/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4840/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4841/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4842/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4843/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4844/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4845/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4846/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4847/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4848/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4849/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4850/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4851/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4852/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4853/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4854/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4855/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4856/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4857/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4858/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4859/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4860/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4861/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4862/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4863/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4864/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4865/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4866/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4867/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4868/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4869/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4870/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4871/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4872/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4873/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4874/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4875/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4876/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4877/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4878/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4879/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4880/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4881/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4882/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4883/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4884/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4885/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4886/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4887/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4888/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4889/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4890/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4891/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4892/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4893/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4894/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4895/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4896/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4897/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4898/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4899/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4900/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4901/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4902/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4903/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4904/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4905/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4906/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4907/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4908/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4909/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4910/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4911/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4912/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4913/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4914/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4915/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4916/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4917/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4918/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4919/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4920/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4921/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4922/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4923/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4924/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4925/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4926/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4927/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4928/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4929/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4930/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4931/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4932/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4933/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4934/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4935/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4936/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4937/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4938/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4939/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4940/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4941/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4942/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4943/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4944/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4945/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4946/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4947/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4948/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4949/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4950/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4951/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4952/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4953/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4954/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4955/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4956/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4957/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4958/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4959/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4960/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4961/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4962/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4963/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4964/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4965/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4966/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4967/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4968/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4969/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4970/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4971/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4972/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4973/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4974/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4975/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4976/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4977/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4978/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4979/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4980/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4981/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4982/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4983/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4984/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4985/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4986/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4987/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4988/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4989/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4990/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4991/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4992/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4993/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4994/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4995/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4996/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4997/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4998/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 4999/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5000/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5001/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5002/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5003/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5004/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5005/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5006/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5007/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5008/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5009/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5010/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5011/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5012/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5013/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5014/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5015/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5016/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5017/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5018/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5019/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5020/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5021/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5022/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5023/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5024/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5025/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5026/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5027/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5028/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5029/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5030/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5031/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5032/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5033/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5034/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5035/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5036/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5037/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5038/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5039/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5040/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5041/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5042/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5043/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5044/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5045/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5046/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5047/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5048/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5049/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5050/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5051/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5052/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5053/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5054/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5055/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5056/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5057/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5058/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5059/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5060/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5061/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5062/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5063/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5064/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5065/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5066/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5067/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5068/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5069/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5070/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5071/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5072/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5073/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5074/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5075/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5076/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5077/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5078/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5079/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5080/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5081/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5082/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5083/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5084/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5085/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5086/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5087/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5088/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5089/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5090/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5091/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5092/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5093/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5094/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5095/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5096/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5097/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5098/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5099/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5100/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5101/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5102/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5103/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5104/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5105/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5106/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5107/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5108/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5109/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5110/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5111/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5112/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5113/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5114/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5115/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5116/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5117/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5118/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5119/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5120/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5121/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5122/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5123/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5124/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5125/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5126/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5127/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5128/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5129/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5130/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5131/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5132/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5133/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5134/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5135/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5136/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5137/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5138/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5139/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5140/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5141/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5142/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5143/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5144/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5145/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5146/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5147/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5148/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5149/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5150/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5151/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5152/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5153/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5154/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5155/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5156/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5157/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5158/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5159/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5160/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5161/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5162/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5163/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5164/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5165/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5166/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5167/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5168/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5169/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5170/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5171/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5172/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5173/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5174/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5175/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5176/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5177/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5178/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5179/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5180/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5181/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5182/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5183/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5184/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5185/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5186/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5187/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5188/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5189/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5190/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5191/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5192/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5193/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5194/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5195/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5196/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5197/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5198/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5199/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5200/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5201/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5202/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5203/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5204/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5205/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5206/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5207/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5208/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5209/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5210/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5211/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5212/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5213/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5214/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5215/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5216/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5217/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5218/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5219/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5220/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5221/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5222/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5223/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5224/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5225/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5226/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5227/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5228/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5229/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5230/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5231/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5232/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5233/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5234/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5235/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5236/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5237/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5238/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5239/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5240/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5241/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5242/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5243/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5244/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5245/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5246/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5247/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5248/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5249/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5250/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5251/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5252/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5253/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5254/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5255/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5256/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5257/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5258/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5259/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5260/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5261/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5262/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5263/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5264/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5265/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5266/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5267/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5268/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5269/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5270/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5271/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5272/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5273/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5274/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5275/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5276/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5277/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5278/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5279/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5280/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5281/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5282/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5283/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5284/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5285/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5286/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5287/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5288/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5289/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5290/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5291/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5292/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5293/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5294/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5295/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5296/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5297/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5298/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5299/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5300/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5301/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5302/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5303/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5304/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5305/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5306/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5307/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5308/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5309/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5310/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5311/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5312/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5313/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5314/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5315/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5316/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5317/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5318/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5319/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5320/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5321/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5322/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5323/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5324/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5325/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5326/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5327/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5328/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5329/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5330/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5331/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5332/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5333/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5334/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5335/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5336/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5337/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5338/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5339/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5340/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5341/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5342/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5343/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5344/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5345/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5346/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5347/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5348/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5349/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5350/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5351/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5352/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5353/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5354/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5355/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5356/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5357/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5358/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5359/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5360/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5361/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5362/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5363/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5364/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5365/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5366/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5367/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5368/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5369/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5370/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5371/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5372/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5373/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5374/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5375/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5376/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5377/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5378/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5379/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5380/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5381/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5382/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5383/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5384/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5385/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5386/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5387/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5388/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5389/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5390/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5391/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5392/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5393/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5394/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5395/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5396/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5397/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5398/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5399/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5400/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5401/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5402/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5403/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5404/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5405/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5406/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5407/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5408/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5409/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5410/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5411/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5412/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5413/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5414/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5415/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5416/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5417/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5418/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5419/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5420/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5421/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5422/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5423/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5424/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5425/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5426/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5427/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5428/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5429/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5430/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5431/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5432/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5433/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5434/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5435/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5436/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5437/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5438/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5439/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5440/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5441/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5442/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5443/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5444/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5445/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5446/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5447/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5448/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5449/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5450/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5451/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5452/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5453/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5454/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5455/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5456/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5457/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5458/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5459/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5460/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5461/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5462/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5463/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5464/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5465/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5466/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5467/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5468/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5469/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5470/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5471/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5472/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5473/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5474/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5475/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5476/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5477/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5478/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5479/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5480/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5481/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5482/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5483/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5484/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5485/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5486/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5487/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5488/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5489/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5490/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5491/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5492/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5493/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5494/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5495/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5496/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5497/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5498/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5499/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5500/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5501/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5502/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5503/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5504/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5505/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5506/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5507/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5508/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5509/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5510/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5511/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5512/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5513/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5514/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5515/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5516/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5517/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5518/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5519/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5520/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5521/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5522/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5523/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5524/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5525/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5526/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5527/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5528/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5529/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5530/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5531/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5532/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5533/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5534/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5535/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5536/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5537/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5538/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5539/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5540/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5541/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5542/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5543/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5544/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5545/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5546/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5547/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5548/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5549/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5550/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5551/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5552/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5553/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5554/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5555/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5556/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5557/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5558/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5559/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5560/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5561/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5562/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5563/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5564/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5565/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5566/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5567/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5568/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5569/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5570/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5571/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5572/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5573/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5574/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5575/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5576/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5577/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5578/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5579/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5580/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5581/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5582/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5583/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5584/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5585/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5586/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5587/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5588/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5589/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5590/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5591/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5592/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5593/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5594/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5595/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5596/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5597/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5598/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5599/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5600/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5601/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5602/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5603/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5604/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5605/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5606/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5607/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5608/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5609/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5610/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5611/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5612/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5613/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5614/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5615/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5616/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5617/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5618/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5619/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5620/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5621/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5622/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5623/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5624/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5625/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5626/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5627/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5628/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5629/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5630/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5631/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5632/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5633/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5634/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5635/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5636/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5637/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5638/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5639/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5640/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5641/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5642/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5643/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5644/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5645/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5646/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5647/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5648/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5649/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5650/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5651/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5652/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5653/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5654/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5655/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5656/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5657/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5658/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5659/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5660/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5661/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5662/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5663/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5664/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5665/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5666/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5667/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5668/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5669/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5670/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5671/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5672/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5673/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5674/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5675/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5676/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5677/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5678/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5679/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5680/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5681/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5682/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5683/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5684/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5685/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5686/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5687/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5688/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5689/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5690/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5691/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5692/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5693/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5694/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5695/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5696/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5697/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5698/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5699/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5700/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5701/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5702/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5703/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5704/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5705/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5706/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5707/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5708/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5709/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5710/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5711/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5712/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5713/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5714/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5715/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5716/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5717/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5718/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5719/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5720/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5721/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5722/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5723/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5724/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5725/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5726/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5727/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5728/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5729/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5730/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5731/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5732/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5733/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5734/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5735/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5736/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5737/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5738/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5739/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5740/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5741/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5742/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5743/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5744/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5745/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5746/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5747/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5748/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5749/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5750/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5751/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5752/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5753/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5754/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5755/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5756/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5757/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5758/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5759/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5760/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5761/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5762/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5763/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5764/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5765/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5766/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5767/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5768/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5769/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5770/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5771/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5772/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5773/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5774/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5775/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5776/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5777/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5778/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5779/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5780/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5781/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5782/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5783/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5784/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5785/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5786/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5787/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5788/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5789/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5790/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5791/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5792/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5793/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5794/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5795/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5796/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5797/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5798/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5799/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5800/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5801/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5802/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5803/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5804/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5805/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5806/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5807/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5808/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5809/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5810/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5811/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5812/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5813/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5814/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5815/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5816/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5817/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5818/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5819/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5820/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5821/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5822/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5823/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5824/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5825/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5826/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5827/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5828/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5829/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5830/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5831/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5832/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5833/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5834/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5835/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5836/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5837/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5838/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5839/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5840/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5841/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5842/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5843/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5844/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5845/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5846/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5847/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5848/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5849/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5850/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5851/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5852/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5853/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5854/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5855/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5856/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5857/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5858/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5859/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5860/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5861/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5862/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5863/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5864/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5865/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5866/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5867/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5868/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5869/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5870/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5871/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5872/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5873/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5874/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5875/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5876/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5877/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5878/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5879/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5880/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5881/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5882/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5883/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5884/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5885/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5886/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5887/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5888/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5889/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5890/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5891/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5892/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5893/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5894/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5895/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5896/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5897/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5898/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5899/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5900/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5901/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5902/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5903/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5904/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5905/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5906/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5907/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5908/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5909/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5910/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5911/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5912/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5913/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5914/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5915/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5916/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5917/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5918/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5919/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5920/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5921/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5922/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5923/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5924/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5925/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5926/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5927/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5928/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5929/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5930/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5931/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5932/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5933/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5934/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5935/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5936/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5937/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5938/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5939/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5940/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5941/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5942/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5943/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5944/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5945/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5946/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5947/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5948/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5949/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5950/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5951/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5952/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5953/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5954/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5955/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5956/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5957/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5958/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5959/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5960/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5961/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5962/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5963/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5964/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5965/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5966/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5967/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5968/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5969/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5970/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5971/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5972/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5973/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5974/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5975/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5976/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5977/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5978/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5979/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5980/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5981/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5982/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5983/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5984/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5985/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5986/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5987/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5988/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5989/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5990/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5991/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5992/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5993/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5994/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5995/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5996/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5997/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5998/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 5999/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6000/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6001/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6002/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6003/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6004/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6005/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6006/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6007/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6008/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6009/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6010/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6011/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6012/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6013/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6014/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6015/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6016/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6017/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6018/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6019/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6020/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6021/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6022/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6023/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6024/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6025/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6026/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6027/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6028/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6029/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6030/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6031/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6032/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6033/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6034/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6035/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6036/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6037/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6038/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6039/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6040/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6041/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6042/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6043/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6044/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6045/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6046/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6047/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6048/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6049/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6050/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6051/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6052/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6053/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6054/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6055/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6056/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6057/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6058/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6059/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6060/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6061/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6062/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6063/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6064/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6065/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6066/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6067/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6068/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6069/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6070/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6071/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6072/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6073/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6074/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6075/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6076/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6077/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6078/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6079/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6080/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6081/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6082/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6083/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6084/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6085/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6086/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6087/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6088/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6089/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6090/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6091/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6092/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6093/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6094/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6095/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6096/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6097/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6098/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6099/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6100/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6101/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6102/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6103/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6104/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6105/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6106/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6107/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6108/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6109/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6110/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6111/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6112/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6113/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6114/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6115/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6116/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6117/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6118/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6119/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6120/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6121/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6122/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6123/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6124/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6125/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6126/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6127/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6128/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6129/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6130/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6131/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6132/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6133/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6134/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6135/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6136/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6137/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6138/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6139/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6140/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6141/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6142/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6143/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6144/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6145/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6146/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6147/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6148/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6149/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6150/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6151/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6152/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6153/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6154/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6155/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6156/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6157/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6158/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6159/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6160/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6161/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6162/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6163/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6164/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6165/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6166/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6167/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6168/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6169/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6170/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6171/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6172/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6173/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6174/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6175/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6176/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6177/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6178/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6179/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6180/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6181/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6182/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6183/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6184/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6185/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6186/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6187/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6188/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6189/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6190/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6191/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6192/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6193/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6194/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6195/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6196/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6197/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6198/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6199/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6200/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6201/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6202/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6203/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6204/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6205/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6206/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6207/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6208/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6209/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6210/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6211/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6212/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6213/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6214/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6215/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6216/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6217/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6218/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6219/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6220/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6221/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6222/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6223/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6224/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6225/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6226/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6227/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6228/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6229/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6230/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6231/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6232/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6233/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6234/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6235/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6236/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6237/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6238/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6239/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6240/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6241/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6242/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6243/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6244/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6245/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6246/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6247/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6248/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6249/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6250/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6251/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6252/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6253/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6254/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6255/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6256/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6257/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6258/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6259/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6260/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6261/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6262/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6263/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6264/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6265/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6266/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6267/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6268/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6269/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6270/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6271/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6272/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6273/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6274/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6275/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6276/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6277/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6278/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6279/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6280/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6281/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6282/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6283/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6284/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6285/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6286/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6287/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6288/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6289/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6290/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6291/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6292/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6293/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6294/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6295/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6296/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6297/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6298/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6299/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6300/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6301/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6302/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6303/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6304/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6305/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6306/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6307/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6308/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6309/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6310/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6311/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6312/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6313/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6314/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6315/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6316/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6317/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6318/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6319/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6320/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6321/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6322/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6323/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6324/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6325/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6326/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6327/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6328/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6329/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6330/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6331/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6332/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6333/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6334/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6335/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6336/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6337/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6338/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6339/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6340/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6341/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6342/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6343/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6344/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6345/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6346/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6347/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6348/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6349/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6350/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6351/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6352/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6353/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6354/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6355/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6356/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6357/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6358/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6359/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6360/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6361/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6362/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6363/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6364/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6365/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6366/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6367/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6368/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6369/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6370/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6371/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6372/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6373/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6374/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6375/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6376/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6377/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6378/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6379/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6380/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6381/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6382/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6383/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6384/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6385/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6386/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6387/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6388/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6389/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6390/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6391/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6392/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6393/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6394/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6395/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6396/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6397/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6398/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6399/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6400/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6401/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6402/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6403/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6404/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6405/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6406/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6407/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6408/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6409/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6410/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6411/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6412/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6413/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6414/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6415/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6416/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6417/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6418/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6419/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6420/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6421/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6422/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6423/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6424/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6425/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6426/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6427/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6428/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6429/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6430/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6431/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6432/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6433/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6434/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6435/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6436/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6437/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6438/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6439/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6440/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6441/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6442/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6443/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6444/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6445/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6446/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6447/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6448/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6449/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6450/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6451/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6452/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6453/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6454/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6455/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6456/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6457/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6458/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6459/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6460/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6461/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6462/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6463/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6464/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6465/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6466/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6467/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6468/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6469/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6470/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6471/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6472/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6473/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6474/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6475/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6476/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6477/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6478/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6479/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6480/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6481/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6482/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6483/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6484/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6485/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6486/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6487/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6488/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6489/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6490/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6491/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6492/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6493/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6494/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6495/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6496/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6497/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6498/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6499/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6500/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6501/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6502/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6503/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6504/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6505/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6506/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6507/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6508/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6509/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6510/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6511/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6512/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6513/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6514/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6515/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6516/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6517/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6518/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6519/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6520/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6521/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6522/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6523/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6524/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6525/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6526/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6527/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6528/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6529/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6530/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6531/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6532/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6533/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6534/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6535/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6536/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6537/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6538/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6539/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6540/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6541/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6542/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6543/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6544/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6545/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6546/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6547/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6548/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6549/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6550/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6551/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6552/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6553/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6554/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6555/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6556/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6557/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6558/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6559/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6560/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6561/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6562/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6563/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6564/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6565/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6566/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6567/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6568/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6569/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6570/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6571/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6572/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6573/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6574/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6575/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6576/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6577/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6578/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6579/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6580/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6581/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6582/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6583/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6584/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6585/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6586/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6587/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6588/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6589/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6590/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6591/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6592/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6593/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6594/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6595/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6596/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6597/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6598/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6599/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6600/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6601/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6602/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6603/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6604/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6605/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6606/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6607/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6608/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6609/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6610/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6611/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6612/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6613/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6614/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6615/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6616/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6617/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6618/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6619/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6620/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6621/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6622/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6623/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6624/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6625/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6626/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6627/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6628/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6629/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6630/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6631/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6632/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6633/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6634/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6635/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6636/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6637/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6638/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6639/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6640/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6641/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6642/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6643/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6644/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6645/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6646/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6647/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6648/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6649/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6650/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6651/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6652/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6653/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6654/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6655/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6656/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6657/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6658/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6659/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6660/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6661/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6662/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6663/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6664/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6665/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6666/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6667/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6668/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6669/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6670/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6671/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6672/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6673/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6674/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6675/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6676/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6677/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6678/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6679/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6680/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6681/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6682/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6683/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6684/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6685/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6686/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6687/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6688/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6689/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6690/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6691/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6692/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6693/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6694/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6695/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6696/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6697/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6698/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6699/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6700/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6701/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6702/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6703/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6704/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6705/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6706/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6707/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6708/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6709/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6710/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6711/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6712/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6713/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6714/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6715/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6716/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6717/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6718/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6719/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6720/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6721/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6722/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6723/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6724/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6725/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6726/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6727/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6728/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6729/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6730/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6731/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6732/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6733/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6734/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6735/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6736/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6737/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6738/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6739/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6740/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6741/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6742/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6743/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6744/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6745/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6746/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6747/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6748/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6749/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6750/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6751/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6752/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6753/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6754/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6755/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6756/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6757/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6758/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6759/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6760/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6761/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6762/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6763/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6764/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6765/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6766/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6767/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6768/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6769/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6770/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6771/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6772/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6773/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6774/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6775/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6776/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6777/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6778/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6779/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6780/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6781/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6782/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6783/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6784/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6785/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6786/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6787/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6788/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6789/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6790/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6791/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6792/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6793/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6794/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6795/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6796/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6797/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6798/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6799/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6800/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6801/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6802/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6803/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6804/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6805/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6806/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6807/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6808/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6809/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6810/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6811/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6812/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6813/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6814/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6815/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6816/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6817/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6818/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6819/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6820/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6821/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6822/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6823/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6824/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6825/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6826/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6827/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6828/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6829/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6830/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6831/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6832/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6833/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6834/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6835/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6836/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6837/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6838/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6839/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6840/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6841/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6842/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6843/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6844/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6845/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6846/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6847/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6848/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6849/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6850/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6851/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6852/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6853/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6854/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6855/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6856/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6857/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6858/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6859/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6860/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6861/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6862/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6863/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6864/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6865/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6866/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6867/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6868/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6869/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6870/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6871/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6872/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6873/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6874/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6875/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6876/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6877/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6878/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6879/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6880/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6881/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6882/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6883/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6884/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6885/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6886/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6887/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6888/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6889/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6890/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6891/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6892/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6893/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6894/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6895/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6896/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6897/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6898/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6899/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6900/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6901/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6902/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6903/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6904/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6905/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6906/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6907/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6908/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6909/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6910/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6911/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6912/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6913/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6914/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6915/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6916/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6917/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6918/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6919/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6920/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6921/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6922/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6923/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6924/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6925/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6926/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6927/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6928/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6929/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6930/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6931/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6932/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6933/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6934/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6935/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6936/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6937/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6938/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6939/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6940/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6941/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6942/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6943/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6944/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6945/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6946/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6947/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6948/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6949/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6950/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6951/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6952/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6953/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6954/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6955/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6956/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6957/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6958/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6959/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6960/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6961/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6962/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6963/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6964/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6965/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6966/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6967/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6968/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6969/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6970/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6971/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6972/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6973/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6974/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6975/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6976/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6977/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6978/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6979/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6980/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6981/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6982/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6983/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6984/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6985/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6986/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6987/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6988/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6989/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6990/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6991/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6992/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6993/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6994/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6995/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6996/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6997/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6998/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 6999/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7000/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7001/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7002/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7003/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7004/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7005/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7006/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7007/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7008/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7009/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7010/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7011/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7012/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7013/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7014/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7015/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7016/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7017/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7018/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7019/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7020/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7021/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7022/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7023/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7024/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7025/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7026/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7027/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7028/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7029/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7030/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7031/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7032/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7033/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7034/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7035/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7036/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7037/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7038/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7039/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7040/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7041/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7042/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7043/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7044/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7045/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7046/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7047/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7048/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7049/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7050/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7051/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7052/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7053/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7054/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7055/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7056/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7057/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7058/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7059/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7060/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7061/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7062/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7063/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7064/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7065/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7066/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7067/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7068/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7069/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7070/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7071/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7072/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7073/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7074/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7075/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7076/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7077/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7078/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7079/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7080/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7081/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7082/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7083/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7084/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7085/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7086/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7087/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7088/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7089/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7090/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7091/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7092/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7093/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7094/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7095/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7096/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7097/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7098/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7099/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7100/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7101/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7102/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7103/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7104/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7105/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7106/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7107/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7108/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7109/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7110/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7111/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7112/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7113/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7114/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7115/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7116/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7117/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7118/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7119/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7120/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7121/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7122/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7123/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7124/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7125/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7126/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7127/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7128/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7129/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7130/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7131/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7132/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7133/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7134/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7135/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7136/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7137/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7138/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7139/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7140/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7141/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7142/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7143/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7144/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7145/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7146/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7147/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7148/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7149/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7150/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7151/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7152/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7153/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7154/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7155/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7156/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7157/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7158/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7159/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7160/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7161/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7162/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7163/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7164/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7165/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7166/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7167/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7168/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7169/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7170/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7171/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7172/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7173/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7174/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7175/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7176/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7177/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7178/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7179/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7180/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7181/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7182/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7183/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7184/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7185/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7186/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7187/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7188/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7189/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7190/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7191/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7192/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7193/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7194/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7195/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7196/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7197/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7198/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7199/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7200/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7201/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7202/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7203/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7204/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7205/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7206/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7207/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7208/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7209/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7210/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7211/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7212/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7213/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7214/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7215/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7216/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7217/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7218/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7219/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7220/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7221/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7222/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7223/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7224/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7225/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7226/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7227/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7228/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7229/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7230/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7231/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7232/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7233/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7234/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7235/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7236/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7237/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7238/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7239/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7240/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7241/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7242/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7243/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7244/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7245/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7246/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7247/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7248/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7249/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7250/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7251/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7252/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7253/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7254/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7255/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7256/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7257/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7258/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7259/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7260/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7261/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7262/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7263/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7264/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7265/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7266/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7267/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7268/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7269/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7270/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7271/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7272/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7273/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7274/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7275/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7276/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7277/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7278/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7279/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7280/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7281/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7282/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7283/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7284/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7285/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7286/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7287/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7288/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7289/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7290/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7291/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7292/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7293/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7294/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7295/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7296/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7297/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7298/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7299/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7300/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7301/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7302/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7303/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7304/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7305/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7306/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7307/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7308/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7309/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7310/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7311/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7312/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7313/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7314/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7315/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7316/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7317/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7318/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7319/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7320/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7321/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7322/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7323/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7324/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7325/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7326/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7327/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7328/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7329/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7330/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7331/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7332/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7333/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7334/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7335/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7336/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7337/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7338/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7339/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7340/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7341/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7342/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7343/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7344/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7345/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7346/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7347/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7348/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7349/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7350/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7351/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7352/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7353/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7354/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7355/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7356/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7357/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7358/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7359/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7360/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7361/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7362/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7363/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7364/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7365/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7366/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7367/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7368/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7369/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7370/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7371/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7372/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7373/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7374/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7375/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7376/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7377/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7378/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7379/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7380/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7381/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7382/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7383/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7384/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7385/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7386/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7387/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7388/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7389/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7390/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7391/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7392/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7393/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7394/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7395/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7396/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7397/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7398/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7399/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7400/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7401/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7402/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7403/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7404/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7405/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7406/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7407/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7408/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7409/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7410/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7411/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7412/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7413/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7414/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7415/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7416/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7417/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7418/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7419/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7420/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7421/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7422/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7423/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7424/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7425/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7426/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7427/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7428/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7429/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7430/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7431/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7432/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7433/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7434/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7435/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7436/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7437/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7438/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7439/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7440/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7441/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7442/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7443/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7444/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7445/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7446/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7447/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7448/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7449/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7450/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7451/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7452/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7453/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7454/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7455/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7456/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7457/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7458/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7459/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7460/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7461/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7462/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7463/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7464/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7465/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7466/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7467/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7468/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7469/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7470/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7471/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7472/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7473/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7474/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7475/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7476/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7477/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7478/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7479/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7480/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7481/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7482/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7483/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7484/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7485/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7486/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7487/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7488/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7489/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7490/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7491/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7492/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7493/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7494/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7495/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7496/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7497/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7498/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7499/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7500/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7501/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7502/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7503/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7504/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7505/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7506/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7507/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7508/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7509/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7510/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7511/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7512/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7513/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7514/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7515/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7516/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7517/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7518/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7519/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7520/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7521/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7522/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7523/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7524/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7525/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7526/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7527/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7528/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7529/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7530/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7531/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7532/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7533/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7534/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7535/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7536/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7537/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7538/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7539/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7540/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7541/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7542/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7543/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7544/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7545/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7546/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7547/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7548/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7549/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7550/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7551/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7552/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7553/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7554/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7555/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7556/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7557/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7558/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7559/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7560/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7561/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7562/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7563/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7564/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7565/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7566/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7567/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7568/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7569/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7570/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7571/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7572/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7573/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7574/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7575/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7576/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7577/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7578/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7579/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7580/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7581/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7582/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7583/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7584/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7585/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7586/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7587/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7588/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7589/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7590/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7591/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7592/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7593/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7594/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7595/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7596/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7597/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7598/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7599/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7600/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7601/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7602/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7603/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7604/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7605/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7606/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7607/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7608/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7609/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7610/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7611/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7612/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7613/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7614/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7615/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7616/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7617/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7618/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7619/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7620/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7621/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7622/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7623/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7624/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7625/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7626/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7627/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7628/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7629/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7630/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7631/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7632/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7633/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7634/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7635/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7636/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7637/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7638/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7639/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7640/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7641/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7642/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7643/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7644/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7645/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7646/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7647/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7648/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7649/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7650/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7651/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7652/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7653/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7654/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7655/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7656/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7657/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7658/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7659/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7660/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7661/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7662/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7663/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7664/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7665/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7666/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7667/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7668/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7669/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7670/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7671/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7672/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7673/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7674/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7675/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7676/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7677/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7678/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7679/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7680/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7681/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7682/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7683/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7684/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7685/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7686/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7687/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7688/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7689/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7690/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7691/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7692/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7693/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7694/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7695/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7696/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7697/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7698/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7699/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7700/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7701/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7702/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7703/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7704/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7705/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7706/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7707/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7708/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7709/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7710/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7711/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7712/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7713/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7714/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7715/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7716/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7717/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7718/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7719/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7720/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7721/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7722/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7723/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7724/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7725/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7726/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7727/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7728/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7729/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7730/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7731/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7732/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7733/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7734/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7735/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7736/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7737/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7738/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7739/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7740/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7741/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7742/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7743/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7744/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7745/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7746/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7747/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7748/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7749/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7750/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7751/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7752/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7753/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7754/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7755/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7756/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7757/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7758/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7759/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7760/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7761/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7762/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7763/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7764/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7765/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7766/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7767/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7768/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7769/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7770/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7771/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7772/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7773/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7774/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7775/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7776/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7777/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7778/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7779/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7780/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7781/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7782/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7783/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7784/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7785/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7786/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7787/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7788/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7789/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7790/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7791/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7792/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7793/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7794/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7795/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7796/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7797/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7798/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7799/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7800/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7801/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7802/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7803/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7804/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7805/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7806/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7807/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7808/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7809/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7810/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7811/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7812/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7813/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7814/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7815/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7816/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7817/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7818/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7819/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7820/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7821/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7822/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7823/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7824/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7825/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7826/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7827/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7828/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7829/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7830/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7831/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7832/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7833/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7834/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7835/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7836/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7837/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7838/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7839/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7840/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7841/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7842/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7843/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7844/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7845/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7846/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7847/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7848/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7849/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7850/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7851/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7852/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7853/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7854/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7855/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7856/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7857/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7858/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7859/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7860/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7861/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7862/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7863/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7864/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7865/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7866/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7867/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7868/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7869/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7870/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7871/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7872/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7873/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7874/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7875/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7876/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7877/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7878/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7879/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7880/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7881/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7882/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7883/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7884/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7885/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7886/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7887/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7888/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7889/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7890/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7891/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7892/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7893/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7894/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7895/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7896/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7897/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7898/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7899/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7900/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7901/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7902/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7903/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7904/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7905/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7906/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7907/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7908/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7909/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7910/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7911/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7912/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7913/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7914/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7915/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7916/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7917/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7918/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7919/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7920/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7921/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7922/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7923/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7924/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7925/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7926/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7927/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7928/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7929/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7930/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7931/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7932/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7933/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7934/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7935/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7936/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7937/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7938/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7939/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7940/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7941/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7942/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7943/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7944/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7945/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7946/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7947/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7948/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7949/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7950/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7951/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7952/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7953/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7954/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7955/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7956/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7957/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7958/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7959/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7960/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7961/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7962/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7963/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7964/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7965/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7966/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7967/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7968/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7969/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7970/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7971/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7972/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7973/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7974/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7975/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7976/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7977/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7978/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7979/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7980/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7981/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7982/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7983/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7984/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7985/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7986/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7987/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7988/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7989/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7990/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7991/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7992/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7993/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7994/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7995/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7996/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7997/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7998/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 7999/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n",
      "Epoch: 8000/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4291\n"
     ]
    }
   ],
   "source": [
    "from LogisticRegression import LogisticRegression\n",
    "\n",
    "epochs = 8000\n",
    "alpha = 0.5\n",
    "logistic_reg2 = LogisticRegression(x=train_x_map,y=train_y_ex,val_x=val_x_map,val_y=val_y_ex,epoch=epochs,lr=alpha,scale=2,regularize=\"L2\")\n",
    "theta, loss, val_loss = logistic_reg2.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看精度，损失和F1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 79.17%\n",
      "My F1 Score: 0.8148\n"
     ]
    }
   ],
   "source": [
    "acc = logistic_reg2.test(val_x_map,val_y_ex)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(acc * 100))\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_true=val_y_ex,y_pred=logistic_reg2.predict(val_x_map))\n",
    "print(\"My F1 Score: {:.4f}\".format(f1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用库函数验证"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Accuracy: 79.17%\n",
      "Sklearn Val Loss: 0.4206\n",
      "Sklearn F1 Score: 0.8148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sk_lr2 = LogisticRegression()\n",
    "sk_lr2.fit(train_x_map,train_y)\n",
    "sk_pred2 = sk_lr2.predict(val_x_map)\n",
    "count2 = np.sum(np.equal(sk_pred2,val_y))\n",
    "sk_acc2 = count2/val_y.shape[0]\n",
    "sk_prob2 = sk_lr2.predict_proba(val_x_map)\n",
    "\n",
    "from LogisticRegression import bce_loss\n",
    "sk_loss2 = bce_loss(sk_prob2[:,1], val_y_ex)\n",
    "sk_f12 = f1_score(y_true=val_y_ex,y_pred=sk_pred2)\n",
    "print(\"Sklearn Accuracy: {:.2f}%\".format(sk_acc2 * 100))\n",
    "print(\"Sklearn Val Loss: {:.4f}\".format(sk_loss2))\n",
    "print(\"Sklearn F1 Score: {:.4f}\".format(sk_f12))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可视化决策边界"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAKqCAYAAABGhh8JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAADELklEQVR4nOzde1zUVf7H8TeiomIgeUMdTVQodL1hRWJFloRWrkrb1mZqppaWXdZtxfpt2W1L3K1tt63sYt6q7bJrFyszclNTkloBY4sSlaIxSXQJEk0L5vfHyMjAXGHu83o+Hjxwzvd8v3MGBObzPed8PhEmk8kkAAAAAADgd238PQAAAAAAAGBGkA4AAAAAQIAgSAcAAAAAIEAQpAMAAAAAECAI0gEAAAAACBAE6QAAAAAABAiCdAAAAAAAAgRBOgAAAAAAAYIgHQAAAACAAEGQDgAAJEnXXnut+vfv7+9hAAAQ1gjSAQAIcBERES59bNq0yd9Dbearr77SzJkzNXDgQHXo0EHx8fE6//zztXjx4hZd75133tE999zj2UECABBAIkwmk8nfgwAAAPY9//zzVo9Xr16t3NxcrVmzxqo9IyNDPXv2bPHz/PTTT6qvr1dUVFSLr9HY7t27ddZZZ6ljx4667rrr1L9/f+3fv18FBQVav369fvzxR7evOX/+fD3++OPi7QsAIFS19fcAAACAY9dcc43V4+3btys3N7dZe1NHjhxRp06dXH6edu3atWh89vzlL3/R4cOHVVRUpNNOO83q2IEDBzz6XAAAhAqWuwMAEAIuuOAC/eIXv9COHTt0/vnnq1OnTrrzzjslSW+88YYuvfRS9e7dW1FRURo4cKDuv/9+1dXVWV2j6Z70r776ShEREfrzn/+sp59+WgMHDlRUVJTOOussffLJJ07HtGfPHhkMhmYBuiT16NGjWdv69et13nnnKTo6WqeccoouvfRSffbZZ1bje/zxxyVZbwEAACCUMJMOAECIOHTokCZMmKCrrrpK11xzjWXp+8qVK9W5c2ctWLBAnTt31r///W/dfffdqqmp0Z/+9Cen133xxRf1ww8/6IYbblBERISWLl2qrKws7d271+Hs+2mnnab3339f//73v3XhhRc6fI41a9ZoxowZyszMVE5Ojo4cOaInn3xS5557rgoLC9W/f3/dcMMN+vbbb20u9QcAIFSwJx0AgCBja1/2BRdcoM2bN2vZsmW64YYbrPofPXpUHTt2tGqbO3eu1qxZo//973+WPejXXnutNm3apK+++kqSeSY9ISFBXbt2VWlpqeLi4iRJb775piZNmqR169bpsssuszvOzz77TGeddZaOHj2qESNGKD09XWPHjlVGRobVMvzDhw+rb9++uuKKK/T0009b2r/77judfvrp+vWvf21pZ086ACDUsdwdAIAQERUVpZkzZzZrbxyg//DDDzp48KDOO+88HTlyRF988YXT61555ZWWAF2SzjvvPEnS3r17HZ43ZMgQFRUV6ZprrtFXX32lv/71r5o8ebJ69uypZ555xtIvNzdX33//vX7zm9/o4MGDlo/IyEilpqbqgw8+cDpGAABCBcvdAQAIEX369FH79u2btX/22Wf6wx/+oH//+9+qqamxOlZdXe30uv369bN63BCwV1VVOT03KSlJa9asUV1dnT7//HO99dZbWrp0qa6//nolJCRo3LhxKi0tlSS7S+JjYmKcPg8AAKGCIB0AgBDRdEm7JH3//fdKT09XTEyM7rvvPku98oKCAmVnZ6u+vt7pdSMjI222u7PkPDIyUkOHDtXQoUM1evRojR07Vi+88ILGjRtnGcOaNWsUHx/f7Ny2bXm7AgAIH/zVAwAghG3atEmHDh3S2rVrdf7551vay8rK/DamM888U5K0f/9+SdLAgQMlmTO+jxs3zuG5ZHMHAIQ69qQDABDCGmbBG896Hz9+XE888YTXn/vDDz/UTz/91Kz9nXfekSSdfvrpkqTMzEzFxMTowQcftNm/srLS8u/o6GhJ5hUCAACEImbSAQAIYWlpaYqLi9OMGTN0yy23KCIiQmvWrPFJdvScnBzt2LFDWVlZGjZsmCSpoKBAq1ev1qmnnqrbbrtNknnP+ZNPPqlp06YpJSVFV111lbp3767y8nK9/fbbGjNmjP7+979LkkaNGiVJuuWWW5SZmanIyEhdddVVXn8tAAD4CkE6AAAhrGvXrnrrrbf0u9/9Tn/4wx8UFxena665RhdddJEyMzO9+tx33nmnXnzxRW3evFkvvPCCjhw5ol69eumqq67SXXfdpYSEBEvfq6++Wr1799aSJUv0pz/9SceOHVOfPn103nnnWWWsz8rK0s0336yXXnpJzz//vEwmE0E6ACCkUCcdAAAAAIAAwZ50AAAAAAACBEE6AAAAAAABgiAdAAAAAIAAQZAOAAAAAECAIEgHAAAAACBAEKQDAAAAABAgwrJOen19vb799ludcsopioiI8PdwAAAAAAAhzmQy6YcfflDv3r3Vpo39+fKwDNK//fZb9e3b19/DAAAAAACEmW+++UYGg8Hu8bAM0k855RRJ5i9OTEyMn0cDAAAAAAh1NTU16tu3ryUetScsg/SGJe4xMTEE6QAAAAAAn3G25ZrEcQAAAAAABAiCdAAAAAAAAgRBOgAAAAAAASIs96S7qq6uTj/99JO/hwHAjnbt2ikyMtLfwwAAAAA8hiDdBpPJpIqKCn3//ff+HgoAJ7p06aL4+HinCTgAAACAYECQbkNDgN6jRw916tSJN/9AADKZTDpy5IgOHDggSerVq5efRwQAAAC0HkF6E3V1dZYAvWvXrv4eDgAHOnbsKEk6cOCAevTowdJ3AAAABD0SxzXRsAe9U6dOfh4JAFc0/KySPwIAAAChgCDdDpa4A8GBn1UAAACEEoJ0AAAAAAACBEE6As6mTZsUERHhUnZ9d/qGsq+++koREREqKiry91AAAAAAtAJBeoi49tprFRERoblz5zY7dtNNNykiIkLXXnttq54jIiLC8hEdHa3ExERde+212rFjR6uu21RaWpr279+v2NhYj/ZtjYavb8NH165dNX78eH366adefV4AAAAA4YUgPYT07dtXL730ko4ePWpp+/HHH/Xiiy+qX79+HnmOFStWaP/+/frss8/0+OOP6/Dhw0pNTdXq1as9cn1Jat++vct1r93p21rjx4/X/v37tX//fm3cuFFt27bVZZdd5vXn9ZXjx4/7ewgAAABA2CNIDyEpKSnq27ev1q5da2lbu3at+vXrp5EjR1raVq9era5du+rYsWNW50+ePFnTpk1z+BxdunRRfHy8+vfvr4svvlj//Oc/NXXqVM2fP19VVVWWflu3btV5552njh07qm/fvrrllltUW1trOX7s2DFlZ2erb9++ioqK0qBBg7R8+XJJzZewf/3115o4caLi4uIUHR2tIUOG6J133rHZV5L+9a9/aciQIYqKilL//v318MMPW72G/v3768EHH9R1112nU045Rf369dPTTz/t9OsbFRWl+Ph4xcfHa8SIEVq0aJG++eYbVVZWWvoUFxfrwgsvVMeOHdW1a1ddf/31Onz4sOX4BRdcoNtuu63Z173xKgdXxvfxxx9r5MiR6tChg84880wVFhZaHa+rq9OsWbOUkJCgjh076vTTT9df//pXqz7XXnutJk+erD/+8Y/q3bu3Tj/9dN133336xS9+0ey1jxgxQnfddZfTrxEAAACA1iFI96p8SWtOfPaN6667TitWrLA8fu655zRz5kyrPldccYXq6ur05ptvWtoOHDigt99+W9ddd53bz/nb3/5WP/zwg3JzcyVJe/bs0fjx43X55Zfr008/1csvv6ytW7dq/vz5lnOmT5+uf/zjH/rb3/6mkpISPfXUU+rcubPN69900006duyYtmzZouLiYuXk5Njtu2PHDv3617/WVVddpeLiYt1zzz266667tHLlSqt+Dz/8sCW4vfHGGzVv3jx9+eWXLr/mw4cP6/nnn9egQYPUtWtXSVJtba0yMzMVFxenTz75RK+++qref/99q9ftKkfjO3z4sC677DINHjxYO3bs0D333KPbb7/d6vz6+noZDAa9+uqr+vzzz3X33Xfrzjvv1CuvvGLVb+PGjfryyy+Vm5urt956S9ddd51KSkr0ySefWPoUFhbq008/bfb/CAAAAIAXmMJQdXW1SZKpurq62bGjR4+aPv/8c9PRo0db+SwLTSaTGn0sbOX1HJsxY4Zp0qRJpgMHDpiioqJMX331lemrr74ydejQwVRZWWmaNGmSacaMGZb+8+bNM02YMMHy+OGHHzYNGDDAVF9fb/c5JJlee+21Zu1Hjx41STLl5OSYTCaTadasWabrr7/eqs+HH35oatOmjeno0aOmL7/80iTJlJuba/N5PvjgA5MkU1VVlclkMpmGDh1quueee1zqe/XVV5syMjKs+vz+9783DR482PL4tNNOM11zzTWWx/X19aYePXqYnnzySbuvfcaMGabIyEhTdHS0KTo62iTJ1KtXL9OOHTssfZ5++mlTXFyc6fDhw5a2t99+29SmTRtTRUWFyWQymdLT00233nqr1bWbfm+cje+pp54yde3a1er/6JNPPmmSZCosLLT7Gm666SbT5ZdfbvWaevbsaTp27JhVvwkTJpjmzZtneXzzzTebLrjgArvX9TfP/cwCAAAA3uMoDm2MmXSvyJe0tEnbUvliRr179+669NJLtXLlSq1YsUKXXnqpunXr1qzfnDlz9N5772nfvn2SpJUrV1qSo7nLZDJJOlmveufOnVq5cqU6d+5s+cjMzFR9fb3KyspUVFSkyMhIpaenu3T9W265RQ888IDGjBmjxYsXO0zWVlJSojFjxli1jRkzRqWlpaqrq7O0DRs2zPLviIgIxcfH68CBAw7HMXbsWBUVFamoqEgff/yxMjMzNWHCBH399deW5x4+fLiio6Otnru+vt6tWXpn4yspKdGwYcPUoUMHS5/Ro0c3u8bjjz+uUaNGqXv37urcubOefvpplZeXW/UZOnSo2rdvb9U2Z84c/eMf/9CPP/6o48eP68UXX2zRCgsAAAAA7iNI94pdbrZ71nXXXaeVK1dq1apVdoOrkSNHavjw4Vq9erV27Nihzz77rMXZ30tKSiRJCQkJkszLsW+44QZLQFtUVKSdO3eqtLRUAwcOVMeOHd26/uzZs7V3715NmzZNxcXFOvPMM/XYY4+1aKwN2rVrZ/U4IiJC9fX1Ds+Jjo7WoEGDNGjQIJ111ll69tlnVVtbq2eeecbl523Tpo3lpkaDn376ySPja+yll17S7bffrlmzZum9995TUVGRZs6c2Sw5XOMbCg0mTpyoqKgovfbaa1q3bp1++ukn/epXv3L5uQEAAAC0HEG6VyS52e5Z48eP1/Hjx/XTTz8pMzPTbr/Zs2dbZtzHjRunvn37tuj5Hn30UcXExGjcuHGSzAnsPv/8c0tA2/ijffv2Gjp0qOrr67V582aXn6Nv376aO3eu1q5dq9/97nd2A+Pk5GRt27bNqm3btm1KSkpSZGRki16fPREREWrTpo0lm35ycrJ27txplSBv27ZtatOmjU4//XRJ5pUO+/fvtxyvq6vTf//7X7eeNzk5WZ9++ql+/PFHS9v27dut+mzbtk1paWm68cYbNXLkSA0aNEh79uxx6fpt27bVjBkztGLFCq1YsUJXXXWV2zdWAAAAALQMQbpXpEpa2KQt+0S790VGRqqkpESff/65w8D06quvltFo1DPPPOPycubvv/9eFRUV+vrrr5Wbm6tf/epXevHFF/Xkk0+qS5cukqTs7Gzl5eVp/vz5KioqUmlpqd544w1LArX+/ftrxowZuu666/T666+rrKxMmzZtapbUrMFtt92mDRs2qKysTAUFBfrggw+UnJxss+/vfvc7bdy4Uffff7927dqlVatW6e9//3uzxGotcezYMVVUVKiiokIlJSW6+eabdfjwYU2cOFGSNHXqVHXo0EEzZszQf//7X33wwQe6+eabNW3aNPXs2VOSdOGFF+rtt9/W22+/rS+++ELz5s2zykzviquvvloRERGaM2eOPv/8c73zzjv685//bNUnMTFR//nPf7Rhwwbt2rVLd911l1UyOGdmz56tf//733r33XdZ6g4AAAD4UFt/DyB05UjKknmJe5J8FaA3iImJcdonNjZWl19+ud5++21NnjzZpes2ZPju0KGD+vTpo3PPPVcff/yxUlJSLH2GDRumzZs36//+7/903nnnyWQyaeDAgbryyistfZ588kndeeeduvHGG3Xo0CH169dPd955p83nrKur00033SSj0aiYmBiNHz9ef/nLX2z2TUlJ0SuvvKK7775b999/v3r16qX77ruvxUv5G3v33XfVq1cvSdIpp5yiM844Q6+++qouuOACSVKnTp20YcMG3XrrrTrrrLPUqVMnXX755XrkkUcs17juuuu0c+dOTZ8+XW3bttVvf/tbjR071q1xdO7cWevWrdPcuXM1cuRIDR48WDk5Obr88sstfW644QYVFhbqyiuvVEREhH7zm9/oxhtv1Pr16116jsTERKWlpel///ufUlN9+38XAAAACGcRpqYbZMNATU2NYmNjVV1d3SyY/fHHH1VWVqaEhASrxFyh6qKLLtKQIUP0t7/9zd9DQQAxmUxKTEzUjTfeqAULFvh7OA6F288sAAAAgpOjOLQxZtLDVFVVlTZt2qRNmzbpiSee8PdwEEAqKyv10ksvqaKigtroCCqF5VUqO1irhG7RGtkvzt/DAQAAaBGC9DA1cuRIVVVVKScnx5LUDJCkHj16qFu3bnr66acVF0egg+CwZH2Jlm3ea3k8N32AFk2wnbsCAAAgkBGkh6mvvvrK30NAgArDHTAIcoXlVVYBuiQt27xXmUPimVEHAABBh+zuAICgVnaw1q12AACAQEaQDgAIagndot1qBwAACGQE6QCAoDayX5zmpg+wapuXPoCl7gAAICixJx0AEPQWTUhW5pB4srsDAICgR5AOAAgJI/vFEZwjYFASEADQUgTpAAAAHkRJQABAa7AnPYxERETo9ddft3u8f//+evTRR302nkC1cuVKdenSxeN9Q9mmTZsUERGh77//3t9DAQC/slcSsLC8yk8jAgAEG4L0EFFZWal58+apX79+ioqKUnx8vDIzM7Vt2zZ/D80jvvrqK0VERFg+TjnlFA0ZMkQ33XSTSktLPfpcV155pXbt2uXxvq1xwQUXWL3+nj176oorrtDXX3/t9ecGALiOkoAAgNYiSA8Rl19+uQoLC7Vq1Srt2rVLb775pi644AIdOnTI30Ozcvz48Vad//7772v//v3auXOnHnzwQZWUlGj48OHauHGjh0YodezYUT169PB439aaM2eO9u/fr2+//VZvvPGGvvnmG11zzTU+eW5faO3/DQAIBJQEBAC0FkF6CPj+++/14YcfKicnR2PHjtVpp52ms88+W3fccYd++ctf2j1v8eLF6tWrlz799FO71509e7a6d++umJgYXXjhhdq5c6fl+J49ezRp0iT17NlTnTt31llnnaX333/f6hr9+/fX/fffr+nTpysmJkbXX3+9ZYn4hg0blJycrM6dO2v8+PHav3+/09fatWtXxcfHa8CAAZo0aZLef/99paamatasWaqrq7P0e+ONN5SSkqIOHTpowIABuvfee/Xzzz9bvbYbbrhBPXv2VIcOHfSLX/xCb731lqTmS9h37typsWPH6pRTTlFMTIxGjRql//znPzb7StKTTz6pgQMHqn379jr99NO1Zs0aq+MRERF69tlnNWXKFHXq1EmJiYl68803nb72Tp06KT4+Xr169dI555yj+fPnq6CgwKrP5s2bdfbZZysqKkq9evXSokWLrF63rS0NI0aM0D333OPW+N555x0lJSWpY8eOGjt2rL766iur44cOHdJvfvMb9enTR506ddLQoUP1j3/8w6rPBRdcoPnz5+u2225Tt27dlJmZqeuuu06XXXaZVb+ffvpJPXr00PLly51+jQDA3ygJCABoLYJ0LzIajdq5c6eMRqNXn6dz587q3LmzXn/9dR07dsxpf5PJpJtvvlmrV6/Whx9+qGHDhtnsd8UVV+jAgQNav369duzYoZSUFF100UX63//+J0k6fPiwLrnkEm3cuFGFhYUaP368Jk6cqPLycqvr/PnPf9bw4cNVWFiou+66S5J05MgR/fnPf9aaNWu0ZcsWlZeX6/bbb3f7tbdp00a33nqrvv76a+3YsUOS9OGHH2r69Om69dZb9fnnn+upp57SypUr9cc//lGSVF9frwkTJmjbtm16/vnn9fnnn2vJkiWKjIy0+RxTp06VwWDQJ598oh07dmjRokVq166dzb6vvfaabr31Vv3ud7/Tf//7X91www2aOXOmPvjgA6t+9957r37961/r008/1SWXXKKpU6davq6u+N///qdXXnlFqamplrZ9+/bpkksu0VlnnaWdO3fqySef1PLly/XAAw+4fF1XxvfNN98oKytLEydOVFFRkWbPnq1FixZZnf/jjz9q1KhRevvtt/Xf//5X119/vaZNm6aPP/7Yqt+qVavUvn17bdu2TcuWLdPs2bP17rvvWt2weeutt3TkyBFdeeWVbr8OAPCHRROS9dqNaXrk18P12o1pyiZpHADAHaYwVF1dbZJkqq6ubnbs6NGjps8//9x09OjRVj3He++9Z7rnnnssH++9916rrufMP//5T1NcXJypQ4cOprS0NNMdd9xh2rlzp1UfSaZXX33VdPXVV5uSk5NNRqPR6vhpp51m+stf/mIymUymDz/80BQTE2P68ccfrfoMHDjQ9NRTT9kdx5AhQ0yPPfaY1TUnT55s1WfFihUmSabdu3db2h5//HFTz5497V63rKzMJMlUWFjY7FhJSYlJkunll182mUwm00UXXWR68MEHrfqsWbPG1KtXL5PJZDJt2LDB1KZNG9OXX35p87lWrFhhio2NtTw+5ZRTTCtXrnSpb1pammnOnDlWfa644grTJZdcYnksyfSHP/zB8vjw4cMmSab169fbfA6TyWRKT083tWvXzhQdHW3q1KmTSZIpKSnJVFZWZulz5513mk4//XRTfX29pe3xxx83de7c2VRXV2cymay/xw2GDx9uWrx4scvju+OOO0yDBw+2ukZ2drZJkqmqqsrua7j00ktNv/vd76xe08iRI5v1Gzx4sCknJ8fyeOLEiaZrr73W7nU99TMLAAAAeJOjOLQxZtK9wGg0Ki8vz6otLy/PqzPql19+ub799lu9+eabGj9+vDZt2qSUlBStXLnSqt9vf/tb5efna8uWLerTp4/d6+3cuVOHDx9W165dLTP1nTt3VllZmfbs2SPJPJN+++23Kzk5WV26dFHnzp1VUlLSbCb9zDPPbHb9Tp06aeDAgZbHvXr10oEDB1r02k0mkyTzMu2Gsd93331W427Yz33kyBEVFRXJYDAoKSnJpesvWLBAs2fP1rhx47RkyRLL67elpKREY8aMsWobM2aMSkpKrNoar16Ijo5WTEyM09c/depUFRUVaefOndq6dasGDRqkiy++WD/88IPluUePHm35OjQ89+HDh93+v+dofCUlJVYz+JI0evRoq8d1dXW6//77NXToUJ166qnq3LmzNmzY0Oz/xqhRo5o99+zZs7VixQpJ0nfffaf169fruuuuc2v8AAAAQLAiSPcCe8navJ3ErUOHDsrIyNBdd92lvLw8XXvttVq8eLFVn4yMDO3bt08bNmxweK3Dhw+rV69eKioqsvr48ssv9fvf/16SdPvtt+u1117Tgw8+qA8//FBFRUUaOnRoswRg0dHNk+U0XS4eERFhCbbd1RAAJyQkWMZ+7733Wo27uLhYpaWl6tChgzp27OjW9e+55x599tlnuvTSS/Xvf/9bgwcP1muvvdaisTaw9frr6+sdnhMbG6tBgwZp0KBBGjNmjJYvX67S0lK9/PLLLj9vmzZtmn2df/rpJ4+Mr7E//elP+utf/6rs7Gx98MEHKioqUmZmpkv/N6ZPn669e/fqo48+0vPPP6+EhASdd955Lj83AAAAEMza+nsAoahr165utXvL4MGDm9VF/+Uvf6mJEyfq6quvVmRkpK666iqb56akpKiiokJt27ZV//79bfbZtm2brr32Wk2ZMkWSOThumkDM2+rr6/W3v/1NCQkJGjlypCTz2L/88ksNGjTI5jnDhg2T0WjUrl27XJ5NT0pKUlJSkn7729/qN7/5jVasWGF53Y0lJydr27ZtmjFjhqVt27ZtGjx4cAtenWMNe+iPHj1qee5//etfMplMltn0bdu26ZRTTpHBYJAkde/e3Wq/d01NjcrKytx63uTk5GaJ5LZv3271eNu2bZo0aZIl+3x9fb127drl0teha9eumjx5slasWKGPPvpIM2fOdGt8AAAAQDBjJt0LDAaD0tLSrNrGjBljCZQ87dChQ7rwwgv1/PPP69NPP1VZWZleffVVLV26VJMmTWrWf8qUKVqzZo1mzpypf/7znzavOW7cOI0ePVqTJ0/We++9p6+++kp5eXn6v//7P0tm88TERK1du9ayBPvqq692a7a1pa+1oqJCe/fu1Ztvvqlx48bp448/1vLlyy1B6913363Vq1fr3nvv1WeffaaSkhK99NJL+sMf/iBJSk9P1/nnn6/LL79cubm5Kisr0/r16/Xuu+82e76jR49q/vz52rRpk77++mtt27ZNn3zyiZKTbScB+v3vf6+VK1fqySefVGlpqR555BGtXbu2RUnxmjpy5IgqKipUUVGhnTt3at68eerQoYMuvvhiSdKNN96ob775RjfffLO++OILvfHGG1q8eLEWLFigNm3MP+oXXnih1qxZow8//FDFxcWaMWOG3YR59sydO1elpaX6/e9/ry+//FIvvvhis20ViYmJys3NVV5enkpKSnTDDTfou+++c/k5Zs+erVWrVqmkpMTqhgcAAAAQ6phJ95KMjAwlJyfr0KFD6tq1q9cCdMmc3T01NVV/+ctftGfPHv3000/q27ev5syZozvvvNPmOb/61a9UX1+vadOmqU2bNsrKyrI6HhERoXfeeUf/93//p5kzZ6qyslLx8fE6//zz1bNnT0nSI488ouuuu05paWnq1q2bsrOzVVNT47XXKZlvHkjmPe2nnXaaxo4dq6efftpq1jwzM1NvvfWW7rvvPuXk5Khdu3Y644wzNHv2bEuff/3rX7r99tv1m9/8RrW1tRo0aJCWLFnS7PkiIyN16NAhTZ8+Xd999526deumrKws3XvvvTbHN3nyZP31r3/Vn//8Z916661KSEjQihUrdMEFF7T6tT/zzDN65plnJElxcXEaNmyY3nnnHZ1++umSpD59+uidd97R73//ew0fPlynnnqqZs2aZbk5IUl33HGHysrKdNlllyk2Nlb333+/2zPp/fr107/+9S/99re/1WOPPaazzz5bDz74oNW+8T/84Q/au3evMjMz1alTJ11//fWaPHmyqqurXXqOcePGqVevXhoyZIh69+7t1vgAAACAYBZhaulG4CBWU1Oj2NhYVVdXKyYmxurYjz/+qLKyMiUkJKhDhw5+GiEQ3g4fPqw+ffpoxYoVzW4gNcXPLAAAAIKBozi0MWbSAQSM+vp6HTx4UA8//LC6dOmiX/7yl/4eEgAAAOBTBOkAAkZ5ebkSEhJkMBi0cuVKtW3LrygAAACEF94BAwgY/fv3b3EpPgAAACAUkN0dAAAAAIAAQZAOAAAAAECAIEgHAAAAACBAEKQDAAAAABAgCNIBAAAAAAgQBOkAAAAAAAQIgnS4ZNOmTYqIiND333/vsF///v316KOP+mRMAAAAABBqvBqkb9myRRMnTlTv3r0VERGh119/3ek5mzZtUkpKiqKiojRo0CCtXLmyWZ/HH39c/fv3V4cOHZSamqqPP/7Y84OHlbS0NO3fv1+xsbGSpJUrV6pLly7N+n3yySe6/vrrfTw6AAAAAAgNXg3Sa2trNXz4cD3++OMu9S8rK9Oll16qsWPHqqioSLfddptmz56tDRs2WPq8/PLLWrBggRYvXqyCggINHz5cmZmZOnDggLdeBiS1b99e8fHxioiIcNive/fu6tSpk49GBQAAAAChxatB+oQJE/TAAw9oypQpLvVftmyZEhIS9PDDDys5OVnz58/Xr371K/3lL3+x9HnkkUc0Z84czZw5U4MHD9ayZcvUqVMnPffcc956GUHjggsu0Pz58zV//nzFxsaqW7duuuuuu2QymSRJVVVVmj59uuLi4tSpUydNmDBBpaWllvO//vprTZw4UXFxcYqOjtaQIUP0zjvvSLJe7r5p0ybNnDlT1dXVioiIUEREhO655x5J1svdr776al155ZVWY/zpp5/UrVs3rV69WpJUX1+vhx56SAkJCerYsaOGDx+uf/7zn17+SqGxI8d+VlXtcR059rO/hwKEhMLyKq0tMKqwvMrfQwEAAEGorb8H0NhHH32kcePGWbVlZmbqtttukyQdP35cO3bs0B133GE53qZNG40bN04fffSRL4fqmvx8adcuKSlJSk31yVOuWrVKs2bN0scff6z//Oc/uv7669WvXz/NmTNH1157rUpLS/Xmm28qJiZG2dnZuuSSS/T555+rXbt2uummm3T8+HFt2bJF0dHR+vzzz9W5c+dmz5GWlqZHH31Ud999t7788ktJstlv6tSpuuKKK3T48GHL8Q0bNujIkSOWGzcPPfSQnn/+eS1btkyJiYnasmWLrrnmGnXv3l3p6ele/EpBkvZXH1XlD8csj7ufEqVesR39OCIguC1ZX6Jlm/daHs9NH6BFE5L9OCIAABBsAipIr6ioUM+ePa3aevbsqZqaGh09elRVVVWqq6uz2eeLL76we91jx47p2LGTgUhNTY1nB25Ldra0dOnJxwsXSjk5Xn/avn376i9/+YsiIiJ0+umnq7i4WH/5y190wQUX6M0339S2bduUlpYmSXrhhRfUt29fvf7667riiitUXl6uyy+/XEOHDpUkDRgwwOZztG/fXrGxsYqIiFB8fLzdsWRmZio6Olqvvfaapk2bJkl68cUX9ctf/lKnnHKKjh07pgcffFDvv/++Ro8ebXnOrVu36qmnniJI97Ijx362CtAlqfKHY4rt0E6dogLqVwPCXGF5lcoO1iqhW7RG9ovz93DsKiyvsgrQJWnZ5r3KHBIf0OMGAACBJSyyuz/00EOKjY21fPTt29e7T5ifbx2gS+bH+fnefV5J55xzjtW+8dGjR6u0tFSff/652rZtq9RGM/pdu3bV6aefrpKSEknSLbfcogceeEBjxozR4sWL9emnn7ZqLG3bttWvf/1rvfDCC5LMOQreeOMNTZ06VZK0e/duHTlyRBkZGercubPlY/Xq1dqzZ0+rnhvOHfu53q12wB+WrC/RlCfytOCVnZryRJ6WrC/x95DsKjtY61Y7AACALQEVpMfHx+u7776zavvuu+8UExOjjh07qlu3boqMjLTZx9GM7h133KHq6mrLxzfffOOV8Vvs2uVee4CYPXu29u7dq2nTpqm4uFhnnnmmHnvssVZdc+rUqdq4caMOHDig119/XR07dtT48eMlSYcPH5Ykvf322yoqKrJ8fP755+xL94GotrZ//O21A75mb2Y6UPd6J3SLdqsdAADAloB6Nz569Ght3LjRqi03N9eyFLp9+/YaNWqUVZ/6+npt3LjR0seWqKgoxcTEWH14VVKSe+0elN9ktn779u1KTEzU4MGD9fPPP1sdP3TokL788ksNHjzY0ta3b1/NnTtXa9eu1e9+9zs988wzNp+nffv2qqurczqetLQ09e3bVy+//LJeeOEFXXHFFWrXrp0kafDgwYqKilJ5ebkGDRpk9eH11Q5Qp6i26n5KlFVb91OiWOqOgBFsM9Mj+8Vpbrr1NqF56QNY6g4AANzi1Xfjhw8f1u7duy2Py8rKVFRUpFNPPVX9+vXTHXfcoX379lkyfc+dO1d///vftXDhQl133XX697//rVdeeUVvv/225RoLFizQjBkzdOaZZ+rss8/Wo48+qtraWs2cOdObL8U9qanmPeiNl7xnZ/skeVx5ebkWLFigG264QQUFBXrsscf08MMPKzExUZMmTdKcOXP01FNP6ZRTTtGiRYvUp08fTZo0SZJ02223acKECUpKSlJVVZU++OADJSfbTnjUv39/HT58WBs3btTw4cPVqVMnu6XXrr76ai1btky7du3SBx98YGk/5ZRTdPvtt+u3v/2t6uvrde6556q6ulrbtm1TTEyMZsyY4fkvEKz0iu2o2A7tdOznekW1bUOAjoASjDPTiyYkK3NIfFDsoQcAAIHJq+/I//Of/2js2LGWxwsWLJAkzZgxQytXrtT+/ftVXl5uOZ6QkKC3335bv/3tb/XXv/5VBoNBzz77rDIzMy19rrzySlVWVuruu+9WRUWFRowYoXfffbdZMjm/y8mRsrJ8nt19+vTpOnr0qM4++2xFRkbq1ltv1fXXXy9JWrFihW699VZddtllOn78uM4//3y98847lpnturo63XTTTTIajYqJidH48eOtyt81lpaWprlz5+rKK6/UoUOHtHjxYksZtqamTp2qP/7xjzrttNM0ZswYq2P333+/unfvroceekh79+5Vly5dlJKSojvvvNNzXxQ41CmqrTpFOe8H+FrDzHTjJe/BMDM9sl9cwI8RAAAErghTQxHtMFJTU6PY2FhVV1c3W/r+448/qqysTAkJCerQoYOfRtgyF1xwgUaMGGGpUw6Eg2D+mYVrgiW7OwAAgCOO4tDGWNsKAAhozEwDAIBwElCJ4wAAAAAACGfMpIeQTZs2+XsIAFoiP9/n+SsAAAAQmJhJBwB/ys6WzjlHmj7d/Dk7298jAgAAgB8RpAOAv+TnW5dqlMyP8/P9Mx4AAAD4HUE6APjLrl3utQMAACDkEaQDgL8kJbnXDgAAgJBHkA4A/pKaKi1caN2WnU3yOAAAgDBGdncA8KecHCkri+zuAAAAkMRMOnzknnvu0YgRI/w9DCAwpaZK06YRoAMAAIAgHZ4XERGh119/3art9ttv18aNG/0zIAAAAAAIEix3h0907txZnTt39vcwAABBprC8SmUHa5XQLVoj+8X5ezgAAHgdM+kh5IILLtAtt9yihQsX6tRTT1V8fLzuuecey/Hvv/9es2fPVvfu3RUTE6MLL7xQO3futLrGAw88oB49euiUU07R7NmztWjRIqtl6p988okyMjLUrVs3xcbGKj09XQUFBZbj/fv3lyRNmTJFERERlseNl7u/99576tChg77//nur57711lt14YUXWh5v3bpV5513njp27Ki+ffvqlltuUW1tbau/TgCA4LBkfYmmPJGnBa/s1JQn8rRkfYm/hwQAgNcRpHtRYXmV1hYYVVhe5bPnXLVqlaKjo5Wfn6+lS5fqvvvuU25uriTpiiuu0IEDB7R+/Xrt2LFDKSkpuuiii/S///1PkvTCCy/oj3/8o3JycrRjxw7169dPTz75pNX1f/jhB82YMUNbt27V9u3blZiYqEsuuUQ//PCDJHMQL0krVqzQ/v37LY8bu+iii9SlSxf961//srTV1dXp5Zdf1tSpUyVJe/bs0fjx43X55Zfr008/1csvv6ytW7dq/vz5nv+iAQACTmF5lZZt3mvVtmzzXp/+TQUAwB9Y7u4lS9aXWL25mJs+QIsmJHv9eYcNG6bFixdLkhITE/X3v/9dGzduVMeOHfXxxx/rwIEDioqKkiT9+c9/1uuvv65//vOfuv766/XYY49p1qxZmjlzpiTp7rvv1nvvvafDhw9brt94pluSnn76aXXp0kWbN2/WZZddpu7du0uSunTpovj4eJtjjIyM1FVXXaUXX3xRs2bNkiRt3LhR33//vS6//HJJ0kMPPaSpU6fqtttus7yWv/3tb0pPT9eTTz6pDh06eOgrBgAIRGUHba+cKjtYy7J3AEBIYybdC/x593/YsGFWj3v16qUDBw5o586dOnz4sLp27WrZH965c2eVlZVpz549kqQvv/xSZ599ttX5TR9/9913mjNnjhITExUbG6uYmBgdPnxY5eXlbo1z6tSp2rRpk7799ltJ5ln8Sy+9VF26dJEk7dy5UytXrrQaa2Zmpurr61VWVubWcyE0HTn2s6pqj+vo8Z/9PRTAr/yxassXErpFu9UOAECoYCbdC/x5979du3ZWjyMiIlRfX6/Dhw+rV69e2rRpU7NzGgJjV8yYMUOHDh3SX//6V5122mmKiorS6NGjdfz4cbfGedZZZ2ngwIF66aWXNG/ePL322mtauXKl5fjhw4d1ww036JZbbml2br9+/dx6LoSe/dVHVfnDMUmS6efjOnr0Jz+PCPAPf63a8oWR/eI0N32A1eublz6AWXQAQMgjSPeCQLz7n5KSooqKCrVt29aSzK2p008/XZ988ommT59uaWu6p3zbtm164okndMkll0iSvvnmGx08eNCqT7t27VRXV+d0TFOnTtULL7wgg8GgNm3a6NJLL7Ua7+eff65Bgwa5+hIRJo4c+9kSoDf44cef9fm31UoZwDYIhA97q7Yyh8SHTCC7aEKyMofEk90dABBWWO7uBQ13/xvz993/cePGafTo0Zo8ebLee+89ffXVV8rLy9P//d//6T//+Y8k6eabb9by5cu1atUqlZaW6oEHHtCnn36qiIgIy3USExO1Zs0alZSUKD8/X1OnTlXHjh2tnqt///7auHGjKioqVFVlf/nl1KlTVVBQoD/+8Y/61a9+ZdkrL0nZ2dnKy8vT/PnzVVRUpNLSUr3xxhskjoOO/Vxvs91YddTHIwH8y9GqrVAysl+cslIMBOgAgLBBkO4liyYk67Ub0/TIr4frtRvTlO3n5YcRERF65513dP7552vmzJlKSkrSVVddpa+//lo9e/aUZA6a77jjDt1+++1KSUlRWVmZrr32WqskbcuXL1dVVZVSUlI0bdo03XLLLerRo4fVcz388MPKzc1V3759NXLkSLtjGjRokM4++2x9+umnlqzuDYYNG6bNmzdr165dOu+88zRy5Ejdfffd6t27twe/KqGtYc/2kWOhtWc7qq3tX1uGuI4224FQFYirtgAAQOtFmEwmk78H4Ws1NTWKjY1VdXW1YmJirI79+OOPKisrU0JCAhnEJWVkZCg+Pl5r1qzx91DghsZ7tiWp+ylR6hUbOkFssz3p/6vQiMFJ/Mwi7DTdkz4vfYDfbwoDAADbHMWhjbEnHRZHjhzRsmXLlJmZqcjISP3jH//Q+++/b6mzjuBga8925Q/HFNuhnTpFhcaPfK/Yjort0M689L2urSqOtnN+EhCC2LMNAEDoCY137PCIhiXxf/zjH/Xjjz/q9NNP17/+9S+NGzfO30ODG+zt2T72c706Rdk8FJQ6RbVVpyjpxx9tv14gXIzsF0dwDgBACCFIh0XHjh31/vvv+3sYaCV7e7bttQMAAAAIHLxrB0JMp6i26n6K9ZR591OiQmapOwAAaK6wvEprC4wqLLdfWQdAcOBdux1hmE8PIaTxnu2otm1COkDnZxUAEO6aJpGcmz5Ai0giCQQtZtKbaNfOnIDqyJEjfh4J0DqdotoqLrp9SAfo0smf1YafXQAAwklheZVVgC5JyzbvZUYdCGKh/e69BSIjI9WlSxcdOHBAktSpUydFRET4eVQAmjKZTDpy5IgOHDigLl26KDIy0t9DAgDA58oO1tptJ6kkEJwI0m2Ij4+XJEugDiBwdenSxfIzC3vyJa0/8e++ktpLSpKU6qPn3iXp+Innbfjsq+cHgNCW0C3arXYAgY8g3YaIiAj16tVLPXr00E8//eTv4QCwo127dmE0g94Q7Lob3GZLWmrn2EJJOa0cV0ufu6XP39KvAwCEppH94jQ3fYDVkvd56QOYRQeCWIQpDLMu1dTUKDY2VtXV1YqJifH3cACELVcDzqbBrqvBbb6kc5z02e7kuVvKled29/nd/To0XkEwwY3nAYDgU1hepbKDtUroFk2ADgQoV+NQEscBgF9kyxzETj/xOdtOv3w1n41eeqLdmV0e6tMSrl7X1X7ufh0avr73nvhw9DUGgOA3sl+cslIMBOhACCBIBwCfcyfgtBfEuhLcJnmoT0u4el1X+7nzdbD19ZVcv7kBAADgPwTpANBq+ZLWyPUA0J2A014Q60pwmyrzknB7suW9JeDOntvd53fn6+DoBkZLVw64+z0GAABoGRLHAUCrtGS/uDsBZ0Ow2/g53AlucyRlyT/Z3Rue2xPZ3d35Oji6gdGSlQMtzQkAAADgPhLHkTgOgE2uJHWzlxzNlWRoTQO/bElLWjmecNDSZHsNbY6+xvaer6Xf44bz+b4BAADX41Bm0gGgWSDl6sypo2XrzgKyxrPMrgRwqS70CQeufh2ariBoaXb31nyPHf0/IngHAAC2EaQDCDPOAvJrJD3f5JylMgd8TYOp1uwXlwi8vc0TX9+Wfo/tJQfMkrRWjm8CEcADABDOSBwHIIw0LXs2Tc0DqaYBegNbM6q2kqN5MxkbfK+l32N7M/Dr5Tizv6ul+QAAQKhiJh1AiLE3C2lrZtNeQG6LvZlTd5etI/i05HvsboK6hqDe3uy7o7wI/N8DACCUMJMOIIQ4moV0p/TWNBvXdRQApZ44hyApdLn7PbY3Az/BTv8kuVear+F6zLoDABBqCNIBhAh7e4AblhHbm9m0FZCvljl7d8NndzOCA5J5Br7p/yNHy+fd2f/u7P+7LdR6BwAgGLDcHUAQcGVJr7Ms3PbqbC+RdJON65PUzRaj0ajS0lJJspQQafh3ZGSk6urqrNp8eTxwxzLsRN8PTrRdqerqoZIOKTa2jyIjE1VXV6Dq6iOS7lRs7DuKjKxX166HZDBcI9v/D93NOm8v0zzL5QEACDQE6QACVEPwkCvz7F8De+XQXJmFtLe3OLQDck8F1nv37pXRaPTPiwhZ30v6rNHj9pImWx4NHDhQQ4futPE9ipCUrtjYakVG1quuro2qq2MlRSg2tqBJ388l5SsxsY8Mhn0nrrxU0n7Z/tkicIdZYXmVyg7WKqFbtEb2i/P3cAAgbESYTCaTvwfha64WkQfga/YC86a2y7XZwoaZ8uBnNBp16NChZsGasyC7pKREu3fv9tu4EVgGDfpSycklJwJ6KTa22urfkZGjVVf3UaO2NFVXD5Z0SImJZ8hgyPTX0OFjS9aXaNnmvZbHc9MHaNGEZD+OCACCn6txKEE6QToQIJoG2I6sVvO95A2CZxbQ1cB737592rNnjz+HGhb6GI3qeuiQDnXtqn0Gg7+HE5AGDfpZyclTTszOm5frV1d3lWR7FUbXrl1l4GsZdArLqzTlibxm7a/dmMaMOgC0gqtxKMvdAQQAW0mwHHFU3iowlq47W2JeXFxM4B1ALsrN1bnbtlkebx0zRhszMvw4osC0e3db7d69rlHL907PMRgMGjBggNOtFomJiQT0AaLsYK3ddoJ0APA+gnQAAcCd8mjOyqH5hqMgnCXmwaWP0WgVoEvSudu26YvkZGbUPcBoNLqUy2DLli1WAb2trRzMzvtGQrdot9oBAJ5FkA4gADiaGZfMS9szFChL2HNzc5WX13wpKJrr27evEhISAjq7e8/33rM59nH9+qns3HM9OhaS7znmakCflpamDFY6eM3IfnGamz7Aak/6vPQBzKIDgI+wJ5096YCXubpHvOmedP8G5vZmyuvr67V161afj8fbGgfTngqMg2b5cn6+dM45zdu3b5dSPf9/r+n/LU/evAinmwDnn3++3f+PQfN/L8CR3R0APIvEcQ4QpAO+Yq82sz2+S/rmKFAKxkCnpUF2q5YP5+dLu3ZJSUleCWZ9KjtbWrrU+vGS4KwM0JqSe6G0VcPR0nmCeACAPxCkO0CQDvhCviQbs5N2y6d5XuPs6cEYhNsLvANij27ToHbhQinH0Q2YIBBKNx1awbUg3zq7+969H8hojPTjqN1HEA8A8DWCdAcI0gFPsjf7vUbSdBv9HZVPa53GwUWgli0bNGiQfvGLX3hvdtsXfLw8HMHBaNyg0tIvJHVVbOxgRUb+U3V165vVZN+7d4CMxtP8O1gXEMQDADyNEmwAfMDRcnZ7yeCcJYlzzF5t8UBapmtrr2zAB97u2GUnG/+uXQTpYcxgyJTBkNmoJUXSJJlv4h2XNFuSNHbsZhmNfXToUFfV1d1lt856dXW1tmzZ4suXYMVREjt7mehD6uccAOA3BOkAWshWbfOlkrJ0slb5wiZ93Cuf1nS5ejDUFh8zZozGjh3r72F4V5KdGy322hHGGn4XSOZg3fz7wGDYJ4PhGkm/cnBuvn7+eavy8s717hBbyFEQP3DgQPXp00dSCN6kAwB4HUE6gBayV9t8l06+Kc+ROWh3LRlcMC9XD6s34amp5j3oTROtMYsOh9z7fSDtUkbG+0pOLjkx697Gaul8ZGS9pW3v3skyGqu9O3w37Nmzx+bvr4EDB2ro0KEsnQcAOMSedPakAy3UusRwTZetB0oyN0dZ0l0OwsMlAVm4vM4wEzhlt+z9jrFltYzGsSdu8r2v2Nh3GgX0aSopGaKPdu1XdX2UYtscU/c2td4adIs0XTofNjf8ACDMkDjOAYJ0wBF3yqA13ZOeLal52apADMgHDRqk3r17S/LwTHgoZj1H2FiyvkTLNu+1PJ6bPkCLJiT7cURNf8dMkzkpZVMNNwdtB/ZL1r+vZZt/tDyefPpPmtT/azUkuQuknBYNGgfuzLoDQGggSHeAIB2wx9265pK9oL4hMPfnPvLGs+I+SexE1nMEscLyKk15Iq9Z+2s3pgXAjHrj3zGObg42rypRWJ6kKU880uyqr924QCP77VLD7zlHpecCKYgfNGiQkpOTCdwBIAiR3R2Am5wlgrMn9USm5kOqqyvwy0y5rX3ifnnjStZzBLGyg7aXgJcdrPVzkN44+ZzkeG978+SFZQf72Lxq2cE+J4J08+85gyG10e+MfEnGE9dLUUpKis0g3h+rgnbv3m11w8BWpnmWywNAcCNIB8JW09kpVxLBneSvmfKms+MB9WaUrOcIYgndot1q96+mgXvjduuqEgndLrJ5hYRu+xo9avx7zvaKIoPB0Ox3zdixY22WhfR14ktbmeYJ3AEgeBGkA2HJ1pvQLDt9TwaYDTNJvpo9CuiA3BayniOIjewXp7npA6z2pM9LH+DnWfSWsJ5pH9kvVXPTS5q8rldPzKI3aPg95+qKopM3Oa1n4E+yFbz7cum8rcC9cWk4lskDQOBiTzp70hF2HGVlX6uGN6jmJewzVFd3uc+WdTZO5hbUbyDJeo4gFjjZ3T3r5OtaqZH97mp0xPGedrPVMieta+jfOJC/RtLFci3ZplmglJtkfzsA+BaJ4xwgSEd4s/8m1FzCaJP27jXKaDzm1VE03kceFLPkAEKIvSoWzkpLOisL50qyzeYaz7o3JLn01573hmXyoRKwh+pNJwDBKaCC9Mcff1x/+tOfVFFRoeHDh+uxxx7T2WefbbPvBRdcoM2bNzdrv+SSS/T2229Lkq699lqtWrXK6nhmZqbeffddl8ZDkI7wZvtNZm7uKuXllXn1mRsCcwJyAIHLvezxzTUE9J7RNGGdLzPNp6WlKSMjwyfP5Q2BV1IQQLgLmOzuL7/8shYsWKBly5YpNTVVjz76qDIzM/Xll1+qR48ezfqvXbtWx48ftzw+dOiQhg8friuuuMKq3/jx47VixQrL46ioKO+9CCCkWCdWMhr7aMeOmSoq8myAzkw5gODkXvb45pom27Q3a++apgnrmmaa9+Zy+by8PLVp00Zt2rSRFFzL4QvLq6wCdElatnmvMofEM6MOIOB5PUh/5JFHNGfOHM2cOVOStGzZMr399tt67rnntGjRomb9Tz31VKvHL730kjp16tQsSI+KilJ8fLz3Bg6EtBwZjRdq8+ad2r37qMeuykw5gNDgevb45hoH8q3fv25L08C96XJ5T1bd2Lp1q+Xfjcu9BXrAHrglBQHAOa8G6cePH9eOHTt0xx13WNratGmjcePG6aOPPnLpGsuXL9dVV12l6GjrEjCbNm1Sjx49FBcXpwsvvFAPPPCAunbtavMax44d07FjJ/fX1tTUtODVAMHA8YyNp8umJSYm6owzzmCmHEAYaTzTnivzEvgG2Tr5u9dWpvjnT3xILd2/bkvToH348OHNsst7an97Q9b4LVu2BHTiueAqKQgA1ry6J/3bb79Vnz59lJeXp9GjR1vaFy5cqM2bNys/P9/h+R9//LFSU1OVn59vtYe9YXY9ISFBe/bs0Z133qnOnTvro48+UmRkZLPr3HPPPbr33nubtbMnHaEjX9L9kt5u1GZ+A+jpsmkNZdEC6c0YAPiPvZujvt+/7owv9rcH0kx70z3p89IHKJs96QD8KCASx7U2SL/hhhv00Ucf6dNPP3XYb+/evRo4cKDef/99XXTRRc2O25pJ79u3L0E6QsR0Wc/kmPeZl5YO0t69k2U0Vrfq6ueee25Q7kcEAP9ylglesi7tZuv8lu9ld1VD4F5TU6OioiKPXrthpt2fq63I7g4gkARE4rhu3bopMjJS3333nVX7d99953Q/eW1trV566SXdd999Tp9nwIAB6tatm3bv3m0zSI+KiiKxHEJQvqQFkvIsLUZjH23efL527z79REvrAvQxY8bY/JkCADjj7v71xryzl92WxkvlO3XqpLy8PCdnuG737t1WM/UDBw5Unz59JPnupu/IfnEE5wCCjleD9Pbt22vUqFHauHGjJk+eLEmqr6/Xxo0bNX/+fIfnvvrqqzp27JiuueYap8/TsO+qV69enhg2EAROzp6fnDUfIKPxtFZfuUePHjrjjDOYNQeAVnN1/3pjvtvL3lRGRoaSk5Mte9k9vRx+z549lnwowZSEDgB8zet10l9++WXNmDFDTz31lM4++2w9+uijeuWVV/TFF1+oZ8+emj59uvr06aOHHnrI6rzzzjtPffr00UsvvWTVfvjwYd177726/PLLFR8frz179mjhwoX64YcfVFxc7NKMOXXSEbxOzp43nzVvvWHDhmnKlCkeux4AoDFXlrAH1l52X5V7C4Sl8YGI5fpAaAmI5e6SdOWVV6qyslJ33323KioqNGLECL377rvq2bOnJKm8vNyy37XBl19+qa1bt+q9995rdr3IyEh9+umnWrVqlb7//nv17t1bF198se6//36WtCOEmRPDGY1FOnSoq4qLr9aePa7U63WOsmkA4Cv2Srs11pJa7N7jqNybJ2fabS2NHzp0aFj/bWqa+G5u+gAtIvEdEBa8PpMeiJhJR3CZLqPx3x6bNadsGgAEuqZ70pvybVZ4R3wx0z506FBlZWV5/LqBrLC8SlOeaJ4f4LUb05hRB4JYwMykA2gp89L2tWt7qLh4TquuxD5zAAgmLdnL7h++mGkvLi5WVVWVRo4cGTY3mMsO1tptJ0gHQh9BOhCAjMY5Ki0tVUnJUFVWti4hIvvMASAYNSyNnybpJvmiHJsnNA7aU1JSLDPte/fuldFobPF1jUaj1fmhvhw+oVu0W+0AQgvL3VnujgBiNBq1efPftHt3y/8I9+3bVyNGjAib2QYAQHDwVMDeVKgG7E33pM9LH6Bs9qQDQc3VOJQgnSAdAWLt2rUqLi5WZX20quujFNvmmLq3sb3czZ5QmDUnky0AhD5vBeyhVtaNv4lAaCFId4AgHYHEaDRqw4YNMhqN+uR4H/237uTy9l9E7tdZ7fc5PD+UsrOTyRYAwk/DPvbi4mKPJp4bNGiQ0tPTg/5vI4DQQZDuAEE6AkVubq7y8szZWyvro/XWseYB6WVRJTZn1BMTE3X++eeHzJsPMtkGuPx8adcuKSlJSg3sPbFhge8HQpQ3Ava0tDRlZGR45FoA0BpkdwcCXEFBgSVAl6Tq+iib/arro6yC9FALzhuQyTaAZWdLSxuVg1q4UMrJ8d94wh3fD4SwhsRzw4cP91im+Ly8PLVt2zZklsADCH3MpDOTDj9o2H/emKOZ9CHx0SFfQo2ZdC9p7Yxrfr50zjnN27dvZwbXH/h+hA9WSzTTsI+9pKRElZWVLboGS+AB+BMz6UCAcfbmonubWv0icr/VnvShkft10YiBQZ8MzhUj+8VpbvqAZplsCdBbwRMzrrt22W8ncPA9vh/hgdUSNjXMso8dO9bmzW5X7N69W7t37w7ZjPAAQgMz6cykw8vMZdU2u7xMryG7e0K3aF1/+cVh9+aBTLYe4qkZV2ZuAwvfj9AX1N/jfPmynrunlsMPHTpUWVlZHh4dADTHTDqCSigGZu4G5w26t6lV9za1mnX5lLAL0CXzjHqo/B/wK0/NuKammmfxGs/qZWf7P1gI16XAgfr9gOcE7WqJbEmN/l/qGkkXy5sBe8PMuiSlpKTIaDRqx44dKioqcus6xcXFqqioUHJyckhvKwMQPJhJZybd70Kx7FbjrO0tMWbMGI0bN86DI0LY8fRsXCAFxSwFDqzvBzwrKGfS8yXZGLPFQkm++xlt6VL4BuxbB+AtlGBzgCA9cIRisjCj0ajly5e36NxQzdwOP2kazGZnS0uW+G88nhCUAQzgpqD72V0jabqTPtvliyXwDVobqEvmmfoBAwYwuw7AY1jujqAQamW3jEaj1q5d6/Z5BOfwipwcKSsrtGZcg3YpMOCGoPvZTXKhzy75MkjPysrS2WefbdmzXlhYKKPR6NY1jEajjEajtmzZwuw6AJ8iSIdfJXSLdqs9kLl7175HjzqdccZY7tDDu1JTg+ANvhuS7AQD9tqBYBVUP7upMi9pX+qgT5KDbRreSTjXdM96a2bXG7LCk2QOgC+w3J3l7n7XdE/6vPQByg6iPelGo1EbNmxw6w79sGG9NGXK9V4cFRDCgm4pMBAuGoLtXJmXwDfIlrJNdnJJNE0459396w0Z4YuLi7Vnz54WXcNgMCgzM5Mb7ADcxp50BwjSA08wZndvSfZ2lrUDHkLiNCDANZodz5edXBLPSqmzbZzrm/3rLa3C0oA966EpGN+TIngQpDtAkI7WasmSuYkThygl5VdeGhEAAAFqzRppuo3EcqtvkKY9ZeOE1ZKmNXrs3frrRqNRpaWl2rt3r9v71huwZz00hGLFIQQWV+PQNj4cExASWhKgDxv2MwE6ACA82c0lcZa9Exr9O1vm8m7TT3zO9uTIJJlnxMeOHatZs2Zp1qxZLQq0d+/ereXLl7coeSwCQ2F5lVWALknLNu9VYXmVn0aEcEaQDrihoKCgBQF6L02Zcr+XRgQAQIBLTTXvQW8sO1tKnSXzHnSrAzo5W56v5snolp5oz5d533u+R4dqMBg0a9YsDR06tEXnFxcXa/ny5S2ekYf/OKo4BPgay91Z7g4XuTuD3rdve1188TSWvgEAILUgu7u9+uuXSnq70WPvJJtrbZI5lsAHl8LyKk15Iq9Z+2s3prE3HR7DnnQHCNLhjpZlby/SlCmL5MuasIBXkagNgM/ly7zE3RXbT3z2zt711iSZo2xb8Aj2ikMIfATpDhCkw1W5ubnKy2t+V9WexMQvdf75W2QwXCOJklAIEU1LnllKJwGAtzUt0dZ0Ft1eu/dm1929cS8RqAcTsrvDmwjSHSBIhyuMRqOWL1/ucv+JE01KSRkob2WfBfwiP99O6aTtzKgD8JHGy+El92bXvfN7qiVJZEeMGKFRo0YF5PJ3AlPAN1yNQ9v6cExAUCktLXW577BhRUpJYXk7QtCuXfbbCdIB+ESqrP++LpRrs+vr5a3l71lZWTr77LPd2rNeVFSkoqKigNurTtkxIPAwk85MOmxw5w65ef/56QqJ5e3sO0ZTzKQDCEjuzq57Z/l7g5bsWQ+EYJ1kaYBvUScdaCFXA/S4uIOaNct0IkFcCATo2dnmYGz6dPPnbM/XokUQsls6iQAdgD+lSpqmk7PsTUu5NeX90m1Tp07VrFmz1KNHD5fOCYTa6pQdAwITQTrQiDt10IcOLZbBMFAhscQ9P986MZhkfpzv2TcxCFI5OeaZ89WrzZ+XhMBNKQAhJkfmPeirJS220+d+mWfcp5/47Pmb0QaDQRMnTnTrHH/WVk/oFu1WOwDfIEgHTsjNzdW6detc7p+YuFsnl9kFOUf7jgHJPHM+bRoz6AACWMPs+gQ7x5vuW2+YXfcsg8GgtLQ0t85pSFbr61n1kf3iNDd9gFXbvPQBLHUH/IzEcYDMfxzdKbU2ZsyHJ8qshUjAkmTnZoO9dgCA28ig7SsNy99dSS63S974W56RkaHk5GS3y7UVFxerqqpKmZmZPturvmhCsjKHxPN/EwggJI4jcRwkl5eZJSZ20/nnt5fBMEwhE6A3aFoLOzubZc0A4CFk0PYHV5LLea9MW4OWlGuTpLS0NGVkZHhhRAD8hTrpDhCko7GCggKXlrlPnDhEKSm/8sGI/Ijs7gDgcWTQDhTZsp5dz5avEr+2JPu7JM2aNStgSrUBaD3qpAMucPXutsHwtVJSBjjtF/RSUwnOAcDDHGXQJkj3pRxJWXK/dnrjGfmW/Y1syP5uNBrdWgK/du1aZWVlEagDYYbEcQhb7iw/y8x8TyGTJA4A4FNk0A4kjUu3uSJbnswIbzAYNGvWLA0dOtSl/lVVVVq+fLleeOEFv2R/B+AfBOkIS+6UWgu5JHEAAJ8ig3awypf18njJUxnhs7Ky3FrKHgg11QH4DnvS2ZMednJzc13O5D5xYjelpJwpAnQAQGuR3T3YrJF5Br2p1TLPxrd+GbzkfmI5g8Hg0+zvADyHxHEOEKSHr4Y6pK4YNmyYpkyZcrKBpGoAAISRfNnPCL9WzUu83aWWButGo1HPvfFvlVZUK7bNMXVvYzuPQWNDhw5VVlZWi54PgH+4Goey3B1hZceOHS71axagZ2dL55wjTZ9u/pzduj1pAAAg0DXUW2+s4e9/02Xwb6s1e9afL/5Bz33TVR/+NEBvHUvWJ8f7OD2nuLiY5e9AiCJIR9jIzc1VUVGR034TJ05sPoO+tMkf46VLze0AACCE5cg8c776xOclMi9xt8f9PeuF5VVatnmvVdt/63qpst55YsHi4mISygEhiCAdYcFoNLq0D71Hjx5KSUmxbtxl54+xvXYAABBCmmaEd1btxb33B/ZK9I0472LFxTnPXeDqKkEAwYMgHWHh0KFDLvU744wzmjcm2fljbK8dAIDWys+X1qxh1VZAsrUMvjH33h/YK8U3KqmvS3vOi4qKKNEGhBiCdIQFV7OmJiYmNm9MTZUWNvljnJ1N8jgAgHeQByUINCyDv7RJe7bcTR7nqESfwWBQWlqa02tQog0ILWR3J7t7yCsoKNC6deuc9hszZozGjRtnvwPZ3QHAOX5Xtk5+vjkwb2r7dr6eAcszpdgclegzGo1at26dDhw44PQ6lGgDAhcl2BwgSA8frtZEHzFihCZNmuSDEQFACMvOtk60uXChlJPjv/EEozVrzDPoTa1eLU2b5vvxwMNaHtC7U0ZWktLS0pSRkeHWcwDwLkqwIey5mixOkkaNGuXl0QBAiKMShmeQByWEZctcpm36ic+XyZ1M8K4ufW+Ql5fHPnUgSBGkI2SVlpa61G/MmDEsCQOA1qIShmeQByVE5ct+bXXXV0hkZGRo1qxZGjRokEv9165dS6AOBCGCdISskpISp30mThzieB86AMA1zAB7Tk6OeQ/66tXmz0uW+HtEaDVHN6uel3SuXJ1VNxgMmjp1qiZOnOi0b1VVlZYvX67c3FyXrg0gMBCkIyQZjUZVVlY67NOjx36lpBz10YgAIMQxA+xZqanmPeh8/UKEs5tV2+TurHpKSoqGDh3qUt+8vDwVFBS4fG0A/kWQjpC0Y8cOp33OOOMLuVvLFADgADPAgB3Oaqs3cG9WPSsry+VAfd26dZRoA4IEQTpCTm5uroqKipz2S0zsqdaUSgHgR/n55izYJCULPMwAA3Y01FZ3lvzNvVn1rKwsl5a+S1JxcTGBOhAECNIRUlzN6D5mzIcyGBb4YEQAPC4721xHevp08+fsbH+PCABclCpzEO5KAO76rLo7S9+Li4tZ+g4EOIJ0hBRXlrmPGLFD48adKWbRAR/y1Mw3Zb4AhITVcm9W3Xm5Npa+A6GDIB0hw9Vl7qNG3SSJfZKAz3hy5psyXwBChjuz6q6Va8vKynK5RBtL34HARZAOryosr9LaAqMKy6u8+jyuLnPv0aOzDIZMr44FQCOenvmmzFfoIb8Awp6rs+qSeQn8dIc93CnRxtJ3IDARpMNrlqwv0ZQn8rTglZ2a8kSelqx3Xre8pUpLS13q17u314YAwBZPz3xT5iu0kF8AOMGdWfU1cnWfusFgcNpv3bp11FEHAgxBOryisLxKyzbvtWpbtnmv12bUa2pqXOoXE9PTK88PwA5vzHxT5is0kF8AsKFhVv1SJ/1cu9GZmena6sG8vDwZjUaX+gLwPoJ0eEXZwVq32lsrJibGpX6JiRd45fkB2OGtmW/KfAU/8gsAdqRKekuOl8C7dqPTYDAoLc2VZfSur0oE4H1t/T0AhKaEbtFutbfWvn37nPYZM2aMS8u+AHhYTo6UlWUOvpKSCKxhRn4BwImGJfDTZV7i3iBb7lSoycjIUHJyst58801VVlba7bdlyxZVVVUpKyurheMF4CnMpMMrRvaL09z0AVZt89IHaGS/OI8/l9Fo1J49exz2GTGis8aNG+fx5wbgIma+0ZSv8wuQoA5Bq2EJfMNn97f4GAwGjRkzxmk/Mr4DgYGZdHjNognJyhwSr7KDtUroFu2VAF1ybXkWe9EBIAD5apVFdrb1/veFC83PDQSNVLkze25L165dXepXXFys/v37KyUlpVXPB6DlIkwmk8nfg/C1mpoaxcbGqrq62uW9zAhcb7zxhtP66LNmzWKpOwCEo/x8c+b4prZvZ2UHQlC+zEnlkmQrqM/NzXWpZK0kpaWlKSMjw6OjA8Kdq3Eoy90R9GprHSejYy86AIQxEtQhbGRLOkfmPeznnHhsLSMjQ7NmzdKgQYOcXo2M74D/EKQjqOXm5jpc7p6Y2J296AAQzkhQh7CQL6lJSUMtla166gaDQVOnTtXEiROdXnXDhg0eGR0A9/gkSH/88cfVv39/dejQQampqfr444/t9l25cqUiIiKsPjp06GDVx2Qy6e6771avXr3UsWNHjRs3jrIRYchoNDpdshUd3cdHowEABCRfJ6gD/MLeyhD7K0ZSUlKcrjQ0Go0qKChoxbgAtITXg/SXX35ZCxYs0OLFi1VQUKDhw4crMzNTBw4csHtOTEyM9u/fb/n4+uuvrY4vXbpUf/vb37Rs2TLl5+crOjpamZmZ+vHHH739chBAXEsYR86BsEDWZgCO5OSY96CvXm3+vMT97NhAYLO3MiRJ5tn0NbI1q56Zmen0yuvWrVNubm5rBucRheVVWltgVGF5lb+HAnid14P0Rx55RHPmzNHMmTM1ePBgLVu2TJ06ddJzzz1n95yIiAjFx8dbPnr2PJmZ22Qy6dFHH9Uf/vAHTZo0ScOGDdPq1av17bff6vXXX/f2y0EAqampcdonMTHRByOBX2Vnm5NCTZ9u/pzdfA8eAFAGEKEtVVKTFSPKlrRWjvapGwwGpaWlOb26v/enL1lfoilP5GnBKzs15Yk8LVlf4rexAL7g1SD9+PHj2rFjh9We4DZt2mjcuHH66KOP7J53+PBhnXbaaerbt68mTZqkzz77zHKsrKxMFRUVVteMjY1Vamqqw2siFFU6PNqjRw+vJ4zjrq6f5edbl1WSzI+ZUQcAhJ0cWddTnyJX9qlnZGQE9P70wvIqLdu816pt2ea9vPdCSPNqkH7w4EHV1dVZzYRLUs+ePVVRUWHznNNPP13PPfec3njjDT3//POqr69XWlqa5e5dw3nuXPPYsWOqqamx+kDw27fvO4fHe/fu7dXn565uACBrMwAAjaRKmnbis+v71AN5f3rZQdtVfOy1A6Eg4LK7jx49WtOnT9eIESOUnp6utWvXqnv37nrqqadafM2HHnpIsbGxlo++fft6cMTwB6PRqMrKn/32/NzVDRBkbQYA+EJQ5j6x97fwuGztUQ/U/ekJ3aLdagdCgVeD9G7duikyMlLffWc94/ndd98pPj7epWu0a9dOI0eO1O7duyXJcp4717zjjjtUXV1t+fjmm2/cfSkIMP7O5s9d3QBB1mYAgLcFbe4TW/vUUyXNlq096u7sT/fljPrIfnGamz7Aqm1e+gCN7BfnszEAvubVIL19+/YaNWqUNm7caGmrr6/Xxo0bNXr0aJeuUVdXp+LiYvXq1UuSlJCQoPj4eKtr1tTUKD8/3+41o6KiFBMTY/WB4FZTs8dpH29+n7mrG0DI2gwA8Jagz33SeJ/6s2qe4d16j7qr+9N9PaO+aEKyXrsxTY/8erheuzFN2ROSffbcgD94fbn7ggUL9Mwzz2jVqlUqKSnRvHnzVFtbq5kzZ0qSpk+frjvuuMPS/7777tN7772nvXv3qqCgQNdcc42+/vprzZ49W5I58/ttt92mBx54QG+++aaKi4s1ffp09e7dW5MnT/b2y0HAqHbaw5uZ3bmrG2DI2gwA8IaQyH3SsE+9vZ3j1q/Flf3pku8zvo/sF6esFAPvtRAW2nr7Ca688kpVVlbq7rvvVkVFhUaMGKF3333XkvitvLxcbdqcvFdQVVWlOXPmqKKiQnFxcRo1apTy8vI0ePBgS5+FCxeqtrZW119/vb7//nude+65evfdd9WhQwdvvxwEiJiYnpIO2z0+ZswYr2d2XzQhWZlD4lV2sFYJ3aL5owEAQKgJqdwnzvaoJ8kc0Jv3py9fvtzpFQ8dOuT191tAOIowmUwmfw/C12pqahQbG6vq6mqWvgepgoJ/at26z2weO/fcc3XRRRf5eESAE/n55pmXpCRm/AEgmGRnWy95z84O4q1V2bIuy5Yq6yXwC2VeIi/l5uYqLy/P4dUGDhyoa665xsNjBEKXq3Go12fSAc/LVnV1vqSxNo82XpkBBISmb/AWLjTvpQcABL6cHCkrK0RutOZIypJ5iftxmZPINbb0xPFUZWRkqG3bttqyZYvdq+3Zs0dGo5HZdMDDiGYQZPIlLdX+/farA9TU1PhuOIEmKEvEhLigTzoEAAit3CfO9qivUMPsuiv5fXbs2OGpgQE4gSAdQWaXcnPHqbSUrJ7NBG2JmBAXEkmHAAChx94e9afUUJ7NlbJsRUVFPq+dDoQ6gnQEFaOxh/LyzvX3MAIPs7WBK6SSDgEAQoetOuqNmcuzuVKWzdeZ3oFQR5COoFJaWunvIQQmZmsDV2qqeQ96Y9nZIbJkEgAQ3BrqqN9g57j5fURKSoq6d+/u8EobNmzw6MiAcEbiOASRbNXUlEga5bBXWGbsZ7Y2sIVU0iEAQGhp+Jv0lI1jJ99HJCcnq7LS/mSJ0WgkiRzgIcykI0iYE8a5wpUkJyGH2drAF1JJhwAAocXW0veG3DZrJOWTRA7wIWbSESRcW7bdo0eP8L2Dy2wtAABoscbl2ZIkrZU5gZyZwbBQaWnjHNZOLyoqUqdOnZSRkeHlsQKhjZl0BAnXlm337t3by+MIcMzWAgCAFmsozyY1X8G4VBkZMS4lkSsoKDjZQHlYwG0E6QgSzjKQAgAAwDPsrWDc5VISuXXr1pnLslEeFmgRgnQEkSxJKf4eBAAAQIizt4LR3J6cnOz0Cl+/8grlYYEWIkhHkMiWeV9UgbOOAAAAaBV7ieTM2+lcSSLX9dAh2wcoDws4RZCOIOB6ZncAAAB4QkMN9dUnPi+xHDEYDEpLS3N49qGuXW0foDws4BRBOoIAd1wBAAB8ryGRXPOEtBkZGRoxYoTdM/cZDNo6Zox1I+VhAZdQgg1B4OQd15iYGoc9Y2JivD0YAAAASBo1apSKiorsHt+YkaGec+cq0WSiPCzgBmbSEQRO7ouKja122DM2NtYH4wEAAIAry97Le/WiPCzgJoJ0BAnzvqjq6msd9qqudhzEAwAAwHMyMjJ0/vnn2z2+detWczk2AC4jSEcQSVVNTX+HPWpqHC+HBwAAgGc5y/ael5cno9Hoo9EAwY8gHQAAAECLGQwGde/e3WGf0tJSH40GCH4E6QgC+ZLWnPgMAACAQJOcnOzweElJiY9GAgQ/gnQEuGxJ50iafuLzJ/4dDgAAAJpxtuS9srKSJe+AiwjSEcDyJS1t0vapPwYCAK7Lz5fWrDF/BoAw4Uqm9x07dvhoNEBwI0hHAFvv7wEAgHuys6VzzpGmTzd/zs7294gAwGcyMjIczqgXFRWR6R1wAUE6AACekJ8vLW2y+mfpUmbUAYSVXr3qHR4n0zvgHEE6AtgEfw8AAFy3a5d77QAQcrKVmLjIaS+WvQOOEaQjgKVKWtikbZg/BgIAziUludcOACHFnEvIYNin7t33O+zJsnfAMYJ0BLgcSdslrT7x+Sz/DgcA7ElNlRY2ubGYnW1uB4CQd3LVUHLyF057s+wdsI8gHUEgVdK0E58BIIDl5Ejbt0urV5s/L1ni7xEBgI+cXDWUmLjbpTNKS0u9NRggqBGkAwDgSamp0rRpzKADCDMntykaDPuUlrbV6Rk1NTVeHhMQnNr6ewAAAAAAQkGOpCxJu5SRkaTKyh0qLa3096CAoMNMOoJKTExMq44DAADAmxq2Ka5Vr16vOOx58OBBn4wICDYE6QgqsbGxrToOAAAAbzNnene2N91oNJI8DrCBIB1Bpbq6ulXHAQAA4G3mTO+u7E0neZxnFJZXaW2BUYXlVf4eCjyAPekIKs4SjJCABAAAwN9OZnrPyHhflZVdVVqabLPn/v2Oa6rDuSXrS7Rs817L47npA7Rogu2vN4IDM+kAEC7y86U1a8yfAQDwmpOZ3iWpV68Kuz1LS0uVm5vrgzGFpsLyKqsAXZKWbd7LjHqQI0gHgHCQnS2dc440fbr5c3a2v0cEAAhpOZK2S1qtxMQ7HPbMy8tjb3oLlR2sdasdwYEgHQBCXX6+tHSpddvSpcyoAwC8zJzp3WDoou7dHS9rZ296yyR0i3arHcGBIB0hZd++ff4eAhB4du1yrx0AAI/apT59vnXYg7xCLTOyX5zmpg+wapuXPkAj+8X5aUTwBBLHIaRUVlbKaDTKYDD4eyhA4EhKcq8dAACPSlJMjOMgnImWlls0IVmZQ+JVdrBWCd2iCdBDADPpCDkslwKaSE2VFi60bsvONrcDAOB1qUpMHOSwR8NEC1pmZL84ZaUYCNBDBEE6Qo7by6XIeI1wkJMjbd8urV5t/rxkib9HBAAIIwZDOjXTARex3B1BJSYmxrMXzM62Tqi1cKE5mAFCUWoqs+cAAD9JcloznX3pgBkz6QgqiYmJnrsYGa8BAAB8xFw7PTr6iN0etbWUDQMkgnQEGYPBoLS0NM9cjIzXAAAAPpSjmJgUu0dLS0uVm5vrw/EAgYkgHUEnIyPDMzPqZLwGAADwqcTE0Q6P5+XlkUAOYY8gHUEpOjq69Rch4zUAAIBPGQyZ6t69zmEfEsgh3JE4DkHJUQI5t5LL5eRIWVnmJe5JSQToAAAAXpacPFaVlVv8PQwgYBGkB7DC8iqVHaxVQrdoah42ERsba/dYfX29excj43Voys/n5gsAAAHI0fs4V44DoY4gPUAtWV+iZZv3Wh7PTR+gRRNsl6sIffmSdklKkjkzqFRdXW2399atW1VfX6+MjAyfjA4BiNJ6AAAELEfv4yTpm2++UUqK/QRzQKhjT3oAKiyvsgrQJWnZ5r0qLK/y04j8KVvSOZKmn/icLcl5HU2SjoQxSusBABDUioqKyPKOsEaQHoDKDtquEWmvPXTlS2oSbGnpiXbnSDoSpiitBwBAQHOlSg8TLghnBOkBKKGb7czl9tpD13q77a4kh3M2244QRWk9AAACmsFgUFpamtN+TLggXBGkB6CR/eI0N32AVdu89AFhmDzO3t1To2fqpCM0UVoPAICAl5GRocTE7g77MOGCcEXiuAC1aEKyMofEB0R2d/9lmTfYbTcYDOrevbsqKyt9OB4EDUrrAQAQ8KKj+0jivRzQFEF6ABvZL87vs+f+zTI/QdK9dtqlPn36EKTDPkrrAQAQ0JxtX9y3b7ePRgIEFpa7wy7/Z5lPldRk2bKy1VCGzZl9+/Z5ekAAAADwEGfbFysrD5M8DmGJIB12BUaW+RxJ2yWtPvF5ictnVlZW8osdAAAgQLmSQI7kcQhHBOmwK3CyzKdKmiZXZ9Ab4xc7AABA4DInkLM/o07yOIQjgnTYFXhZ5vMlrVFDnXTKsAEAAAS/6GhHE0C+zT9UWF6ltQVGH27vBJojcRwcCpws89mSljZ6vFCJiTdry5YtfhoPAAAAvK229n8+ey7/JkwGTmImHU6N7BenrBSDn2fQlzZpWyqDYZ/TfUwAAAA+l58vrVlj/gynHK2OLC09qtzcXK+Pwf8Jk4GTCNIRBHbZbXe2j6m21pdJ7gAAQNjLzpbOOUeaPt38OTvb3yMKeM6yvOfl5Xk9GXBgJEwGzAjSEQSSHLb36tXL7pmlpaU+ufsKAACg/HxpaZPVf0uXMqPuhMFgkMFgcNjn0KFDXh1D4CRMBgjSERQc10uPjY11eLYv7r4CAABol53Vf/baYTFy5EiHx+vqvFuxJ/ASJiOc+SRIf/zxx9W/f3916NBBqamp+vjjj+32feaZZ3TeeecpLi5OcXFxGjduXLP+1157rSIiIqw+xo8f7+2XAb+yXy+9urra6dmUYgMAAF6XZGf1n712WDh7P1ddvc/rY1g0IVmv3ZimR349XK/dmKZsksbBT7wepL/88stasGCBFi9erIKCAg0fPlyZmZk6cOCAzf6bNm3Sb37zG33wwQf66KOP1LdvX1188cXat8/6B3P8+PHav3+/5eMf//iHt18K/C5V5iXuu9RQhs1VlGIDAABel5oqLWyy+i8729wOh5y9V6up8c2yc/8nTAZ8EKQ/8sgjmjNnjmbOnKnBgwdr2bJl6tSpk5577jmb/V944QXdeOONGjFihM444ww9++yzqq+v18aNG636RUVFKT4+3vIRF8cPUujLlnSOpOknPpsTsThLNgIAAOAzOTnS9u3S6tXmz0uWOD8HLuju7wEAPuPVIP348ePasWOHxo0bd/IJ27TRuHHj9NFHH7l0jSNHjuinn37SqaeeatW+adMm9ejRQ6effrrmzZvnMJnEsWPHVFNTY/WBYGO7DJuUL4PBoO7dHf/iJss7AADwmdRUado0ZtA96hN/DwDwGa8G6QcPHlRdXZ169uxp1d6zZ09VVFS4dI3s7Gz17t3bKtAfP368Vq9erY0bNyonJ0ebN2/WhAkTVFdXZ/MaDz30kGJjYy0fffv2bfmLgp/YL8MmSX369HF4NlneAQAAApejWumStG/fIbm73REIVgGd3X3JkiV66aWX9Nprr6lDhw6W9quuukq//OUvNXToUE2ePFlvvfWWPvnkE23atMnmde644w5VV1dbPr755hsfvQJ4juMybK4gyzsAAEBgcrZ9sbIyXkbjpz4aDeBfXg3Su3XrpsjISH333XdW7d99953i4+MdnvvnP/9ZS5Ys0Xvvvadhw4Y57DtgwAB169ZNu3fvtnk8KipKMTExVh8INrbKsF1q+Zer31OyvAMAAAQeg8GgtLQ0h31KSzv6aDSAf3k1SG/fvr1GjRpllfStIQnc6NGj7Z63dOlS3X///Xr33Xd15plnOn0eo9GoQ4cOqVevXh4ZNwJVQxm2huD8bTUkkHM1eRz5CAAAAAJTRkaGw/d0NTU/+nA0gP94fbn7ggUL9Mwzz2jVqlUqKSnRvHnzVFtbq5kzZ0qSpk+frjvuuMPSPycnR3fddZeee+459e/fXxUVFaqoqNDhw4clSYcPH9bvf/97bd++XV999ZU2btyoSZMmadCgQcrMzPT2y0FAeLvJ46UyGPY5vfsKAACAwBYd7ajU2ptqqO4DhLK23n6CK6+8UpWVlbr77rtVUVGhESNG6N1337UkkysvL1ebNifvFTz55JM6fvy4fvWrX1ldZ/HixbrnnnsUGRmpTz/9VKtWrdL333+v3r176+KLL9b999+vqKgob78c+J39BHIZGdNUWVnpcEn7vn37vDMsAAAA+MBSSVkyb4UEQpPXg3RJmj9/vubPn2/zWNNkb1999ZXDa3Xs2FEbNmzw0MgQfBwnkHN891WqrKyU0WiUwWDw8LgAAADgG7tEkI5QFtDZ3YHmWp9AjuRxXpafL61ZY/4MAADgca5X9wGCEUE6glDrEsjt37/fe0MLd9nZ0jnnSNOnmz9ns28MAAC4ztGES21tJ5n3pDOLjtBGkI4g1rIEcqWlpcrNzfXesHwl0Gas8/OlpUut25YuDZzxAQCAgOdowqW0NFm5uRf5cDSAfxCkI0g5SiDnuHyHJOXl5cloNHp+WL4SiDPWu+x8T+y1AwAANGEwGNS9e3e7x4P+PRzgAoJ0BCnHCeR69erl9AqHDh3y4Hh8KFBnrJPsfE/stQMAANiQnJzs8PihQ0/4aCSAfxCkI0jZSiA3TQ17lGJjY51eoa6uzuOj8olAnbFOTZUWNvmeZGeb2wEAAFzk7H1cXd16SWynQ+jySQk2wDtyJO2XtObE4zWSeknKUWRkpNOzq6urvTc0bwrkGeucHCkry3zDICmJAB0AALjN2Xu06upYSetFAjmEKmbSEcTydTJAb7BUUr66du3q9OySkhJvDMr7An3GOjVVmjYtcMYDAACCSk1NjZPjzkvuAsGMmXQEMfvJ4wyGVHXv3l2VlZV2z66srJTRaJTBYPDO8LyJGWsAABDWJvh7AIDXEKQjiNlb3n1cktSnTx+HQbpkLscWlEG6ZA7MCc4BAEDYGSaWuiOUsdwdQcxW8jhJmi0pWzExzpdCOVtOBQAAgEATJxLHIZQRpCPI5Uh61kb7UiUmHnd6dm1trcdHBAAAAG/aLOkcSdn+HgjgFQTpCAHtbbYaDAeUlpbm8MzS0lLl5uZ6Y1AAAADwKnPCYCDUEKQjBNjbm56rjIwMJSYmOjw7Ly9PRqPR88MCAk1+vrRmjfkzAAABypUtiyet99o4AH8hSEcISJV0jY32NZLy1atXL6dX2LFjh6cHBQSW7GzpnHOk6dPNn7NZIggACEzOJlj27evjo5EA/kGQjhBxsZ329U5/0UtSUVERy94RuvLzpaVLrduWLmVGHQAQkAwGg8Mti5WV8TIaGwJ1SrEh9BCkI0TYW/J+rwyGx9S9e3enV2DZO0LWrl3utQMA4GfOtiyWlg6SOXEcpdgQegjSESLslWOTpKXq08d2crmmSktLPTYiIGAk2bmJZa8dAIAAEB0dbfdYTc01kpb4bjCADxGkI4TkSFps80hMjGul1qibjpCUmiotbHITKzvb3A4ACC4kAT3B+SpJIFgRpCPE2N6XlJh4ho/HAQSYnBxp+3Zp9Wrz5yXMPgBA0CEJaCOVakgSDIQagnSEGFvL3rNlMGQ6rZkuSQcPHvTKqICAkJoqTZvGDDoABKMwTALqqBRbTMzzkqZLOkfmvelA6CBIRwjKkbRd0uoTn80zhhkZGTr33HMdnmk0GkkeBwAAAk8YJgGNjY11cKy60aOlYkYdoaStvwcAeEeqTmb7zJe0S1KS2rRxfl+qtLRUBoPBi2MDAABwUxgmAa2urnZwrGkAv15kekeoYCYdIS5b5mVQDcuh3nd6xv79+708JgAAADeFYRJQRwl9a2rsL4UHgh1BOkJYvszLn05KTFzl9KzS0lLl5uZ6aUwAAAAtRBJQB2wnDwaCEUE6QljzPVoGwz6lpZmcnpmXl8fedAAAEHhIAmpDtljqjlBCkI4QZnuPVkbGvRox4ienZ5eWlnp6QAAAAPCIX6ppkmAgVBCkI4TZKsdmNmrUSqdnl5SUeHY4AAAA8JDukqaJGXSEIoJ0hLgcSYubtRoM+9S9u+PiBpWVlSx5BwAAAOBTBOkIA7YTifTpc8jpmTt27PD0YAAAAOAR+ZLWiBrpCDUE6QgDqZKuadYaE1Pg9MyioiIyvQMAAAScT2RdZjfbv8MBPIggHWHi4mYtiYm7XTqTTO8AAAC+FxPjqBb6p00eLxUz6ggVBOkIE80zvZvLsW116WwyvQMAAPhWYmKim2es98o4AF8jSEeYsJ3pPSPjfY0Y4XzfOZneAQAAfMtgMKh79+5unMHKR4QGgnSEkRxJzzZrHTXK+d50Mr0DAAD4Xp8+fdzobfDaOABfIkhHmJmlpjPq5nJs+52eyZJ3AACAwFBb28lGq+2KPgh9heVVWltgVGF5lb+H4hGOC0UDISlHUkdJ91pakpO/UGVlL4dn1dTUeHdYAAAAsGIveVxpabJyc8cpI+P9Ey3ZMm9vRLhZsr5EyzbvtTyemz5AiyYk+3FErcdMOsKU9Z1WVzK9U44NAADAt2JjY+0ey8s7V0bj05K2S1riszEhcBSWV1kF6JK0bPPeoJ9RJ0hHmLKune5qpnfKsQEAAPhOdXW1w+OlpYPEDHr4KjtY61Z7sCBIRxizrp2ekfG+EhOdZ3HfscN5NngAAAC0nrPthmxHbL1g3s+d0C3arfZgQZCOMNa8dnqvXhVOz2LZOwAAAELBkvUlmvJEnha8slNTnsjTkvXBVXZ4ZL84zU0fYNU2L32ARvaL89OIPIPEcQhjDbXTl1paEhNHa8sW52fm5eUpOTlZBgOlPgAAABB87O3nzhwSH1RB7qIJycocEq+yg7VK6BYdVGO3h5l0hLkcmZONrJa0XQbDQ+revbtLZ1KSDQAAAMEqlPZzj+wXp6wUQ0gE6BJBOiDzjPo0NSQdSU52rWRDSUlwLQcCAAAITfmS1pz4DFeF6n7uUECQDjSRmPieS/0qKyvJ9A4AAOBXn0g6R9L0E5+z/TucIBKq+7lDAXvSASv5MhiWKC1tnPLyznXae8eOHexLBwAA8JtPmzxeKilLlGVzTSju5w4FBOmAlV2SzOXYjhzpqKKiUQ57FxUVqVOnTsrIyPDF4AAAAODUehGku25kvziC8wDDcnfAysmybKNGFbh0Rl5eHsveAQAAAgbvyxDcCNIBK6mSLpUkGQz7lJa21aWzyPQOAAAAwBMI0oFm7rL8KyPjfY0YscPpGWR6BwAACBTkC0JwI0gHmkmVtNDyyJVl72R6BwAACBQT/D0AoFUI0gGbciQ9K8m87L179/1Oz9ixw/mMOwAAADxpWJPH2SJpHIId2d0REArLqwKw9MMsmbO9L1Vy8heqrOzlsDeZ3gEAADwrJibGyfGLJE2U+T1bkgjQEQoI0uF3S9aXaNnmvZbHc9MHaNGEZD+OqLEcSUlKTFysLVvGOu2dl5en5ORkaqcDAAB4QGxsrAvHU0RwjlDCcnf4VWF5lVWALknLNu9VYXmVn0ZkyywZDGNdzvTOsncAAADPqK6ubtVxIBgRpMOvyg7WutXuPxe7nOm9qKhIubm5PhhTiMvPl9asMX8GAABhqaamplXHgWBEkA6/SugW7Va7/yRJci3Tu2Re9k6291bIzpbOOUeaPt38OTvb3yMCAAAAfIIgHX41sl+c5qYPsGqblz4ggJLHNTCXZXM107skbdiwwbtDClX5+dLSpdZtS5cG/ow6M/8AAADwABLHwe8WTUhW5pD4AMzu3pQ5iVxy8hqnmd4lyWg0ymg0kkTOXbt22W9PDdCkMNnZ1jcWFi6UcnL8Nx4AAAAELWbSERBG9otTVoohgAP0BrOUmNjT5d4kkWuBpCT32v0tWGf+AQAAEJAI0gE3GQwLXM70ThK5FkhNNc9EN5adHbiz6I5m/gEAAAA3sdwdcFuqMjJS1LXr61q3brLT3tROb4GcHCkryxzoJiUFboAuBd/MPwAEqvz84Pi9DwSJwvKqINhOCluYSQdaJEcpKcuUlhbrUm+SyLVAaqo0bVrgv1ELtpl/AAhEVPVAC8XExPh7CAFpyfoSTXkiTwte2akpT+RpyfoSfw8JbvBJkP7444+rf//+6tChg1JTU/Xxxx877P/qq6/qjDPOUIcOHTR06FC98847VsdNJpPuvvtu9erVSx07dtS4ceNUWlrqzZcA2JCqjJjRuqyqSn2clFtrSCKHEJWTI23fLq1ebf68ZIm/RwQAwYPcHnBg3759Do8nJib6aCTBo7C8Sss277VqW7Z5rwrLq/w0IrjL60H6yy+/rAULFmjx4sUqKCjQ8OHDlZmZqQMHDtjsn5eXp9/85jeaNWuWCgsLNXnyZE2ePFn//e9/LX2WLl2qv/3tb1q2bJny8/MVHR2tzMxM/fjjj95+OcBJJ+76j/rrXzX72Wd1kZO95ySRC3HBMvMPAIGG3B6ww2g0qrKy0u7xMWPGsJ3QhrKDtW61I/B4PUh/5JFHNGfOHM2cOVODBw/WsmXL1KlTJz333HM2+//1r3/V+PHj9fvf/17Jycm6//77lZKSor///e+SzLPojz76qP7whz9o0qRJGjZsmFavXq1vv/1Wr7/+urdfDmBm467/udu2OZxRJ4kcAAA2kNsDdjhaKZuYmKhx48b5cDTBI6FbtFvtCDxeDdKPHz+uHTt2WP0AtWnTRuPGjdNHH31k85yPPvqo2Q9cZmampX9ZWZkqKiqs+sTGxio1NdXuNQGPs3N3v+uhQw5Py8vLY9k7AACNkdsDdtTU1Ng9Fh1NwGnPyH5xmps+wKptXvoAkscFEa9mdz948KDq6urUs6d1XemePXvqiy++sHlORUWFzf4VFRWW4w1t9vo0dezYMR07dszy2NEPPOASO3f3D3Xt6vTUHTt2sDQLAIDGgqmqBxAEFk1IVuaQeLK7B6mwyO7+0EMPKTY21vLRt29ffw8Jwc7OXf/ul13m9FSWvQMAYAO5PdCEo8ztzY/lS1pz4jMk84x6VoqBAD0IeTVI79atmyIjI/Xdd99ZtX/33XeKj4+3eU58fLzD/g2f3bnmHXfcoerqasvHN99806LXA1ixkdF71KhRLp3KsncAAADHYmPtl7q1PpYt6RxJ0098poQfgptXg/T27dtr1KhR2rhxo6Wtvr5eGzdu1OjRo22eM3r0aKv+kpSbm2vpn5CQoPj4eKs+NTU1ys/Pt3vNqKgoxcTEWH0AHtHkrr/BYHB5KTu10+FV+fnSmjWUMAIABK3q6moXjuVLalLCT0vFjDqCmdeXuy9YsEDPPPOMVq1apZKSEs2bN0+1tbWaOXOmJGn69Om64447LP1vvfVWvfvuu3r44Yf1xRdf6J577tF//vMfzZ8/X5IUERGh2267TQ888IDefPNNFRcXa/r06erdu7cmT57s7ZcDODVgwADnnUTtdHjRifKAmj7d/DmbGQUAQPBxlEfq5LH1dnrYawcCn1cTx0nSlVdeqcrKSt19992qqKjQiBEj9O6771oSv5WXl6tNm5P3CtLS0vTiiy/qD3/4g+68804lJibq9ddf1y9+8QtLn4ULF6q2tlbXX3+9vv/+e5177rl699131aFDB2+/HMCpxMREbdmyxaW+JJGDx9koD6ilS80JmdjnCQAIOfYmPJgIQfCKMJlMJn8PwtdqamoUGxur6upqlr7DK3Jzc5WXl+dS37S0NGVkZHh5RAgba9aYZ9CbWr3avDUDAIAg8cYbb6ioqMjmsREjRmjSpEmSZktabqPHLEnPem9wQAu4GoeGRXZ3wNcyMjI0ceJEl/qSRA4eZac8oN12AEDQKiyv0toCowrLq/w9FAAeRJAOeElKSorS0tJc6rthw9NeHg3Chp3ygCx1B4DQsmR9iaY8kacFr+zUlCfytGR9ib+HBMBDCNIBL8rIyNCIESOc9jMaI1VQ8E/vDwjhwUZ5QABA6Cgsr9KyzXut2pZt3suMOhAiCNIBL3O1dvq6dZ8pN/dRUTIEHtGkPCAAIHSUHax1qx1AcCFIB7zMndrpeXnVKiiYK4mSWQAAwLaEbtFutQMILgTpgA9kZma63HfdusnKzS0QM+oAAMCWkf3iNDd9gFXbvPQBGtkvzk8jAuBJXq+TDsA8m56WluZyWba8vHOVnPy8zBPwLFcGAADWFk1IVuaQeJUdrFVCt2gCdCCEMJMO+Ig7ZdkkacOGWknniKXvAADAlpH94pSVYgjZAL221pU99va2FLq21RAIRATpgA+lpKS4vD/daDxNRmMfSUvF0ncAABBOcnNzVVpa6kLPCW62A4GPIB3wMXf2p+/YkXLiX7u8Mxh4VWF5ldYWGCmJAwCAG4xGo9MtgjExMSf+lSppYZOj2WK7IIIZe9IBH3Nnf3pR0Sh16nRUGRl7ZJ5N5w9OsFiyvsSqhu3c9AFaNCHZjyMCACA4HDp0yGmfxMTERo9yJGXJPKmRJN4vIdgxkw444Y3ZUHf2p+flnSuj8VmxPz14FJZXWQXokrRs815m1AEAcEFdXZ3D4wMHDrSxfTBV0jQRoCMUEKQDDixZX6IpT+RpwSs7NeWJPC1ZX+Kxa6ekpCgtLc2lvhs2XHziX+xPDwZlB20nurHXDgAATqqurnZ4vE+fPj4aCeAfBOmAHb6YDc3IyNCIESOc9jMaT1NBQUO/FSJQD2wJ3aLdagcAACfV1NS06jgQ7AjSATt8NRs6atQol/qtWzdZubnjJD0llr4HtpH94jQ3fYBV27z0ASFbIgcAAACeQ+I4eFxheZXKDtYqoVt0UAclvpoNNRgMMhgMMhqNTvvm5Z2r5OQSGQz7ZF76niX2XgWmRROSlTkkPiR+FgAAgOtC5b0w/IcgHR4VShmtG2ZDG78eb82GZmZmavny5S713bDhYs2ateLEo4bPBOqBaGS/OP44AwAQRkLpvTD8h+Xu8JhQzGi9aEKyXrsxTY/8erheuzFN2V76JdtQls0V1vvTG5a+Xyb2qQMAAPhPKL4Xhn8QpMNjQjWj9ch+ccpKMXh9RtSdsmwn96c3eFvsUwcAAOErX9Ia+XPSIlTfC8P3CNLhMWS0br2UlBQbdT9ty8s7t9GMegNKtAEAgHCTLfNkxXT5c9KC98LwFIJ0eAwZrT0jMzPT5b7NZ9QlSrQBAIBgtm/fPjd658s8SdGYfyYteC8MTyFxHDyKjNat17A/PS8vz6X+1hnfJfM+9ackLZSU46VRAgAAeJ7RaFRlZaXDPjExMY0erbfTa738kViX98LwBGbS4XG+2sMdytzZny5Ja9dOkdHYp0krS98BAEBwKS0tddonMTGx0SN7JWydl7b1Ft4Lo7UI0oEA5c7+9Kqqblq+fI6Npe+7PD8wAAAAL6mpqXF4fMyYMS6/PwKCFUE6EMDc2Z8umZe+W8+oJ3l2QAAAAH6SmJioceOaTkgAoYcgHQhg7tRPb1BaOujEv7Jl3ovl/5IkAAAArRUdTZZ0hAeCdCDAubs/fe/e8ZK2S1qiQClJAgAA4ArrpHCuHLO39J0l8QheBOlAEEhJSXF5Rt1oPKaCgnYKpJIkAAAAroiNjXXzWF87ve21A4GPIB0IEhkZGTr//PNd6rtu3Trl5n5k5yjJ5AAAQGD65ptv7B6rrq62dYa9K3lkPIA/EKQDQcS65IhjeXnVKigYYeNIktinDgAAAk1ubq6KiorsHred+T3wSrABrUWQDgQRg8HgVtmRdesma+3ayY1asiWtlfU+9WmeHCIAAIDbjEaj8vLy/D0MICAQpANBxt2ybMXFI7R27Z9kTiY3Rc33qT8vc8BuW2F5ldYWGFVYXuXmSAEAAFxTWlrqtI+jpHJAKCFIB4JMS8qyFRfXnkgmZ28/uu2l70vWl2jKE3la8MpOTXkiT0vWl7g9XgAAAGdsL2W3ZnvbH9ndEXoI0oEglJGRoVmzZikuLs7lc8zJ5EwOelgH8IXlVVq2ea9V27LNe5lRBwAgkOXnS2vWmD+HkB49etjZ8jfBzhn22oHAR5AOBCmDwaCsrCy3zsnLK5PROMvOUeuEcmUHa232stcOAAD8LDtbOuccafp08+fsbH+PyGN69+5t50iqpIVN2rJPtAPBiSAdCGItWfq+du0wGY2zm7Q2TyiX0O1PNs9P6BbdgpECAACvys+XljbJO7N0acjNqNuWI3PundUnPi/x73CAViJIB4JcRkaGJk6c6HL/qqoqLV9uUG7uKp38Y9Y8odzIfn/T3HTrPejz0gdoZD/Xl9gDAAAf2WUn74y99gCzb9++Vl4hVeaKNcygI/i19fcAALReSkqKDh065Fbpkry8MnXtOlEpKSkyL3FvbtGE3ytzyIcqO9hfCd2iCdABAAhUSUnutQcQo9GoyspKfw8DCBjMpAMhwt0ZdakhmVyuzPvRbRvZr0xZKQYCdAAAAllqqrSwyd7s7Gxze4BzpfwaEE4I0oEQkpKSoqFDh7p1Tl5enozGPpKusdPDOqEcgAAVohmdAbghJ0favl1avdr8eUlw7M12pfwaNdIRTgjSgRCTlZXldqC+YcMGmYPwaU2ONE8oZ24DEFBCOKMzADelpkrTpgXFDLo7bNdIB0ITQToQgrKystxa+m40GlVQUKCTieTsJ5QzP17uoZECaLWwzugMIByMGTPGTo10IDQRpAMhKiUlxa0/aCf3pzfOjmovI+xsNZ91B+AXQZ7RGQAcLWUfMWKExo0b58PRAP5HkA6EsMzMTLf6m/enGxu1OMoI+7zMS+AB+FUQZ3QGAEmqr6+3e6xv374+HAkQGAjSgRBmMBiUlpbm1jlr165tFKinSlrooDfJ5AC/C+KMzgCQm5urrVu32j1eXV3tw9EAgYEgHQhx7pZmq6qq0vLly08sfZekHEnPOjiDJbWA3wVpRmcA4c1oNCovL89hH1cyvwOhpq2/BwDA+1JSUnTo0CGnfwgby8vLU3Jy8ol97bMkbZJ5iXtTLKlFkMjPN+/TTkoKzVnm1NTQfF1AU6H+sxwOTnwPv/vhB6ddXSu9li/zpEGSzKsAgeDGTDoQJtydUZeaLn23V6Kt8R9D6qkjQFGiDAgN/CwHv0bfw1E33aSLLCv3bHNeei1blIpFqIkwmUwmfw/C12pqahQbG6vq6moX784BoWPt2rUqLi5265y0tDRlZGSceGTvbnW2rMu1XSNzwB7CmM0JDvn55jeETW3fzvcNCCb8LAc/O9/DZ2fP1j4bFWl69OihefPmObqgzIF5U9vFjDoCkatxKDPpQJjJysrS0KFD3TonLy/vRB11ybpEW4N8Na+n/rykcxWys+rM5gQPSpQBoYGf5eBn53vV9dAhm+29e/d2csH1brYDwYEgHQhDWVlZbi99X7dundauXWvnqL03SNtkvsN9mUIqWM/Pl5Y2uSmxdKm5HYGHEmVAaOBnOfjZ+V4d6tq1hRc0utkOBAeCdCBMpaSkuD2jXlxcbCdQd/YG6W2F1D4xZnOCCyXKgNDAz3Lws/E93DpmjM2l7kA4I7s7EMaysrIkya096sXFxerfv79SUlIatabKvAfdVvb3xpZKylLQ7xNjNif45ORIWVnkEACCHT/LwS8nR1u6ddOhjz7Soa5dHQboznNH2Ts3uIP+wvIqlR2sVUK3aI3sF+fv4cAPCNKBMJeVlaX+/ftr3bp1Lp+zbt06ffXVV5Yg32yNpAg5Txa3S0EfpDfMBDRe8s5sTuCjRBkQGvhZDnpVSUn69MgRp/2cZ3afIOleO+3Bacn6Ei3bvNfyeG76AC2akOzHEcEfWO4OoMVL35cvX96oRJskrZY5o+qlDs4MkdnmnBxzRuHVq82flyzx94gAAAgK+/btc9pnzJgxMjhdBp8qqckWiGblYYNHYXmVVYAuScs271VheZWfRgR/IUhHSCgsr9LaAiO/xFqhJVnfjUajli9frlyrGqepkt6S7WA9eP9w2pSaKk2b5p8Znfx8ac0aktUBAIKK0WhUZWWlwz6JiYkaN26ci1fMkfk9R8NEQfDeNC87WOtWO0IXy90R9FgW5DktWfoumUu0JScnN7nj3RCs26urjhbLzrZear9woXlmHwCAAFdaWuq0T3R0tJtXTVUovMdI6Gb7ddtrR+hiJh1BjWVBnpeSkqK0tDS3z9uxY4edI7bqqqPFKP8GAAhiNTU1Tvs4TxgXmkb2i9Pc9AFWbfPSB5A8Lgwxk46g5mhZEL/QWi4jI0PJyclau3atqqpcu+FRVFSkurq6Jsnk4HGOyr+RSAkAEOBcCcCdJ4wLXYsmJCtzSDzZ3cMcM+kIaiwL8h6DweB2wG07mZw78mXODs+ssF2UfwOCDzkkAIv6+nqHx11LGNcgNN83jOwXp6wUAwF6GCNIR1BjWZB3GQwGt5e+204m54psSedImn7i8zQ3zw8TDeXfGqP8GxC4srOlc86Rpk83f87O9veIAL/Jzc3V1q1b7R4fMWKEGwnjmr5v4GcLoSPCZDKZ/D0IX6upqVFsbKyqq6vDds9LqCksr2JZkBcVFBS4nUxOkmbNmuXi3fB8mf/ANjVG0sNiP7sN+fnmJe5JSQToQKDKzzcH5k1t387PLcJOw018R0aMGKFJkya5cDV77xu2i/cMCGSuxqHMpCMksCzIu1pSR12S1q5d6+LSdzv7rLVNzKrb4c/ybwBc4yiHBBBmXMnq7rr1brYDwYUgHYBLWlJHvaqqSsuXL9cLL7zgJFh3tp/6eUnnKtT2nAEIceSQgC8FeO4DsroDrvNakP6///1PU6dOVUxMjLp06aJZs2bp8OHDDvvffPPNOv3009WxY0f169dPt9xyi6qrq636RURENPt46aWXvPUyADSSlZWliRMnun3e7t27nexTT5V0jZOrNMyqXyaCdQBBgRwS8JUgyH2wb98+p31cz+o+wc12ILh4LUifOnWqPvvsM+Xm5uqtt97Sli1bdP3119vt/+233+rbb7/Vn//8Z/33v//VypUr9e6772rWrFnN+q5YsUL79++3fEyePNlbLwNAEy2toy5JeXl5DmbU18i1Ze1viyXwAIJGTo55D/rq1ebPS5b4e0QINfn50tKl1m1LlwbUjLrRaFRlZaXDPj169HAjq3uqpCY3wJQt9qMjVHglcVxJSYkGDx6sTz75RGeeeaYk6d1339Ull1wio9Go3r17u3SdV199Vddcc41qa2vVtq25pHtERIRee+21VgXmJI4DWs9oNGrDhg1ul1uLi4tTVlaWgz/E+ZIWSMpz4WoklgMAhLk1a8wz6E2tXm3OXRIAPvjgA23ZssVhH9eTxjWWL3NemyTxXgDBwK+J4z766CN16dLFEqBL0rhx49SmTRvlu3FXr2HwDQF6g5tuukndunXT2Wefreeee07O7jMcO3ZMNTU1Vh8AWsdgMGjWrFkt3qe+du1aOz1SZV7a7sobCxLLAQDCXBDkPti/f7/TPu5PnBGgI3R5JUivqKhQjx49rNratm2rU089VRUVFS5d4+DBg7r//vubLZG/77779Morryg3N1eXX365brzxRj322GMOr/XQQw8pNjbW8tG3b1/3XhCaKSyv0toCowrLq/w9FPhZS/epFxcXa/ny5Q5m4lfLXErlUhWWJ2ltwVgVltt7w0FiOQBAmArw3Ae5ubkuZXZ3fT+6RI10hDq3lrsvWrRIOTk5DvuUlJRo7dq1WrVqlb788kurYz169NC9996refPmObxGTU2NMjIydOqpp+rNN99Uu3bt7Pa9++67tWLFCn3zzTd2+xw7dkzHjh2zun7fvn1Z7t5CS9aXaNnmvZbHc9MHaNGEZD+OCIFg7dq1Ki4ubtG5aWlpysjIsHms+f+3V7VowioHV7tU0l3irjoAIKzk55vL+yUlBUyA7kptdEkaM2aMxo0b5+JVqZGO4OXqcve2do/Y8Lvf/U7XXnutwz4DBgxQfHy8Dhw4YNX+888/63//+5/i4+Mdnv/DDz9o/PjxOuWUU/Taa685DNAlKTU1Vffff7+OHTumqKgom32ioqLsHoN7CsurrAImSVq2ea8yh8RTozzMZWVlSVKLAvW8vDx17dpVKSkpVu22/79docwhH2lkP3t1ht8+8XGNzMnoAAAIA6mpAROcN3B1Bt31AF1yXCM9sF4/0FJuBendu3dX9+7dnfYbPXq0vv/+e+3YsUOjRo2SJP373/9WfX29Uh388qipqVFmZqaioqL05ptvqkOHDk6fq6ioSHFxcQThPlJ2sNZuO0E6srKydPbZZ2vz5s3avXu3W+euW7dOX331lSXYlxz9f7vAQZDe4HlJZSKxHAAA/uHKXvRevXr5YCRAcPHKnvTk5GSNHz9ec+bM0ccff6xt27Zp/vz5uuqqqyyZ3fft26czzjhDH3/8sSRzgH7xxRertrZWy5cvV01NjSoqKlRRUaG6ujpJ5jfxzz77rP773/9q9+7devLJJ/Xggw/q5ptv9sbLgA0J3aLdakf4MRgMmjp1qt196n2MRg3buVN9bOxFb7pP3f7/tyUisVyQyc83ZyAOoJJAAADv8c5edIka6QgHXquT/sILL+iMM87QRRddpEsuuUTnnnuunn76acvxn376SV9++aWOHDkiSSooKFB+fr6Ki4s1aNAg9erVy/LRsN+8Xbt2evzxxzV69GiNGDFCTz31lB555BEtXrzYWy8DTYzsF6e56QOs2ualD2AWHc2kpKQ0y/x+UW6uZj/7rKa89ppmP/usLsrNbXZew/613NxcJ//fTiaWc+55mZPLwC+ys6VzzjGXCDrnHPNjAEDIMhqNystzXkrVvdroDaiRjtDnlTrpgY466a1XWF6lsoO1SugWTYAOhxoSyvUxGjX72WebHX929mzts/MHetasWTIYDC78f3O1tvqzkma5+QrQKvn55sC8qe3bA27vJADAM1ypiy61tjb6cUntRQk2BBO/1klH6BvZL05ZKQYCdDiVlZWlWbNmKdHO/cCuhw7ZPXfdunUyGo0u/H9ztbb6bEmXiVJtPrTLTu4Ae+0AgLDh/mRZ49JrsyX9VwToCEUE6QC8zmAwKH3OHJvHDnXtave8AwcOaPny5Vq7dq2Lz9SwBD7NQZ+3xT51H0qyU9veXjsAIOjFxsa61M+9/ej5kpY2aVsqbrwjFBGkA/CN1FRpofUesq1jxthd6t5YcXGxG4G6q7Pqz0s6V/xx9zIb33dlZ7PUHQBCWGFhodM+Y8aMcXM/uqPSa0BocasEGwC0Sk6ODpx7rratWKFDXbu6FKA3KC4uVv/+/ZvVUrdvtaR0mZfD2dOQ/Z2a6l6VkyNlZZmXuCclEaADQAgzGo2WKi32uF8bHQgvBOkAfKrHxInq3KGDPnUh62tT69atU0lJidLT0128+z5L5uQyTZfHNUVNda9LTSU4B4AwsGPHDqd9oqNbUrp3gqR77bQDoYXl7gB8LiMjw5K53V27d+92c596jpzvU5dOzqqTWA4AgJbIzc1VUVGR034tr67UtOwqpdcQmgjSgTBUWF6ltQVGFZZX+W0MBoNBs2bNalZL3VXFxcVavny50yV1Zq7uU5dILAcAgPtcrY0uuZswTjqZ1f3tE48vlfkG/BI3rwMEB+qkUycdYWbJ+hIt27zX8nhu+gAtmpDsxxGZ/7Bv2LDBxYC7uaFDhyorK8vF3q7WVJfMgfrqFo0JAIBw4mpt9DFjxri5Hz1f5gC9qe1iFh3BhjrpAJopLK+yCtAladnmvX6dUZcCeVZ9jVj6DgCAcyUlJU77jBgxogUJ43a52Q4EP4J0IIyUHax1q93XsrKyWrxX3Wg0avny5XrhhRdcDNYbaqo33d/WFG8CAABwxGg0qrKy0mm/UaNGteDqSW62A8GPIB0IIwndbGdTtdfuD62dVXcvsVyqpLfkOLEcbwIAAHDElYzuPXr0aNFNeMnW33MSxiG0EaQDYWRkvzjNTR9g1TYvfYBG9ovz04jsy8rK0sSJE1t8vmeWwPMmAAAAR1zN6H7GGWe04Or5sl1GdUoLrgUED+qkA2Fm0YRkZQ6JV9nBWiV0iw7IAL1BSkqKDh065HK22KYalsC7nlhutaSbZF7iniTnAXq+G30BAAgt3s3oLjnej87fXYQugnQgDI3sFxfQwXljGRkZSk5OblX29+LiYlVVVSkzM9OFpXapcu0Pf7as7+5fKukuF88FACD4ubLMXTJndG/ZUvfjdtrZiobQxnJ3AAGvtfvUpZOz6rm5/9/evUdHXd/5H3+RYIKgCZCAEScouSBRAwRdUsAlUu5StMbzs1bk0o1YUNdutRrcLVrkbAX0Z3vqTxdPDVirLkdcrJcKijdYBaJLgkZMkQQsHSoIARMuLpLk8/tjmHFmMjOZa+Y7mefjHA7Mdz7zne/wzTczr/l8Pu/Pxigcka/hd8711SujsH8AAKwt2GHu4VV0lxzvp7f42c4X4ujeCOkAEkYk1d+dtmzZopqamgiPJFDF9xVi2TYAQHcWyjD38Cq6+5uL/pSkZWHsD0gshHQACSUaveqvvvpqkNXf/elsmN1PRVAHAHRXTU1NQbWz2WxhfrHu78vwtDD2BSQeQjqAhOTsVS8oKAjr8aFVf/dWKuneAPd/LIa+AwC6q7a2tqDalZSUhPkMrI2O5EZIB5CwbDabZs2apYqKCg0cODDkxzvnqYfXq75cjvXVRwRow9B3AED3U1tbG1S71NTUMJ+hVCyLimRGSAeQ8Gw2Wxeuqe6uVNKTnbQJNH8dAIDEUlNTE/T7ZVZWVpjPUinpj263bxZz0ZFMCOkAugWbzaaxY8eG/Xhnr/pzzz0XYljvbOi799C8ajk+eNDDDgBILBs3btSrr74aVNvwl13zVTTuWfG+iWRCSAfQbUyePDni6u8NDQ1hDIF3Dn2f4bXde2hepRxz1eec+fsH4kMHACARhFLRPfxl1yRpvZ/tjExD8iCkA+hWolH9XQpnCHyppNfkCOvPnPnbfWheoLXVvefdAQBgLbt37w66bXjLrkmOL7OX+LmPonFIHoR0AN1SpNXfpXALyzmL3XgXtwnUA/CspCtFrzoAwKrq6+uDahfdYe5OFI1DciGkA+i23Ku/RzIEPrLl2pw66wH4QCzbBgCwopqaGh06dKjTdjNnzoxgmLu/L7MfEEXjkGx6GGNMvA+iq7W0tCgzM1PNzc3KyMiI9+EA6CLr1q1TXV1dRPvIz89XcXGxsrKywgj+lfLfS+BumxK5x6B231HtPXxCQ7L7qGRwv3gfDgAgAhs3bgxqLvrAgQO1cOHCCJ5pthwjy7xZ+z2R9zyEItgc2rMLjwkA4qq8vFyjR4/WG2+8EXaveGNjoxobGyVJBQUFKisrCyGsL5dULukuSYE+8HwuxweS6jP/Hiorf0Bxt2x9vVZu2uO6vaAsT4umF8XxiAAA4aqpqQm6WNywYcMieKZq+Q7ovqaPWQfveYgVhrsDSCrRKiwnhVsJvlSOoe2BisUNVSJWgq/dd9Tjw4okrdy0R7X7jsbpiAAA4QpluTVJKiwsjODZ/FV0nxzBPmOL9zzEEiEdQFKKRmE5p/DmrDsrwPtatk3yXwneunPW9x4+EdJ2AIA1hbLcmhRJsTgpUSu6856HWCKkA0ha0SosJ0VSCd7Xsm2BKsGvkFV71Idk9wlpOwDAmt54442g20ZWLC5xK7rznodYIqQDSHrRHAJfV1cXYlCXOi7b1lnPQaAQHz8lg/tpQVmex7aFZXkU0gGABGK324MeGTZw4ECNGjUqgmdL3IruvOchligcBwBnOAvLNTU1qa6uzlUgLlR1dXW66KKLIvjgUirpXvnvXXCGeOsVlls0vUhTL82h0i0AJKjt27cH3TayYnGS/y+lp0e4367Bex5ihSXYWIINgB92uz2iSvA2m015eXkqLCwMczh9taSlcsxHd6qUo3fBezm3GZIWyyphHQCQeIJdbs0pGtPFOr6fOd/ngO4n2BxKSCekA+hENNZXD325NnfePebVchSR8+VeOZZ6AwAgeM7aKsEaN25cBHPRJc/3NslqI8OAWCCkB0BIBxAqu92uTZs2qaGhIaL9FBcXq7y8PMKj+aMcS7P5s00J+yGnulr6/HNp6FCpNEFfAwAkoFBWKRk/frwmTJgQwbN5957zBTOSQ7A5lMJxABAEZyX4mTNnRrSf8JZr8xZsYblqOQK9NavBd1BZKX3ve9KcOY6/K6273BwAdCc1NTUhvS9FtiZ6lTrWXLHuyiVAPNCTTk86gBBFY/i7FOmcde9eCHfbJK1TQs1Zr652BHNv27Z13x51Rg0AsIBQ56FHNsw90HvXM3KsdAJ0X/SkA0CMlJeXR2W5Nrvdrs2bN6uqqkrPPfdciL3ry+UI4zO8tjt7n70/BP1ZjnnsFu2d/tzPMjz+tic6Rg0AsAC73R5SQI/dmuhS56PEgOTBEmwAEAbncm3RmKcuSQ0NDWpoaAhxznqppNfUsbDcHwM8ZsWZdmmyVIGeoX4+nPnbnsiqq6UVXh9UV6yQysvpUQfQpd54442g29psthitiS45vkDm9x/gREgHEHe1+44m5Bqjznnqdrtdu3fv1p49eyKca+6Ys3706FGVlJQoNTVVWVlZQQyFL5Xnh5vOgu0tbv+2yDD40lLp3ns9w2tlZfcMrYFGDXTH12tFTDUAQp6HPnXq1Aif0d9701OSKiLcN9C9MCedOelAXC1bX6+Vm/a4bi8oy9Oi6UVxPKLIRLq2ui/hVYQPNO/PF4tU1k2G8JSM8++tpLLS88uge++VllvgZx/oQl07D90da6IjubEEWwCEdEQqUXt+raZ231Fd90THDwkv3TY24f9fo1Vczslms2nq1KkhFpirlrRUjvnowdh25m/Wqo0576BYWSkt44NqzPEFScLgfTZ2ampq9OqrrwbdfubMmREOc/fmPUULSB7B5lCGuwMh6m49v/G09/AJv9sT/UNZtOes2+12VVVVKT8/X8XFxSEMg3efs/6tPIe6e/MO9Dcr8Px2hG35cscc9O4+asBqmGqQEHifjZ1Qv0COfB66L95TtAB4I6QDIajdd9Tjg4Mkrdy0R1MvzUn4UBkPQ7L7hLQ90cRiznpjY6MaGxslhTIM3v0D0efyPwzeu8f9WUk95FgWB1FXWkow7GrJVKAwQfE+GzvhjPCKbB46PeZAuFiCDQhBoJ5fhK5kcD8tKMvz2LawLK/bfRCz2WyaMGGCKioqVFFREcaa6L7V1dWpqqpKNTU1+vjjj4P8AsDf0m3et53+KMcHrWq3fwMJylmg0F13LVCYoHifjY2ampqQA/q4ceMieL+qlGPZzzmy9PKfgEUxJ5056QhBd55DHU/JOPcw2nPWnUIrMufeyyE5Pkj5MkOevewWKTIHhCsZChQmKN5noy/U95t+/fqpvLw8goBeJd9Tq7aJHnUkOwrHBUBIRyS858otLMtTJXPlEAa73a6mpibV1dW5hrBHQ3jV4CVpthxD3IPBhy0AscH7bPSE84VwZCO+Aq0s8owc7zNA8iKkB0BIR6SSsecXsWW326NWZE6SRo4cqcsvvzyMD1pz5FkszrsX3ekZOXrgmW8IIPp4n42cs+BoKCJbaq1a/kdkSXy5CxDSAyKkA7CqaIf1goIClZWVhbF0W2fD4GfLM8xTCR4ArOTdd9/V5s2bg24f+VJrf5Tji15fWA8dkAjpARHSAVidsyJ8fX29Dh06FPH+bDab8vLyVFhYGEbvuvfwRe+A7r49cCV4escAILbC+bI3sh50yfHl7npJS3zc95Skigj2DXQfhPQACOkAEkm0i8xF3rv+ufz3lmw783fHYfCsfQwAsbVx40Zt2dKx8F4g48eP14QJEyJ41kDz0OlBB9wFm0NZJx0ALK68vFwXXXSRXn311ajsr6GhQQ0NDcrPz1dxcbGysrKCCOzua60HslS+KsGz9jEAxJbdbg85oEtSYWFhBM9aLd8B/QFJ08UcdCA8hHQASACjRo1SU1NTWB/A/GlsbHRVlQ+td71UjjnovirBexeZWyGpXHsP/6/PPe09fIKQDgARstvtWrduXciPGz58eASV3KslrfZzX74I6ED4COkAkCAmT56soqIi7d69W3v27JHdbo/avkPvXf+jpB4KrhL8Ug3J3i3p0Q73DMnuE8lhA0DSC3dK1PDhw3XdddeF+ayBhrhL3xUeBRAO5qQzJx1Agop2JXhvwQX2YCrBOyxbP1crN/0f1+2FZb1UOf3vYgk3AAhPuAE9skrunS21xjx0wB8KxwVASAfQnUS7ErwvwQ+H9+5d8exdr903VHsPX6Ah2RepZLD7MEnH3HUAQHBqamrCqlUSWQ+6c4j7kz7u+6mkn4gvXQH/COkBENIBdFfRrgTvLdq96578V4YHADhEMooq/IBerY6FQb1tE7+3gcAI6QEQ0gF0Z3a7XU1NTWpra1NtbW1U5667C37+euDedf/bb5Y0RQR2AHAI94vYwsJCjR8/PswicZ3NP3e2YYg70BlCegCEdADJJNa961IwgT3c3nWnm+VZpA4Akofdbtcbb7wR1peusZ1/zhB3IBSE9AAI6QCSjbN3va6uzrXsWqzYbDbl5eWpsLAwQK9NsL3r7mZLul0MhweQTCL5ojWy+eeS48vROQHuZ4g7EApCegCEdADJrKuGw0udFZyLtHedYnMAurf4BPRgfzczxB0IFSE9AEI6AHzHGsPhpeDmPXp7SlKa6FkH0N2EW729X79+Ki8vD3P++Rx5Ti2698zf3iOfFovfuUDoCOkBENIBwFNXDocfO3asJk+e7OdeZw/O85I2hLhnetYBdA8bN27Uli1bwnpsRUVFmAF9tqRnfWxn5Q0gWoLNoSmxOoAjR45o1qxZysjIUN++fVVRUaHjx48HfMxVV12lHj16ePxZsGCBR5t9+/ZpxowZ6t27twYOHKh77rlHra2tsXoZAJAUbDabRowYoZtvvlkVFRX64Q9/qJkzZ4b5QS+wLVu26OWXX/YzzL5Ujg+K68/8HYoVkn4lR9AHgMRUU1MTdkAfN25cmL+3q+Q7oEuOcO783UxAB7pCzHrSp0+fri+//FJPPvmkTp8+rZ/85Cf6h3/4Bz3//PN+H3PVVVdp6NChevDBB13bevfu7fqWoa2tTSNHjlROTo4efvhhffnll5ozZ47mz5+vX//610EfGz3pABC8WA6H77zInPvcyHUKfjj8vZLKRc8PgEQSnyXWvIe4e6M4HBAtcR3uXl9fr0suuUQfffSRrrjiCknShg0bdPXVV8tut2vQoEE+H3fVVVdp5MiR+u1vf+vz/vXr1+sHP/iB/v73v+u8886TJK1cuVKVlZU6dOiQ0tLSgjo+QjoAhKYrhsMXFBSoqKhIqampQSzl9q2kW0LYO0u4AbCucJdYy83N1ZQpU8IM59WS7pIUqNd+tqRnwtg3AF/iGtJXrVqlu+++W0ePHnVta21tVa9evbR27Vq/lSavuuoq7dy5U8YY5eTkaObMmVq8eLF69+4tSbr//vv1yiuvaMeOHa7H7N27V3l5eaqpqVFJSUlQx0dIB4DwddX89c6LzYVaaG6apJtEzzoAK4j0d2lk1duXKrhlLwnoQDQFm0N7xuLJDxw4oIEDB3o+Uc+e6t+/vw4cOOD3cTfddJMuvPBCDRo0SJ988okqKyu1a9curVu3zrVfZw+6k/N2oP2eOnVKp06dct1uaWkJ+TUBABxsNptrDrvzQ+bhw4f1/vvvR/V5GhsbXR9cfQf25XIMaV8vaUkQe9yg74rRMRweQPxEOo1o5syZGjVqVBiP7Gxou9NTkirC2D+AaAgppC9atEjLlweunFtfXx/2wdx6662ufxcXF+v888/XxIkT1djYqPz8/LD3+9BDD2nJkmA+wAEAQuEM7JLU3t4edrGjzrgHduc89szMTKWm9lJW1i2y2b5RaL3qK7za3yxpigjsAGIp3GHt7oYPHx5GQA9maLvTbBHQgfgKKaTffffdmjdvXsA2eXl5ysnJ0VdffeWxvbW1VUeOHFFOTk7Qz1da6vig1NDQoPz8fOXk5OjDDz/0aHPw4EFJCrjf++67T3fddZfrdktLi3Jzc4M+DgBA5yZPnqyioiLt3r1b9fX1OnToUEyex263d/iAm59frOLi/1JWVpNstuGS/p/8Vyr25Vm39izlFrLqaunzz6WhQ6VSvuQAvNntdm3atEkNDQ0R7Se8Ie7B9p5LDHEHrCGkkD5gwAANGDCg03ZjxozR119/re3bt+vyyy+XJL3zzjtqb293Be9gOOeen3/++a79/vu//7u++uor13D6jRs3KiMjQ5dcconf/aSnpys9PT3o5wUAhMfZsz5hwoSYVoX35uhpd/w7P/9sFRf/QllZvWSzPRXG3lbIMRReYjh8ECorpRVuoxLuvVfqZNQdkEyi8bsw/Ort/tY+9zZD0mLxuw6whpguwXbw4EGtXLnStQTbFVdc4VqCbf/+/Zo4caKeeeYZjR49Wo2NjXr++ed19dVXKysrS5988ol+/vOfy2azadOmTZK+W4Jt0KBBWrFihQ4cOKDZs2frlltuYQk2ALAg55z1trY21dfXR9yLFCqbLVN5eT1UWPhpiIF9hjyLKjEc3qfqaul73+u4fds2etSRWGIwGiQaQ9sjr97u4/r0ME7S/xW/1zqq3XdUew+f0JDsPioZ3C/eh4NuIq6F4yTpueee0x133KGJEycqJSVF119/vX73u9+57j99+rR27dqlkydPSpLS0tL01ltv6be//a1OnDih3NxcXX/99frlL3/pekxqaqpee+01LVy4UGPGjFGfPn00d+5cj3XVAQDW4T5nfdSoUbLb7dq9e7f27NkT0QfXYNntzbLbpc2bbbLZfqO8vB7KzLxAqak1ysp6Rjbbfj+P9K567D4cnsDu8vnn/rcT0pEoojgaJJqrX4Rfvd3Jz/XpwtB2f5atr9fKTXtctxeU5WnR9KI4HhGSTcx60q2MnnQAiL+uDuy+2Gzpysv7UoWF/+UW2L170QNJ8sBOTzoSXZR+hqM151wKp/e8Wr6n5vjrSaf3PJDafUd13RMdC+y9dNtYetQRsbj3pAMAEIj7/PWuWnvdm91+SnZ7f23ePP9MYLcpM7OXUlP/dqYInb+edqck72EvLXX0Orr3QlZWEtCROCIYDRKL31uh9Z77Wu/cvfBl6Znb7itZ0Hvemb2HT/jdTkhHV6EnnZ50ALAU93nszc3Nce5p/6vy8vaosLAhiMDuLskCO9XdkajC7EmPdmHM0HvPK+V/2clt6tijThHMYNGTjlgKNocS0gnpAGB58eppd+cM7JmZzUpNbQ+yp11y9GSViw/JQAi68osf7znplZXSsmUeTdy/PKytrY3qF4fB9Z67B20pcEG4Z+ToMQ8BX7R58J6TvrAsT5XMSUcUENIDIKQDQOKyQmB3Ci+4sw47EFA8lvULEFJjtZxk8Muqefead1Y3w7snvbPds4yiL1R3RywQ0gMgpANA92ClwO40duz7mjz5rU5ahfghGkgWFitGGIuAHtqa58Eso+auUtKyTlt9t3tr/X8D3R2F4wAA3Z6z+NyIESPivia705YtV6pnz9OdzGP/XMwZBXywyLJ+drtd27dvj1pAHzhwoIYNG6bCwsIgwrn77wN/y6h596bPkLRYIf/+sMj/NwBPhHQAQLfgb012Sdq/f3+X9rRv3jxBmzdPUH7+5you/lRtbSlew+GHurX2HsqaZEXnAHdDh4a2PUpi+SVfaBXbff0+8GXxmT8RfrkXp/9vAIEx3J3h7gCQFKzS056f36oLLvi+JKmw8FvZbNMCtCawIwkFUcgtmuI/59zZc/6tpFt83D9b0h/dboc4pL0zXfz/DSQz5qQHQEgHAMSzp91dQcEuFRXVq7k5U5ICFKFzFpxjaDySQIyrjTuv//r6eh06dChq+y0oKNBll12mrKysTsK58zreKM8A7ssz+m7oe4yu+25a3Z3ib7AaQnoAhHQAgDdnT/vhw4f1/vvvx/twJMnHcPnRstmecmtBTzvQGfdRNM3NzdqzZ09Ul1BzmjlzpkaNGuXnXvcv19bJ/xrnvlBoMhzey6gtKMvTIpZRQ5xROA4AgBC4z2lvb2/Xli1b4nxEUmPjUDU2es4Nzc+/SRdc4OhhLyx8Vzbbs2fuoacdEehmPanOnvJYBXJv48aN8xHQQ+kt96dSXMehq9131COgS9LKTXs09dIcetSREAjpAAB4mTx5soqKiiwxHN6be3DfvHmC23D5akk/U2bmZrfh8hNETzs61U3Wye7qYJ6bm6shQ4Z4VWyPRjB/SlKauG7Dt/fwCb/bCelIBAx3Z7g7ACAI7kNmU1NTLbU2uz/5+Z+7et0zM8cqNfVHyso6IJvtKxEAIClh18l2rymRmZnZpcUgOxaEi0Ywd4pyUbgkVbvvqK57ouNoqJduG0tIR1wx3B0AgChyHw4vyWNtdqsG9o7D5f8kSbLZ/qq8vCplZo5Vc/MlkppUWDhMNtvUeBwm4ikB1snuqjnlgXTsNa+W9K6iE8xnS5osvjiLnpLB/bSgLM9jyPvCsjwCOhIGPen0pAMAosAKQSJSBQWtKiq6Ts3Nn0lqUmbmBUpNLQyiUjUSlsV60q10Hfkezi51XMs8VJWSrhO1I2KP6u6wGqq7B0BIBwB4i8WHOSsFjkjl52epuDhFbW0D1dycJckxzDg1NbXTEM8H5diL6P84TutkW3EKyXdLqPmbFlItyceXGp2itxwAIT0gQjoAwF1XLtXjPZfWKuEkUvn5+brgggskffe62tra9GzdMa2rP+5qxzJI0ReVn98YVnf3/rJKslYxRkkqLDxb48ePODPlw7un3LlyguQY2j4nyL0SzAF4IqQHQEgHADhZpcBQd+p1dzrU3kevneoYFpdNzFLRwLM9QlvHIcUIhlV+fqXE+gKqoCBLgwZdKuktFRb+QTbb/jP33CzpWR+PcK5V3llPOsEcgH8UjgMAIAhWWarHuzDdhAkTEj64N7en+9z+580faVfPIx7bNm/eLJvNpry8PI+eeGeID3ZofbLpyp9fXyE8UX42CwsLNWzYp0pN/fOZ5Qn3y3cg9xXQJcf88dIzf+6VZ087wRxAdBHSAQBJbUh2n5C2dyV/wT1ReiszU06FtN1utwcV9PLz81VcXNwhxPv6d3fvoY/059f758n7S5FECeG+5Ob+VUOG7FFhYYNstglyBvDafUP1Yc0EDcn+UCWDg92b+yoJyyWVi8JvAGKF4e4MdweApOc9p3dhWZ4qE2zetFXn/X707QX6tO181+3i1C91Rdr+AI+IvrFjx2ry5Mld+pxdKdyf340bN2rLlo5D5RNRYWGrhg17Tc3NmWduN7gNYf/OsvVztXLT/3HdXlC2Voum/8Gr1Wx5LqvG2uUAooM56QEQ0gEA3rprBXLvCtrx6Bk91N5Hze3pykw5pQEpvodnh+sCu11ZTU1qysrS/gA95ldeeaVSUlIkBe4xDvb+eA6999X73fh1m1pML9ky01TQr2enIwza29v1/vvvd/mxR9N3S6R9K5ttWqfta/cN1XVPPNph+0u33aWSwc714p2BvFr0lAOINkJ6AIR0AAASq9CXLxM3btSVH3zguv3+uHF6u4t7zEMZeh/uFwLu/66vr1dDQ0OXvkYrcM4pb27ecuZ2g2y2WXIMPQ+u4vq6ml/qrhc6Fn179IZzVD5qnwjkAGKNwnEAACAg7znvkjRixAifQ+etFhAvsNs9ArokXfnBB/pLUVHAHvVoa2xsTJgvNRJJQcHnGjTIMVy9sHCMbLZ8SbO8Wq2QY274UHWuUkOy75LUcXj/kOzhksoiOl4AiCZCOgAA8OArvEvSqFGj/BYa6+r571lNTX63d2VIR/ichd0yM8cqNfUKtbUtVWpqu1v1dadNknyvFOAYkj5bHSuuV0q6Tu5D1ksGO9aQ956/352mtwDoHgjpAAAgaP4CvOR//rvkCPR/+9vftGPHjqgcR1NWVkjbEV8jR16g3NzH/RR22yTpAUk7wtizsxfdX8V1z+Hri6YXaeqlOd2y/gSA7oOQDgAAoiJQgJccPfG9e/eOSkXx/Tab3h83rsOcdHrRrWfcuHGaNOlLhRfCnaZL+kYde8vdQ3ipgplTXjK4H+EcgKVROI7CcQAAdCl/c97Dmf8ebHV3xE5ubrqGDNmgzMxmV095ZmbzmaHrd8hmmy9HtfSORdu+s03SOnmGcCf3JdCoug4gcVHdPQBCOgAA1udv/vt3VdB3q7n5U0nS/v3Zamz0PU8d4Sks3KVhw+o9gndz8zxJw72Wodsv/wF8m74L05UKPoR/KylNhHEA3QkhPQBCOgAA3Y9nD/1nkpqUmSmlpp6ltrbTcmT8LGVmXuIV+F9UXd1f1dgYTJXwxONcT9z/cm+fSXrKoyfcc864O/fQ7c5XAHcP306EcADJi5AeACEdAAB4qpbdvl5NTVJbWz+PQN+xCN5G13rdzmHdbW0pXj3Ozn+PVXPz5DP/jnyd9FDvLywsDFgn4Dv+erm923iHbs//Q2n9mX9PF+EbADwR0gMgpAMAgMh49wh/K+lvZ+7LVWL2EruHbOdroMcbAKIl2BxKdXcASEC1+46yhBAQV8FVEk8s3fE1AUDiIaQDQIJZtr5eKzftcd1eUJanRdOL4nhEAAAAiJaUeB8AACB4tfuOegR0SVq5aY9q9x2N0xEBAAAgmgjpAJBA9h4+EdJ2AAAAJBZCOgAkkCHZfULaDgAAgMRCSAeABFIyuJ8WlOV5bFtYlkfxOAAAgG6CwnEAkGAWTS/S1EtzqO4OAADQDRHSASABlQzuRzgHAADohhjuDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBGEdAAAAAAALIKQDgAAAACARRDSAQAAAACwCEI6AAAAAAAWQUgHAAAAAMAiCOkAAAAAAFgEIR0AAAAAAIsgpAMAAAAAYBE9430AAAAAQDKp3XdUew+f0JDsPioZ3C/ehwPAYmLWk37kyBHNmjVLGRkZ6tu3ryoqKnT8+HG/7b/44gv16NHD55+1a9e62vm6f82aNbF6GQAAAEDULFtfr+ue2KK7XvhY1z2xRcvW18f7kABYTMxC+qxZs7Rz505t3LhRr732mjZv3qxbb73Vb/vc3Fx9+eWXHn+WLFmic845R9OnT/dou3r1ao92P/zhD2P1MgAAAICoqN13VCs37fHYtnLTHtXuOxqnIwJgRTEZ7l5fX68NGzboo48+0hVXXCFJeuyxx3T11VfrkUce0aBBgzo8JjU1VTk5OR7bXnrpJd1www0655xzPLb37du3Q1sAAADAyvYePuF3O8PeATjFpCd969at6tu3ryugS9KkSZOUkpKi6urqoPaxfft27dixQxUVFR3uu/3225Wdna3Ro0dr1apVMsYE3NepU6fU0tLi8QcAgGRVu++o1tXY6b0DutiQ7D4hbQeQnGLSk37gwAENHDjQ84l69lT//v114MCBoPZRVVWloqIijR071mP7gw8+qO9///vq3bu33nzzTd122206fvy47rzzTr/7euihh7RkyZLQXwgAAN3MsvX1HsNtF5TladH0ojgeEZA8Sgb304KyPI9rcGFZHr3oADyEFNIXLVqk5cuXB2xTXx958YtvvvlGzz//vBYvXtzhPvdtJSUlOnHihB5++OGAIf2+++7TXXfd5brd0tKi3NzciI8TAIBE4m8+7NRLcwgJQBdZNL1IUy/Nobo7AL9CCul333235s2bF7BNXl6ecnJy9NVXX3lsb21t1ZEjR4KaS/7iiy/q5MmTmjNnTqdtS0tLtXTpUp06dUrp6ek+26Snp/u9DwCAZMF8WMAaSgb345oD4FdIIX3AgAEaMGBAp+3GjBmjr7/+Wtu3b9fll18uSXrnnXfU3t6u0tLSTh9fVVWla665Jqjn2rFjh/r160cIBwCgE8yH7Tqsgw0ACFdM5qQXFRVp2rRpmj9/vlauXKnTp0/rjjvu0I033uiq7L5//35NnDhRzzzzjEaPHu16bENDgzZv3qzXX3+9w35fffVVHTx4UN/73vfUq1cvbdy4Ub/+9a/1i1/8IhYvAwCAboX5sF2Def8AgEjEJKRL0nPPPac77rhDEydOVEpKiq6//nr97ne/c91/+vRp7dq1SydPnvR43KpVq2Sz2TRlypQO+zzrrLP0+OOP6+c//7mMMSooKNCjjz6q+fPnx+plAADQrTAfNraY9w8AiFQP09n6Zd1QS0uLMjMz1dzcrIyMjHgfDgAA6CbW1dh11wsfd9j+6A0jVD7KFocjAgBYRbA5NCbrpAMAACQj5v0DACJFSAcAAIgS57x/d8z7BwCEImZz0gEAAJIR8/4BAJEgpAMAAEQZ62ADAMLFcHcAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYRM94H0A8GGMkSS0tLXE+EgAAAABAMnDmT2ce9ScpQ/qxY8ckSbm5uXE+EgAAAABAMjl27JgyMzP93t/DdBbju6H29nb9/e9/17nnnqsePXrE+3ASRktLi3Jzc/W3v/1NGRkZ8T4chIBzl7g4d4mLc5fYOH+Ji3OXuDh3iYtzFxxjjI4dO6ZBgwYpJcX/zPOk7ElPSUmRzWaL92EkrIyMDC6+BMW5S1ycu8TFuUtsnL/ExblLXJy7xMW561ygHnQnCscBAAAAAGARhHQAAAAAACyCkI6gpaen64EHHlB6enq8DwUh4twlLs5d4uLcJTbOX+Li3CUuzl3i4txFV1IWjgMAAAAAwIroSQcAAAAAwCII6QAAAAAAWAQhHQAAAAAAiyCkAwAAAABgEYR0uBw5ckSzZs1SRkaG+vbtq4qKCh0/ftxv+y+++EI9evTw+Wft2rWudr7uX7NmTVe8pKQR6rmTpKuuuqrDeVmwYIFHm3379mnGjBnq3bu3Bg4cqHvuuUetra2xfClJKdTzd+TIEf3zP/+zLr74Yp199tkaPHiw7rzzTjU3N3u049qLvscff1wXXXSRevXqpdLSUn344YcB269du1bDhg1Tr169VFxcrNdff93jfmOM7r//fp1//vk6++yzNWnSJO3evTuWLyFphXLufv/73+sf//Ef1a9fP/Xr10+TJk3q0H7evHkdrq9p06bF+mUkpVDO3dNPP93hvPTq1cujDddd1wrl/Pn6bNKjRw/NmDHD1YZrL/Y2b96smTNnatCgQerRo4f+9Kc/dfqY9957T6NGjVJ6eroKCgr09NNPd2gT6ntoUjPAGdOmTTMjRoww27ZtM//93/9tCgoKzI9//GO/7VtbW82XX37p8WfJkiXmnHPOMceOHXO1k2RWr17t0e6bb77pipeUNEI9d8YYU1ZWZubPn+9xXpqbm133t7a2mssuu8xMmjTJ1NbWmtdff91kZ2eb++67L9YvJ+mEev7q6upMeXm5eeWVV0xDQ4N5++23TWFhobn++us92nHtRdeaNWtMWlqaWbVqldm5c6eZP3++6du3rzl48KDP9h988IFJTU01K1asMJ999pn55S9/ac466yxTV1fnarNs2TKTmZlp/vSnP5mPP/7YXHPNNWbIkCGcpygL9dzddNNN5vHHHze1tbWmvr7ezJs3z2RmZhq73e5qM3fuXDNt2jSP6+vIkSNd9ZKSRqjnbvXq1SYjI8PjvBw4cMCjDddd1wn1/DU1NXmcu08//dSkpqaa1atXu9pw7cXe66+/bv7t3/7NrFu3zkgyL730UsD2e/bsMb179zZ33XWX+eyzz8xjjz1mUlNTzYYNG1xtQv1ZSHaEdBhjjPnss8+MJPPRRx+5tq1fv9706NHD7N+/P+j9jBw50vzTP/2Tx7ZgLm6EL9xzV1ZWZn72s5/5vf/11183KSkpHh9u/uM//sNkZGSYU6dOReXYEb1r74UXXjBpaWnm9OnTrm1ce9E1evRoc/vtt7tut7W1mUGDBpmHHnrIZ/sbbrjBzJgxw2NbaWmp+elPf2qMMaa9vd3k5OSYhx9+2HX/119/bdLT081//ud/xuAVJK9Qz5231tZWc+6555o//OEPrm1z58411157bbQPFV5CPXerV682mZmZfvfHdde1Ir32fvOb35hzzz3XHD9+3LWNa69rBfNZ4t577zWXXnqpx7Yf/ehHZurUqa7bkf4sJBuGu0OStHXrVvXt21dXXHGFa9ukSZOUkpKi6urqoPaxfft27dixQxUVFR3uu/3225Wdna3Ro0dr1apVMsZE7diTXSTn7rnnnlN2drYuu+wy3XfffTp58qTHfouLi3Xeeee5tk2dOlUtLS3auXNn9F9IkorGtSdJzc3NysjIUM+ePT22c+1Fx7fffqvt27dr0qRJrm0pKSmaNGmStm7d6vMxW7du9WgvOa4hZ/u9e/fqwIEDHm0yMzNVWlrqd58IXTjnztvJkyd1+vRp9e/f32P7e++9p4EDB+riiy/WwoUL1dTUFNVjT3bhnrvjx4/rwgsvVG5urq699lqP9yyuu64TjWuvqqpKN954o/r06eOxnWvPWjp7v4vGz0Ky6dl5EySDAwcOaODAgR7bevbsqf79++vAgQNB7aOqqkpFRUUaO3asx/YHH3xQ3//+99W7d2+9+eabuu2223T8+HHdeeedUTv+ZBbuubvpppt04YUXatCgQfrkk09UWVmpXbt2ad26da79ugd0Sa7bwf5MoHPRuPYOHz6spUuX6tZbb/XYzrUXPYcPH1ZbW5vPa+Ivf/mLz8f4u4ac59X5d6A2iFw4585bZWWlBg0a5PEBc9q0aSovL9eQIUPU2Niof/3Xf9X06dO1detWpaamRvU1JKtwzt3FF1+sVatWafjw4WpubtYjjzyisWPHaufOnbLZbFx3XSjSa+/DDz/Up59+qqqqKo/tXHvW4+/9rqWlRd98842OHj0a8e/hZENI7+YWLVqk5cuXB2xTX18f8fN88803ev7557V48eIO97lvKykp0YkTJ/Twww8TFDoR63PnHuiKi4t1/vnna+LEiWpsbFR+fn7Y+4VDV117LS0tmjFjhi655BL96le/8riPaw+I3LJly7RmzRq99957HgXIbrzxRte/i4uLNXz4cOXn5+u9997TxIkT43GokDRmzBiNGTPGdXvs2LEqKirSk08+qaVLl8bxyBCqqqoqFRcXa/To0R7bufaQDAjp3dzdd9+tefPmBWyTl5ennJwcffXVVx7bW1tbdeTIEeXk5HT6PC+++KJOnjypOXPmdNq2tLRUS5cu1alTp5Sent5p+2TVVefOqbS0VJLU0NCg/Px85eTkdKi6efDgQUkKab/JqivO37FjxzRt2jSde+65eumll3TWWWcFbM+1F77s7Gylpqa6rgGngwcP+j1POTk5Ads7/z548KDOP/98jzYjR46M4tEnt3DOndMjjzyiZcuW6a233tLw4cMDts3Ly1N2drYaGhoIClESyblzOuuss1RSUqKGhgZJXHddKZLzd+LECa1Zs0YPPvhgp8/DtRd//t7vMjIydPbZZys1NTXiaznZMCe9mxswYICGDRsW8E9aWprGjBmjr7/+Wtu3b3c99p133lF7e7srvAVSVVWla665RgMGDOi07Y4dO9SvXz9CQie66tw57dixQ5JcH1rGjBmjuro6jwC5ceNGZWRk6JJLLonOi+zGYn3+WlpaNGXKFKWlpemVV17psMSQL1x74UtLS9Pll1+ut99+27Wtvb1db7/9tkevnbsxY8Z4tJcc15Cz/ZAhQ5STk+PRpqWlRdXV1X73idCFc+4kacWKFVq6dKk2bNjgUTPCH7vdrqamJo/gh8iEe+7ctbW1qa6uznVeuO66TiTnb+3atTp16pRuvvnmTp+Hay/+Onu/i8a1nHTiXbkO1jFt2jRTUlJiqqurzfvvv28KCws9loGy2+3m4osvNtXV1R6P2717t+nRo4dZv359h32+8sor5ve//72pq6szu3fvNk888YTp3bu3uf/++2P+epJJqOeuoaHBPPjgg+Z//ud/zN69e83LL79s8vLyzPjx412PcS7BNmXKFLNjxw6zYcMGM2DAAJZgi4FQz19zc7MpLS01xcXFpqGhwWMZmtbWVmMM114srFmzxqSnp5unn37afPbZZ+bWW281ffv2da2AMHv2bLNo0SJX+w8++MD07NnTPPLII6a+vt488MADPpdg69u3r3n55ZfNJ598Yq699lqWgoqBUM/dsmXLTFpamnnxxRc9ri/n8qLHjh0zv/jFL8zWrVvN3r17zVtvvWVGjRplCgsLzf/+7//G5TV2V6GeuyVLlpg33njDNDY2mu3bt5sbb7zR9OrVy+zcudPVhuuu64R6/pyuvPJK86Mf/ajDdq69rnHs2DFTW1tramtrjSTz6KOPmtraWvPXv/7VGGPMokWLzOzZs13tnUuw3XPPPaa+vt48/vjjPpdgC/SzAE+EdLg0NTWZH//4x+acc84xGRkZ5ic/+YnHeud79+41ksy7777r8bj77rvP5Obmmra2tg77XL9+vRk5cqQ555xzTJ8+fcyIESPMypUrfbZF+EI9d/v27TPjx483/fv3N+np6aagoMDcc889HuukG2PMF198YaZPn27OPvtsk52dbe6++26PJb4QHaGev3fffddI8vln7969xhiuvVh57LHHzODBg01aWpoZPXq02bZtm+u+srIyM3fuXI/2L7zwghk6dKhJS0szl156qfnzn//scX97e7tZvHixOe+880x6erqZOHGi2bVrV1e8lKQTyrm78MILfV5fDzzwgDHGmJMnT5opU6aYAQMGmLPOOstceOGFZv78+XzYjJFQzt2//Mu/uNqed9555uqrrzY1NTUe++O661qh/t78y1/+YiSZN998s8O+uPa6hr/PGc5zNXfuXFNWVtbhMSNHjjRpaWkmLy/PY217p0A/C/DUwxjW4wEAAAAAwAqYkw4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIgjpAAAAAABYBCEdAAAAAACLIKQDAAAAAGARhHQAAAAAACyCkA4AAAAAgEUQ0gEAAAAAsAhCOgAAAAAAFkFIBwAAAADAIv4/uAEbkgp5GJUAAAAASUVORK5CYII=\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = np.linspace(-1, 1.5, 700)\n",
    "t2 = np.linspace(-1, 1.5, 700)\n",
    "\n",
    "coordinates = np.array([[x, y] for x in t1 for y in t2])\n",
    "\n",
    "mapped_cord_x = feature_mapping(np.array(coordinates), degree=6)  # this is a dataframe\n",
    "prob = logistic_reg2.get_inner_product(mapped_cord_x)\n",
    "sk_prob_coor = sk_lr2.predict_proba(mapped_cord_x)\n",
    "idx1 = np.where(abs(prob[0,:])<5e-3)\n",
    "idx2 = np.where(np.logical_and(sk_prob_coor[:,0] >= 0.495, sk_prob_coor[:,0] <= 0.505))\n",
    "my_bd = coordinates[idx1]\n",
    "sk_bd = coordinates[idx2]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=my_bd[:, 0], y=my_bd[:, 1], s=10, color=\"yellow\", label=\"My Decision Boundary\")\n",
    "ax.scatter(x=sk_bd[:, 0], y=sk_bd[:, 1], s=10, color=\"gray\", label=\"Sklearn Decision Boundary\")\n",
    "ax.scatter(x=positive_data[:, 0], y=positive_data[:, 1], s=10, color=\"red\",label=\"positive\")\n",
    "ax.scatter(x=negative_data[:, 0], y=negative_data[:, 1], s=10, label=\"negative\")\n",
    "ax.set_title('Train Set')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}