{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1 逻辑回归\n",
    "### Logistic函数 (Sigmoid)\n",
    "### 为什么Sigmoid函数可以表示二分类概率？详见伯努利分布和指数分布族\n",
    "g 代表一个常用的逻辑函数（logistic function）为S形函数（Sigmoid function），公式为： $$g\\left( z \\right)=\\frac{1}{1+{{e}^{-z}}}$$\n",
    "合起来，我们得到逻辑回归模型的假设函数：\n",
    "$${{h}_{\\theta }}\\left( x \\right)=\\frac{1}{1+{{e}^{-{{\\theta}^{T}}X}}}$$\n",
    "### 损失函数\n",
    "### 关于交叉熵详见Liu II\n",
    "Binary Cross Entropy\n",
    "$$loss=-(y\\log{\\hat{y}}+(1-y)\\log{(1-\\hat{y})})$$\n",
    "$$J(\\theta)=-\\frac{1}{m}\\sum_{i=1}^{m}{(y\\log{h_{\\theta}(x)}-(1-y)\\log{(1-h_{\\theta}(x))})}$$\n",
    "### 梯度下降\n",
    "$$\\theta_{j}=\\theta_{j}-\\alpha\\frac{1}{m}\\sum_{i=1}^{m}{(h_{\\theta}(x^{(i)})-y^{(i)})x_{j}^{(i)}}$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from LogisticRegression import sigmoid\n",
    "\n",
    "nums = np.arange(-5, 5, step=0.1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(nums, sigmoid(nums), 'r')\n",
    "ax.set_title(\"Sigmoid Function\")\n",
    "ax.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "加载数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[34.62365962, 78.02469282,  0.        ],\n       [30.28671077, 43.89499752,  0.        ],\n       [35.84740877, 72.90219803,  0.        ],\n       [60.18259939, 86.3085521 ,  1.        ],\n       [79.03273605, 75.34437644,  1.        ],\n       [45.08327748, 56.31637178,  0.        ],\n       [61.10666454, 96.51142588,  1.        ],\n       [75.02474557, 46.55401354,  1.        ],\n       [76.0987867 , 87.42056972,  1.        ],\n       [84.43281996, 43.53339331,  1.        ],\n       [95.86155507, 38.22527806,  0.        ],\n       [75.01365839, 30.60326323,  0.        ],\n       [82.30705337, 76.4819633 ,  1.        ],\n       [69.36458876, 97.71869196,  1.        ],\n       [39.53833914, 76.03681085,  0.        ],\n       [53.97105215, 89.20735014,  1.        ],\n       [69.07014406, 52.74046973,  1.        ],\n       [67.94685548, 46.67857411,  0.        ],\n       [70.66150955, 92.92713789,  1.        ],\n       [76.97878373, 47.57596365,  1.        ],\n       [67.37202755, 42.83843832,  0.        ],\n       [89.67677575, 65.79936593,  1.        ],\n       [50.53478829, 48.85581153,  0.        ],\n       [34.21206098, 44.2095286 ,  0.        ],\n       [77.92409145, 68.97235999,  1.        ],\n       [62.27101367, 69.95445795,  1.        ],\n       [80.19018075, 44.82162893,  1.        ],\n       [93.1143888 , 38.80067034,  0.        ],\n       [61.83020602, 50.25610789,  0.        ],\n       [38.7858038 , 64.99568096,  0.        ],\n       [61.37928945, 72.80788731,  1.        ],\n       [85.40451939, 57.05198398,  1.        ],\n       [52.10797973, 63.12762377,  0.        ],\n       [52.04540477, 69.43286012,  1.        ],\n       [40.23689374, 71.16774802,  0.        ],\n       [54.63510555, 52.21388588,  0.        ],\n       [33.91550011, 98.86943574,  0.        ],\n       [64.17698887, 80.90806059,  1.        ],\n       [74.78925296, 41.57341523,  0.        ],\n       [34.18364003, 75.23772034,  0.        ],\n       [83.90239366, 56.30804622,  1.        ],\n       [51.54772027, 46.85629026,  0.        ],\n       [94.44336777, 65.56892161,  1.        ],\n       [82.36875376, 40.61825516,  0.        ],\n       [51.04775177, 45.82270146,  0.        ],\n       [62.22267576, 52.06099195,  0.        ],\n       [77.19303493, 70.4582    ,  1.        ],\n       [97.77159928, 86.72782233,  1.        ],\n       [62.0730638 , 96.76882412,  1.        ],\n       [91.5649745 , 88.69629255,  1.        ],\n       [79.94481794, 74.16311935,  1.        ],\n       [99.27252693, 60.999031  ,  1.        ],\n       [90.54671411, 43.39060181,  1.        ],\n       [34.52451385, 60.39634246,  0.        ],\n       [50.28649612, 49.80453881,  0.        ],\n       [49.58667722, 59.80895099,  0.        ],\n       [97.64563396, 68.86157272,  1.        ],\n       [32.57720017, 95.59854761,  0.        ],\n       [74.24869137, 69.82457123,  1.        ],\n       [71.79646206, 78.45356225,  1.        ],\n       [75.39561147, 85.75993667,  1.        ],\n       [35.28611282, 47.02051395,  0.        ],\n       [56.2538175 , 39.26147251,  0.        ],\n       [30.05882245, 49.59297387,  0.        ],\n       [44.66826172, 66.45008615,  0.        ],\n       [66.56089447, 41.09209808,  0.        ],\n       [40.45755098, 97.53518549,  1.        ],\n       [49.07256322, 51.88321182,  0.        ],\n       [80.27957401, 92.11606081,  1.        ],\n       [66.74671857, 60.99139403,  1.        ],\n       [32.72283304, 43.30717306,  0.        ],\n       [64.03932042, 78.03168802,  1.        ],\n       [72.34649423, 96.22759297,  1.        ],\n       [60.45788574, 73.0949981 ,  1.        ],\n       [58.84095622, 75.85844831,  1.        ],\n       [99.8278578 , 72.36925193,  1.        ],\n       [47.26426911, 88.475865  ,  1.        ],\n       [50.4581598 , 75.80985953,  1.        ],\n       [60.45555629, 42.50840944,  0.        ],\n       [82.22666158, 42.71987854,  0.        ],\n       [88.91389642, 69.8037889 ,  1.        ],\n       [94.83450672, 45.6943068 ,  1.        ],\n       [67.31925747, 66.58935318,  1.        ],\n       [57.23870632, 59.51428198,  1.        ],\n       [80.366756  , 90.9601479 ,  1.        ],\n       [68.46852179, 85.5943071 ,  1.        ],\n       [42.07545454, 78.844786  ,  0.        ],\n       [75.47770201, 90.424539  ,  1.        ],\n       [78.63542435, 96.64742717,  1.        ],\n       [52.34800399, 60.76950526,  0.        ],\n       [94.09433113, 77.15910509,  1.        ],\n       [90.44855097, 87.50879176,  1.        ],\n       [55.48216114, 35.57070347,  0.        ],\n       [74.49269242, 84.84513685,  1.        ],\n       [89.84580671, 45.35828361,  1.        ],\n       [83.48916274, 48.3802858 ,  1.        ],\n       [42.26170081, 87.10385094,  1.        ],\n       [99.31500881, 68.77540947,  1.        ],\n       [55.34001756, 64.93193801,  1.        ],\n       [74.775893  , 89.5298129 ,  1.        ]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt(fname='ex2data1.txt',delimiter=\",\")\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看数据集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "positive_data_idx= np.where(data[:,2]==1)\n",
    "positive_data = data[positive_data_idx]\n",
    "negative_data_idx= np.where(data[:, 2] == 0)\n",
    "negative_data = data[negative_data_idx]\n",
    "ax.scatter(x=positive_data[:, 0], y=positive_data[:, 1], s=10, color=\"red\",label=\"positive\")\n",
    "ax.scatter(x=negative_data[:, 0], y=negative_data[:, 1], s=10, label=\"negative\")\n",
    "ax.set_title(\"Dataset\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "划分训练集、验证集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y = train_test_split(data[:, :-1], data[:, -1], test_size=0.2)\n",
    "# train_x, val_x, train_y, val_y = data[:, :-1], data[:, :-1], data[:, -1], data[:, -1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=train_x[:,0], y=train_x[:,1], s=10, label=\"Train\")\n",
    "ax.scatter(x=val_x[:,0], y=val_x[:,1], s=10, color=\"red\", label=\"Validation\")\n",
    "ax.set_title('Dataset for Train and Validation')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看训练集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_train_data = train_x[np.where(train_y[:]==1)]\n",
    "negative_train_data = train_x[np.where(train_y[:]==0)]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=positive_train_data[:,0], y=positive_train_data[:,1], s=10, label=\"Positive\")\n",
    "ax.scatter(x=negative_train_data[:,0], y=negative_train_data[:,1], s=10, label=\"Negative\")\n",
    "ax.set_title('Train Set')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看验证集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9IAAAKqCAYAAADWlWbGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHNUlEQVR4nO3dfZzVdYH3//dwN47AACIyIDcOQoKuGspeBmiU4iJrVurlejO13mYapVBuofvzLlPU3crVNrHWy1sotSs1KzMkpdVYQ8O0MJVAkRS4JJgREEQ4vz98eHSCki8CZ2Cez8fjPPR8vt9zzmfmfD344ntzqkqlUikAAADAJmlT6QkAAADA9kRIAwAAQAFCGgAAAAoQ0gAAAFCAkAYAAIAChDQAAAAUIKQBAACgACENAAAABQhpAAAAKEBIA8D78MILL6Sqqio333xzeeySSy5JVVXVJj2+qqoql1xyyRad00c+8pF85CMf2aLPCQC8Q0gD0Gp8/OMfz84775zXXnvtr67T0NCQDh06ZOnSpdtwZsXNmTMnl1xySV544YVKT6WZF154Iaeeemr23HPP7LTTTqmrq8uHP/zhXHzxxZv1fD/96U+3+F80AMD7JaQBaDUaGhry+uuv5+67797o8lWrVuXee+/NEUccke7du2/26/x//9//l9dff32zH78p5syZk0svvXSjIf3zn/88P//5z7fq62/M3LlzM3To0DzwwAM58cQT861vfSvjxo1L9+7dc9VVV23Wc/70pz/NpZdeuoVnCgDvT7tKTwAAtpWPf/zj6dy5c6ZOnZp//ud/3mD5vffem5UrV6ahoeF9vU67du3Srl3l/ojt0KFDRV73m9/8ZlasWJEnn3wy/fv3b7ZsyZIlFZkTAGwN9kgD0GrU1NTkmGOOyfTp0zcadlOnTk3nzp3z8Y9/PH/+859z3nnnZd99902nTp1SW1ubsWPH5re//e17vs7GzpFes2ZNJkyYkB49epRfY+HChRs89sUXX8znPve57LXXXqmpqUn37t1z3HHHNdvzfPPNN+e4445Lknz0ox9NVVVVqqqq8vDDDyfZ+DnSS5Ysyemnn56ePXtmp512yv77759bbrml2Tpvn+/97//+7/nOd76TPffcM9XV1fn7v//7zJo16z1/7j/+8Y/p06fPBhGdJLvtttsGY/fff38OOeSQdOzYMZ07d86RRx6Z3//+9+Xlp5xySv7zP/8zSco/46aeew4AW5M90gC0Kg0NDbnlllty55135vOf/3x5/M9//nP5kOSampr8/ve/zz333JPjjjsu9fX1Wbx4cW644YaMGjUqc+bMSe/evQu97hlnnJHbb789J510UkaMGJFf/OIXOfLIIzdYb9asWfnVr36VE044IX369MkLL7yQ66+/Ph/5yEcyZ86c7Lzzzvnwhz+cc845J9dee20uuOCCDBkyJEnK//xLr7/+ej7ykY9k7ty5+fznP5/6+vrcddddOeWUU7J8+fKce+65zdafOnVqXnvttXz2s59NVVVVrr766hxzzDGZN29e2rdv/1d/xv79++fBBx/ML37xixx66KF/8/dx22235eSTT86YMWNy1VVXZdWqVbn++utz8MEHZ/bs2dljjz3y2c9+Ni+//HKmTZuW22677b1+xQCw7ZQAoBV58803S7169SoNHz682fjkyZNLSUoPPPBAqVQqlVavXl1at25ds3Xmz59fqq6uLn31q19tNpakdNNNN5XHLr744tK7/4h98sknS0lKn/vc55o930knnVRKUrr44ovLY6tWrdpgzjNnziwlKd16663lsbvuuquUpPTQQw9tsP6oUaNKo0aNKt+/5pprSklKt99+e3nsjTfeKA0fPrzUqVOnUlNTU7OfpXv37qU///nP5XXvvffeUpLSfffdt8Frvdvvfve7Uk1NTSlJ6YMf/GDp3HPPLd1zzz2llStXNlvvtddeK3Xt2rX0mc98ptn4okWLSl26dGk2Pm7cuJL/XQGgpXFoNwCtStu2bXPCCSdk5syZzQ6Xnjp1anr27JnDDjssSVJdXZ02bd76Y3LdunVZunRpOnXqlL322iu/+c1vCr3mT3/60yTJOeec02x8/PjxG6xbU1NT/ve1a9dm6dKlGThwYLp27Vr4dd/9+nV1dTnxxBPLY+3bt88555yTFStWZMaMGc3WP/7449OtW7fy/UMOOSRJMm/evL/5Ovvss0+efPLJfOpTn8oLL7yQ//iP/8gnP/nJ9OzZM9/97nfL602bNi3Lly/PiSeemFdffbV8a9u2bQ466KA89NBDm/VzAsC2IqQBaHXevpjY1KlTkyQLFy7Mf//3f+eEE05I27ZtkyTr16/PN7/5zQwaNCjV1dXZdddd06NHjzz11FNpbGws9Hovvvhi2rRpkz333LPZ+F577bXBuq+//nouuuii9O3bt9nrLl++vPDrvvv1Bw0aVP6Lgbe9fSj4iy++2Gy8X79+ze6/HdXLli17z9f6wAc+kNtuuy2vvvpqnnrqqVxxxRVp165dzjzzzDz44INJkueffz5Jcuihh6ZHjx7Nbj//+c9dmAyAFs850gC0OgceeGAGDx6c733ve7ngggvyve99L6VSqdnVuq+44opceOGFOe2003LZZZdll112SZs2bTJ+/PisX79+q83tC1/4Qm666aaMHz8+w4cPT5cuXVJVVZUTTjhhq77uu739lwl/qVQqFXqOfffdN/vuu2+GDx+ej370o5kyZUpGjx5d/jluu+221NXVbfDYSl7xHAA2hT+pAGiVGhoacuGFF+app57K1KlTM2jQoPz93/99efkPfvCDfPSjH82NN97Y7HHLly/PrrvuWui1+vfvn/Xr1+ePf/xjs73Qzz777Abr/uAHP8jJJ5+cr3/96+Wx1atXZ/ny5c3WK3L16v79++epp57K+vXrm+2V/sMf/lBevjUNGzYsSfLKK68kSXnP/G677ZbRo0f/zce6SjcALZFDuwFold7e+3zRRRflySef3OC7o9u2bbvBHti77rorf/rTnwq/1tixY5Mk1157bbPxa665ZoN1N/a61113XdatW9dsrGPHjkmyQWBvzD/+4z9m0aJFueOOO8pjb775Zq677rp06tQpo0aN2pQf4z3993//d9auXbvB+NvniL/9lwhjxoxJbW1trrjiio2u///+3/8r/3uRnxMAthV7pAFolerr6zNixIjce++9SbJBSH/sYx/LV7/61Zx66qkZMWJEnn766UyZMiUDBgwo/Fof/OAHc+KJJ+bb3/52GhsbM2LEiEyfPj1z587dYN2Pfexjue2229KlS5fsvffemTlzZh588MF07959g+ds27ZtrrrqqjQ2Nqa6ujqHHnroRr+v+cwzz8wNN9yQU045JU888UT22GOP/OAHP8ijjz6aa665Jp07dy78M23MVVddlSeeeCLHHHNM9ttvvyTJb37zm9x6663ZZZddyhdXq62tzfXXX59Pf/rTOeCAA3LCCSekR48eWbBgQX7yk59k5MiR+da3vpXkrcPwk7cu1DZmzJjyxeIAoJKENACtVkNDQ371q1/lf/2v/5WBAwc2W3bBBRdk5cqVmTp1au64444ccMAB+clPfpKJEydu1mv9n//zf9KjR49MmTIl99xzTw499ND85Cc/Sd++fZut9x//8R9p27ZtpkyZktWrV2fkyJF58MEHM2bMmGbr1dXVZfLkyZk0aVJOP/30rFu3Lg899NBGQ7qmpiYPP/xwJk6cmFtuuSVNTU3Za6+9ctNNN+WUU07ZrJ9nYy644IJMnTo1M2bMyJQpU7Jq1ar06tUrJ5xwQi688MLU19eX1z3ppJPSu3fvXHnllfm3f/u3rFmzJrvvvnsOOeSQnHrqqeX1jjnmmHzhC1/I97///dx+++0plUpCGoCKqyoVuXIIAAAAtHLOkQYAAIAChDQAAAAUIKQBAACgACENAAAABQhpAAAAKEBIAwAAQAEt7nuk169fn5dffjmdO3dOVVVVpacDAADADq5UKuW1115L796906bNe+9vbnEh/fLLL6dv376VngYAAACtzEsvvZQ+ffq853otLqQ7d+6c5K0foLa2tsKzAQAAYEfX1NSUvn37lnv0vbS4kH77cO7a2lohDQAAwDazqacXu9gYAAAAFCCkAQAAoAAhDQAAAAW0uHOkN9W6deuydu3aSk+DAtq3b5+2bdtWehoAAADvy3YX0qVSKYsWLcry5csrPRU2Q9euXVNXV+c7wgEAgO3WdhfSb0f0brvtlp133lmQbSdKpVJWrVqVJUuWJEl69epV4RkBAABsnu0qpNetW1eO6O7du1d6OhRUU1OTJFmyZEl22203h3kDAADbpe3qYmNvnxO98847V3gmbK633zvntwMAANur7Sqk3+Zw7u2X9w4AANjebZchDQAAAJUipLdzDz/8cKqqqt7zKuZ77LFHrrnmmm0yJwAAgB2ZkN5GTjnllFRVVaWqqiodOnTIwIED89WvfjVvvvnm+3reESNG5JVXXkmXLl2SJDfffHO6du26wXqzZs3KmWee+b5eCwAAgO3sqt3buyOOOCI33XRT1qxZk5/+9KcZN25c2rdvn/PPP3+zn7NDhw6pq6t7z/V69Oix2a8BAADAO+yR3oaqq6tTV1eX/v375+yzz87o0aPzox/9KMuWLcs///M/p1u3btl5550zduzYPP/88+XHvfjiiznqqKPSrVu3dOzYMfvss09++tOfJml+aPfDDz+cU089NY2NjeW935dcckmS5od2n3TSSTn++OObzW3t2rXZddddc+uttyZJ1q9fn0mTJqW+vj41NTXZf//984Mf/GDr/5IAAABauFa9R3r2gmWZ/+rK1O/aMUP7ddvmr19TU5OlS5fmlFNOyfPPP58f/ehHqa2tzVe+8pX84z/+Y+bMmZP27dtn3LhxeeONN/LLX/4yHTt2zJw5c9KpU6cNnm/EiBG55pprctFFF+XZZ59Nko2u19DQkOOOOy4rVqwoL3/ggQeyatWqHH300UmSSZMm5fbbb8/kyZMzaNCg/PKXv8ynPvWp9OjRI6NGjdqKvxUAAICWrdWG9JX3P5PJM+aV7581akAmjh2yTV67VCpl+vTpeeCBBzJ27Njcc889efTRRzNixIgkyZQpU9K3b9/cc889Oe6447JgwYIce+yx2XfffZMkAwYM2OjzdujQIV26dElVVdXfPNx7zJgx6dixY+6+++58+tOfTpJMnTo1H//4x9O5c+esWbMmV1xxRR588MEMHz68/JqPPPJIbrjhBiENAAC0aq3y0O7ZC5Y1i+gkmTxjXmYvWLZVX/fHP/5xOnXqlJ122iljx47N8ccfn1NOOSXt2rXLQQcdVF6ve/fu2WuvvfLMM88kSc4555x87Wtfy8iRI3PxxRfnqaeeel/zaNeuXf7pn/4pU6ZMSZKsXLky9957bxoaGpIkc+fOzapVq3L44YenU6dO5dutt96aP/7xj+/rtQEAALZ3rTKk57+6stD4lvLRj340Tz75ZJ5//vm8/vrrueWWW1JVVfWejzvjjDMyb968fPrTn87TTz+dYcOG5brrrntfc2loaMj06dOzZMmS3HPPPampqckRRxyRJFmxYkWS5Cc/+UmefPLJ8m3OnDnOkwYAAFq9VhnS9bt2LDS+pXTs2DEDBw5Mv3790q7dW0fVDxkyJG+++WYee+yx8npLly7Ns88+m7333rs81rdv35x11ln54Q9/mC996Uv57ne/u9HX6NChQ9atW/eecxkxYkT69u2bO+64I1OmTMlxxx2X9u3bJ0n23nvvVFdXZ8GCBRk4cGCzW9++fd/PrwAAAGC71yrPkR7ar1vOGjWg2eHdZ48aUJELjg0aNCif+MQn8pnPfCY33HBDOnfunIkTJ2b33XfPJz7xiSTJ+PHjM3bs2HzgAx/IsmXL8tBDD2XIkI2fz73HHntkxYoVmT59evbff//svPPO2XnnnTe67kknnZTJkyfnueeey0MPPVQe79y5c84777xMmDAh69evz8EHH5zGxsY8+uijqa2tzcknn7zlfxEAAADbiVYZ0kkyceyQjNmnrqJX7X7bTTfdlHPPPTcf+9jH8sYbb+TDH/5wfvrTn5b3EK9bty7jxo3LwoULU1tbmyOOOCLf/OY3N/pcI0aMyFlnnZXjjz8+S5cuzcUXX1z+Cqy/1NDQkMsvvzz9+/fPyJEjmy277LLL0qNHj0yaNCnz5s1L165dc8ABB+SCCy7Yoj87AADA9qaqVCqVKj2Jd2tqakqXLl3S2NiY2traZstWr16d+fPnp76+PjvttFOFZsj74T0EAABamr/VoRvTavdIAwCwY5u9YFmLOPoQ2PEIaQAAdjhX3v9Ms+vhnDVqQCaO3fg1ZgCKapVX7QYAYMc1e8GyZhGdJJNnzMvsBcsqNCNgRyOkAQDYocx/dWWhcYCihDQAADuU+l07FhoHKEpIAwCwQxnar1vOGjWg2djZowa44BiwxbjYGAAAO5yJY4dkzD51rtoNbBVCGgCAHdLQft0ENLBVOLQbAAAAChDSlO2xxx655pprKj0NAACAFk1IbyOnnHJKqqqqcuWVVzYbv+eee1JVVbVN53LzzTena9euG4zPmjUrZ5555jadCwAAwPZGSG9DO+20U6666qosW7as0lPZqB49emTnnXeu9DQAAABaNCG9DY0ePTp1dXWZNGnSX13nkUceySGHHJKampr07ds355xzTlauXFle/sorr+TII49MTU1N6uvrM3Xq1A0Oyf7GN76RfffdNx07dkzfvn3zuc99LitWrEiSPPzwwzn11FPT2NiYqqqqVFVV5ZJLLknS/NDuk046Kccff3yzua1duza77rprbr311iTJ+vXrM2nSpNTX16empib7779/fvCDH2yB3xQAAEDL1bpDeuHjyW+//9Y/t4G2bdvmiiuuyHXXXZeFCxdusPyPf/xjjjjiiBx77LF56qmncscdd+SRRx7J5z//+fI6//zP/5yXX345Dz/8cP7v//2/+c53vpMlS5Y0e542bdrk2muvze9///vccsst+cUvfpEvf/nLSZIRI0bkmmuuSW1tbV555ZW88sorOe+88zaYS0NDQ+67775ygCfJAw88kFWrVuXoo49OkkyaNCm33nprJk+enN///veZMGFCPvWpT2XGjBlb5PcFAADQErXer7+adnHy6DXv3B85Pjn80q3+skcffXQ++MEP5uKLL86NN97YbNmkSZPS0NCQ8ePHJ0kGDRqUa6+9NqNGjcr111+fF154IQ8++GBmzZqVYcOGJUn+67/+K4MGDWr2PG8/PnlrL/PXvva1nHXWWfn2t7+dDh06pEuXLqmqqkpdXd1fneeYMWPSsWPH3H333fn0pz+dJJk6dWo+/vGPp3PnzlmzZk2uuOKKPPjggxk+fHiSZMCAAXnkkUdyww03ZNSoUe/3VwUAANAitc6QXvh484hO3ro/5Kikz7Ct/vJXXXVVDj300A32BP/2t7/NU089lSlTppTHSqVS1q9fn/nz5+e5555Lu3btcsABB5SXDxw4MN26Nf9+xAcffDCTJk3KH/7whzQ1NeXNN9/M6tWrs2rVqk0+B7pdu3b5p3/6p0yZMiWf/vSns3Llytx77735/ve/nySZO3duVq1alcMPP7zZ4954440MHTq00O8DAABge9I6Q3rp3L8+vg1C+sMf/nDGjBmT888/P6ecckp5fMWKFfnsZz+bc845Z4PH9OvXL88999x7PvcLL7yQj33sYzn77LNz+eWXZ5dddskjjzyS008/PW+88Uahi4k1NDRk1KhRWbJkSaZNm5aampocccQR5bkmyU9+8pPsvvvuzR5XXV29ya8BAACwvWmdId19YLHxreDKK6/MBz/4wey1117lsQMOOCBz5szJwIEbn8dee+2VN998M7Nnz86BBx6Y5K09w+++CvgTTzyR9evX5+tf/3ratHnrFPg777yz2fN06NAh69ate885jhgxIn379s0dd9yR+++/P8cdd1zat2+fJNl7771TXV2dBQsWOIwbAABoVVpnSPcZ9tY50c3OkZ6wTfZGv23fffdNQ0NDrr322vLYV77ylXzoQx/K5z//+Zxxxhnp2LFj5syZk2nTpuVb3/pWBg8enNGjR+fMM8/M9ddfn/bt2+dLX/pSampqyt9FPXDgwKxduzbXXXddjjrqqDz66KOZPHlys9feY489smLFikyfPj37779/dt5557+6p/qkk07K5MmT89xzz+Whhx4qj3fu3DnnnXdeJkyYkPXr1+fggw9OY2NjHn300dTW1ubkk0/eCr81AACAymu9V+0+/NLkjOnJ0Te89c/DL9nmU/jqV7+a9evXl+/vt99+mTFjRp577rkccsghGTp0aC666KL07t27vM6tt96anj175sMf/nCOPvrofOYzn0nnzp2z0047JUn233//fOMb38hVV12Vv/u7v8uUKVM2+LqtESNG5Kyzzsrxxx+fHj165Oqrr/6rc2xoaMicOXOy++67Z+TIkc2WXXbZZbnwwgszadKkDBkyJEcccUR+8pOfpL6+fkv8egAAAFqkqlKpVKr0JN6tqakpXbp0SWNjY2pra5stW716debPn5/6+vpyOLZ2CxcuTN++ffPggw/msMMOq/R03pP3EAAAaGn+VoduTOE90q+99lrGjx+f/v37p6amJiNGjMisWbPKy0ulUi666KL06tUrNTU1GT16dJ5//vmiL8Nf8Ytf/CI/+tGPMn/+/PzqV7/KCSeckD322CMf/vCHKz01AACAVqFwSJ9xxhmZNm1abrvttjz99NP5h3/4h4wePTp/+tOfkiRXX311rr322kyePDmPPfZYOnbsmDFjxmT16tVbfPKt0dq1a3PBBRdkn332ydFHH50ePXrk4YcfLl8EDAAAgK2r0KHdr7/+ejp37px77703Rx55ZHn8wAMPzNixY3PZZZeld+/e+dKXvlT+juTGxsb07NkzN998c0444YT3fA2Hdu/YvIcAAEBLs1UP7X7zzTezbt26DQKopqYmjzzySObPn59FixZl9OjR5WVdunTJQQcdlJkzZ270OdesWZOmpqZmNwAAAGipCoV0586dM3z48Fx22WV5+eWXs27dutx+++2ZOXNmXnnllSxatChJ0rNnz2aP69mzZ3nZX5o0aVK6dOlSvvXt2/c959HCro9GAd47AABge1f4HOnbbrstpVIpu+++e6qrq3PttdfmxBNPTJs2m/dNWueff34aGxvLt5deeumvrvv2ecCrVq3arNei8t5+75zTDQAAbK/aFX3AnnvumRkzZmTlypVpampKr169cvzxx2fAgAGpq6tLkixevDi9evUqP2bx4sX54Ac/uNHnq66uTnV19Sa9dtu2bdO1a9csWbIkSbLzzjunqqqq6I9ABZRKpaxatSpLlixJ165d07Zt20pPCQC2e7MXLMv8V1emfteOGdqvW6WnA9BqFA7pt3Xs2DEdO3bMsmXL8sADD+Tqq69OfX196urqMn369HI4NzU15bHHHsvZZ5+9RSb8dqy/HdNsX7p27Vp+DwGAzXfl/c9k8ox55ftnjRqQiWOHVHBGAK1H4ZB+4IEHUiqVstdee2Xu3Ln5l3/5lwwePDinnnpqqqqqMn78+Hzta1/LoEGDUl9fnwsvvDC9e/fOJz/5yS0y4aqqqvTq1Su77bZb1q5du0Wek22jffv29kQDwBYwe8GyZhGdJJNnzMuYfersmQbYBgqHdGNjY84///wsXLgwu+yyS4499thcfvnl5XNev/zlL2flypU588wzs3z58hx88MH52c9+tsW/6qht27aiDABolea/uvKvjgtpgK2v0PdIbwtFv78LYEfgPEegiNkLluXob/9qg/G7PzfCZwjAZijaoZt9jjQAW4bzHIGihvbrlrNGDWj22XH2qAEiGmAbEdIAFeQ8R2BzTRw7JGP2qXM0C0AFCGmACnKeI/B+DO3XzWcFQAW0qfQEAFqz+l07FhoHAKDyhDRABb19nuO7Oc8RAKBlc2g3QIU5zxEAYPsipAFaAOc5AgBsPxzaDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEAB7So9AQAAto7ZC5Zl/qsrU79rxwzt163S0wHYYQhpAIAd0JX3P5PJM+aV7581akAmjh1SwRkB7Dgc2g0AbHOzFyzLD3+zMLMXLKv0VHZIsxcsaxbRSTJ5xjy/b4AtxB5pAGCbsqd065v/6sq/Ou4Qb4D3zx5pAGCbsad026jftWOhcQCKEdIAwDbzt/aUsuUM7dctZ40a0Gzs7FED7I0G2EIc2g0AbDP2lG47E8cOyZh96ly1G2ArsEcaANhm7Cndtob265ZjDujj9wuwhdkjDQBsU/aUArC9E9IAwDY3tF83AQ3AdktIAwBsR2YvWGZvPkCFCWkAgO2E7+AGaBlcbAwAYDvgO7gBWg4hDQCwHfAd3AAth5AGANgO+A5ugJZDSAMAbAd8BzdAy+FiYwAA2wnfwQ3QMghpAIDtiO/gBqg8h3YDAABAAUIaAAAAChDSAAAAUICQBgAAgAKENAAAABQgpAEAAKAAIQ0AAAAFCGkAAAAoQEgDAABAAUIaAAAAChDSAAAAUICQBgAAgAKENAAAABQgpAEAAKAAIQ0AAAAFCGkAAAAoQEgDAABAAUIaAAAAChDSAAAAUICQBgAAgAKENAAAABQgpAEAAKAAIQ0AAAAFCGkAAAAoQEgDAABAAUIaAAAAChDSAAAAUICQBgAAgAKENAAAABQgpAEAAKAAIQ0AAAAFCGkAAAAoQEgDAABAAUIaAAAAChDSAAAAUICQBgAAgAKENAAAABQgpAEAAKAAIQ0AAAAFCGkAAAAoQEgDAABAAYVCet26dbnwwgtTX1+fmpqa7LnnnrnssstSKpXK65RKpVx00UXp1atXampqMnr06Dz//PNbfOIAAABQCYVC+qqrrsr111+fb33rW3nmmWdy1VVX5eqrr851111XXufqq6/Otddem8mTJ+exxx5Lx44dM2bMmKxevXqLTx4AAAC2tarSu3cnv4ePfexj6dmzZ2688cby2LHHHpuamprcfvvtKZVK6d27d770pS/lvPPOS5I0NjamZ8+eufnmm3PCCSe852s0NTWlS5cuaWxsTG1t7Wb8SAAAALDpinZooT3SI0aMyPTp0/Pcc88lSX7729/mkUceydixY5Mk8+fPz6JFizJ69OjyY7p06ZKDDjooM2fO3OhzrlmzJk1NTc1uAAAA0FK1K7LyxIkT09TUlMGDB6dt27ZZt25dLr/88jQ0NCRJFi1alCTp2bNns8f17NmzvOwvTZo0KZdeeunmzB0AAAC2uUJ7pO+8885MmTIlU6dOzW9+85vccsst+fd///fccsstmz2B888/P42NjeXbSy+9tNnPBQAAAFtboT3S//Iv/5KJEyeWz3Xed9998+KLL2bSpEk5+eSTU1dXlyRZvHhxevXqVX7c4sWL88EPfnCjz1ldXZ3q6urNnD4AAABsW4X2SK9atSpt2jR/SNu2bbN+/fokSX19ferq6jJ9+vTy8qampjz22GMZPnz4FpguAAAAVFahPdJHHXVULr/88vTr1y/77LNPZs+enW984xs57bTTkiRVVVUZP358vva1r2XQoEGpr6/PhRdemN69e+eTn/zk1pg/AAAAbFOFQvq6667LhRdemM997nNZsmRJevfunc9+9rO56KKLyut8+ctfzsqVK3PmmWdm+fLlOfjgg/Ozn/0sO+200xafPAAAAGxrhb5HelvwPdIAAABsS1v1e6QBAACgtRPSAAAAUICQBgAAgAKENAAAABQgpAEAAKAAIQ0AAAAFCGkAAAAoQEgDAABAAUIaAAAAChDSAAAAUICQBgAAgALaVXoCAMA7Zi9Ylvmvrkz9rh0ztF+3Sk8HANgIIQ0ALcSV9z+TyTPmle+fNWpAJo4dUsEZAQAb49BuAGgBZi9Y1iyik2TyjHmZvWBZhWYEAPw1QhoAWoD5r64sNA4AVI6QBoAWoH7XjoXGAYDKEdIA0AIM7dctZ40a0Gzs7FEDXHAMAFogFxsDgBZi4tghGbNPnat2A0ALJ6QBoAUZ2q+bgAaAFs6h3QAAAFCAPdIAAAAt3OwFy5z604IIaQAAgBbsyvufyeQZ88r3zxo1IBPHDqngjHBoNwAAQAs1e8GyZhGdJJNnzMvsBcsqNCMSIQ0AANBizX91ZaFxtg0hDQAA0ELV79qx0DjbhpAGAABooYb265azRg1oNnb2qAEuOFZhLjYGAADQgk0cOyRj9qlz1e4WREgDAAC0cEP7dRPQLYhDuwEAAKAAIQ0AAAAFCGkAAAAoQEgDAABAAUIaAAAAChDSAAAAUICvvwJ2OLMXLPM9iwAAbDVCGtihXHn/M5k8Y175/lmjBmTi2CEVnBEAADsah3YDO4zZC5Y1i+gkmTxjXmYvWFahGQEAsCMS0sAOY/6rKwuNAwDA5hDSwA6jfteOhcYBAGBzCGlghzG0X7ecNWpAs7GzRw1wwTEAALYoFxsDdigTxw7JmH3qXLUbAICtRkgDO5yh/boJaAAAthqHdgMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQQKGQ3mOPPVJVVbXBbdy4cUmS1atXZ9y4cenevXs6deqUY489NosXL94qEwcAAIBKKBTSs2bNyiuvvFK+TZs2LUly3HHHJUkmTJiQ++67L3fddVdmzJiRl19+Occcc8yWnzUAAABUSFWpVCpt7oPHjx+fH//4x3n++efT1NSUHj16ZOrUqfnf//t/J0n+8Ic/ZMiQIZk5c2Y+9KEPbdJzNjU1pUuXLmlsbExtbe3mTg0AAAA2SdEO3exzpN94443cfvvtOe2001JVVZUnnngia9euzejRo8vrDB48OP369cvMmTP/6vOsWbMmTU1NzW4AAADQUm12SN9zzz1Zvnx5TjnllCTJokWL0qFDh3Tt2rXZej179syiRYv+6vNMmjQpXbp0Kd/69u27uVMCAACArW6zQ/rGG2/M2LFj07t37/c1gfPPPz+NjY3l20svvfS+ng8AAAC2pnab86AXX3wxDz74YH74wx+Wx+rq6vLGG29k+fLlzfZKL168OHV1dX/1uaqrq1NdXb050wAAAIBtbrP2SN90003ZbbfdcuSRR5bHDjzwwLRv3z7Tp08vjz377LNZsGBBhg8f/v5nCgAAAC1A4T3S69evz0033ZSTTz457dq98/AuXbrk9NNPzxe/+MXssssuqa2tzRe+8IUMHz58k6/YDQAAAC1d4ZB+8MEHs2DBgpx22mkbLPvmN7+ZNm3a5Nhjj82aNWsyZsyYfPvb394iEwUAAICW4H19j/TW4HukAQAA2Ja22fdIAwAAQGskpAEAAKCAzfr6KwAAAHgvsxcsy/xXV6Z+144Z2q9bpaezxQhpAAAAtrgr738mk2fMK98/a9SATBw7pIIz2nIc2g0AAMAWNXvBsmYRnSSTZ8zL7AXLKjSjLUtIAwAAsEXNf3VlofHtjZAGAABgi6rftWOh8e2NkAYAAGCLGtqvW84aNaDZ2NmjBuwwFxxzsTEAAAC2uIljh2TMPnWu2g0AAACbami/bjtUQL/Nod0AAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoIB2lZ4AwHZn4ePJ0rlJ94FJn2GVng0AANuYkAYoYtrFyaPXvHN/5Pjk8EsrNRsAACrAod0Am2rh480jOnnr/sLHKzEbAAAqREgDbKqlc4uNAwCwQ3Jod0vlHExoeboPLDYOAMAOSUi3RM7BhJapz7C3/nts9t/nBH/ZBQDQylSVSqVSpSfxbk1NTenSpUsaGxtTW1tb6elsewsfT/7rsA3Hz5juf9ahpXDECADADqVohxY+R/pPf/pTPvWpT6V79+6pqanJvvvum8cff+dCO6VSKRdddFF69eqVmpqajB49Os8//3zRl2m9nIMJLV+fYcn+J4hoAIBWqlBIL1u2LCNHjkz79u1z//33Z86cOfn617+ebt26lde5+uqrc+2112by5Ml57LHH0rFjx4wZMyarV6/e4pPfITkHEwAAoEUrdGj3xIkT8+ijj+a///u/N7q8VCqld+/e+dKXvpTzzjsvSdLY2JiePXvm5ptvzgknnPCer9HqD+1ONnKO9ITk8EsqNRsAAIAd2lY9tPtHP/pRhg0bluOOOy677bZbhg4dmu9+97vl5fPnz8+iRYsyevTo8liXLl1y0EEHZebMmRt9zjVr1qSpqanZrdU7/NK3zok++oa3/imiAQAAWoxCIT1v3rxcf/31GTRoUB544IGcffbZOeecc3LLLbckSRYtWpQk6dmzZ7PH9ezZs7zsL02aNCldunQp3/r27bs5P8eOxzmYAAAALVKhkF6/fn0OOOCAXHHFFRk6dGjOPPPMfOYzn8nkyZM3ewLnn39+Ghsby7eXXnpps58LAAAAtrZCId2rV6/svffezcaGDBmSBQsWJEnq6uqSJIsXL262zuLFi8vL/lJ1dXVqa2ub3QAAAKClKhTSI0eOzLPPPtts7Lnnnkv//v2TJPX19amrq8v06dPLy5uamvLYY49l+PDhW2C6AAAAUFntiqw8YcKEjBgxIldccUX+6Z/+Kb/+9a/zne98J9/5zneSJFVVVRk/fny+9rWvZdCgQamvr8+FF16Y3r1755Of/OTWmD8AAABsU4VC+u///u9z99135/zzz89Xv/rV1NfX55prrklDQ0N5nS9/+ctZuXJlzjzzzCxfvjwHH3xwfvazn2WnnXba4pMHAACAba3Q90hvC75HGgAAgG1pq36PNAAAALR2QhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAtpVegLA+7Dw8WTp3KT7wKTPsErPBgAAWgUhDduraRcnj17zzv2R45PDL63UbAAAoNVwaDdsjxY+3jyik7fuL3y8ErMBAIBWRUjD9mjp3GLjAADAFiOkYXvUfWCxcQAAYIsR0rA96jPsrXOi323kBBccAwCAbcDFxmB7dfilyZCjXLUbAAC2MSEN27M+wwQ0AABsYw7tBgAAgAKENAAAABQgpAEAAKAAIQ0AAAAFCGkAAAAoQEgDAABAAUIaAAAAChDSAAAAUICQBgAAgAKENAAAABQgpAEAAKAAIQ0AAAAFCGkAAAAoQEgDAABAAUIaAAAAChDSAAAAUICQBgAAgAKENAAAABQgpAEAAKAAIQ0AAAAFCGkAAAAoQEgDAABAAUIaAAAAChDSAAAAUICQBgAAgAKENAAAABQgpAEAAKAAIQ0AAAAFCGkAAAAoQEgDAABAAUIaAAAAChDSAAAAUICQBgAAgAKENAAAABQgpAEAAKCAdpWeAACbaOHjydK5SfeBSZ9hlZ4NAECrJaQBtgfTLk4evead+yPHJ4dfWqnZAAC0ag7tBmjpFj7ePKKTt+4vfLwSswEAaPWENEBLt3RusXEAALYqIQ3Q0nUfWGwcAICtSkgDtHR9hr11TvS7jZzggmMAABXiYmMA24PDL02GHOWq3QAALYCQBthe9BkmoAEAWgCHdgMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFFAopC+55JJUVVU1uw0ePLi8fPXq1Rk3bly6d++eTp065dhjj83ixYu3+KQBAACgUgrvkd5nn33yyiuvlG+PPPJIedmECRNy33335a677sqMGTPy8ssv55hjjtmiEwYAAIBKalf4Ae3apa6uboPxxsbG3HjjjZk6dWoOPfTQJMlNN92UIUOG5H/+53/yoQ996P3PFgAAACqs8B7p559/Pr17986AAQPS0NCQBQsWJEmeeOKJrF27NqNHjy6vO3jw4PTr1y8zZ87ccjMGAACACiq0R/qggw7KzTffnL322iuvvPJKLr300hxyyCH53e9+l0WLFqVDhw7p2rVrs8f07NkzixYt+qvPuWbNmqxZs6Z8v6mpqdhPAAAAANtQoZAeO3Zs+d/322+/HHTQQenfv3/uvPPO1NTUbNYEJk2alEsvvXSzHgsAAADb2vv6+quuXbvmAx/4QObOnZu6urq88cYbWb58ebN1Fi9evNFzqt92/vnnp7GxsXx76aWX3s+UAAAAYKt6XyG9YsWK/PGPf0yvXr1y4IEHpn379pk+fXp5+bPPPpsFCxZk+PDhf/U5qqurU1tb2+wGAAAALVWhQ7vPO++8HHXUUenfv39efvnlXHzxxWnbtm1OPPHEdOnSJaeffnq++MUvZpdddkltbW2+8IUvZPjw4a7YDQAAwA6jUEgvXLgwJ554YpYuXZoePXrk4IMPzv/8z/+kR48eSZJvfvObadOmTY499tisWbMmY8aMybe//e2tMnEAAACohKpSqVSq9CTerampKV26dEljY6PDvAEAANjqinbo+zpHGgAAAFobIQ0AAAAFCGkAAAAoQEgDAABAAUIaAAAAChDSAAAAUICQBgAAgAKENAAAABQgpAEAAKAAIQ0AAAAFCGkAAAAoQEgDAABAAUIaAAAAChDSAAAAUICQBgAAgAKENAAAABTQrtITAABg+zF7wbLMf3Vl6nftmKH9ulV6OgAVIaQBANgkV97/TCbPmFe+f9aoAZk4dkgFZwRQGQ7tBgDgPc1esKxZRCfJ5BnzMnvBsgrNCKByhDQAAO9p/qsrC40D7MiENAAA76l+146FxgF2ZEIaAID3NLRft5w1akCzsbNHDXDBMaBVcrExAAA2ycSxQzJmnzpX7QZaPSENAMAmG9qvm4AGWj2HdgMAAEAB9kgDAFvHwseTpXOT7gOTPsMqPRsA2GKENACw5U27OHn0mnfujxyfHH5ppWYDAFuUQ7sBgC1r4ePNIzp56/7CxysxGwDY4oQ0ALBlLZ1bbBwAtjNCGgDYsroPLDYOANsZIQ0AbFl9hr11TvS7jZzggmMA7DBcbAwA2PIOvzQZcpSrdgOwQxLSAMDW0WeYgAZgh+TQbgAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQQLtKTwAAALa02QuWZf6rK1O/a8cM7det0tMBdjBCGgCAHcqV9z+TyTPmle+fNWpAJo4dUsEZATsah3YDALDDmL1gWbOITpLJM+Zl9oJlFZoRsCMS0gAA7DDmv7qy0DjA5hDSAADsMOp37VhoHGBzCGkAAHYYQ/t1y1mjBjQbO3vUABccA7YoFxsDAGCHMnHskIzZp85Vu4GtRkgDALDDGdqvm4AGthqHdgMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAX4Hun3Y+HjydK5SfeBSZ9hlZ4NAAAA24CQ3lzTLk4evead+yPHJ4dfWqnZAAAAsI04tHtzLHy8eUQnb91f+HglZgMAAMA2JKQ3x9K5xcYBAADYYQjpzdF9YLFxAAAAdhhCenP0GfbWOdHvNnKCC44BAAC0Ai42trkOvzQZcpSrdgMAALQyQvr96DNMQAMAALQyDu0GAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKENIAAABQgJAGAACAAoQ0AAAAFCCkAQAAoAAhDQAAAAUIaQAAAChASAMAAEABQhoAAAAKaFfpCQAALczCx5Olc5PuA5M+wyo9GwBocYQ0APCOaRcnj17zzv2R45PDL63UbACgRXJoNwDwloWPN4/o5K37Cx+vxGwAoMUS0gDAW5bOLTYOAK2UkAYA3tJ9YLFxAGilhDQA8JY+w946J/rdRk5wwTEA+AsuNgYAvOPwS5MhR7lqNwD8DUIaAGiuzzABDQB/g0O7AQAAoAAhDQAAAAW8r5C+8sorU1VVlfHjx5fHVq9enXHjxqV79+7p1KlTjj322CxevPj9zhMAAABahM0O6VmzZuWGG27Ifvvt12x8woQJue+++3LXXXdlxowZefnll3PMMce874kCAABAS7BZIb1ixYo0NDTku9/9brp161Yeb2xszI033phvfOMbOfTQQ3PggQfmpptuyq9+9av8z//8zxabNAAAAFTKZoX0uHHjcuSRR2b06NHNxp944omsXbu22fjgwYPTr1+/zJw58/3NFAAAAFqAwl9/9f3vfz+/+c1vMmvWrA2WLVq0KB06dEjXrl2bjffs2TOLFi3a6POtWbMma9asKd9vamoqOiUAAADYZgrtkX7ppZdy7rnnZsqUKdlpp522yAQmTZqULl26lG99+/bdIs8LAAAAW0OhkH7iiSeyZMmSHHDAAWnXrl3atWuXGTNm5Nprr027du3Ss2fPvPHGG1m+fHmzxy1evDh1dXUbfc7zzz8/jY2N5dtLL7202T8MAAAAbG2FDu0+7LDD8vTTTzcbO/XUUzN48OB85StfSd++fdO+fftMnz49xx57bJLk2WefzYIFCzJ8+PCNPmd1dXWqq6s3c/oAAACwbRUK6c6dO+fv/u7vmo117Ngx3bt3L4+ffvrp+eIXv5hddtkltbW1+cIXvpDhw4fnQx/60JabNQAAAFRI4YuNvZdvfvObadOmTY499tisWbMmY8aMybe//e0t/TIAAABQEVWlUqlU6Um8W1NTU7p06ZLGxsbU1tZWejoAAADs4Ip26GZ9jzQAAAC0VkIaAAAAChDSAAAAUICQBgAAgAKENAAAABQgpAEAAKAAIQ0AAAAFCGkAAAAoQEgDAABAAe0qPQEAAAAqaOHjydK5SfeBSZ9hlZ7NdkFIAwAAtFbTLk4evead+yPHJ4dfWqnZbDcc2g0AANAaLXy8eUQnb91f+HglZrNdEdIAAACt0dK5xcYpE9IAAACtUfeBxcYpE9IAAACtUZ9hb50T/W4jJ7jg2CZwsTEAAIDW6vBLkyFHuWp3QUIaAACgNeszTEAX5NBuAAAAKEBIAwAAQAFCGgAAAAoQ0gAAAFCAkAYAAIAChDQAAAAUIKQBAACgACENAAAABQhpAAAAKEBIAwAAQAFCGgAAAAoQ0gAAAFCAkAYAAIAChDQAAAAUIKQBAACgACENAAAABQhpAAAAKEBIAwAAQAFCGgAAAAoQ0gAAAFCAkAYAAIAChDQAAAAU0K7SE/hLpVIpSdLU1FThmQAAANAavN2fb/foe2lxIf3aa68lSfr27VvhmQAAANCavPbaa+nSpct7rldV2tTk3kbWr1+fl19+OZ07d05VVVWzZU1NTenbt29eeuml1NbWVmiGVJrtgLfZFkhsB7zFdkBiO+AdtgWSYttBqVTKa6+9lt69e6dNm/c+A7rF7ZFu06ZN+vTp8zfXqa2t9R8EtgPKbAsktgPeYjsgsR3wDtsCyaZvB5uyJ/ptLjYGAAAABQhpAAAAKGC7Cunq6upcfPHFqa6urvRUqCDbAW+zLZDYDniL7YDEdsA7bAskW3c7aHEXGwMAAICWbLvaIw0AAACVJqQBAACgACENAAAABQhpAAAAKKDFhfT111+f/fbbr/yl2cOHD8/9999fXr569eqMGzcu3bt3T6dOnXLsscdm8eLFFZwx28KVV16ZqqqqjB8/vjxmW2gdLrnkklRVVTW7DR48uLzcdtB6/OlPf8qnPvWpdO/ePTU1Ndl3333z+OOPl5eXSqVcdNFF6dWrV2pqajJ69Og8//zzFZwxW9oee+yxwedBVVVVxo0bl8TnQWuxbt26XHjhhamvr09NTU323HPPXHbZZXn39XN9HrQer732WsaPH5/+/funpqYmI0aMyKxZs8rLbQs7nl/+8pc56qij0rt371RVVeWee+5ptnxT3vM///nPaWhoSG1tbbp27ZrTTz89K1asKDSPFhfSffr0yZVXXpknnngijz/+eA499NB84hOfyO9///skyYQJE3LfffflrrvuyowZM/Lyyy/nmGOOqfCs2ZpmzZqVG264Ifvtt1+zcdtC67HPPvvklVdeKd8eeeSR8jLbQeuwbNmyjBw5Mu3bt8/999+fOXPm5Otf/3q6detWXufqq6/Otddem8mTJ+exxx5Lx44dM2bMmKxevbqCM2dLmjVrVrPPgmnTpiVJjjvuuCQ+D1qLq666Ktdff32+9a1v5ZlnnslVV12Vq6++Otddd115HZ8HrccZZ5yRadOm5bbbbsvTTz+df/iHf8jo0aPzpz/9KYltYUe0cuXK7L///vnP//zPjS7flPe8oaEhv//97zNt2rT8+Mc/zi9/+cuceeaZxSZS2g5069at9F//9V+l5cuXl9q3b1+66667ysueeeaZUpLSzJkzKzhDtpbXXnutNGjQoNK0adNKo0aNKp177rmlUqlkW2hFLr744tL++++/0WW2g9bjK1/5Sunggw/+q8vXr19fqqurK/3bv/1beWz58uWl6urq0ve+971tMUUq4Nxzzy3tueeepfXr1/s8aEWOPPLI0mmnndZs7Jhjjik1NDSUSiWfB63JqlWrSm3bti39+Mc/bjZ+wAEHlP71X//VttAKJCndfffd5fub8p7PmTOnlKQ0a9as8jr3339/qaqqqvSnP/1pk1+7xe2Rfrd169bl+9//flauXJnhw4fniSeeyNq1azN69OjyOoMHD06/fv0yc+bMCs6UrWXcuHE58sgjm73nSWwLrczzzz+f3r17Z8CAAWloaMiCBQuS2A5akx/96EcZNmxYjjvuuOy2224ZOnRovvvd75aXz58/P4sWLWq2LXTp0iUHHXSQbWEH9cYbb+T222/PaaedlqqqKp8HrciIESMyffr0PPfcc0mS3/72t3nkkUcyduzYJD4PWpM333wz69aty0477dRsvKamJo888ohtoRXalPd85syZ6dq1a4YNG1ZeZ/To0WnTpk0ee+yxTX6tdltu2lvO008/neHDh2f16tXp1KlT7r777uy999558skn06FDh3Tt2rXZ+j179syiRYsqM1m2mu9///v5zW9+0+w8l7ctWrTIttBKHHTQQbn55puz11575ZVXXsmll16aQw45JL/73e9sB63IvHnzcv311+eLX/xiLrjggsyaNSvnnHNOOnTokJNPPrn8fvfs2bPZ42wLO6577rkny5cvzymnnJLEnwutycSJE9PU1JTBgwenbdu2WbduXS6//PI0NDQkic+DVqRz584ZPnx4LrvssgwZMiQ9e/bM9773vcycOTMDBw60LbRCm/KeL1q0KLvttluz5e3atcsuu+xSaLtokSG911575cknn0xjY2N+8IMf5OSTT86MGTMqPS22oZdeeinnnntupk2btsHfMtK6vL2HIUn222+/HHTQQenfv3/uvPPO1NTUVHBmbEvr16/PsGHDcsUVVyRJhg4dmt/97neZPHlyTj755ArPjkq48cYbM3bs2PTu3bvSU2Ebu/POOzNlypRMnTo1++yzT5588smMHz8+vXv39nnQCt1222057bTTsvvuu6dt27Y54IADcuKJJ+aJJ56o9NTYwbXIQ7s7dOiQgQMH5sADD8ykSZOy//775z/+4z9SV1eXN954I8uXL2+2/uLFi1NXV1eZybJVPPHEE1myZEkOOOCAtGvXLu3atcuMGTNy7bXXpl27dunZs6dtoZXq2rVrPvCBD2Tu3Lk+E1qRXr16Ze+99242NmTIkPJh/m+/3395hWbbwo7pxRdfzIMPPpgzzjijPObzoPX4l3/5l0ycODEnnHBC9t1333z605/OhAkTMmnSpCQ+D1qbPffcMzNmzMiKFSvy0ksv5de//nXWrl2bAQMG2BZaoU15z+vq6rJkyZJmy9988838+c9/LrRdtMiQ/kvr16/PmjVrcuCBB6Z9+/aZPn16edmzzz6bBQsWZPjw4RWcIVvaYYcdlqeffjpPPvlk+TZs2LA0NDSU/9220DqtWLEif/zjH9OrVy+fCa3IyJEj8+yzzzYbe+6559K/f/8kSX19ferq6pptC01NTXnsscdsCzugm266KbvttluOPPLI8pjPg9Zj1apVadOm+f/Ctm3bNuvXr0/i86C16tixY3r16pVly5blgQceyCc+8QnbQiu0Ke/58OHDs3z58mZHLfziF7/I+vXrc9BBB236i73/a6VtWRMnTizNmDGjNH/+/NJTTz1VmjhxYqmqqqr085//vFQqlUpnnXVWqV+/fqVf/OIXpccff7w0fPjw0vDhwys8a7aFd1+1u1SyLbQWX/rSl0oPP/xwaf78+aVHH320NHr06NKuu+5aWrJkSalUsh20Fr/+9a9L7dq1K11++eWl559/vjRlypTSzjvvXLr99tvL61x55ZWlrl27lu69997SU089VfrEJz5Rqq+vL73++usVnDlb2rp160r9+vUrfeUrX9lgmc+D1uHkk08u7b777qUf//jHpfnz55d++MMflnbdddfSl7/85fI6Pg9aj5/97Gel+++/vzRv3rzSz3/+89L+++9fOuigg0pvvPFGqVSyLeyIXnvttdLs2bNLs2fPLiUpfeMb3yjNnj279OKLL5ZKpU17z4844ojS0KFDS4899ljpkUceKQ0aNKh04oknFppHiwvp0047rdS/f/9Shw4dSj169Cgddthh5YgulUql119/vfS5z32u1K1bt9LOO+9cOvroo0uvvPJKBWfMtvKXIW1baB2OP/74Uq9evUodOnQo7b777qXjjz++NHfu3PJy20Hrcd9995X+7u/+rlRdXV0aPHhw6Tvf+U6z5evXry9deOGFpZ49e5aqq6tLhx12WOnZZ5+t0GzZWh544IFSko2+tz4PWoempqbSueeeW+rXr19pp512Kg0YMKD0r//6r6U1a9aU1/F50HrccccdpQEDBpQ6dOhQqqurK40bN660fPny8nLbwo7noYceKiXZ4HbyySeXSqVNe8+XLl1aOvHEE0udOnUq1dbWlk499dTSa6+9VmgeVaVSqfT+d6IDAABA67BdnCMNAAAALYWQBgAAgAKENAAAABQgpAEAAKAAIQ0AAAAFCGkAAAAoQEgDAABAAUIaAAAAChDSAAAAUICQBgAAgAKENAAAABQgpAEAAKCA/x8RIQV6iuogugAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_val_data = val_x[np.where(val_y[:]==1)]\n",
    "negative_val_data = val_x[np.where(val_y[:]==0)]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=positive_val_data[:,0], y=positive_val_data[:,1], s=10, label=\"Positive\")\n",
    "ax.scatter(x=negative_val_data[:,0], y=negative_val_data[:,1], s=10, label=\"Negative\")\n",
    "ax.legend(loc=2)\n",
    "ax.set_title('Validation Set')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "整理维度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(20, 1)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_ex = np.expand_dims(train_y,axis=1)\n",
    "val_y_ex = np.expand_dims(val_y,axis=1)\n",
    "val_y_ex.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "进行逻辑回归，查看参数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '，' (U+FF0C) (206114234.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn [1], line 1\u001B[1;36m\u001B[0m\n\u001B[1;33m    进行逻辑回归，查看参数\u001B[0m\n\u001B[1;37m          ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid character '，' (U+FF0C)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5000, Train Loss: 0.6931\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6916\n",
      "Epoch: 2/5000, Train Loss: 0.6917\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6900\n",
      "Epoch: 3/5000, Train Loss: 0.6902\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6884\n",
      "Epoch: 4/5000, Train Loss: 0.6888\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6869\n",
      "Epoch: 5/5000, Train Loss: 0.6873\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6853\n",
      "Epoch: 6/5000, Train Loss: 0.6859\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6838\n",
      "Epoch: 7/5000, Train Loss: 0.6845\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6822\n",
      "Epoch: 8/5000, Train Loss: 0.6831\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6807\n",
      "Epoch: 9/5000, Train Loss: 0.6816\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6792\n",
      "Epoch: 10/5000, Train Loss: 0.6802\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6777\n",
      "Epoch: 11/5000, Train Loss: 0.6788\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6762\n",
      "Epoch: 12/5000, Train Loss: 0.6774\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6747\n",
      "Epoch: 13/5000, Train Loss: 0.6760\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6732\n",
      "Epoch: 14/5000, Train Loss: 0.6747\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6717\n",
      "Epoch: 15/5000, Train Loss: 0.6733\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6702\n",
      "Epoch: 16/5000, Train Loss: 0.6719\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6687\n",
      "Epoch: 17/5000, Train Loss: 0.6705\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6673\n",
      "Epoch: 18/5000, Train Loss: 0.6692\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6658\n",
      "Epoch: 19/5000, Train Loss: 0.6678\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6644\n",
      "Epoch: 20/5000, Train Loss: 0.6665\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6629\n",
      "Epoch: 21/5000, Train Loss: 0.6652\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6615\n",
      "Epoch: 22/5000, Train Loss: 0.6638\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6601\n",
      "Epoch: 23/5000, Train Loss: 0.6625\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6586\n",
      "Epoch: 24/5000, Train Loss: 0.6612\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6572\n",
      "Epoch: 25/5000, Train Loss: 0.6599\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6558\n",
      "Epoch: 26/5000, Train Loss: 0.6586\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6544\n",
      "Epoch: 27/5000, Train Loss: 0.6573\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6530\n",
      "Epoch: 28/5000, Train Loss: 0.6560\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6516\n",
      "Epoch: 29/5000, Train Loss: 0.6547\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6503\n",
      "Epoch: 30/5000, Train Loss: 0.6534\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6489\n",
      "Epoch: 31/5000, Train Loss: 0.6521\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6475\n",
      "Epoch: 32/5000, Train Loss: 0.6509\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6462\n",
      "Epoch: 33/5000, Train Loss: 0.6496\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6448\n",
      "Epoch: 34/5000, Train Loss: 0.6483\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6435\n",
      "Epoch: 35/5000, Train Loss: 0.6471\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6421\n",
      "Epoch: 36/5000, Train Loss: 0.6458\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6408\n",
      "Epoch: 37/5000, Train Loss: 0.6446\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6395\n",
      "Epoch: 38/5000, Train Loss: 0.6434\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6382\n",
      "Epoch: 39/5000, Train Loss: 0.6421\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6368\n",
      "Epoch: 40/5000, Train Loss: 0.6409\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6355\n",
      "Epoch: 41/5000, Train Loss: 0.6397\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6342\n",
      "Epoch: 42/5000, Train Loss: 0.6385\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6330\n",
      "Epoch: 43/5000, Train Loss: 0.6373\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6317\n",
      "Epoch: 44/5000, Train Loss: 0.6361\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6304\n",
      "Epoch: 45/5000, Train Loss: 0.6349\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6291\n",
      "Epoch: 46/5000, Train Loss: 0.6337\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6278\n",
      "Epoch: 47/5000, Train Loss: 0.6325\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6266\n",
      "Epoch: 48/5000, Train Loss: 0.6313\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6253\n",
      "Epoch: 49/5000, Train Loss: 0.6302\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6241\n",
      "Epoch: 50/5000, Train Loss: 0.6290\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6228\n",
      "Epoch: 51/5000, Train Loss: 0.6278\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6216\n",
      "Epoch: 52/5000, Train Loss: 0.6267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6204\n",
      "Epoch: 53/5000, Train Loss: 0.6255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6191\n",
      "Epoch: 54/5000, Train Loss: 0.6244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6179\n",
      "Epoch: 55/5000, Train Loss: 0.6232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6167\n",
      "Epoch: 56/5000, Train Loss: 0.6221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6155\n",
      "Epoch: 57/5000, Train Loss: 0.6210\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6143\n",
      "Epoch: 58/5000, Train Loss: 0.6199\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6131\n",
      "Epoch: 59/5000, Train Loss: 0.6187\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6119\n",
      "Epoch: 60/5000, Train Loss: 0.6176\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6107\n",
      "Epoch: 61/5000, Train Loss: 0.6165\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6095\n",
      "Epoch: 62/5000, Train Loss: 0.6154\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6084\n",
      "Epoch: 63/5000, Train Loss: 0.6143\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6072\n",
      "Epoch: 64/5000, Train Loss: 0.6132\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6060\n",
      "Epoch: 65/5000, Train Loss: 0.6121\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6049\n",
      "Epoch: 66/5000, Train Loss: 0.6110\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6037\n",
      "Epoch: 67/5000, Train Loss: 0.6100\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6026\n",
      "Epoch: 68/5000, Train Loss: 0.6089\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6015\n",
      "Epoch: 69/5000, Train Loss: 0.6078\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.6003\n",
      "Epoch: 70/5000, Train Loss: 0.6068\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5992\n",
      "Epoch: 71/5000, Train Loss: 0.6057\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5981\n",
      "Epoch: 72/5000, Train Loss: 0.6046\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5970\n",
      "Epoch: 73/5000, Train Loss: 0.6036\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5958\n",
      "Epoch: 74/5000, Train Loss: 0.6025\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5947\n",
      "Epoch: 75/5000, Train Loss: 0.6015\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5936\n",
      "Epoch: 76/5000, Train Loss: 0.6005\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5925\n",
      "Epoch: 77/5000, Train Loss: 0.5994\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5914\n",
      "Epoch: 78/5000, Train Loss: 0.5984\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5904\n",
      "Epoch: 79/5000, Train Loss: 0.5974\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5893\n",
      "Epoch: 80/5000, Train Loss: 0.5964\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5882\n",
      "Epoch: 81/5000, Train Loss: 0.5954\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5871\n",
      "Epoch: 82/5000, Train Loss: 0.5944\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5861\n",
      "Epoch: 83/5000, Train Loss: 0.5934\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5850\n",
      "Epoch: 84/5000, Train Loss: 0.5924\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5840\n",
      "Epoch: 85/5000, Train Loss: 0.5914\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5829\n",
      "Epoch: 86/5000, Train Loss: 0.5904\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5819\n",
      "Epoch: 87/5000, Train Loss: 0.5894\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5808\n",
      "Epoch: 88/5000, Train Loss: 0.5884\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5798\n",
      "Epoch: 89/5000, Train Loss: 0.5874\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5788\n",
      "Epoch: 90/5000, Train Loss: 0.5865\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5777\n",
      "Epoch: 91/5000, Train Loss: 0.5855\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5767\n",
      "Epoch: 92/5000, Train Loss: 0.5845\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5757\n",
      "Epoch: 93/5000, Train Loss: 0.5836\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5747\n",
      "Epoch: 94/5000, Train Loss: 0.5826\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5737\n",
      "Epoch: 95/5000, Train Loss: 0.5817\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5727\n",
      "Epoch: 96/5000, Train Loss: 0.5807\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5717\n",
      "Epoch: 97/5000, Train Loss: 0.5798\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5707\n",
      "Epoch: 98/5000, Train Loss: 0.5788\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5697\n",
      "Epoch: 99/5000, Train Loss: 0.5779\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5687\n",
      "Epoch: 100/5000, Train Loss: 0.5770\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5677\n",
      "Epoch: 101/5000, Train Loss: 0.5761\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5668\n",
      "Epoch: 102/5000, Train Loss: 0.5751\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5658\n",
      "Epoch: 103/5000, Train Loss: 0.5742\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5648\n",
      "Epoch: 104/5000, Train Loss: 0.5733\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5639\n",
      "Epoch: 105/5000, Train Loss: 0.5724\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5629\n",
      "Epoch: 106/5000, Train Loss: 0.5715\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5620\n",
      "Epoch: 107/5000, Train Loss: 0.5706\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5610\n",
      "Epoch: 108/5000, Train Loss: 0.5697\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5601\n",
      "Epoch: 109/5000, Train Loss: 0.5688\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5591\n",
      "Epoch: 110/5000, Train Loss: 0.5679\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5582\n",
      "Epoch: 111/5000, Train Loss: 0.5670\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5573\n",
      "Epoch: 112/5000, Train Loss: 0.5661\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5564\n",
      "Epoch: 113/5000, Train Loss: 0.5653\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5554\n",
      "Epoch: 114/5000, Train Loss: 0.5644\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5545\n",
      "Epoch: 115/5000, Train Loss: 0.5635\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5536\n",
      "Epoch: 116/5000, Train Loss: 0.5627\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5527\n",
      "Epoch: 117/5000, Train Loss: 0.5618\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5518\n",
      "Epoch: 118/5000, Train Loss: 0.5609\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5509\n",
      "Epoch: 119/5000, Train Loss: 0.5601\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5500\n",
      "Epoch: 120/5000, Train Loss: 0.5592\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5491\n",
      "Epoch: 121/5000, Train Loss: 0.5584\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5482\n",
      "Epoch: 122/5000, Train Loss: 0.5575\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5474\n",
      "Epoch: 123/5000, Train Loss: 0.5567\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5465\n",
      "Epoch: 124/5000, Train Loss: 0.5559\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5456\n",
      "Epoch: 125/5000, Train Loss: 0.5550\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5447\n",
      "Epoch: 126/5000, Train Loss: 0.5542\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5439\n",
      "Epoch: 127/5000, Train Loss: 0.5534\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5430\n",
      "Epoch: 128/5000, Train Loss: 0.5526\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5421\n",
      "Epoch: 129/5000, Train Loss: 0.5517\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5413\n",
      "Epoch: 130/5000, Train Loss: 0.5509\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5404\n",
      "Epoch: 131/5000, Train Loss: 0.5501\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5396\n",
      "Epoch: 132/5000, Train Loss: 0.5493\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5387\n",
      "Epoch: 133/5000, Train Loss: 0.5485\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5379\n",
      "Epoch: 134/5000, Train Loss: 0.5477\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5371\n",
      "Epoch: 135/5000, Train Loss: 0.5469\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5362\n",
      "Epoch: 136/5000, Train Loss: 0.5461\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5354\n",
      "Epoch: 137/5000, Train Loss: 0.5453\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5346\n",
      "Epoch: 138/5000, Train Loss: 0.5445\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5338\n",
      "Epoch: 139/5000, Train Loss: 0.5438\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5329\n",
      "Epoch: 140/5000, Train Loss: 0.5430\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5321\n",
      "Epoch: 141/5000, Train Loss: 0.5422\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5313\n",
      "Epoch: 142/5000, Train Loss: 0.5414\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5305\n",
      "Epoch: 143/5000, Train Loss: 0.5407\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5297\n",
      "Epoch: 144/5000, Train Loss: 0.5399\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5289\n",
      "Epoch: 145/5000, Train Loss: 0.5391\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5281\n",
      "Epoch: 146/5000, Train Loss: 0.5384\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5273\n",
      "Epoch: 147/5000, Train Loss: 0.5376\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5265\n",
      "Epoch: 148/5000, Train Loss: 0.5368\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5258\n",
      "Epoch: 149/5000, Train Loss: 0.5361\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5250\n",
      "Epoch: 150/5000, Train Loss: 0.5353\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5242\n",
      "Epoch: 151/5000, Train Loss: 0.5346\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5234\n",
      "Epoch: 152/5000, Train Loss: 0.5339\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5227\n",
      "Epoch: 153/5000, Train Loss: 0.5331\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5219\n",
      "Epoch: 154/5000, Train Loss: 0.5324\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5211\n",
      "Epoch: 155/5000, Train Loss: 0.5316\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5204\n",
      "Epoch: 156/5000, Train Loss: 0.5309\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5196\n",
      "Epoch: 157/5000, Train Loss: 0.5302\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5188\n",
      "Epoch: 158/5000, Train Loss: 0.5295\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5181\n",
      "Epoch: 159/5000, Train Loss: 0.5287\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5174\n",
      "Epoch: 160/5000, Train Loss: 0.5280\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5166\n",
      "Epoch: 161/5000, Train Loss: 0.5273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5159\n",
      "Epoch: 162/5000, Train Loss: 0.5266\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5151\n",
      "Epoch: 163/5000, Train Loss: 0.5259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5144\n",
      "Epoch: 164/5000, Train Loss: 0.5252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5137\n",
      "Epoch: 165/5000, Train Loss: 0.5245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5129\n",
      "Epoch: 166/5000, Train Loss: 0.5238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5122\n",
      "Epoch: 167/5000, Train Loss: 0.5231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5115\n",
      "Epoch: 168/5000, Train Loss: 0.5224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5108\n",
      "Epoch: 169/5000, Train Loss: 0.5217\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5101\n",
      "Epoch: 170/5000, Train Loss: 0.5210\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5093\n",
      "Epoch: 171/5000, Train Loss: 0.5203\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5086\n",
      "Epoch: 172/5000, Train Loss: 0.5196\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5079\n",
      "Epoch: 173/5000, Train Loss: 0.5190\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5072\n",
      "Epoch: 174/5000, Train Loss: 0.5183\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5065\n",
      "Epoch: 175/5000, Train Loss: 0.5176\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5058\n",
      "Epoch: 176/5000, Train Loss: 0.5169\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5051\n",
      "Epoch: 177/5000, Train Loss: 0.5163\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5044\n",
      "Epoch: 178/5000, Train Loss: 0.5156\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5038\n",
      "Epoch: 179/5000, Train Loss: 0.5149\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5031\n",
      "Epoch: 180/5000, Train Loss: 0.5143\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5024\n",
      "Epoch: 181/5000, Train Loss: 0.5136\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5017\n",
      "Epoch: 182/5000, Train Loss: 0.5130\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5010\n",
      "Epoch: 183/5000, Train Loss: 0.5123\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.5004\n",
      "Epoch: 184/5000, Train Loss: 0.5117\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4997\n",
      "Epoch: 185/5000, Train Loss: 0.5110\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4990\n",
      "Epoch: 186/5000, Train Loss: 0.5104\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4984\n",
      "Epoch: 187/5000, Train Loss: 0.5097\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4977\n",
      "Epoch: 188/5000, Train Loss: 0.5091\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4970\n",
      "Epoch: 189/5000, Train Loss: 0.5084\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4964\n",
      "Epoch: 190/5000, Train Loss: 0.5078\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4957\n",
      "Epoch: 191/5000, Train Loss: 0.5072\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4951\n",
      "Epoch: 192/5000, Train Loss: 0.5065\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4944\n",
      "Epoch: 193/5000, Train Loss: 0.5059\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4938\n",
      "Epoch: 194/5000, Train Loss: 0.5053\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4931\n",
      "Epoch: 195/5000, Train Loss: 0.5047\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4925\n",
      "Epoch: 196/5000, Train Loss: 0.5040\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4919\n",
      "Epoch: 197/5000, Train Loss: 0.5034\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4912\n",
      "Epoch: 198/5000, Train Loss: 0.5028\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4906\n",
      "Epoch: 199/5000, Train Loss: 0.5022\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4900\n",
      "Epoch: 200/5000, Train Loss: 0.5016\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4893\n",
      "Epoch: 201/5000, Train Loss: 0.5010\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4887\n",
      "Epoch: 202/5000, Train Loss: 0.5004\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4881\n",
      "Epoch: 203/5000, Train Loss: 0.4998\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4875\n",
      "Epoch: 204/5000, Train Loss: 0.4992\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4869\n",
      "Epoch: 205/5000, Train Loss: 0.4986\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4862\n",
      "Epoch: 206/5000, Train Loss: 0.4980\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4856\n",
      "Epoch: 207/5000, Train Loss: 0.4974\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4850\n",
      "Epoch: 208/5000, Train Loss: 0.4968\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4844\n",
      "Epoch: 209/5000, Train Loss: 0.4962\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4838\n",
      "Epoch: 210/5000, Train Loss: 0.4956\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4832\n",
      "Epoch: 211/5000, Train Loss: 0.4950\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4826\n",
      "Epoch: 212/5000, Train Loss: 0.4944\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4820\n",
      "Epoch: 213/5000, Train Loss: 0.4938\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4814\n",
      "Epoch: 214/5000, Train Loss: 0.4933\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4808\n",
      "Epoch: 215/5000, Train Loss: 0.4927\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4802\n",
      "Epoch: 216/5000, Train Loss: 0.4921\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4796\n",
      "Epoch: 217/5000, Train Loss: 0.4915\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4791\n",
      "Epoch: 218/5000, Train Loss: 0.4910\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4785\n",
      "Epoch: 219/5000, Train Loss: 0.4904\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4779\n",
      "Epoch: 220/5000, Train Loss: 0.4898\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4773\n",
      "Epoch: 221/5000, Train Loss: 0.4893\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4768\n",
      "Epoch: 222/5000, Train Loss: 0.4887\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4762\n",
      "Epoch: 223/5000, Train Loss: 0.4881\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4756\n",
      "Epoch: 224/5000, Train Loss: 0.4876\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4750\n",
      "Epoch: 225/5000, Train Loss: 0.4870\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4745\n",
      "Epoch: 226/5000, Train Loss: 0.4865\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4739\n",
      "Epoch: 227/5000, Train Loss: 0.4859\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4733\n",
      "Epoch: 228/5000, Train Loss: 0.4854\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4728\n",
      "Epoch: 229/5000, Train Loss: 0.4848\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4722\n",
      "Epoch: 230/5000, Train Loss: 0.4843\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4717\n",
      "Epoch: 231/5000, Train Loss: 0.4837\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4711\n",
      "Epoch: 232/5000, Train Loss: 0.4832\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4706\n",
      "Epoch: 233/5000, Train Loss: 0.4827\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4700\n",
      "Epoch: 234/5000, Train Loss: 0.4821\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4695\n",
      "Epoch: 235/5000, Train Loss: 0.4816\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4689\n",
      "Epoch: 236/5000, Train Loss: 0.4811\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4684\n",
      "Epoch: 237/5000, Train Loss: 0.4805\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4679\n",
      "Epoch: 238/5000, Train Loss: 0.4800\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4673\n",
      "Epoch: 239/5000, Train Loss: 0.4795\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4668\n",
      "Epoch: 240/5000, Train Loss: 0.4789\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4663\n",
      "Epoch: 241/5000, Train Loss: 0.4784\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4657\n",
      "Epoch: 242/5000, Train Loss: 0.4779\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4652\n",
      "Epoch: 243/5000, Train Loss: 0.4774\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4647\n",
      "Epoch: 244/5000, Train Loss: 0.4769\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4641\n",
      "Epoch: 245/5000, Train Loss: 0.4764\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4636\n",
      "Epoch: 246/5000, Train Loss: 0.4758\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4631\n",
      "Epoch: 247/5000, Train Loss: 0.4753\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4626\n",
      "Epoch: 248/5000, Train Loss: 0.4748\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4621\n",
      "Epoch: 249/5000, Train Loss: 0.4743\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4615\n",
      "Epoch: 250/5000, Train Loss: 0.4738\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4610\n",
      "Epoch: 251/5000, Train Loss: 0.4733\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4605\n",
      "Epoch: 252/5000, Train Loss: 0.4728\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4600\n",
      "Epoch: 253/5000, Train Loss: 0.4723\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4595\n",
      "Epoch: 254/5000, Train Loss: 0.4718\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4590\n",
      "Epoch: 255/5000, Train Loss: 0.4713\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4585\n",
      "Epoch: 256/5000, Train Loss: 0.4708\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4580\n",
      "Epoch: 257/5000, Train Loss: 0.4703\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4575\n",
      "Epoch: 258/5000, Train Loss: 0.4698\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4570\n",
      "Epoch: 259/5000, Train Loss: 0.4693\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4565\n",
      "Epoch: 260/5000, Train Loss: 0.4688\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4560\n",
      "Epoch: 261/5000, Train Loss: 0.4683\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4555\n",
      "Epoch: 262/5000, Train Loss: 0.4679\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4550\n",
      "Epoch: 263/5000, Train Loss: 0.4674\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4546\n",
      "Epoch: 264/5000, Train Loss: 0.4669\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4541\n",
      "Epoch: 265/5000, Train Loss: 0.4664\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4536\n",
      "Epoch: 266/5000, Train Loss: 0.4659\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4531\n",
      "Epoch: 267/5000, Train Loss: 0.4655\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4526\n",
      "Epoch: 268/5000, Train Loss: 0.4650\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4521\n",
      "Epoch: 269/5000, Train Loss: 0.4645\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4517\n",
      "Epoch: 270/5000, Train Loss: 0.4640\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4512\n",
      "Epoch: 271/5000, Train Loss: 0.4636\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4507\n",
      "Epoch: 272/5000, Train Loss: 0.4631\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4502\n",
      "Epoch: 273/5000, Train Loss: 0.4626\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4498\n",
      "Epoch: 274/5000, Train Loss: 0.4622\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4493\n",
      "Epoch: 275/5000, Train Loss: 0.4617\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4488\n",
      "Epoch: 276/5000, Train Loss: 0.4613\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4484\n",
      "Epoch: 277/5000, Train Loss: 0.4608\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4479\n",
      "Epoch: 278/5000, Train Loss: 0.4603\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4475\n",
      "Epoch: 279/5000, Train Loss: 0.4599\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4470\n",
      "Epoch: 280/5000, Train Loss: 0.4594\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4465\n",
      "Epoch: 281/5000, Train Loss: 0.4590\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4461\n",
      "Epoch: 282/5000, Train Loss: 0.4585\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4456\n",
      "Epoch: 283/5000, Train Loss: 0.4581\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4452\n",
      "Epoch: 284/5000, Train Loss: 0.4576\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4447\n",
      "Epoch: 285/5000, Train Loss: 0.4572\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4443\n",
      "Epoch: 286/5000, Train Loss: 0.4567\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4438\n",
      "Epoch: 287/5000, Train Loss: 0.4563\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4434\n",
      "Epoch: 288/5000, Train Loss: 0.4558\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4429\n",
      "Epoch: 289/5000, Train Loss: 0.4554\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4425\n",
      "Epoch: 290/5000, Train Loss: 0.4550\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4421\n",
      "Epoch: 291/5000, Train Loss: 0.4545\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4416\n",
      "Epoch: 292/5000, Train Loss: 0.4541\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4412\n",
      "Epoch: 293/5000, Train Loss: 0.4536\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4408\n",
      "Epoch: 294/5000, Train Loss: 0.4532\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4403\n",
      "Epoch: 295/5000, Train Loss: 0.4528\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4399\n",
      "Epoch: 296/5000, Train Loss: 0.4523\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4395\n",
      "Epoch: 297/5000, Train Loss: 0.4519\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4390\n",
      "Epoch: 298/5000, Train Loss: 0.4515\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4386\n",
      "Epoch: 299/5000, Train Loss: 0.4511\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4382\n",
      "Epoch: 300/5000, Train Loss: 0.4506\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4377\n",
      "Epoch: 301/5000, Train Loss: 0.4502\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4373\n",
      "Epoch: 302/5000, Train Loss: 0.4498\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4369\n",
      "Epoch: 303/5000, Train Loss: 0.4494\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4365\n",
      "Epoch: 304/5000, Train Loss: 0.4489\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4361\n",
      "Epoch: 305/5000, Train Loss: 0.4485\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4356\n",
      "Epoch: 306/5000, Train Loss: 0.4481\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4352\n",
      "Epoch: 307/5000, Train Loss: 0.4477\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4348\n",
      "Epoch: 308/5000, Train Loss: 0.4473\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4344\n",
      "Epoch: 309/5000, Train Loss: 0.4469\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4340\n",
      "Epoch: 310/5000, Train Loss: 0.4465\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4336\n",
      "Epoch: 311/5000, Train Loss: 0.4461\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4332\n",
      "Epoch: 312/5000, Train Loss: 0.4456\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4328\n",
      "Epoch: 313/5000, Train Loss: 0.4452\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4324\n",
      "Epoch: 314/5000, Train Loss: 0.4448\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4320\n",
      "Epoch: 315/5000, Train Loss: 0.4444\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4316\n",
      "Epoch: 316/5000, Train Loss: 0.4440\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4312\n",
      "Epoch: 317/5000, Train Loss: 0.4436\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4308\n",
      "Epoch: 318/5000, Train Loss: 0.4432\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4304\n",
      "Epoch: 319/5000, Train Loss: 0.4428\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4300\n",
      "Epoch: 320/5000, Train Loss: 0.4424\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4296\n",
      "Epoch: 321/5000, Train Loss: 0.4420\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4292\n",
      "Epoch: 322/5000, Train Loss: 0.4416\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4288\n",
      "Epoch: 323/5000, Train Loss: 0.4412\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4284\n",
      "Epoch: 324/5000, Train Loss: 0.4408\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4280\n",
      "Epoch: 325/5000, Train Loss: 0.4405\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4276\n",
      "Epoch: 326/5000, Train Loss: 0.4401\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4272\n",
      "Epoch: 327/5000, Train Loss: 0.4397\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4268\n",
      "Epoch: 328/5000, Train Loss: 0.4393\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4265\n",
      "Epoch: 329/5000, Train Loss: 0.4389\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4261\n",
      "Epoch: 330/5000, Train Loss: 0.4385\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4257\n",
      "Epoch: 331/5000, Train Loss: 0.4381\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4253\n",
      "Epoch: 332/5000, Train Loss: 0.4377\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4249\n",
      "Epoch: 333/5000, Train Loss: 0.4374\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4245\n",
      "Epoch: 334/5000, Train Loss: 0.4370\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4242\n",
      "Epoch: 335/5000, Train Loss: 0.4366\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4238\n",
      "Epoch: 336/5000, Train Loss: 0.4362\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4234\n",
      "Epoch: 337/5000, Train Loss: 0.4359\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4231\n",
      "Epoch: 338/5000, Train Loss: 0.4355\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4227\n",
      "Epoch: 339/5000, Train Loss: 0.4351\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4223\n",
      "Epoch: 340/5000, Train Loss: 0.4347\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4219\n",
      "Epoch: 341/5000, Train Loss: 0.4344\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4216\n",
      "Epoch: 342/5000, Train Loss: 0.4340\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4212\n",
      "Epoch: 343/5000, Train Loss: 0.4336\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4208\n",
      "Epoch: 344/5000, Train Loss: 0.4332\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4205\n",
      "Epoch: 345/5000, Train Loss: 0.4329\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4201\n",
      "Epoch: 346/5000, Train Loss: 0.4325\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4198\n",
      "Epoch: 347/5000, Train Loss: 0.4321\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4194\n",
      "Epoch: 348/5000, Train Loss: 0.4318\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4190\n",
      "Epoch: 349/5000, Train Loss: 0.4314\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4187\n",
      "Epoch: 350/5000, Train Loss: 0.4311\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4183\n",
      "Epoch: 351/5000, Train Loss: 0.4307\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4180\n",
      "Epoch: 352/5000, Train Loss: 0.4303\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4176\n",
      "Epoch: 353/5000, Train Loss: 0.4300\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4173\n",
      "Epoch: 354/5000, Train Loss: 0.4296\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4169\n",
      "Epoch: 355/5000, Train Loss: 0.4293\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4166\n",
      "Epoch: 356/5000, Train Loss: 0.4289\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4162\n",
      "Epoch: 357/5000, Train Loss: 0.4286\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4159\n",
      "Epoch: 358/5000, Train Loss: 0.4282\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4155\n",
      "Epoch: 359/5000, Train Loss: 0.4279\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4152\n",
      "Epoch: 360/5000, Train Loss: 0.4275\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4148\n",
      "Epoch: 361/5000, Train Loss: 0.4272\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4145\n",
      "Epoch: 362/5000, Train Loss: 0.4268\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4141\n",
      "Epoch: 363/5000, Train Loss: 0.4265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4138\n",
      "Epoch: 364/5000, Train Loss: 0.4261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4135\n",
      "Epoch: 365/5000, Train Loss: 0.4258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4131\n",
      "Epoch: 366/5000, Train Loss: 0.4254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4128\n",
      "Epoch: 367/5000, Train Loss: 0.4251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4124\n",
      "Epoch: 368/5000, Train Loss: 0.4247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4121\n",
      "Epoch: 369/5000, Train Loss: 0.4244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4118\n",
      "Epoch: 370/5000, Train Loss: 0.4241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4114\n",
      "Epoch: 371/5000, Train Loss: 0.4237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4111\n",
      "Epoch: 372/5000, Train Loss: 0.4234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4108\n",
      "Epoch: 373/5000, Train Loss: 0.4230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4104\n",
      "Epoch: 374/5000, Train Loss: 0.4227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4101\n",
      "Epoch: 375/5000, Train Loss: 0.4224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4098\n",
      "Epoch: 376/5000, Train Loss: 0.4220\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4095\n",
      "Epoch: 377/5000, Train Loss: 0.4217\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4091\n",
      "Epoch: 378/5000, Train Loss: 0.4214\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4088\n",
      "Epoch: 379/5000, Train Loss: 0.4210\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4085\n",
      "Epoch: 380/5000, Train Loss: 0.4207\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4082\n",
      "Epoch: 381/5000, Train Loss: 0.4204\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4078\n",
      "Epoch: 382/5000, Train Loss: 0.4201\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4075\n",
      "Epoch: 383/5000, Train Loss: 0.4197\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4072\n",
      "Epoch: 384/5000, Train Loss: 0.4194\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4069\n",
      "Epoch: 385/5000, Train Loss: 0.4191\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4066\n",
      "Epoch: 386/5000, Train Loss: 0.4188\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4062\n",
      "Epoch: 387/5000, Train Loss: 0.4184\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4059\n",
      "Epoch: 388/5000, Train Loss: 0.4181\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4056\n",
      "Epoch: 389/5000, Train Loss: 0.4178\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4053\n",
      "Epoch: 390/5000, Train Loss: 0.4175\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4050\n",
      "Epoch: 391/5000, Train Loss: 0.4172\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4047\n",
      "Epoch: 392/5000, Train Loss: 0.4168\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4044\n",
      "Epoch: 393/5000, Train Loss: 0.4165\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4041\n",
      "Epoch: 394/5000, Train Loss: 0.4162\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4038\n",
      "Epoch: 395/5000, Train Loss: 0.4159\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4034\n",
      "Epoch: 396/5000, Train Loss: 0.4156\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4031\n",
      "Epoch: 397/5000, Train Loss: 0.4153\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4028\n",
      "Epoch: 398/5000, Train Loss: 0.4149\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4025\n",
      "Epoch: 399/5000, Train Loss: 0.4146\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4022\n",
      "Epoch: 400/5000, Train Loss: 0.4143\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4019\n",
      "Epoch: 401/5000, Train Loss: 0.4140\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4016\n",
      "Epoch: 402/5000, Train Loss: 0.4137\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4013\n",
      "Epoch: 403/5000, Train Loss: 0.4134\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4010\n",
      "Epoch: 404/5000, Train Loss: 0.4131\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4007\n",
      "Epoch: 405/5000, Train Loss: 0.4128\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4004\n",
      "Epoch: 406/5000, Train Loss: 0.4125\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.4001\n",
      "Epoch: 407/5000, Train Loss: 0.4122\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3998\n",
      "Epoch: 408/5000, Train Loss: 0.4119\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3995\n",
      "Epoch: 409/5000, Train Loss: 0.4116\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3992\n",
      "Epoch: 410/5000, Train Loss: 0.4113\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3989\n",
      "Epoch: 411/5000, Train Loss: 0.4110\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3987\n",
      "Epoch: 412/5000, Train Loss: 0.4107\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3984\n",
      "Epoch: 413/5000, Train Loss: 0.4104\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3981\n",
      "Epoch: 414/5000, Train Loss: 0.4101\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3978\n",
      "Epoch: 415/5000, Train Loss: 0.4098\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3975\n",
      "Epoch: 416/5000, Train Loss: 0.4095\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3972\n",
      "Epoch: 417/5000, Train Loss: 0.4092\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3969\n",
      "Epoch: 418/5000, Train Loss: 0.4089\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3966\n",
      "Epoch: 419/5000, Train Loss: 0.4086\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3963\n",
      "Epoch: 420/5000, Train Loss: 0.4083\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3961\n",
      "Epoch: 421/5000, Train Loss: 0.4080\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3958\n",
      "Epoch: 422/5000, Train Loss: 0.4077\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3955\n",
      "Epoch: 423/5000, Train Loss: 0.4074\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3952\n",
      "Epoch: 424/5000, Train Loss: 0.4071\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3949\n",
      "Epoch: 425/5000, Train Loss: 0.4068\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3947\n",
      "Epoch: 426/5000, Train Loss: 0.4065\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3944\n",
      "Epoch: 427/5000, Train Loss: 0.4063\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3941\n",
      "Epoch: 428/5000, Train Loss: 0.4060\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3938\n",
      "Epoch: 429/5000, Train Loss: 0.4057\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3935\n",
      "Epoch: 430/5000, Train Loss: 0.4054\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3933\n",
      "Epoch: 431/5000, Train Loss: 0.4051\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3930\n",
      "Epoch: 432/5000, Train Loss: 0.4048\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3927\n",
      "Epoch: 433/5000, Train Loss: 0.4045\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3924\n",
      "Epoch: 434/5000, Train Loss: 0.4043\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3922\n",
      "Epoch: 435/5000, Train Loss: 0.4040\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3919\n",
      "Epoch: 436/5000, Train Loss: 0.4037\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3916\n",
      "Epoch: 437/5000, Train Loss: 0.4034\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3914\n",
      "Epoch: 438/5000, Train Loss: 0.4031\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3911\n",
      "Epoch: 439/5000, Train Loss: 0.4029\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3908\n",
      "Epoch: 440/5000, Train Loss: 0.4026\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3906\n",
      "Epoch: 441/5000, Train Loss: 0.4023\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3903\n",
      "Epoch: 442/5000, Train Loss: 0.4020\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3900\n",
      "Epoch: 443/5000, Train Loss: 0.4018\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3898\n",
      "Epoch: 444/5000, Train Loss: 0.4015\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3895\n",
      "Epoch: 445/5000, Train Loss: 0.4012\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3892\n",
      "Epoch: 446/5000, Train Loss: 0.4009\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3890\n",
      "Epoch: 447/5000, Train Loss: 0.4007\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3887\n",
      "Epoch: 448/5000, Train Loss: 0.4004\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3884\n",
      "Epoch: 449/5000, Train Loss: 0.4001\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3882\n",
      "Epoch: 450/5000, Train Loss: 0.3998\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3879\n",
      "Epoch: 451/5000, Train Loss: 0.3996\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3877\n",
      "Epoch: 452/5000, Train Loss: 0.3993\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3874\n",
      "Epoch: 453/5000, Train Loss: 0.3990\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3871\n",
      "Epoch: 454/5000, Train Loss: 0.3988\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3869\n",
      "Epoch: 455/5000, Train Loss: 0.3985\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3866\n",
      "Epoch: 456/5000, Train Loss: 0.3982\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3864\n",
      "Epoch: 457/5000, Train Loss: 0.3980\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3861\n",
      "Epoch: 458/5000, Train Loss: 0.3977\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3859\n",
      "Epoch: 459/5000, Train Loss: 0.3974\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3856\n",
      "Epoch: 460/5000, Train Loss: 0.3972\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3854\n",
      "Epoch: 461/5000, Train Loss: 0.3969\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3851\n",
      "Epoch: 462/5000, Train Loss: 0.3967\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3849\n",
      "Epoch: 463/5000, Train Loss: 0.3964\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3846\n",
      "Epoch: 464/5000, Train Loss: 0.3961\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3844\n",
      "Epoch: 465/5000, Train Loss: 0.3959\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3841\n",
      "Epoch: 466/5000, Train Loss: 0.3956\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3839\n",
      "Epoch: 467/5000, Train Loss: 0.3954\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3836\n",
      "Epoch: 468/5000, Train Loss: 0.3951\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3834\n",
      "Epoch: 469/5000, Train Loss: 0.3948\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3831\n",
      "Epoch: 470/5000, Train Loss: 0.3946\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3829\n",
      "Epoch: 471/5000, Train Loss: 0.3943\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3826\n",
      "Epoch: 472/5000, Train Loss: 0.3941\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3824\n",
      "Epoch: 473/5000, Train Loss: 0.3938\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3822\n",
      "Epoch: 474/5000, Train Loss: 0.3936\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3819\n",
      "Epoch: 475/5000, Train Loss: 0.3933\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3817\n",
      "Epoch: 476/5000, Train Loss: 0.3931\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3814\n",
      "Epoch: 477/5000, Train Loss: 0.3928\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3812\n",
      "Epoch: 478/5000, Train Loss: 0.3926\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3810\n",
      "Epoch: 479/5000, Train Loss: 0.3923\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3807\n",
      "Epoch: 480/5000, Train Loss: 0.3921\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3805\n",
      "Epoch: 481/5000, Train Loss: 0.3918\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3802\n",
      "Epoch: 482/5000, Train Loss: 0.3916\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3800\n",
      "Epoch: 483/5000, Train Loss: 0.3913\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3798\n",
      "Epoch: 484/5000, Train Loss: 0.3911\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3795\n",
      "Epoch: 485/5000, Train Loss: 0.3908\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3793\n",
      "Epoch: 486/5000, Train Loss: 0.3906\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3791\n",
      "Epoch: 487/5000, Train Loss: 0.3903\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3788\n",
      "Epoch: 488/5000, Train Loss: 0.3901\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3786\n",
      "Epoch: 489/5000, Train Loss: 0.3899\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3784\n",
      "Epoch: 490/5000, Train Loss: 0.3896\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3781\n",
      "Epoch: 491/5000, Train Loss: 0.3894\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3779\n",
      "Epoch: 492/5000, Train Loss: 0.3891\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3777\n",
      "Epoch: 493/5000, Train Loss: 0.3889\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3774\n",
      "Epoch: 494/5000, Train Loss: 0.3886\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3772\n",
      "Epoch: 495/5000, Train Loss: 0.3884\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3770\n",
      "Epoch: 496/5000, Train Loss: 0.3882\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3768\n",
      "Epoch: 497/5000, Train Loss: 0.3879\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3765\n",
      "Epoch: 498/5000, Train Loss: 0.3877\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3763\n",
      "Epoch: 499/5000, Train Loss: 0.3874\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3761\n",
      "Epoch: 500/5000, Train Loss: 0.3872\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3759\n",
      "Epoch: 501/5000, Train Loss: 0.3870\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3756\n",
      "Epoch: 502/5000, Train Loss: 0.3867\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3754\n",
      "Epoch: 503/5000, Train Loss: 0.3865\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3752\n",
      "Epoch: 504/5000, Train Loss: 0.3863\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3750\n",
      "Epoch: 505/5000, Train Loss: 0.3860\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3747\n",
      "Epoch: 506/5000, Train Loss: 0.3858\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3745\n",
      "Epoch: 507/5000, Train Loss: 0.3856\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3743\n",
      "Epoch: 508/5000, Train Loss: 0.3853\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3741\n",
      "Epoch: 509/5000, Train Loss: 0.3851\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3739\n",
      "Epoch: 510/5000, Train Loss: 0.3849\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3736\n",
      "Epoch: 511/5000, Train Loss: 0.3846\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3734\n",
      "Epoch: 512/5000, Train Loss: 0.3844\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3732\n",
      "Epoch: 513/5000, Train Loss: 0.3842\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3730\n",
      "Epoch: 514/5000, Train Loss: 0.3840\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3728\n",
      "Epoch: 515/5000, Train Loss: 0.3837\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3725\n",
      "Epoch: 516/5000, Train Loss: 0.3835\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3723\n",
      "Epoch: 517/5000, Train Loss: 0.3833\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3721\n",
      "Epoch: 518/5000, Train Loss: 0.3830\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3719\n",
      "Epoch: 519/5000, Train Loss: 0.3828\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3717\n",
      "Epoch: 520/5000, Train Loss: 0.3826\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3715\n",
      "Epoch: 521/5000, Train Loss: 0.3824\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3713\n",
      "Epoch: 522/5000, Train Loss: 0.3821\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3711\n",
      "Epoch: 523/5000, Train Loss: 0.3819\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3708\n",
      "Epoch: 524/5000, Train Loss: 0.3817\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3706\n",
      "Epoch: 525/5000, Train Loss: 0.3815\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3704\n",
      "Epoch: 526/5000, Train Loss: 0.3813\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3702\n",
      "Epoch: 527/5000, Train Loss: 0.3810\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3700\n",
      "Epoch: 528/5000, Train Loss: 0.3808\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3698\n",
      "Epoch: 529/5000, Train Loss: 0.3806\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3696\n",
      "Epoch: 530/5000, Train Loss: 0.3804\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3694\n",
      "Epoch: 531/5000, Train Loss: 0.3802\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3692\n",
      "Epoch: 532/5000, Train Loss: 0.3799\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3690\n",
      "Epoch: 533/5000, Train Loss: 0.3797\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3688\n",
      "Epoch: 534/5000, Train Loss: 0.3795\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3686\n",
      "Epoch: 535/5000, Train Loss: 0.3793\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3684\n",
      "Epoch: 536/5000, Train Loss: 0.3791\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3681\n",
      "Epoch: 537/5000, Train Loss: 0.3788\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3679\n",
      "Epoch: 538/5000, Train Loss: 0.3786\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3677\n",
      "Epoch: 539/5000, Train Loss: 0.3784\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3675\n",
      "Epoch: 540/5000, Train Loss: 0.3782\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3673\n",
      "Epoch: 541/5000, Train Loss: 0.3780\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3671\n",
      "Epoch: 542/5000, Train Loss: 0.3778\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3669\n",
      "Epoch: 543/5000, Train Loss: 0.3776\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3667\n",
      "Epoch: 544/5000, Train Loss: 0.3773\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3665\n",
      "Epoch: 545/5000, Train Loss: 0.3771\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3663\n",
      "Epoch: 546/5000, Train Loss: 0.3769\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3661\n",
      "Epoch: 547/5000, Train Loss: 0.3767\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3659\n",
      "Epoch: 548/5000, Train Loss: 0.3765\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3657\n",
      "Epoch: 549/5000, Train Loss: 0.3763\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3655\n",
      "Epoch: 550/5000, Train Loss: 0.3761\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3653\n",
      "Epoch: 551/5000, Train Loss: 0.3759\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3651\n",
      "Epoch: 552/5000, Train Loss: 0.3757\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3650\n",
      "Epoch: 553/5000, Train Loss: 0.3755\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3648\n",
      "Epoch: 554/5000, Train Loss: 0.3753\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3646\n",
      "Epoch: 555/5000, Train Loss: 0.3750\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3644\n",
      "Epoch: 556/5000, Train Loss: 0.3748\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3642\n",
      "Epoch: 557/5000, Train Loss: 0.3746\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3640\n",
      "Epoch: 558/5000, Train Loss: 0.3744\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3638\n",
      "Epoch: 559/5000, Train Loss: 0.3742\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3636\n",
      "Epoch: 560/5000, Train Loss: 0.3740\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3634\n",
      "Epoch: 561/5000, Train Loss: 0.3738\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3632\n",
      "Epoch: 562/5000, Train Loss: 0.3736\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3630\n",
      "Epoch: 563/5000, Train Loss: 0.3734\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3628\n",
      "Epoch: 564/5000, Train Loss: 0.3732\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3626\n",
      "Epoch: 565/5000, Train Loss: 0.3730\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3625\n",
      "Epoch: 566/5000, Train Loss: 0.3728\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3623\n",
      "Epoch: 567/5000, Train Loss: 0.3726\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3621\n",
      "Epoch: 568/5000, Train Loss: 0.3724\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3619\n",
      "Epoch: 569/5000, Train Loss: 0.3722\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3617\n",
      "Epoch: 570/5000, Train Loss: 0.3720\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3615\n",
      "Epoch: 571/5000, Train Loss: 0.3718\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3613\n",
      "Epoch: 572/5000, Train Loss: 0.3716\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3611\n",
      "Epoch: 573/5000, Train Loss: 0.3714\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3610\n",
      "Epoch: 574/5000, Train Loss: 0.3712\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3608\n",
      "Epoch: 575/5000, Train Loss: 0.3710\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3606\n",
      "Epoch: 576/5000, Train Loss: 0.3708\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3604\n",
      "Epoch: 577/5000, Train Loss: 0.3706\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3602\n",
      "Epoch: 578/5000, Train Loss: 0.3704\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3600\n",
      "Epoch: 579/5000, Train Loss: 0.3702\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3599\n",
      "Epoch: 580/5000, Train Loss: 0.3700\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3597\n",
      "Epoch: 581/5000, Train Loss: 0.3698\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3595\n",
      "Epoch: 582/5000, Train Loss: 0.3696\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3593\n",
      "Epoch: 583/5000, Train Loss: 0.3694\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3591\n",
      "Epoch: 584/5000, Train Loss: 0.3692\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3590\n",
      "Epoch: 585/5000, Train Loss: 0.3691\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3588\n",
      "Epoch: 586/5000, Train Loss: 0.3689\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3586\n",
      "Epoch: 587/5000, Train Loss: 0.3687\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3584\n",
      "Epoch: 588/5000, Train Loss: 0.3685\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3582\n",
      "Epoch: 589/5000, Train Loss: 0.3683\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3581\n",
      "Epoch: 590/5000, Train Loss: 0.3681\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3579\n",
      "Epoch: 591/5000, Train Loss: 0.3679\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3577\n",
      "Epoch: 592/5000, Train Loss: 0.3677\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3575\n",
      "Epoch: 593/5000, Train Loss: 0.3675\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3574\n",
      "Epoch: 594/5000, Train Loss: 0.3673\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3572\n",
      "Epoch: 595/5000, Train Loss: 0.3671\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3570\n",
      "Epoch: 596/5000, Train Loss: 0.3670\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3568\n",
      "Epoch: 597/5000, Train Loss: 0.3668\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3566\n",
      "Epoch: 598/5000, Train Loss: 0.3666\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3565\n",
      "Epoch: 599/5000, Train Loss: 0.3664\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3563\n",
      "Epoch: 600/5000, Train Loss: 0.3662\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3561\n",
      "Epoch: 601/5000, Train Loss: 0.3660\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3560\n",
      "Epoch: 602/5000, Train Loss: 0.3658\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3558\n",
      "Epoch: 603/5000, Train Loss: 0.3657\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3556\n",
      "Epoch: 604/5000, Train Loss: 0.3655\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3554\n",
      "Epoch: 605/5000, Train Loss: 0.3653\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3553\n",
      "Epoch: 606/5000, Train Loss: 0.3651\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3551\n",
      "Epoch: 607/5000, Train Loss: 0.3649\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3549\n",
      "Epoch: 608/5000, Train Loss: 0.3647\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3548\n",
      "Epoch: 609/5000, Train Loss: 0.3645\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3546\n",
      "Epoch: 610/5000, Train Loss: 0.3644\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3544\n",
      "Epoch: 611/5000, Train Loss: 0.3642\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3543\n",
      "Epoch: 612/5000, Train Loss: 0.3640\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3541\n",
      "Epoch: 613/5000, Train Loss: 0.3638\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3539\n",
      "Epoch: 614/5000, Train Loss: 0.3636\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3537\n",
      "Epoch: 615/5000, Train Loss: 0.3635\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3536\n",
      "Epoch: 616/5000, Train Loss: 0.3633\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3534\n",
      "Epoch: 617/5000, Train Loss: 0.3631\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3532\n",
      "Epoch: 618/5000, Train Loss: 0.3629\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3531\n",
      "Epoch: 619/5000, Train Loss: 0.3627\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3529\n",
      "Epoch: 620/5000, Train Loss: 0.3626\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3528\n",
      "Epoch: 621/5000, Train Loss: 0.3624\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3526\n",
      "Epoch: 622/5000, Train Loss: 0.3622\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3524\n",
      "Epoch: 623/5000, Train Loss: 0.3620\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3523\n",
      "Epoch: 624/5000, Train Loss: 0.3619\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3521\n",
      "Epoch: 625/5000, Train Loss: 0.3617\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3519\n",
      "Epoch: 626/5000, Train Loss: 0.3615\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3518\n",
      "Epoch: 627/5000, Train Loss: 0.3613\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3516\n",
      "Epoch: 628/5000, Train Loss: 0.3611\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3514\n",
      "Epoch: 629/5000, Train Loss: 0.3610\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3513\n",
      "Epoch: 630/5000, Train Loss: 0.3608\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3511\n",
      "Epoch: 631/5000, Train Loss: 0.3606\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3510\n",
      "Epoch: 632/5000, Train Loss: 0.3604\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3508\n",
      "Epoch: 633/5000, Train Loss: 0.3603\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3506\n",
      "Epoch: 634/5000, Train Loss: 0.3601\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3505\n",
      "Epoch: 635/5000, Train Loss: 0.3599\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3503\n",
      "Epoch: 636/5000, Train Loss: 0.3598\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3502\n",
      "Epoch: 637/5000, Train Loss: 0.3596\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3500\n",
      "Epoch: 638/5000, Train Loss: 0.3594\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3498\n",
      "Epoch: 639/5000, Train Loss: 0.3592\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3497\n",
      "Epoch: 640/5000, Train Loss: 0.3591\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3495\n",
      "Epoch: 641/5000, Train Loss: 0.3589\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3494\n",
      "Epoch: 642/5000, Train Loss: 0.3587\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3492\n",
      "Epoch: 643/5000, Train Loss: 0.3586\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3491\n",
      "Epoch: 644/5000, Train Loss: 0.3584\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3489\n",
      "Epoch: 645/5000, Train Loss: 0.3582\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3488\n",
      "Epoch: 646/5000, Train Loss: 0.3581\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3486\n",
      "Epoch: 647/5000, Train Loss: 0.3579\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3484\n",
      "Epoch: 648/5000, Train Loss: 0.3577\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3483\n",
      "Epoch: 649/5000, Train Loss: 0.3575\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3481\n",
      "Epoch: 650/5000, Train Loss: 0.3574\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3480\n",
      "Epoch: 651/5000, Train Loss: 0.3572\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3478\n",
      "Epoch: 652/5000, Train Loss: 0.3570\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3477\n",
      "Epoch: 653/5000, Train Loss: 0.3569\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3475\n",
      "Epoch: 654/5000, Train Loss: 0.3567\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3474\n",
      "Epoch: 655/5000, Train Loss: 0.3565\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3472\n",
      "Epoch: 656/5000, Train Loss: 0.3564\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3471\n",
      "Epoch: 657/5000, Train Loss: 0.3562\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3469\n",
      "Epoch: 658/5000, Train Loss: 0.3561\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3468\n",
      "Epoch: 659/5000, Train Loss: 0.3559\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3466\n",
      "Epoch: 660/5000, Train Loss: 0.3557\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3465\n",
      "Epoch: 661/5000, Train Loss: 0.3556\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3463\n",
      "Epoch: 662/5000, Train Loss: 0.3554\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3462\n",
      "Epoch: 663/5000, Train Loss: 0.3552\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3460\n",
      "Epoch: 664/5000, Train Loss: 0.3551\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3459\n",
      "Epoch: 665/5000, Train Loss: 0.3549\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3457\n",
      "Epoch: 666/5000, Train Loss: 0.3548\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3456\n",
      "Epoch: 667/5000, Train Loss: 0.3546\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3454\n",
      "Epoch: 668/5000, Train Loss: 0.3544\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3453\n",
      "Epoch: 669/5000, Train Loss: 0.3543\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3451\n",
      "Epoch: 670/5000, Train Loss: 0.3541\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3450\n",
      "Epoch: 671/5000, Train Loss: 0.3539\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3448\n",
      "Epoch: 672/5000, Train Loss: 0.3538\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3447\n",
      "Epoch: 673/5000, Train Loss: 0.3536\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3445\n",
      "Epoch: 674/5000, Train Loss: 0.3535\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3444\n",
      "Epoch: 675/5000, Train Loss: 0.3533\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3443\n",
      "Epoch: 676/5000, Train Loss: 0.3531\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3441\n",
      "Epoch: 677/5000, Train Loss: 0.3530\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3440\n",
      "Epoch: 678/5000, Train Loss: 0.3528\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3438\n",
      "Epoch: 679/5000, Train Loss: 0.3527\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3437\n",
      "Epoch: 680/5000, Train Loss: 0.3525\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3435\n",
      "Epoch: 681/5000, Train Loss: 0.3524\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3434\n",
      "Epoch: 682/5000, Train Loss: 0.3522\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3432\n",
      "Epoch: 683/5000, Train Loss: 0.3520\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3431\n",
      "Epoch: 684/5000, Train Loss: 0.3519\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3430\n",
      "Epoch: 685/5000, Train Loss: 0.3517\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3428\n",
      "Epoch: 686/5000, Train Loss: 0.3516\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3427\n",
      "Epoch: 687/5000, Train Loss: 0.3514\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3425\n",
      "Epoch: 688/5000, Train Loss: 0.3513\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3424\n",
      "Epoch: 689/5000, Train Loss: 0.3511\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3423\n",
      "Epoch: 690/5000, Train Loss: 0.3510\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3421\n",
      "Epoch: 691/5000, Train Loss: 0.3508\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3420\n",
      "Epoch: 692/5000, Train Loss: 0.3507\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3418\n",
      "Epoch: 693/5000, Train Loss: 0.3505\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3417\n",
      "Epoch: 694/5000, Train Loss: 0.3504\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3416\n",
      "Epoch: 695/5000, Train Loss: 0.3502\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3414\n",
      "Epoch: 696/5000, Train Loss: 0.3500\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3413\n",
      "Epoch: 697/5000, Train Loss: 0.3499\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3411\n",
      "Epoch: 698/5000, Train Loss: 0.3497\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3410\n",
      "Epoch: 699/5000, Train Loss: 0.3496\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3409\n",
      "Epoch: 700/5000, Train Loss: 0.3494\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3407\n",
      "Epoch: 701/5000, Train Loss: 0.3493\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3406\n",
      "Epoch: 702/5000, Train Loss: 0.3491\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3405\n",
      "Epoch: 703/5000, Train Loss: 0.3490\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3403\n",
      "Epoch: 704/5000, Train Loss: 0.3488\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3402\n",
      "Epoch: 705/5000, Train Loss: 0.3487\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3401\n",
      "Epoch: 706/5000, Train Loss: 0.3485\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3399\n",
      "Epoch: 707/5000, Train Loss: 0.3484\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3398\n",
      "Epoch: 708/5000, Train Loss: 0.3482\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3396\n",
      "Epoch: 709/5000, Train Loss: 0.3481\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3395\n",
      "Epoch: 710/5000, Train Loss: 0.3479\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3394\n",
      "Epoch: 711/5000, Train Loss: 0.3478\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3392\n",
      "Epoch: 712/5000, Train Loss: 0.3477\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3391\n",
      "Epoch: 713/5000, Train Loss: 0.3475\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3390\n",
      "Epoch: 714/5000, Train Loss: 0.3474\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3388\n",
      "Epoch: 715/5000, Train Loss: 0.3472\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3387\n",
      "Epoch: 716/5000, Train Loss: 0.3471\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3386\n",
      "Epoch: 717/5000, Train Loss: 0.3469\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3384\n",
      "Epoch: 718/5000, Train Loss: 0.3468\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3383\n",
      "Epoch: 719/5000, Train Loss: 0.3466\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3382\n",
      "Epoch: 720/5000, Train Loss: 0.3465\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3381\n",
      "Epoch: 721/5000, Train Loss: 0.3463\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3379\n",
      "Epoch: 722/5000, Train Loss: 0.3462\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3378\n",
      "Epoch: 723/5000, Train Loss: 0.3460\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3377\n",
      "Epoch: 724/5000, Train Loss: 0.3459\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3375\n",
      "Epoch: 725/5000, Train Loss: 0.3458\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3374\n",
      "Epoch: 726/5000, Train Loss: 0.3456\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3373\n",
      "Epoch: 727/5000, Train Loss: 0.3455\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3371\n",
      "Epoch: 728/5000, Train Loss: 0.3453\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3370\n",
      "Epoch: 729/5000, Train Loss: 0.3452\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3369\n",
      "Epoch: 730/5000, Train Loss: 0.3450\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3368\n",
      "Epoch: 731/5000, Train Loss: 0.3449\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3366\n",
      "Epoch: 732/5000, Train Loss: 0.3448\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3365\n",
      "Epoch: 733/5000, Train Loss: 0.3446\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3364\n",
      "Epoch: 734/5000, Train Loss: 0.3445\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3362\n",
      "Epoch: 735/5000, Train Loss: 0.3443\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3361\n",
      "Epoch: 736/5000, Train Loss: 0.3442\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3360\n",
      "Epoch: 737/5000, Train Loss: 0.3441\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3359\n",
      "Epoch: 738/5000, Train Loss: 0.3439\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3357\n",
      "Epoch: 739/5000, Train Loss: 0.3438\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3356\n",
      "Epoch: 740/5000, Train Loss: 0.3436\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3355\n",
      "Epoch: 741/5000, Train Loss: 0.3435\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3354\n",
      "Epoch: 742/5000, Train Loss: 0.3434\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3352\n",
      "Epoch: 743/5000, Train Loss: 0.3432\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3351\n",
      "Epoch: 744/5000, Train Loss: 0.3431\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3350\n",
      "Epoch: 745/5000, Train Loss: 0.3429\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3349\n",
      "Epoch: 746/5000, Train Loss: 0.3428\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3347\n",
      "Epoch: 747/5000, Train Loss: 0.3427\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3346\n",
      "Epoch: 748/5000, Train Loss: 0.3425\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3345\n",
      "Epoch: 749/5000, Train Loss: 0.3424\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3344\n",
      "Epoch: 750/5000, Train Loss: 0.3423\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3342\n",
      "Epoch: 751/5000, Train Loss: 0.3421\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3341\n",
      "Epoch: 752/5000, Train Loss: 0.3420\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3340\n",
      "Epoch: 753/5000, Train Loss: 0.3418\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3339\n",
      "Epoch: 754/5000, Train Loss: 0.3417\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3338\n",
      "Epoch: 755/5000, Train Loss: 0.3416\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3336\n",
      "Epoch: 756/5000, Train Loss: 0.3414\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3335\n",
      "Epoch: 757/5000, Train Loss: 0.3413\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3334\n",
      "Epoch: 758/5000, Train Loss: 0.3412\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3333\n",
      "Epoch: 759/5000, Train Loss: 0.3410\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3331\n",
      "Epoch: 760/5000, Train Loss: 0.3409\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3330\n",
      "Epoch: 761/5000, Train Loss: 0.3408\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3329\n",
      "Epoch: 762/5000, Train Loss: 0.3406\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3328\n",
      "Epoch: 763/5000, Train Loss: 0.3405\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3327\n",
      "Epoch: 764/5000, Train Loss: 0.3404\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3325\n",
      "Epoch: 765/5000, Train Loss: 0.3402\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3324\n",
      "Epoch: 766/5000, Train Loss: 0.3401\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3323\n",
      "Epoch: 767/5000, Train Loss: 0.3400\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3322\n",
      "Epoch: 768/5000, Train Loss: 0.3398\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3321\n",
      "Epoch: 769/5000, Train Loss: 0.3397\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3320\n",
      "Epoch: 770/5000, Train Loss: 0.3396\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3318\n",
      "Epoch: 771/5000, Train Loss: 0.3394\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3317\n",
      "Epoch: 772/5000, Train Loss: 0.3393\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3316\n",
      "Epoch: 773/5000, Train Loss: 0.3392\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3315\n",
      "Epoch: 774/5000, Train Loss: 0.3390\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3314\n",
      "Epoch: 775/5000, Train Loss: 0.3389\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3313\n",
      "Epoch: 776/5000, Train Loss: 0.3388\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3311\n",
      "Epoch: 777/5000, Train Loss: 0.3387\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3310\n",
      "Epoch: 778/5000, Train Loss: 0.3385\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3309\n",
      "Epoch: 779/5000, Train Loss: 0.3384\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3308\n",
      "Epoch: 780/5000, Train Loss: 0.3383\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3307\n",
      "Epoch: 781/5000, Train Loss: 0.3381\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3306\n",
      "Epoch: 782/5000, Train Loss: 0.3380\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3304\n",
      "Epoch: 783/5000, Train Loss: 0.3379\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3303\n",
      "Epoch: 784/5000, Train Loss: 0.3377\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3302\n",
      "Epoch: 785/5000, Train Loss: 0.3376\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3301\n",
      "Epoch: 786/5000, Train Loss: 0.3375\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3300\n",
      "Epoch: 787/5000, Train Loss: 0.3374\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3299\n",
      "Epoch: 788/5000, Train Loss: 0.3372\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3298\n",
      "Epoch: 789/5000, Train Loss: 0.3371\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3296\n",
      "Epoch: 790/5000, Train Loss: 0.3370\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3295\n",
      "Epoch: 791/5000, Train Loss: 0.3369\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3294\n",
      "Epoch: 792/5000, Train Loss: 0.3367\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3293\n",
      "Epoch: 793/5000, Train Loss: 0.3366\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3292\n",
      "Epoch: 794/5000, Train Loss: 0.3365\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3291\n",
      "Epoch: 795/5000, Train Loss: 0.3364\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3290\n",
      "Epoch: 796/5000, Train Loss: 0.3362\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3289\n",
      "Epoch: 797/5000, Train Loss: 0.3361\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3287\n",
      "Epoch: 798/5000, Train Loss: 0.3360\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3286\n",
      "Epoch: 799/5000, Train Loss: 0.3358\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3285\n",
      "Epoch: 800/5000, Train Loss: 0.3357\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3284\n",
      "Epoch: 801/5000, Train Loss: 0.3356\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3283\n",
      "Epoch: 802/5000, Train Loss: 0.3355\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3282\n",
      "Epoch: 803/5000, Train Loss: 0.3354\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3281\n",
      "Epoch: 804/5000, Train Loss: 0.3352\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3280\n",
      "Epoch: 805/5000, Train Loss: 0.3351\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3279\n",
      "Epoch: 806/5000, Train Loss: 0.3350\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3277\n",
      "Epoch: 807/5000, Train Loss: 0.3349\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3276\n",
      "Epoch: 808/5000, Train Loss: 0.3347\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3275\n",
      "Epoch: 809/5000, Train Loss: 0.3346\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3274\n",
      "Epoch: 810/5000, Train Loss: 0.3345\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3273\n",
      "Epoch: 811/5000, Train Loss: 0.3344\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3272\n",
      "Epoch: 812/5000, Train Loss: 0.3342\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3271\n",
      "Epoch: 813/5000, Train Loss: 0.3341\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3270\n",
      "Epoch: 814/5000, Train Loss: 0.3340\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3269\n",
      "Epoch: 815/5000, Train Loss: 0.3339\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3268\n",
      "Epoch: 816/5000, Train Loss: 0.3338\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3267\n",
      "Epoch: 817/5000, Train Loss: 0.3336\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3266\n",
      "Epoch: 818/5000, Train Loss: 0.3335\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3264\n",
      "Epoch: 819/5000, Train Loss: 0.3334\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3263\n",
      "Epoch: 820/5000, Train Loss: 0.3333\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3262\n",
      "Epoch: 821/5000, Train Loss: 0.3332\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3261\n",
      "Epoch: 822/5000, Train Loss: 0.3330\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3260\n",
      "Epoch: 823/5000, Train Loss: 0.3329\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3259\n",
      "Epoch: 824/5000, Train Loss: 0.3328\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3258\n",
      "Epoch: 825/5000, Train Loss: 0.3327\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3257\n",
      "Epoch: 826/5000, Train Loss: 0.3326\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3256\n",
      "Epoch: 827/5000, Train Loss: 0.3324\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3255\n",
      "Epoch: 828/5000, Train Loss: 0.3323\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3254\n",
      "Epoch: 829/5000, Train Loss: 0.3322\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3253\n",
      "Epoch: 830/5000, Train Loss: 0.3321\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3252\n",
      "Epoch: 831/5000, Train Loss: 0.3320\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3251\n",
      "Epoch: 832/5000, Train Loss: 0.3318\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3250\n",
      "Epoch: 833/5000, Train Loss: 0.3317\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3249\n",
      "Epoch: 834/5000, Train Loss: 0.3316\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3248\n",
      "Epoch: 835/5000, Train Loss: 0.3315\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3247\n",
      "Epoch: 836/5000, Train Loss: 0.3314\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3246\n",
      "Epoch: 837/5000, Train Loss: 0.3313\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3244\n",
      "Epoch: 838/5000, Train Loss: 0.3311\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3243\n",
      "Epoch: 839/5000, Train Loss: 0.3310\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3242\n",
      "Epoch: 840/5000, Train Loss: 0.3309\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3241\n",
      "Epoch: 841/5000, Train Loss: 0.3308\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3240\n",
      "Epoch: 842/5000, Train Loss: 0.3307\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3239\n",
      "Epoch: 843/5000, Train Loss: 0.3306\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3238\n",
      "Epoch: 844/5000, Train Loss: 0.3304\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3237\n",
      "Epoch: 845/5000, Train Loss: 0.3303\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3236\n",
      "Epoch: 846/5000, Train Loss: 0.3302\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3235\n",
      "Epoch: 847/5000, Train Loss: 0.3301\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3234\n",
      "Epoch: 848/5000, Train Loss: 0.3300\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3233\n",
      "Epoch: 849/5000, Train Loss: 0.3299\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3232\n",
      "Epoch: 850/5000, Train Loss: 0.3298\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3231\n",
      "Epoch: 851/5000, Train Loss: 0.3296\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3230\n",
      "Epoch: 852/5000, Train Loss: 0.3295\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3229\n",
      "Epoch: 853/5000, Train Loss: 0.3294\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3228\n",
      "Epoch: 854/5000, Train Loss: 0.3293\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3227\n",
      "Epoch: 855/5000, Train Loss: 0.3292\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3226\n",
      "Epoch: 856/5000, Train Loss: 0.3291\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3225\n",
      "Epoch: 857/5000, Train Loss: 0.3290\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3224\n",
      "Epoch: 858/5000, Train Loss: 0.3288\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3223\n",
      "Epoch: 859/5000, Train Loss: 0.3287\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3222\n",
      "Epoch: 860/5000, Train Loss: 0.3286\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3221\n",
      "Epoch: 861/5000, Train Loss: 0.3285\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3220\n",
      "Epoch: 862/5000, Train Loss: 0.3284\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3219\n",
      "Epoch: 863/5000, Train Loss: 0.3283\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3218\n",
      "Epoch: 864/5000, Train Loss: 0.3282\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3217\n",
      "Epoch: 865/5000, Train Loss: 0.3281\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3216\n",
      "Epoch: 866/5000, Train Loss: 0.3280\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3215\n",
      "Epoch: 867/5000, Train Loss: 0.3278\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3214\n",
      "Epoch: 868/5000, Train Loss: 0.3277\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3213\n",
      "Epoch: 869/5000, Train Loss: 0.3276\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3212\n",
      "Epoch: 870/5000, Train Loss: 0.3275\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3211\n",
      "Epoch: 871/5000, Train Loss: 0.3274\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3211\n",
      "Epoch: 872/5000, Train Loss: 0.3273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3210\n",
      "Epoch: 873/5000, Train Loss: 0.3272\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3209\n",
      "Epoch: 874/5000, Train Loss: 0.3271\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3208\n",
      "Epoch: 875/5000, Train Loss: 0.3270\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3207\n",
      "Epoch: 876/5000, Train Loss: 0.3268\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3206\n",
      "Epoch: 877/5000, Train Loss: 0.3267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3205\n",
      "Epoch: 878/5000, Train Loss: 0.3266\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3204\n",
      "Epoch: 879/5000, Train Loss: 0.3265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3203\n",
      "Epoch: 880/5000, Train Loss: 0.3264\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3202\n",
      "Epoch: 881/5000, Train Loss: 0.3263\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3201\n",
      "Epoch: 882/5000, Train Loss: 0.3262\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3200\n",
      "Epoch: 883/5000, Train Loss: 0.3261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3199\n",
      "Epoch: 884/5000, Train Loss: 0.3260\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3198\n",
      "Epoch: 885/5000, Train Loss: 0.3259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3197\n",
      "Epoch: 886/5000, Train Loss: 0.3258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3196\n",
      "Epoch: 887/5000, Train Loss: 0.3257\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3195\n",
      "Epoch: 888/5000, Train Loss: 0.3256\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3194\n",
      "Epoch: 889/5000, Train Loss: 0.3254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3193\n",
      "Epoch: 890/5000, Train Loss: 0.3253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3192\n",
      "Epoch: 891/5000, Train Loss: 0.3252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3192\n",
      "Epoch: 892/5000, Train Loss: 0.3251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3191\n",
      "Epoch: 893/5000, Train Loss: 0.3250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3190\n",
      "Epoch: 894/5000, Train Loss: 0.3249\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3189\n",
      "Epoch: 895/5000, Train Loss: 0.3248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3188\n",
      "Epoch: 896/5000, Train Loss: 0.3247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3187\n",
      "Epoch: 897/5000, Train Loss: 0.3246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3186\n",
      "Epoch: 898/5000, Train Loss: 0.3245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3185\n",
      "Epoch: 899/5000, Train Loss: 0.3244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3184\n",
      "Epoch: 900/5000, Train Loss: 0.3243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3183\n",
      "Epoch: 901/5000, Train Loss: 0.3242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3182\n",
      "Epoch: 902/5000, Train Loss: 0.3241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3181\n",
      "Epoch: 903/5000, Train Loss: 0.3240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3180\n",
      "Epoch: 904/5000, Train Loss: 0.3239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3180\n",
      "Epoch: 905/5000, Train Loss: 0.3238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3179\n",
      "Epoch: 906/5000, Train Loss: 0.3237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3178\n",
      "Epoch: 907/5000, Train Loss: 0.3235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3177\n",
      "Epoch: 908/5000, Train Loss: 0.3234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3176\n",
      "Epoch: 909/5000, Train Loss: 0.3233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3175\n",
      "Epoch: 910/5000, Train Loss: 0.3232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3174\n",
      "Epoch: 911/5000, Train Loss: 0.3231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3173\n",
      "Epoch: 912/5000, Train Loss: 0.3230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3172\n",
      "Epoch: 913/5000, Train Loss: 0.3229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3171\n",
      "Epoch: 914/5000, Train Loss: 0.3228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3171\n",
      "Epoch: 915/5000, Train Loss: 0.3227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3170\n",
      "Epoch: 916/5000, Train Loss: 0.3226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3169\n",
      "Epoch: 917/5000, Train Loss: 0.3225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3168\n",
      "Epoch: 918/5000, Train Loss: 0.3224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3167\n",
      "Epoch: 919/5000, Train Loss: 0.3223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3166\n",
      "Epoch: 920/5000, Train Loss: 0.3222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3165\n",
      "Epoch: 921/5000, Train Loss: 0.3221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3164\n",
      "Epoch: 922/5000, Train Loss: 0.3220\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3163\n",
      "Epoch: 923/5000, Train Loss: 0.3219\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3163\n",
      "Epoch: 924/5000, Train Loss: 0.3218\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3162\n",
      "Epoch: 925/5000, Train Loss: 0.3217\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3161\n",
      "Epoch: 926/5000, Train Loss: 0.3216\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3160\n",
      "Epoch: 927/5000, Train Loss: 0.3215\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3159\n",
      "Epoch: 928/5000, Train Loss: 0.3214\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3158\n",
      "Epoch: 929/5000, Train Loss: 0.3213\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3157\n",
      "Epoch: 930/5000, Train Loss: 0.3212\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3156\n",
      "Epoch: 931/5000, Train Loss: 0.3211\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3156\n",
      "Epoch: 932/5000, Train Loss: 0.3210\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3155\n",
      "Epoch: 933/5000, Train Loss: 0.3209\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3154\n",
      "Epoch: 934/5000, Train Loss: 0.3208\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3153\n",
      "Epoch: 935/5000, Train Loss: 0.3207\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3152\n",
      "Epoch: 936/5000, Train Loss: 0.3206\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3151\n",
      "Epoch: 937/5000, Train Loss: 0.3205\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3150\n",
      "Epoch: 938/5000, Train Loss: 0.3204\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3150\n",
      "Epoch: 939/5000, Train Loss: 0.3203\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3149\n",
      "Epoch: 940/5000, Train Loss: 0.3202\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3148\n",
      "Epoch: 941/5000, Train Loss: 0.3201\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3147\n",
      "Epoch: 942/5000, Train Loss: 0.3200\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3146\n",
      "Epoch: 943/5000, Train Loss: 0.3199\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3145\n",
      "Epoch: 944/5000, Train Loss: 0.3198\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3144\n",
      "Epoch: 945/5000, Train Loss: 0.3197\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3144\n",
      "Epoch: 946/5000, Train Loss: 0.3196\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3143\n",
      "Epoch: 947/5000, Train Loss: 0.3195\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3142\n",
      "Epoch: 948/5000, Train Loss: 0.3194\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3141\n",
      "Epoch: 949/5000, Train Loss: 0.3193\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3140\n",
      "Epoch: 950/5000, Train Loss: 0.3192\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3139\n",
      "Epoch: 951/5000, Train Loss: 0.3191\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3139\n",
      "Epoch: 952/5000, Train Loss: 0.3190\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3138\n",
      "Epoch: 953/5000, Train Loss: 0.3189\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3137\n",
      "Epoch: 954/5000, Train Loss: 0.3188\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3136\n",
      "Epoch: 955/5000, Train Loss: 0.3187\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3135\n",
      "Epoch: 956/5000, Train Loss: 0.3187\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3134\n",
      "Epoch: 957/5000, Train Loss: 0.3186\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3134\n",
      "Epoch: 958/5000, Train Loss: 0.3185\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3133\n",
      "Epoch: 959/5000, Train Loss: 0.3184\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3132\n",
      "Epoch: 960/5000, Train Loss: 0.3183\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3131\n",
      "Epoch: 961/5000, Train Loss: 0.3182\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3130\n",
      "Epoch: 962/5000, Train Loss: 0.3181\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3129\n",
      "Epoch: 963/5000, Train Loss: 0.3180\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3129\n",
      "Epoch: 964/5000, Train Loss: 0.3179\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3128\n",
      "Epoch: 965/5000, Train Loss: 0.3178\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3127\n",
      "Epoch: 966/5000, Train Loss: 0.3177\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3126\n",
      "Epoch: 967/5000, Train Loss: 0.3176\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3125\n",
      "Epoch: 968/5000, Train Loss: 0.3175\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3125\n",
      "Epoch: 969/5000, Train Loss: 0.3174\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3124\n",
      "Epoch: 970/5000, Train Loss: 0.3173\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3123\n",
      "Epoch: 971/5000, Train Loss: 0.3172\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3122\n",
      "Epoch: 972/5000, Train Loss: 0.3171\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3121\n",
      "Epoch: 973/5000, Train Loss: 0.3170\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3121\n",
      "Epoch: 974/5000, Train Loss: 0.3169\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3120\n",
      "Epoch: 975/5000, Train Loss: 0.3169\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3119\n",
      "Epoch: 976/5000, Train Loss: 0.3168\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3118\n",
      "Epoch: 977/5000, Train Loss: 0.3167\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3117\n",
      "Epoch: 978/5000, Train Loss: 0.3166\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3117\n",
      "Epoch: 979/5000, Train Loss: 0.3165\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3116\n",
      "Epoch: 980/5000, Train Loss: 0.3164\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3115\n",
      "Epoch: 981/5000, Train Loss: 0.3163\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3114\n",
      "Epoch: 982/5000, Train Loss: 0.3162\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3113\n",
      "Epoch: 983/5000, Train Loss: 0.3161\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3113\n",
      "Epoch: 984/5000, Train Loss: 0.3160\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3112\n",
      "Epoch: 985/5000, Train Loss: 0.3159\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3111\n",
      "Epoch: 986/5000, Train Loss: 0.3158\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3110\n",
      "Epoch: 987/5000, Train Loss: 0.3157\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3109\n",
      "Epoch: 988/5000, Train Loss: 0.3157\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3109\n",
      "Epoch: 989/5000, Train Loss: 0.3156\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3108\n",
      "Epoch: 990/5000, Train Loss: 0.3155\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3107\n",
      "Epoch: 991/5000, Train Loss: 0.3154\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3106\n",
      "Epoch: 992/5000, Train Loss: 0.3153\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3105\n",
      "Epoch: 993/5000, Train Loss: 0.3152\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3105\n",
      "Epoch: 994/5000, Train Loss: 0.3151\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3104\n",
      "Epoch: 995/5000, Train Loss: 0.3150\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3103\n",
      "Epoch: 996/5000, Train Loss: 0.3149\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3102\n",
      "Epoch: 997/5000, Train Loss: 0.3148\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3102\n",
      "Epoch: 998/5000, Train Loss: 0.3147\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3101\n",
      "Epoch: 999/5000, Train Loss: 0.3147\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3100\n",
      "Epoch: 1000/5000, Train Loss: 0.3146\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3099\n",
      "Epoch: 1001/5000, Train Loss: 0.3145\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3099\n",
      "Epoch: 1002/5000, Train Loss: 0.3144\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3098\n",
      "Epoch: 1003/5000, Train Loss: 0.3143\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3097\n",
      "Epoch: 1004/5000, Train Loss: 0.3142\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3096\n",
      "Epoch: 1005/5000, Train Loss: 0.3141\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3095\n",
      "Epoch: 1006/5000, Train Loss: 0.3140\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3095\n",
      "Epoch: 1007/5000, Train Loss: 0.3139\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3094\n",
      "Epoch: 1008/5000, Train Loss: 0.3139\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3093\n",
      "Epoch: 1009/5000, Train Loss: 0.3138\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3092\n",
      "Epoch: 1010/5000, Train Loss: 0.3137\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3092\n",
      "Epoch: 1011/5000, Train Loss: 0.3136\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3091\n",
      "Epoch: 1012/5000, Train Loss: 0.3135\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3090\n",
      "Epoch: 1013/5000, Train Loss: 0.3134\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3089\n",
      "Epoch: 1014/5000, Train Loss: 0.3133\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3089\n",
      "Epoch: 1015/5000, Train Loss: 0.3132\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3088\n",
      "Epoch: 1016/5000, Train Loss: 0.3131\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3087\n",
      "Epoch: 1017/5000, Train Loss: 0.3131\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3086\n",
      "Epoch: 1018/5000, Train Loss: 0.3130\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3086\n",
      "Epoch: 1019/5000, Train Loss: 0.3129\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3085\n",
      "Epoch: 1020/5000, Train Loss: 0.3128\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3084\n",
      "Epoch: 1021/5000, Train Loss: 0.3127\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3083\n",
      "Epoch: 1022/5000, Train Loss: 0.3126\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3083\n",
      "Epoch: 1023/5000, Train Loss: 0.3125\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3082\n",
      "Epoch: 1024/5000, Train Loss: 0.3125\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3081\n",
      "Epoch: 1025/5000, Train Loss: 0.3124\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3080\n",
      "Epoch: 1026/5000, Train Loss: 0.3123\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3080\n",
      "Epoch: 1027/5000, Train Loss: 0.3122\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3079\n",
      "Epoch: 1028/5000, Train Loss: 0.3121\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3078\n",
      "Epoch: 1029/5000, Train Loss: 0.3120\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3078\n",
      "Epoch: 1030/5000, Train Loss: 0.3119\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3077\n",
      "Epoch: 1031/5000, Train Loss: 0.3118\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3076\n",
      "Epoch: 1032/5000, Train Loss: 0.3118\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3075\n",
      "Epoch: 1033/5000, Train Loss: 0.3117\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3075\n",
      "Epoch: 1034/5000, Train Loss: 0.3116\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3074\n",
      "Epoch: 1035/5000, Train Loss: 0.3115\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3073\n",
      "Epoch: 1036/5000, Train Loss: 0.3114\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3072\n",
      "Epoch: 1037/5000, Train Loss: 0.3113\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3072\n",
      "Epoch: 1038/5000, Train Loss: 0.3113\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3071\n",
      "Epoch: 1039/5000, Train Loss: 0.3112\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3070\n",
      "Epoch: 1040/5000, Train Loss: 0.3111\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3070\n",
      "Epoch: 1041/5000, Train Loss: 0.3110\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3069\n",
      "Epoch: 1042/5000, Train Loss: 0.3109\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3068\n",
      "Epoch: 1043/5000, Train Loss: 0.3108\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3067\n",
      "Epoch: 1044/5000, Train Loss: 0.3107\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3067\n",
      "Epoch: 1045/5000, Train Loss: 0.3107\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3066\n",
      "Epoch: 1046/5000, Train Loss: 0.3106\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3065\n",
      "Epoch: 1047/5000, Train Loss: 0.3105\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3065\n",
      "Epoch: 1048/5000, Train Loss: 0.3104\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3064\n",
      "Epoch: 1049/5000, Train Loss: 0.3103\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3063\n",
      "Epoch: 1050/5000, Train Loss: 0.3102\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3062\n",
      "Epoch: 1051/5000, Train Loss: 0.3102\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3062\n",
      "Epoch: 1052/5000, Train Loss: 0.3101\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3061\n",
      "Epoch: 1053/5000, Train Loss: 0.3100\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3060\n",
      "Epoch: 1054/5000, Train Loss: 0.3099\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3060\n",
      "Epoch: 1055/5000, Train Loss: 0.3098\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3059\n",
      "Epoch: 1056/5000, Train Loss: 0.3097\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3058\n",
      "Epoch: 1057/5000, Train Loss: 0.3097\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3057\n",
      "Epoch: 1058/5000, Train Loss: 0.3096\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3057\n",
      "Epoch: 1059/5000, Train Loss: 0.3095\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3056\n",
      "Epoch: 1060/5000, Train Loss: 0.3094\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3055\n",
      "Epoch: 1061/5000, Train Loss: 0.3093\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3055\n",
      "Epoch: 1062/5000, Train Loss: 0.3093\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3054\n",
      "Epoch: 1063/5000, Train Loss: 0.3092\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3053\n",
      "Epoch: 1064/5000, Train Loss: 0.3091\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3053\n",
      "Epoch: 1065/5000, Train Loss: 0.3090\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3052\n",
      "Epoch: 1066/5000, Train Loss: 0.3089\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3051\n",
      "Epoch: 1067/5000, Train Loss: 0.3088\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3051\n",
      "Epoch: 1068/5000, Train Loss: 0.3088\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3050\n",
      "Epoch: 1069/5000, Train Loss: 0.3087\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3049\n",
      "Epoch: 1070/5000, Train Loss: 0.3086\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3048\n",
      "Epoch: 1071/5000, Train Loss: 0.3085\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3048\n",
      "Epoch: 1072/5000, Train Loss: 0.3084\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3047\n",
      "Epoch: 1073/5000, Train Loss: 0.3084\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3046\n",
      "Epoch: 1074/5000, Train Loss: 0.3083\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3046\n",
      "Epoch: 1075/5000, Train Loss: 0.3082\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3045\n",
      "Epoch: 1076/5000, Train Loss: 0.3081\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3044\n",
      "Epoch: 1077/5000, Train Loss: 0.3080\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3044\n",
      "Epoch: 1078/5000, Train Loss: 0.3080\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3043\n",
      "Epoch: 1079/5000, Train Loss: 0.3079\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3042\n",
      "Epoch: 1080/5000, Train Loss: 0.3078\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3042\n",
      "Epoch: 1081/5000, Train Loss: 0.3077\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3041\n",
      "Epoch: 1082/5000, Train Loss: 0.3076\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3040\n",
      "Epoch: 1083/5000, Train Loss: 0.3076\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3040\n",
      "Epoch: 1084/5000, Train Loss: 0.3075\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3039\n",
      "Epoch: 1085/5000, Train Loss: 0.3074\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3038\n",
      "Epoch: 1086/5000, Train Loss: 0.3073\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3038\n",
      "Epoch: 1087/5000, Train Loss: 0.3072\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3037\n",
      "Epoch: 1088/5000, Train Loss: 0.3072\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3036\n",
      "Epoch: 1089/5000, Train Loss: 0.3071\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3036\n",
      "Epoch: 1090/5000, Train Loss: 0.3070\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3035\n",
      "Epoch: 1091/5000, Train Loss: 0.3069\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3034\n",
      "Epoch: 1092/5000, Train Loss: 0.3068\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3034\n",
      "Epoch: 1093/5000, Train Loss: 0.3068\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3033\n",
      "Epoch: 1094/5000, Train Loss: 0.3067\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3032\n",
      "Epoch: 1095/5000, Train Loss: 0.3066\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3032\n",
      "Epoch: 1096/5000, Train Loss: 0.3065\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3031\n",
      "Epoch: 1097/5000, Train Loss: 0.3065\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3030\n",
      "Epoch: 1098/5000, Train Loss: 0.3064\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3030\n",
      "Epoch: 1099/5000, Train Loss: 0.3063\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3029\n",
      "Epoch: 1100/5000, Train Loss: 0.3062\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3028\n",
      "Epoch: 1101/5000, Train Loss: 0.3061\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3028\n",
      "Epoch: 1102/5000, Train Loss: 0.3061\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3027\n",
      "Epoch: 1103/5000, Train Loss: 0.3060\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3026\n",
      "Epoch: 1104/5000, Train Loss: 0.3059\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3026\n",
      "Epoch: 1105/5000, Train Loss: 0.3058\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3025\n",
      "Epoch: 1106/5000, Train Loss: 0.3058\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3025\n",
      "Epoch: 1107/5000, Train Loss: 0.3057\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3024\n",
      "Epoch: 1108/5000, Train Loss: 0.3056\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3023\n",
      "Epoch: 1109/5000, Train Loss: 0.3055\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3023\n",
      "Epoch: 1110/5000, Train Loss: 0.3054\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3022\n",
      "Epoch: 1111/5000, Train Loss: 0.3054\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3021\n",
      "Epoch: 1112/5000, Train Loss: 0.3053\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3021\n",
      "Epoch: 1113/5000, Train Loss: 0.3052\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3020\n",
      "Epoch: 1114/5000, Train Loss: 0.3051\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3019\n",
      "Epoch: 1115/5000, Train Loss: 0.3051\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3019\n",
      "Epoch: 1116/5000, Train Loss: 0.3050\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3018\n",
      "Epoch: 1117/5000, Train Loss: 0.3049\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3017\n",
      "Epoch: 1118/5000, Train Loss: 0.3048\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3017\n",
      "Epoch: 1119/5000, Train Loss: 0.3048\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3016\n",
      "Epoch: 1120/5000, Train Loss: 0.3047\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3016\n",
      "Epoch: 1121/5000, Train Loss: 0.3046\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3015\n",
      "Epoch: 1122/5000, Train Loss: 0.3045\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3014\n",
      "Epoch: 1123/5000, Train Loss: 0.3045\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3014\n",
      "Epoch: 1124/5000, Train Loss: 0.3044\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3013\n",
      "Epoch: 1125/5000, Train Loss: 0.3043\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3012\n",
      "Epoch: 1126/5000, Train Loss: 0.3042\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3012\n",
      "Epoch: 1127/5000, Train Loss: 0.3042\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3011\n",
      "Epoch: 1128/5000, Train Loss: 0.3041\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3011\n",
      "Epoch: 1129/5000, Train Loss: 0.3040\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3010\n",
      "Epoch: 1130/5000, Train Loss: 0.3039\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3009\n",
      "Epoch: 1131/5000, Train Loss: 0.3039\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3009\n",
      "Epoch: 1132/5000, Train Loss: 0.3038\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3008\n",
      "Epoch: 1133/5000, Train Loss: 0.3037\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3007\n",
      "Epoch: 1134/5000, Train Loss: 0.3036\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3007\n",
      "Epoch: 1135/5000, Train Loss: 0.3036\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3006\n",
      "Epoch: 1136/5000, Train Loss: 0.3035\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3006\n",
      "Epoch: 1137/5000, Train Loss: 0.3034\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3005\n",
      "Epoch: 1138/5000, Train Loss: 0.3033\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3004\n",
      "Epoch: 1139/5000, Train Loss: 0.3033\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3004\n",
      "Epoch: 1140/5000, Train Loss: 0.3032\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3003\n",
      "Epoch: 1141/5000, Train Loss: 0.3031\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3002\n",
      "Epoch: 1142/5000, Train Loss: 0.3030\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3002\n",
      "Epoch: 1143/5000, Train Loss: 0.3030\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3001\n",
      "Epoch: 1144/5000, Train Loss: 0.3029\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3001\n",
      "Epoch: 1145/5000, Train Loss: 0.3028\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.3000\n",
      "Epoch: 1146/5000, Train Loss: 0.3028\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2999\n",
      "Epoch: 1147/5000, Train Loss: 0.3027\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2999\n",
      "Epoch: 1148/5000, Train Loss: 0.3026\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2998\n",
      "Epoch: 1149/5000, Train Loss: 0.3025\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2998\n",
      "Epoch: 1150/5000, Train Loss: 0.3025\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2997\n",
      "Epoch: 1151/5000, Train Loss: 0.3024\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2996\n",
      "Epoch: 1152/5000, Train Loss: 0.3023\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2996\n",
      "Epoch: 1153/5000, Train Loss: 0.3022\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2995\n",
      "Epoch: 1154/5000, Train Loss: 0.3022\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2995\n",
      "Epoch: 1155/5000, Train Loss: 0.3021\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2994\n",
      "Epoch: 1156/5000, Train Loss: 0.3020\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2993\n",
      "Epoch: 1157/5000, Train Loss: 0.3020\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2993\n",
      "Epoch: 1158/5000, Train Loss: 0.3019\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2992\n",
      "Epoch: 1159/5000, Train Loss: 0.3018\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2992\n",
      "Epoch: 1160/5000, Train Loss: 0.3017\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2991\n",
      "Epoch: 1161/5000, Train Loss: 0.3017\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2990\n",
      "Epoch: 1162/5000, Train Loss: 0.3016\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2990\n",
      "Epoch: 1163/5000, Train Loss: 0.3015\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2989\n",
      "Epoch: 1164/5000, Train Loss: 0.3015\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2989\n",
      "Epoch: 1165/5000, Train Loss: 0.3014\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2988\n",
      "Epoch: 1166/5000, Train Loss: 0.3013\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2987\n",
      "Epoch: 1167/5000, Train Loss: 0.3012\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2987\n",
      "Epoch: 1168/5000, Train Loss: 0.3012\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2986\n",
      "Epoch: 1169/5000, Train Loss: 0.3011\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2986\n",
      "Epoch: 1170/5000, Train Loss: 0.3010\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2985\n",
      "Epoch: 1171/5000, Train Loss: 0.3010\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2984\n",
      "Epoch: 1172/5000, Train Loss: 0.3009\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2984\n",
      "Epoch: 1173/5000, Train Loss: 0.3008\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2983\n",
      "Epoch: 1174/5000, Train Loss: 0.3007\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2983\n",
      "Epoch: 1175/5000, Train Loss: 0.3007\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2982\n",
      "Epoch: 1176/5000, Train Loss: 0.3006\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2982\n",
      "Epoch: 1177/5000, Train Loss: 0.3005\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2981\n",
      "Epoch: 1178/5000, Train Loss: 0.3005\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2980\n",
      "Epoch: 1179/5000, Train Loss: 0.3004\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2980\n",
      "Epoch: 1180/5000, Train Loss: 0.3003\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2979\n",
      "Epoch: 1181/5000, Train Loss: 0.3003\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2979\n",
      "Epoch: 1182/5000, Train Loss: 0.3002\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2978\n",
      "Epoch: 1183/5000, Train Loss: 0.3001\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2977\n",
      "Epoch: 1184/5000, Train Loss: 0.3000\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2977\n",
      "Epoch: 1185/5000, Train Loss: 0.3000\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2976\n",
      "Epoch: 1186/5000, Train Loss: 0.2999\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2976\n",
      "Epoch: 1187/5000, Train Loss: 0.2998\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2975\n",
      "Epoch: 1188/5000, Train Loss: 0.2998\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2975\n",
      "Epoch: 1189/5000, Train Loss: 0.2997\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2974\n",
      "Epoch: 1190/5000, Train Loss: 0.2996\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2973\n",
      "Epoch: 1191/5000, Train Loss: 0.2996\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2973\n",
      "Epoch: 1192/5000, Train Loss: 0.2995\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2972\n",
      "Epoch: 1193/5000, Train Loss: 0.2994\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2972\n",
      "Epoch: 1194/5000, Train Loss: 0.2994\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2971\n",
      "Epoch: 1195/5000, Train Loss: 0.2993\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2971\n",
      "Epoch: 1196/5000, Train Loss: 0.2992\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2970\n",
      "Epoch: 1197/5000, Train Loss: 0.2992\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2969\n",
      "Epoch: 1198/5000, Train Loss: 0.2991\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2969\n",
      "Epoch: 1199/5000, Train Loss: 0.2990\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2968\n",
      "Epoch: 1200/5000, Train Loss: 0.2989\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2968\n",
      "Epoch: 1201/5000, Train Loss: 0.2989\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2967\n",
      "Epoch: 1202/5000, Train Loss: 0.2988\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2967\n",
      "Epoch: 1203/5000, Train Loss: 0.2987\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2966\n",
      "Epoch: 1204/5000, Train Loss: 0.2987\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2966\n",
      "Epoch: 1205/5000, Train Loss: 0.2986\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2965\n",
      "Epoch: 1206/5000, Train Loss: 0.2985\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2964\n",
      "Epoch: 1207/5000, Train Loss: 0.2985\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2964\n",
      "Epoch: 1208/5000, Train Loss: 0.2984\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2963\n",
      "Epoch: 1209/5000, Train Loss: 0.2983\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2963\n",
      "Epoch: 1210/5000, Train Loss: 0.2983\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2962\n",
      "Epoch: 1211/5000, Train Loss: 0.2982\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2962\n",
      "Epoch: 1212/5000, Train Loss: 0.2981\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2961\n",
      "Epoch: 1213/5000, Train Loss: 0.2981\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2961\n",
      "Epoch: 1214/5000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2960\n",
      "Epoch: 1215/5000, Train Loss: 0.2979\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2959\n",
      "Epoch: 1216/5000, Train Loss: 0.2979\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2959\n",
      "Epoch: 1217/5000, Train Loss: 0.2978\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2958\n",
      "Epoch: 1218/5000, Train Loss: 0.2977\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2958\n",
      "Epoch: 1219/5000, Train Loss: 0.2977\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2957\n",
      "Epoch: 1220/5000, Train Loss: 0.2976\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2957\n",
      "Epoch: 1221/5000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2956\n",
      "Epoch: 1222/5000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2956\n",
      "Epoch: 1223/5000, Train Loss: 0.2974\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2955\n",
      "Epoch: 1224/5000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2955\n",
      "Epoch: 1225/5000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2954\n",
      "Epoch: 1226/5000, Train Loss: 0.2972\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2953\n",
      "Epoch: 1227/5000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2953\n",
      "Epoch: 1228/5000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2952\n",
      "Epoch: 1229/5000, Train Loss: 0.2970\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2952\n",
      "Epoch: 1230/5000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2951\n",
      "Epoch: 1231/5000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2951\n",
      "Epoch: 1232/5000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2950\n",
      "Epoch: 1233/5000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2950\n",
      "Epoch: 1234/5000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2949\n",
      "Epoch: 1235/5000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2949\n",
      "Epoch: 1236/5000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2948\n",
      "Epoch: 1237/5000, Train Loss: 0.2965\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2948\n",
      "Epoch: 1238/5000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2947\n",
      "Epoch: 1239/5000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2946\n",
      "Epoch: 1240/5000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2946\n",
      "Epoch: 1241/5000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2945\n",
      "Epoch: 1242/5000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2945\n",
      "Epoch: 1243/5000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2944\n",
      "Epoch: 1244/5000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2944\n",
      "Epoch: 1245/5000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2943\n",
      "Epoch: 1246/5000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2943\n",
      "Epoch: 1247/5000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2942\n",
      "Epoch: 1248/5000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2942\n",
      "Epoch: 1249/5000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2941\n",
      "Epoch: 1250/5000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2941\n",
      "Epoch: 1251/5000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2940\n",
      "Epoch: 1252/5000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2940\n",
      "Epoch: 1253/5000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2939\n",
      "Epoch: 1254/5000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2939\n",
      "Epoch: 1255/5000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2938\n",
      "Epoch: 1256/5000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2938\n",
      "Epoch: 1257/5000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2937\n",
      "Epoch: 1258/5000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2937\n",
      "Epoch: 1259/5000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2936\n",
      "Epoch: 1260/5000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2935\n",
      "Epoch: 1261/5000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2935\n",
      "Epoch: 1262/5000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2934\n",
      "Epoch: 1263/5000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2934\n",
      "Epoch: 1264/5000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2933\n",
      "Epoch: 1265/5000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2933\n",
      "Epoch: 1266/5000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2932\n",
      "Epoch: 1267/5000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2932\n",
      "Epoch: 1268/5000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2931\n",
      "Epoch: 1269/5000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2931\n",
      "Epoch: 1270/5000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2930\n",
      "Epoch: 1271/5000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2930\n",
      "Epoch: 1272/5000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2929\n",
      "Epoch: 1273/5000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2929\n",
      "Epoch: 1274/5000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2928\n",
      "Epoch: 1275/5000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2928\n",
      "Epoch: 1276/5000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2927\n",
      "Epoch: 1277/5000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2927\n",
      "Epoch: 1278/5000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2926\n",
      "Epoch: 1279/5000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2926\n",
      "Epoch: 1280/5000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2925\n",
      "Epoch: 1281/5000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2925\n",
      "Epoch: 1282/5000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2924\n",
      "Epoch: 1283/5000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2924\n",
      "Epoch: 1284/5000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2923\n",
      "Epoch: 1285/5000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2923\n",
      "Epoch: 1286/5000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2922\n",
      "Epoch: 1287/5000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2922\n",
      "Epoch: 1288/5000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2921\n",
      "Epoch: 1289/5000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2921\n",
      "Epoch: 1290/5000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2920\n",
      "Epoch: 1291/5000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2920\n",
      "Epoch: 1292/5000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2919\n",
      "Epoch: 1293/5000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2919\n",
      "Epoch: 1294/5000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2918\n",
      "Epoch: 1295/5000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2918\n",
      "Epoch: 1296/5000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2917\n",
      "Epoch: 1297/5000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2917\n",
      "Epoch: 1298/5000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2916\n",
      "Epoch: 1299/5000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2916\n",
      "Epoch: 1300/5000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2915\n",
      "Epoch: 1301/5000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2915\n",
      "Epoch: 1302/5000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2914\n",
      "Epoch: 1303/5000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2914\n",
      "Epoch: 1304/5000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2913\n",
      "Epoch: 1305/5000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2913\n",
      "Epoch: 1306/5000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2912\n",
      "Epoch: 1307/5000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2912\n",
      "Epoch: 1308/5000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2912\n",
      "Epoch: 1309/5000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2911\n",
      "Epoch: 1310/5000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2911\n",
      "Epoch: 1311/5000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2910\n",
      "Epoch: 1312/5000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2910\n",
      "Epoch: 1313/5000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2909\n",
      "Epoch: 1314/5000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2909\n",
      "Epoch: 1315/5000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2908\n",
      "Epoch: 1316/5000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2908\n",
      "Epoch: 1317/5000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2907\n",
      "Epoch: 1318/5000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2907\n",
      "Epoch: 1319/5000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2906\n",
      "Epoch: 1320/5000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2906\n",
      "Epoch: 1321/5000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2905\n",
      "Epoch: 1322/5000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2905\n",
      "Epoch: 1323/5000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2904\n",
      "Epoch: 1324/5000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2904\n",
      "Epoch: 1325/5000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2903\n",
      "Epoch: 1326/5000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2903\n",
      "Epoch: 1327/5000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2902\n",
      "Epoch: 1328/5000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2902\n",
      "Epoch: 1329/5000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2902\n",
      "Epoch: 1330/5000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2901\n",
      "Epoch: 1331/5000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2901\n",
      "Epoch: 1332/5000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2900\n",
      "Epoch: 1333/5000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2900\n",
      "Epoch: 1334/5000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2899\n",
      "Epoch: 1335/5000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2899\n",
      "Epoch: 1336/5000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2898\n",
      "Epoch: 1337/5000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2898\n",
      "Epoch: 1338/5000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2897\n",
      "Epoch: 1339/5000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2897\n",
      "Epoch: 1340/5000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2896\n",
      "Epoch: 1341/5000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2896\n",
      "Epoch: 1342/5000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2895\n",
      "Epoch: 1343/5000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2895\n",
      "Epoch: 1344/5000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2895\n",
      "Epoch: 1345/5000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2894\n",
      "Epoch: 1346/5000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2894\n",
      "Epoch: 1347/5000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2893\n",
      "Epoch: 1348/5000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2893\n",
      "Epoch: 1349/5000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2892\n",
      "Epoch: 1350/5000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2892\n",
      "Epoch: 1351/5000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2891\n",
      "Epoch: 1352/5000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2891\n",
      "Epoch: 1353/5000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2890\n",
      "Epoch: 1354/5000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2890\n",
      "Epoch: 1355/5000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2890\n",
      "Epoch: 1356/5000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2889\n",
      "Epoch: 1357/5000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2889\n",
      "Epoch: 1358/5000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2888\n",
      "Epoch: 1359/5000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2888\n",
      "Epoch: 1360/5000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2887\n",
      "Epoch: 1361/5000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2887\n",
      "Epoch: 1362/5000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2886\n",
      "Epoch: 1363/5000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2886\n",
      "Epoch: 1364/5000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2885\n",
      "Epoch: 1365/5000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2885\n",
      "Epoch: 1366/5000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2885\n",
      "Epoch: 1367/5000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2884\n",
      "Epoch: 1368/5000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2884\n",
      "Epoch: 1369/5000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2883\n",
      "Epoch: 1370/5000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2883\n",
      "Epoch: 1371/5000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2882\n",
      "Epoch: 1372/5000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2882\n",
      "Epoch: 1373/5000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2881\n",
      "Epoch: 1374/5000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2881\n",
      "Epoch: 1375/5000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2881\n",
      "Epoch: 1376/5000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2880\n",
      "Epoch: 1377/5000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2880\n",
      "Epoch: 1378/5000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2879\n",
      "Epoch: 1379/5000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2879\n",
      "Epoch: 1380/5000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2878\n",
      "Epoch: 1381/5000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2878\n",
      "Epoch: 1382/5000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2877\n",
      "Epoch: 1383/5000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2877\n",
      "Epoch: 1384/5000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2877\n",
      "Epoch: 1385/5000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2876\n",
      "Epoch: 1386/5000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2876\n",
      "Epoch: 1387/5000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2875\n",
      "Epoch: 1388/5000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2875\n",
      "Epoch: 1389/5000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2874\n",
      "Epoch: 1390/5000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2874\n",
      "Epoch: 1391/5000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2874\n",
      "Epoch: 1392/5000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2873\n",
      "Epoch: 1393/5000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2873\n",
      "Epoch: 1394/5000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2872\n",
      "Epoch: 1395/5000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2872\n",
      "Epoch: 1396/5000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2871\n",
      "Epoch: 1397/5000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2871\n",
      "Epoch: 1398/5000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2871\n",
      "Epoch: 1399/5000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2870\n",
      "Epoch: 1400/5000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2870\n",
      "Epoch: 1401/5000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2869\n",
      "Epoch: 1402/5000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2869\n",
      "Epoch: 1403/5000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2868\n",
      "Epoch: 1404/5000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2868\n",
      "Epoch: 1405/5000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2868\n",
      "Epoch: 1406/5000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2867\n",
      "Epoch: 1407/5000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2867\n",
      "Epoch: 1408/5000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2866\n",
      "Epoch: 1409/5000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2866\n",
      "Epoch: 1410/5000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2865\n",
      "Epoch: 1411/5000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2865\n",
      "Epoch: 1412/5000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2865\n",
      "Epoch: 1413/5000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2864\n",
      "Epoch: 1414/5000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2864\n",
      "Epoch: 1415/5000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2863\n",
      "Epoch: 1416/5000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2863\n",
      "Epoch: 1417/5000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2862\n",
      "Epoch: 1418/5000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2862\n",
      "Epoch: 1419/5000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2862\n",
      "Epoch: 1420/5000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2861\n",
      "Epoch: 1421/5000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2861\n",
      "Epoch: 1422/5000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2860\n",
      "Epoch: 1423/5000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2860\n",
      "Epoch: 1424/5000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2860\n",
      "Epoch: 1425/5000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2859\n",
      "Epoch: 1426/5000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2859\n",
      "Epoch: 1427/5000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2858\n",
      "Epoch: 1428/5000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2858\n",
      "Epoch: 1429/5000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2858\n",
      "Epoch: 1430/5000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2857\n",
      "Epoch: 1431/5000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2857\n",
      "Epoch: 1432/5000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2856\n",
      "Epoch: 1433/5000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2856\n",
      "Epoch: 1434/5000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2855\n",
      "Epoch: 1435/5000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2855\n",
      "Epoch: 1436/5000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2855\n",
      "Epoch: 1437/5000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2854\n",
      "Epoch: 1438/5000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2854\n",
      "Epoch: 1439/5000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2853\n",
      "Epoch: 1440/5000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2853\n",
      "Epoch: 1441/5000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2853\n",
      "Epoch: 1442/5000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2852\n",
      "Epoch: 1443/5000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2852\n",
      "Epoch: 1444/5000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2851\n",
      "Epoch: 1445/5000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2851\n",
      "Epoch: 1446/5000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2851\n",
      "Epoch: 1447/5000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2850\n",
      "Epoch: 1448/5000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2850\n",
      "Epoch: 1449/5000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2849\n",
      "Epoch: 1450/5000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2849\n",
      "Epoch: 1451/5000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2849\n",
      "Epoch: 1452/5000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2848\n",
      "Epoch: 1453/5000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2848\n",
      "Epoch: 1454/5000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2847\n",
      "Epoch: 1455/5000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2847\n",
      "Epoch: 1456/5000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2847\n",
      "Epoch: 1457/5000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2846\n",
      "Epoch: 1458/5000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2846\n",
      "Epoch: 1459/5000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2845\n",
      "Epoch: 1460/5000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2845\n",
      "Epoch: 1461/5000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2845\n",
      "Epoch: 1462/5000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2844\n",
      "Epoch: 1463/5000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2844\n",
      "Epoch: 1464/5000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2843\n",
      "Epoch: 1465/5000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2843\n",
      "Epoch: 1466/5000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2843\n",
      "Epoch: 1467/5000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2842\n",
      "Epoch: 1468/5000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2842\n",
      "Epoch: 1469/5000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2841\n",
      "Epoch: 1470/5000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2841\n",
      "Epoch: 1471/5000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2841\n",
      "Epoch: 1472/5000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2840\n",
      "Epoch: 1473/5000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2840\n",
      "Epoch: 1474/5000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2839\n",
      "Epoch: 1475/5000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2839\n",
      "Epoch: 1476/5000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2839\n",
      "Epoch: 1477/5000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2838\n",
      "Epoch: 1478/5000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2838\n",
      "Epoch: 1479/5000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2838\n",
      "Epoch: 1480/5000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2837\n",
      "Epoch: 1481/5000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2837\n",
      "Epoch: 1482/5000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2836\n",
      "Epoch: 1483/5000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2836\n",
      "Epoch: 1484/5000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2836\n",
      "Epoch: 1485/5000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2835\n",
      "Epoch: 1486/5000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2835\n",
      "Epoch: 1487/5000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2834\n",
      "Epoch: 1488/5000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2834\n",
      "Epoch: 1489/5000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2834\n",
      "Epoch: 1490/5000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2833\n",
      "Epoch: 1491/5000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2833\n",
      "Epoch: 1492/5000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2833\n",
      "Epoch: 1493/5000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2832\n",
      "Epoch: 1494/5000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2832\n",
      "Epoch: 1495/5000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2831\n",
      "Epoch: 1496/5000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2831\n",
      "Epoch: 1497/5000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2831\n",
      "Epoch: 1498/5000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2830\n",
      "Epoch: 1499/5000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2830\n",
      "Epoch: 1500/5000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2829\n",
      "Epoch: 1501/5000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2829\n",
      "Epoch: 1502/5000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2829\n",
      "Epoch: 1503/5000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2828\n",
      "Epoch: 1504/5000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2828\n",
      "Epoch: 1505/5000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2828\n",
      "Epoch: 1506/5000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2827\n",
      "Epoch: 1507/5000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2827\n",
      "Epoch: 1508/5000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2826\n",
      "Epoch: 1509/5000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2826\n",
      "Epoch: 1510/5000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2826\n",
      "Epoch: 1511/5000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2825\n",
      "Epoch: 1512/5000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2825\n",
      "Epoch: 1513/5000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2825\n",
      "Epoch: 1514/5000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2824\n",
      "Epoch: 1515/5000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2824\n",
      "Epoch: 1516/5000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2824\n",
      "Epoch: 1517/5000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2823\n",
      "Epoch: 1518/5000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2823\n",
      "Epoch: 1519/5000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2822\n",
      "Epoch: 1520/5000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2822\n",
      "Epoch: 1521/5000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2822\n",
      "Epoch: 1522/5000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2821\n",
      "Epoch: 1523/5000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2821\n",
      "Epoch: 1524/5000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2821\n",
      "Epoch: 1525/5000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2820\n",
      "Epoch: 1526/5000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2820\n",
      "Epoch: 1527/5000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2819\n",
      "Epoch: 1528/5000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2819\n",
      "Epoch: 1529/5000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2819\n",
      "Epoch: 1530/5000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2818\n",
      "Epoch: 1531/5000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2818\n",
      "Epoch: 1532/5000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2818\n",
      "Epoch: 1533/5000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2817\n",
      "Epoch: 1534/5000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2817\n",
      "Epoch: 1535/5000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2817\n",
      "Epoch: 1536/5000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2816\n",
      "Epoch: 1537/5000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2816\n",
      "Epoch: 1538/5000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2815\n",
      "Epoch: 1539/5000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2815\n",
      "Epoch: 1540/5000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2815\n",
      "Epoch: 1541/5000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2814\n",
      "Epoch: 1542/5000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2814\n",
      "Epoch: 1543/5000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2814\n",
      "Epoch: 1544/5000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2813\n",
      "Epoch: 1545/5000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2813\n",
      "Epoch: 1546/5000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2813\n",
      "Epoch: 1547/5000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2812\n",
      "Epoch: 1548/5000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2812\n",
      "Epoch: 1549/5000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2812\n",
      "Epoch: 1550/5000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2811\n",
      "Epoch: 1551/5000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2811\n",
      "Epoch: 1552/5000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2810\n",
      "Epoch: 1553/5000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2810\n",
      "Epoch: 1554/5000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2810\n",
      "Epoch: 1555/5000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2809\n",
      "Epoch: 1556/5000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2809\n",
      "Epoch: 1557/5000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2809\n",
      "Epoch: 1558/5000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2808\n",
      "Epoch: 1559/5000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2808\n",
      "Epoch: 1560/5000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2808\n",
      "Epoch: 1561/5000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2807\n",
      "Epoch: 1562/5000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2807\n",
      "Epoch: 1563/5000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2807\n",
      "Epoch: 1564/5000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2806\n",
      "Epoch: 1565/5000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2806\n",
      "Epoch: 1566/5000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2806\n",
      "Epoch: 1567/5000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2805\n",
      "Epoch: 1568/5000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2805\n",
      "Epoch: 1569/5000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2804\n",
      "Epoch: 1570/5000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2804\n",
      "Epoch: 1571/5000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2804\n",
      "Epoch: 1572/5000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2803\n",
      "Epoch: 1573/5000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2803\n",
      "Epoch: 1574/5000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2803\n",
      "Epoch: 1575/5000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2802\n",
      "Epoch: 1576/5000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2802\n",
      "Epoch: 1577/5000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2802\n",
      "Epoch: 1578/5000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2801\n",
      "Epoch: 1579/5000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2801\n",
      "Epoch: 1580/5000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2801\n",
      "Epoch: 1581/5000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2800\n",
      "Epoch: 1582/5000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2800\n",
      "Epoch: 1583/5000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2800\n",
      "Epoch: 1584/5000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2799\n",
      "Epoch: 1585/5000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2799\n",
      "Epoch: 1586/5000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2799\n",
      "Epoch: 1587/5000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2798\n",
      "Epoch: 1588/5000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2798\n",
      "Epoch: 1589/5000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2798\n",
      "Epoch: 1590/5000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2797\n",
      "Epoch: 1591/5000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2797\n",
      "Epoch: 1592/5000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2797\n",
      "Epoch: 1593/5000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2796\n",
      "Epoch: 1594/5000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2796\n",
      "Epoch: 1595/5000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2796\n",
      "Epoch: 1596/5000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2795\n",
      "Epoch: 1597/5000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2795\n",
      "Epoch: 1598/5000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2795\n",
      "Epoch: 1599/5000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2794\n",
      "Epoch: 1600/5000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2794\n",
      "Epoch: 1601/5000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2794\n",
      "Epoch: 1602/5000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2793\n",
      "Epoch: 1603/5000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2793\n",
      "Epoch: 1604/5000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2793\n",
      "Epoch: 1605/5000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2792\n",
      "Epoch: 1606/5000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2792\n",
      "Epoch: 1607/5000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2792\n",
      "Epoch: 1608/5000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2791\n",
      "Epoch: 1609/5000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2791\n",
      "Epoch: 1610/5000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2791\n",
      "Epoch: 1611/5000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2790\n",
      "Epoch: 1612/5000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2790\n",
      "Epoch: 1613/5000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2790\n",
      "Epoch: 1614/5000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2789\n",
      "Epoch: 1615/5000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2789\n",
      "Epoch: 1616/5000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2789\n",
      "Epoch: 1617/5000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2788\n",
      "Epoch: 1618/5000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2788\n",
      "Epoch: 1619/5000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2788\n",
      "Epoch: 1620/5000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2787\n",
      "Epoch: 1621/5000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2787\n",
      "Epoch: 1622/5000, Train Loss: 0.2763\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2787\n",
      "Epoch: 1623/5000, Train Loss: 0.2763\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2786\n",
      "Epoch: 1624/5000, Train Loss: 0.2763\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2786\n",
      "Epoch: 1625/5000, Train Loss: 0.2762\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2786\n",
      "Epoch: 1626/5000, Train Loss: 0.2762\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2785\n",
      "Epoch: 1627/5000, Train Loss: 0.2761\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2785\n",
      "Epoch: 1628/5000, Train Loss: 0.2761\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2785\n",
      "Epoch: 1629/5000, Train Loss: 0.2760\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2784\n",
      "Epoch: 1630/5000, Train Loss: 0.2760\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2784\n",
      "Epoch: 1631/5000, Train Loss: 0.2760\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2784\n",
      "Epoch: 1632/5000, Train Loss: 0.2759\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2783\n",
      "Epoch: 1633/5000, Train Loss: 0.2759\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2783\n",
      "Epoch: 1634/5000, Train Loss: 0.2758\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2783\n",
      "Epoch: 1635/5000, Train Loss: 0.2758\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2782\n",
      "Epoch: 1636/5000, Train Loss: 0.2758\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2782\n",
      "Epoch: 1637/5000, Train Loss: 0.2757\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2782\n",
      "Epoch: 1638/5000, Train Loss: 0.2757\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2781\n",
      "Epoch: 1639/5000, Train Loss: 0.2756\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2781\n",
      "Epoch: 1640/5000, Train Loss: 0.2756\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2781\n",
      "Epoch: 1641/5000, Train Loss: 0.2755\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2780\n",
      "Epoch: 1642/5000, Train Loss: 0.2755\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2780\n",
      "Epoch: 1643/5000, Train Loss: 0.2755\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2780\n",
      "Epoch: 1644/5000, Train Loss: 0.2754\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2780\n",
      "Epoch: 1645/5000, Train Loss: 0.2754\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2779\n",
      "Epoch: 1646/5000, Train Loss: 0.2753\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2779\n",
      "Epoch: 1647/5000, Train Loss: 0.2753\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2779\n",
      "Epoch: 1648/5000, Train Loss: 0.2753\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2778\n",
      "Epoch: 1649/5000, Train Loss: 0.2752\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2778\n",
      "Epoch: 1650/5000, Train Loss: 0.2752\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2778\n",
      "Epoch: 1651/5000, Train Loss: 0.2751\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2777\n",
      "Epoch: 1652/5000, Train Loss: 0.2751\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2777\n",
      "Epoch: 1653/5000, Train Loss: 0.2750\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2777\n",
      "Epoch: 1654/5000, Train Loss: 0.2750\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2776\n",
      "Epoch: 1655/5000, Train Loss: 0.2750\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2776\n",
      "Epoch: 1656/5000, Train Loss: 0.2749\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2776\n",
      "Epoch: 1657/5000, Train Loss: 0.2749\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2775\n",
      "Epoch: 1658/5000, Train Loss: 0.2748\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2775\n",
      "Epoch: 1659/5000, Train Loss: 0.2748\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2775\n",
      "Epoch: 1660/5000, Train Loss: 0.2748\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2774\n",
      "Epoch: 1661/5000, Train Loss: 0.2747\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2774\n",
      "Epoch: 1662/5000, Train Loss: 0.2747\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2774\n",
      "Epoch: 1663/5000, Train Loss: 0.2746\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2774\n",
      "Epoch: 1664/5000, Train Loss: 0.2746\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2773\n",
      "Epoch: 1665/5000, Train Loss: 0.2746\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2773\n",
      "Epoch: 1666/5000, Train Loss: 0.2745\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2773\n",
      "Epoch: 1667/5000, Train Loss: 0.2745\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2772\n",
      "Epoch: 1668/5000, Train Loss: 0.2744\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2772\n",
      "Epoch: 1669/5000, Train Loss: 0.2744\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2772\n",
      "Epoch: 1670/5000, Train Loss: 0.2744\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2771\n",
      "Epoch: 1671/5000, Train Loss: 0.2743\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2771\n",
      "Epoch: 1672/5000, Train Loss: 0.2743\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2771\n",
      "Epoch: 1673/5000, Train Loss: 0.2742\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2770\n",
      "Epoch: 1674/5000, Train Loss: 0.2742\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2770\n",
      "Epoch: 1675/5000, Train Loss: 0.2742\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2770\n",
      "Epoch: 1676/5000, Train Loss: 0.2741\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2769\n",
      "Epoch: 1677/5000, Train Loss: 0.2741\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2769\n",
      "Epoch: 1678/5000, Train Loss: 0.2740\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2769\n",
      "Epoch: 1679/5000, Train Loss: 0.2740\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2769\n",
      "Epoch: 1680/5000, Train Loss: 0.2740\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2768\n",
      "Epoch: 1681/5000, Train Loss: 0.2739\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2768\n",
      "Epoch: 1682/5000, Train Loss: 0.2739\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2768\n",
      "Epoch: 1683/5000, Train Loss: 0.2738\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2767\n",
      "Epoch: 1684/5000, Train Loss: 0.2738\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2767\n",
      "Epoch: 1685/5000, Train Loss: 0.2738\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2767\n",
      "Epoch: 1686/5000, Train Loss: 0.2737\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2766\n",
      "Epoch: 1687/5000, Train Loss: 0.2737\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2766\n",
      "Epoch: 1688/5000, Train Loss: 0.2736\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2766\n",
      "Epoch: 1689/5000, Train Loss: 0.2736\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2766\n",
      "Epoch: 1690/5000, Train Loss: 0.2736\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2765\n",
      "Epoch: 1691/5000, Train Loss: 0.2735\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2765\n",
      "Epoch: 1692/5000, Train Loss: 0.2735\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2765\n",
      "Epoch: 1693/5000, Train Loss: 0.2734\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2764\n",
      "Epoch: 1694/5000, Train Loss: 0.2734\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2764\n",
      "Epoch: 1695/5000, Train Loss: 0.2734\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2764\n",
      "Epoch: 1696/5000, Train Loss: 0.2733\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2763\n",
      "Epoch: 1697/5000, Train Loss: 0.2733\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2763\n",
      "Epoch: 1698/5000, Train Loss: 0.2732\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2763\n",
      "Epoch: 1699/5000, Train Loss: 0.2732\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2762\n",
      "Epoch: 1700/5000, Train Loss: 0.2732\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2762\n",
      "Epoch: 1701/5000, Train Loss: 0.2731\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2762\n",
      "Epoch: 1702/5000, Train Loss: 0.2731\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2762\n",
      "Epoch: 1703/5000, Train Loss: 0.2730\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2761\n",
      "Epoch: 1704/5000, Train Loss: 0.2730\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2761\n",
      "Epoch: 1705/5000, Train Loss: 0.2730\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2761\n",
      "Epoch: 1706/5000, Train Loss: 0.2729\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2760\n",
      "Epoch: 1707/5000, Train Loss: 0.2729\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2760\n",
      "Epoch: 1708/5000, Train Loss: 0.2728\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2760\n",
      "Epoch: 1709/5000, Train Loss: 0.2728\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2760\n",
      "Epoch: 1710/5000, Train Loss: 0.2728\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2759\n",
      "Epoch: 1711/5000, Train Loss: 0.2727\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2759\n",
      "Epoch: 1712/5000, Train Loss: 0.2727\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2759\n",
      "Epoch: 1713/5000, Train Loss: 0.2727\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2758\n",
      "Epoch: 1714/5000, Train Loss: 0.2726\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2758\n",
      "Epoch: 1715/5000, Train Loss: 0.2726\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2758\n",
      "Epoch: 1716/5000, Train Loss: 0.2725\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2757\n",
      "Epoch: 1717/5000, Train Loss: 0.2725\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2757\n",
      "Epoch: 1718/5000, Train Loss: 0.2725\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2757\n",
      "Epoch: 1719/5000, Train Loss: 0.2724\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2757\n",
      "Epoch: 1720/5000, Train Loss: 0.2724\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2756\n",
      "Epoch: 1721/5000, Train Loss: 0.2723\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2756\n",
      "Epoch: 1722/5000, Train Loss: 0.2723\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2756\n",
      "Epoch: 1723/5000, Train Loss: 0.2723\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2755\n",
      "Epoch: 1724/5000, Train Loss: 0.2722\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2755\n",
      "Epoch: 1725/5000, Train Loss: 0.2722\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2755\n",
      "Epoch: 1726/5000, Train Loss: 0.2722\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2755\n",
      "Epoch: 1727/5000, Train Loss: 0.2721\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2754\n",
      "Epoch: 1728/5000, Train Loss: 0.2721\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2754\n",
      "Epoch: 1729/5000, Train Loss: 0.2720\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2754\n",
      "Epoch: 1730/5000, Train Loss: 0.2720\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2753\n",
      "Epoch: 1731/5000, Train Loss: 0.2720\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2753\n",
      "Epoch: 1732/5000, Train Loss: 0.2719\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2753\n",
      "Epoch: 1733/5000, Train Loss: 0.2719\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2752\n",
      "Epoch: 1734/5000, Train Loss: 0.2718\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2752\n",
      "Epoch: 1735/5000, Train Loss: 0.2718\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2752\n",
      "Epoch: 1736/5000, Train Loss: 0.2718\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2752\n",
      "Epoch: 1737/5000, Train Loss: 0.2717\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2751\n",
      "Epoch: 1738/5000, Train Loss: 0.2717\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2751\n",
      "Epoch: 1739/5000, Train Loss: 0.2717\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2751\n",
      "Epoch: 1740/5000, Train Loss: 0.2716\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2750\n",
      "Epoch: 1741/5000, Train Loss: 0.2716\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2750\n",
      "Epoch: 1742/5000, Train Loss: 0.2715\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2750\n",
      "Epoch: 1743/5000, Train Loss: 0.2715\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2750\n",
      "Epoch: 1744/5000, Train Loss: 0.2715\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2749\n",
      "Epoch: 1745/5000, Train Loss: 0.2714\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2749\n",
      "Epoch: 1746/5000, Train Loss: 0.2714\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2749\n",
      "Epoch: 1747/5000, Train Loss: 0.2714\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2748\n",
      "Epoch: 1748/5000, Train Loss: 0.2713\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2748\n",
      "Epoch: 1749/5000, Train Loss: 0.2713\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2748\n",
      "Epoch: 1750/5000, Train Loss: 0.2712\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2748\n",
      "Epoch: 1751/5000, Train Loss: 0.2712\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2747\n",
      "Epoch: 1752/5000, Train Loss: 0.2712\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2747\n",
      "Epoch: 1753/5000, Train Loss: 0.2711\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2747\n",
      "Epoch: 1754/5000, Train Loss: 0.2711\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2746\n",
      "Epoch: 1755/5000, Train Loss: 0.2711\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2746\n",
      "Epoch: 1756/5000, Train Loss: 0.2710\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2746\n",
      "Epoch: 1757/5000, Train Loss: 0.2710\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2746\n",
      "Epoch: 1758/5000, Train Loss: 0.2709\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2745\n",
      "Epoch: 1759/5000, Train Loss: 0.2709\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2745\n",
      "Epoch: 1760/5000, Train Loss: 0.2709\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2745\n",
      "Epoch: 1761/5000, Train Loss: 0.2708\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2745\n",
      "Epoch: 1762/5000, Train Loss: 0.2708\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2744\n",
      "Epoch: 1763/5000, Train Loss: 0.2708\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2744\n",
      "Epoch: 1764/5000, Train Loss: 0.2707\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2744\n",
      "Epoch: 1765/5000, Train Loss: 0.2707\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2743\n",
      "Epoch: 1766/5000, Train Loss: 0.2706\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2743\n",
      "Epoch: 1767/5000, Train Loss: 0.2706\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2743\n",
      "Epoch: 1768/5000, Train Loss: 0.2706\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2743\n",
      "Epoch: 1769/5000, Train Loss: 0.2705\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2742\n",
      "Epoch: 1770/5000, Train Loss: 0.2705\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2742\n",
      "Epoch: 1771/5000, Train Loss: 0.2705\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2742\n",
      "Epoch: 1772/5000, Train Loss: 0.2704\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2741\n",
      "Epoch: 1773/5000, Train Loss: 0.2704\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2741\n",
      "Epoch: 1774/5000, Train Loss: 0.2704\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2741\n",
      "Epoch: 1775/5000, Train Loss: 0.2703\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2741\n",
      "Epoch: 1776/5000, Train Loss: 0.2703\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2740\n",
      "Epoch: 1777/5000, Train Loss: 0.2702\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2740\n",
      "Epoch: 1778/5000, Train Loss: 0.2702\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2740\n",
      "Epoch: 1779/5000, Train Loss: 0.2702\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2740\n",
      "Epoch: 1780/5000, Train Loss: 0.2701\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2739\n",
      "Epoch: 1781/5000, Train Loss: 0.2701\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2739\n",
      "Epoch: 1782/5000, Train Loss: 0.2701\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2739\n",
      "Epoch: 1783/5000, Train Loss: 0.2700\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2738\n",
      "Epoch: 1784/5000, Train Loss: 0.2700\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2738\n",
      "Epoch: 1785/5000, Train Loss: 0.2700\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2738\n",
      "Epoch: 1786/5000, Train Loss: 0.2699\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2738\n",
      "Epoch: 1787/5000, Train Loss: 0.2699\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2737\n",
      "Epoch: 1788/5000, Train Loss: 0.2698\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2737\n",
      "Epoch: 1789/5000, Train Loss: 0.2698\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2737\n",
      "Epoch: 1790/5000, Train Loss: 0.2698\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2737\n",
      "Epoch: 1791/5000, Train Loss: 0.2697\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2736\n",
      "Epoch: 1792/5000, Train Loss: 0.2697\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2736\n",
      "Epoch: 1793/5000, Train Loss: 0.2697\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2736\n",
      "Epoch: 1794/5000, Train Loss: 0.2696\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2735\n",
      "Epoch: 1795/5000, Train Loss: 0.2696\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2735\n",
      "Epoch: 1796/5000, Train Loss: 0.2696\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2735\n",
      "Epoch: 1797/5000, Train Loss: 0.2695\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2735\n",
      "Epoch: 1798/5000, Train Loss: 0.2695\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2734\n",
      "Epoch: 1799/5000, Train Loss: 0.2694\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2734\n",
      "Epoch: 1800/5000, Train Loss: 0.2694\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2734\n",
      "Epoch: 1801/5000, Train Loss: 0.2694\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2734\n",
      "Epoch: 1802/5000, Train Loss: 0.2693\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2733\n",
      "Epoch: 1803/5000, Train Loss: 0.2693\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2733\n",
      "Epoch: 1804/5000, Train Loss: 0.2693\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2733\n",
      "Epoch: 1805/5000, Train Loss: 0.2692\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2732\n",
      "Epoch: 1806/5000, Train Loss: 0.2692\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2732\n",
      "Epoch: 1807/5000, Train Loss: 0.2692\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2732\n",
      "Epoch: 1808/5000, Train Loss: 0.2691\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2732\n",
      "Epoch: 1809/5000, Train Loss: 0.2691\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2731\n",
      "Epoch: 1810/5000, Train Loss: 0.2691\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2731\n",
      "Epoch: 1811/5000, Train Loss: 0.2690\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2731\n",
      "Epoch: 1812/5000, Train Loss: 0.2690\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2731\n",
      "Epoch: 1813/5000, Train Loss: 0.2690\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2730\n",
      "Epoch: 1814/5000, Train Loss: 0.2689\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2730\n",
      "Epoch: 1815/5000, Train Loss: 0.2689\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2730\n",
      "Epoch: 1816/5000, Train Loss: 0.2688\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2730\n",
      "Epoch: 1817/5000, Train Loss: 0.2688\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2729\n",
      "Epoch: 1818/5000, Train Loss: 0.2688\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2729\n",
      "Epoch: 1819/5000, Train Loss: 0.2687\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2729\n",
      "Epoch: 1820/5000, Train Loss: 0.2687\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2728\n",
      "Epoch: 1821/5000, Train Loss: 0.2687\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2728\n",
      "Epoch: 1822/5000, Train Loss: 0.2686\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2728\n",
      "Epoch: 1823/5000, Train Loss: 0.2686\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2728\n",
      "Epoch: 1824/5000, Train Loss: 0.2686\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2727\n",
      "Epoch: 1825/5000, Train Loss: 0.2685\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2727\n",
      "Epoch: 1826/5000, Train Loss: 0.2685\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2727\n",
      "Epoch: 1827/5000, Train Loss: 0.2685\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2727\n",
      "Epoch: 1828/5000, Train Loss: 0.2684\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2726\n",
      "Epoch: 1829/5000, Train Loss: 0.2684\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2726\n",
      "Epoch: 1830/5000, Train Loss: 0.2684\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2726\n",
      "Epoch: 1831/5000, Train Loss: 0.2683\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2726\n",
      "Epoch: 1832/5000, Train Loss: 0.2683\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2725\n",
      "Epoch: 1833/5000, Train Loss: 0.2682\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2725\n",
      "Epoch: 1834/5000, Train Loss: 0.2682\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2725\n",
      "Epoch: 1835/5000, Train Loss: 0.2682\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2725\n",
      "Epoch: 1836/5000, Train Loss: 0.2681\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2724\n",
      "Epoch: 1837/5000, Train Loss: 0.2681\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2724\n",
      "Epoch: 1838/5000, Train Loss: 0.2681\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2724\n",
      "Epoch: 1839/5000, Train Loss: 0.2680\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2724\n",
      "Epoch: 1840/5000, Train Loss: 0.2680\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2723\n",
      "Epoch: 1841/5000, Train Loss: 0.2680\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2723\n",
      "Epoch: 1842/5000, Train Loss: 0.2679\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2723\n",
      "Epoch: 1843/5000, Train Loss: 0.2679\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2722\n",
      "Epoch: 1844/5000, Train Loss: 0.2679\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2722\n",
      "Epoch: 1845/5000, Train Loss: 0.2678\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2722\n",
      "Epoch: 1846/5000, Train Loss: 0.2678\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2722\n",
      "Epoch: 1847/5000, Train Loss: 0.2678\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2721\n",
      "Epoch: 1848/5000, Train Loss: 0.2677\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2721\n",
      "Epoch: 1849/5000, Train Loss: 0.2677\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2721\n",
      "Epoch: 1850/5000, Train Loss: 0.2677\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2721\n",
      "Epoch: 1851/5000, Train Loss: 0.2676\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2720\n",
      "Epoch: 1852/5000, Train Loss: 0.2676\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2720\n",
      "Epoch: 1853/5000, Train Loss: 0.2676\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2720\n",
      "Epoch: 1854/5000, Train Loss: 0.2675\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2720\n",
      "Epoch: 1855/5000, Train Loss: 0.2675\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2719\n",
      "Epoch: 1856/5000, Train Loss: 0.2675\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2719\n",
      "Epoch: 1857/5000, Train Loss: 0.2674\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2719\n",
      "Epoch: 1858/5000, Train Loss: 0.2674\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2719\n",
      "Epoch: 1859/5000, Train Loss: 0.2674\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2718\n",
      "Epoch: 1860/5000, Train Loss: 0.2673\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2718\n",
      "Epoch: 1861/5000, Train Loss: 0.2673\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2718\n",
      "Epoch: 1862/5000, Train Loss: 0.2673\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2718\n",
      "Epoch: 1863/5000, Train Loss: 0.2672\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2717\n",
      "Epoch: 1864/5000, Train Loss: 0.2672\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2717\n",
      "Epoch: 1865/5000, Train Loss: 0.2672\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2717\n",
      "Epoch: 1866/5000, Train Loss: 0.2671\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2717\n",
      "Epoch: 1867/5000, Train Loss: 0.2671\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2716\n",
      "Epoch: 1868/5000, Train Loss: 0.2671\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2716\n",
      "Epoch: 1869/5000, Train Loss: 0.2670\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2716\n",
      "Epoch: 1870/5000, Train Loss: 0.2670\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2716\n",
      "Epoch: 1871/5000, Train Loss: 0.2670\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2715\n",
      "Epoch: 1872/5000, Train Loss: 0.2669\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2715\n",
      "Epoch: 1873/5000, Train Loss: 0.2669\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2715\n",
      "Epoch: 1874/5000, Train Loss: 0.2668\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2715\n",
      "Epoch: 1875/5000, Train Loss: 0.2668\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2714\n",
      "Epoch: 1876/5000, Train Loss: 0.2668\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2714\n",
      "Epoch: 1877/5000, Train Loss: 0.2667\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2714\n",
      "Epoch: 1878/5000, Train Loss: 0.2667\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2714\n",
      "Epoch: 1879/5000, Train Loss: 0.2667\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2713\n",
      "Epoch: 1880/5000, Train Loss: 0.2666\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2713\n",
      "Epoch: 1881/5000, Train Loss: 0.2666\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2713\n",
      "Epoch: 1882/5000, Train Loss: 0.2666\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2713\n",
      "Epoch: 1883/5000, Train Loss: 0.2665\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2712\n",
      "Epoch: 1884/5000, Train Loss: 0.2665\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2712\n",
      "Epoch: 1885/5000, Train Loss: 0.2665\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2712\n",
      "Epoch: 1886/5000, Train Loss: 0.2664\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2712\n",
      "Epoch: 1887/5000, Train Loss: 0.2664\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2711\n",
      "Epoch: 1888/5000, Train Loss: 0.2664\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2711\n",
      "Epoch: 1889/5000, Train Loss: 0.2664\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2711\n",
      "Epoch: 1890/5000, Train Loss: 0.2663\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2711\n",
      "Epoch: 1891/5000, Train Loss: 0.2663\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2710\n",
      "Epoch: 1892/5000, Train Loss: 0.2663\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2710\n",
      "Epoch: 1893/5000, Train Loss: 0.2662\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2710\n",
      "Epoch: 1894/5000, Train Loss: 0.2662\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2710\n",
      "Epoch: 1895/5000, Train Loss: 0.2662\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2709\n",
      "Epoch: 1896/5000, Train Loss: 0.2661\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2709\n",
      "Epoch: 1897/5000, Train Loss: 0.2661\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2709\n",
      "Epoch: 1898/5000, Train Loss: 0.2661\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2709\n",
      "Epoch: 1899/5000, Train Loss: 0.2660\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2708\n",
      "Epoch: 1900/5000, Train Loss: 0.2660\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2708\n",
      "Epoch: 1901/5000, Train Loss: 0.2660\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2708\n",
      "Epoch: 1902/5000, Train Loss: 0.2659\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2708\n",
      "Epoch: 1903/5000, Train Loss: 0.2659\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2708\n",
      "Epoch: 1904/5000, Train Loss: 0.2659\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2707\n",
      "Epoch: 1905/5000, Train Loss: 0.2658\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2707\n",
      "Epoch: 1906/5000, Train Loss: 0.2658\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2707\n",
      "Epoch: 1907/5000, Train Loss: 0.2658\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2707\n",
      "Epoch: 1908/5000, Train Loss: 0.2657\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2706\n",
      "Epoch: 1909/5000, Train Loss: 0.2657\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2706\n",
      "Epoch: 1910/5000, Train Loss: 0.2657\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2706\n",
      "Epoch: 1911/5000, Train Loss: 0.2656\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2706\n",
      "Epoch: 1912/5000, Train Loss: 0.2656\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2705\n",
      "Epoch: 1913/5000, Train Loss: 0.2656\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2705\n",
      "Epoch: 1914/5000, Train Loss: 0.2655\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2705\n",
      "Epoch: 1915/5000, Train Loss: 0.2655\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2705\n",
      "Epoch: 1916/5000, Train Loss: 0.2655\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2704\n",
      "Epoch: 1917/5000, Train Loss: 0.2654\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2704\n",
      "Epoch: 1918/5000, Train Loss: 0.2654\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2704\n",
      "Epoch: 1919/5000, Train Loss: 0.2654\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2704\n",
      "Epoch: 1920/5000, Train Loss: 0.2653\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2703\n",
      "Epoch: 1921/5000, Train Loss: 0.2653\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2703\n",
      "Epoch: 1922/5000, Train Loss: 0.2653\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2703\n",
      "Epoch: 1923/5000, Train Loss: 0.2652\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2703\n",
      "Epoch: 1924/5000, Train Loss: 0.2652\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2702\n",
      "Epoch: 1925/5000, Train Loss: 0.2652\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2702\n",
      "Epoch: 1926/5000, Train Loss: 0.2651\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2702\n",
      "Epoch: 1927/5000, Train Loss: 0.2651\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2702\n",
      "Epoch: 1928/5000, Train Loss: 0.2651\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2702\n",
      "Epoch: 1929/5000, Train Loss: 0.2650\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2701\n",
      "Epoch: 1930/5000, Train Loss: 0.2650\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2701\n",
      "Epoch: 1931/5000, Train Loss: 0.2650\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2701\n",
      "Epoch: 1932/5000, Train Loss: 0.2650\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2701\n",
      "Epoch: 1933/5000, Train Loss: 0.2649\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2700\n",
      "Epoch: 1934/5000, Train Loss: 0.2649\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2700\n",
      "Epoch: 1935/5000, Train Loss: 0.2649\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2700\n",
      "Epoch: 1936/5000, Train Loss: 0.2648\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2700\n",
      "Epoch: 1937/5000, Train Loss: 0.2648\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2699\n",
      "Epoch: 1938/5000, Train Loss: 0.2648\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2699\n",
      "Epoch: 1939/5000, Train Loss: 0.2647\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2699\n",
      "Epoch: 1940/5000, Train Loss: 0.2647\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2699\n",
      "Epoch: 1941/5000, Train Loss: 0.2647\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2698\n",
      "Epoch: 1942/5000, Train Loss: 0.2646\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2698\n",
      "Epoch: 1943/5000, Train Loss: 0.2646\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2698\n",
      "Epoch: 1944/5000, Train Loss: 0.2646\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2698\n",
      "Epoch: 1945/5000, Train Loss: 0.2645\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2698\n",
      "Epoch: 1946/5000, Train Loss: 0.2645\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2697\n",
      "Epoch: 1947/5000, Train Loss: 0.2645\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2697\n",
      "Epoch: 1948/5000, Train Loss: 0.2644\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2697\n",
      "Epoch: 1949/5000, Train Loss: 0.2644\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2697\n",
      "Epoch: 1950/5000, Train Loss: 0.2644\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2696\n",
      "Epoch: 1951/5000, Train Loss: 0.2644\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2696\n",
      "Epoch: 1952/5000, Train Loss: 0.2643\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2696\n",
      "Epoch: 1953/5000, Train Loss: 0.2643\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2696\n",
      "Epoch: 1954/5000, Train Loss: 0.2643\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2695\n",
      "Epoch: 1955/5000, Train Loss: 0.2642\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2695\n",
      "Epoch: 1956/5000, Train Loss: 0.2642\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2695\n",
      "Epoch: 1957/5000, Train Loss: 0.2642\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2695\n",
      "Epoch: 1958/5000, Train Loss: 0.2641\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2695\n",
      "Epoch: 1959/5000, Train Loss: 0.2641\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2694\n",
      "Epoch: 1960/5000, Train Loss: 0.2641\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2694\n",
      "Epoch: 1961/5000, Train Loss: 0.2640\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2694\n",
      "Epoch: 1962/5000, Train Loss: 0.2640\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2694\n",
      "Epoch: 1963/5000, Train Loss: 0.2640\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2693\n",
      "Epoch: 1964/5000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2693\n",
      "Epoch: 1965/5000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2693\n",
      "Epoch: 1966/5000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2693\n",
      "Epoch: 1967/5000, Train Loss: 0.2639\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2693\n",
      "Epoch: 1968/5000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2692\n",
      "Epoch: 1969/5000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2692\n",
      "Epoch: 1970/5000, Train Loss: 0.2638\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2692\n",
      "Epoch: 1971/5000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2692\n",
      "Epoch: 1972/5000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2691\n",
      "Epoch: 1973/5000, Train Loss: 0.2637\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2691\n",
      "Epoch: 1974/5000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2691\n",
      "Epoch: 1975/5000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2691\n",
      "Epoch: 1976/5000, Train Loss: 0.2636\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2690\n",
      "Epoch: 1977/5000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2690\n",
      "Epoch: 1978/5000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2690\n",
      "Epoch: 1979/5000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2690\n",
      "Epoch: 1980/5000, Train Loss: 0.2635\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2690\n",
      "Epoch: 1981/5000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2689\n",
      "Epoch: 1982/5000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2689\n",
      "Epoch: 1983/5000, Train Loss: 0.2634\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2689\n",
      "Epoch: 1984/5000, Train Loss: 0.2633\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2689\n",
      "Epoch: 1985/5000, Train Loss: 0.2633\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2688\n",
      "Epoch: 1986/5000, Train Loss: 0.2633\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2688\n",
      "Epoch: 1987/5000, Train Loss: 0.2632\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2688\n",
      "Epoch: 1988/5000, Train Loss: 0.2632\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2688\n",
      "Epoch: 1989/5000, Train Loss: 0.2632\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2688\n",
      "Epoch: 1990/5000, Train Loss: 0.2631\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2687\n",
      "Epoch: 1991/5000, Train Loss: 0.2631\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2687\n",
      "Epoch: 1992/5000, Train Loss: 0.2631\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2687\n",
      "Epoch: 1993/5000, Train Loss: 0.2631\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2687\n",
      "Epoch: 1994/5000, Train Loss: 0.2630\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2686\n",
      "Epoch: 1995/5000, Train Loss: 0.2630\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2686\n",
      "Epoch: 1996/5000, Train Loss: 0.2630\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2686\n",
      "Epoch: 1997/5000, Train Loss: 0.2629\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2686\n",
      "Epoch: 1998/5000, Train Loss: 0.2629\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2686\n",
      "Epoch: 1999/5000, Train Loss: 0.2629\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2685\n",
      "Epoch: 2000/5000, Train Loss: 0.2628\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2685\n",
      "Epoch: 2001/5000, Train Loss: 0.2628\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2685\n",
      "Epoch: 2002/5000, Train Loss: 0.2628\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2685\n",
      "Epoch: 2003/5000, Train Loss: 0.2628\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2684\n",
      "Epoch: 2004/5000, Train Loss: 0.2627\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2684\n",
      "Epoch: 2005/5000, Train Loss: 0.2627\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2684\n",
      "Epoch: 2006/5000, Train Loss: 0.2627\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2684\n",
      "Epoch: 2007/5000, Train Loss: 0.2626\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2684\n",
      "Epoch: 2008/5000, Train Loss: 0.2626\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2683\n",
      "Epoch: 2009/5000, Train Loss: 0.2626\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2683\n",
      "Epoch: 2010/5000, Train Loss: 0.2625\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2683\n",
      "Epoch: 2011/5000, Train Loss: 0.2625\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2683\n",
      "Epoch: 2012/5000, Train Loss: 0.2625\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2683\n",
      "Epoch: 2013/5000, Train Loss: 0.2625\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2682\n",
      "Epoch: 2014/5000, Train Loss: 0.2624\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2682\n",
      "Epoch: 2015/5000, Train Loss: 0.2624\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2682\n",
      "Epoch: 2016/5000, Train Loss: 0.2624\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2682\n",
      "Epoch: 2017/5000, Train Loss: 0.2623\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2681\n",
      "Epoch: 2018/5000, Train Loss: 0.2623\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2681\n",
      "Epoch: 2019/5000, Train Loss: 0.2623\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2681\n",
      "Epoch: 2020/5000, Train Loss: 0.2622\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2681\n",
      "Epoch: 2021/5000, Train Loss: 0.2622\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2681\n",
      "Epoch: 2022/5000, Train Loss: 0.2622\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2680\n",
      "Epoch: 2023/5000, Train Loss: 0.2622\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2680\n",
      "Epoch: 2024/5000, Train Loss: 0.2621\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2680\n",
      "Epoch: 2025/5000, Train Loss: 0.2621\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2680\n",
      "Epoch: 2026/5000, Train Loss: 0.2621\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2679\n",
      "Epoch: 2027/5000, Train Loss: 0.2620\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2679\n",
      "Epoch: 2028/5000, Train Loss: 0.2620\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2679\n",
      "Epoch: 2029/5000, Train Loss: 0.2620\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2679\n",
      "Epoch: 2030/5000, Train Loss: 0.2620\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2679\n",
      "Epoch: 2031/5000, Train Loss: 0.2619\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2678\n",
      "Epoch: 2032/5000, Train Loss: 0.2619\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2678\n",
      "Epoch: 2033/5000, Train Loss: 0.2619\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2678\n",
      "Epoch: 2034/5000, Train Loss: 0.2618\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2678\n",
      "Epoch: 2035/5000, Train Loss: 0.2618\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2678\n",
      "Epoch: 2036/5000, Train Loss: 0.2618\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2677\n",
      "Epoch: 2037/5000, Train Loss: 0.2617\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2677\n",
      "Epoch: 2038/5000, Train Loss: 0.2617\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2677\n",
      "Epoch: 2039/5000, Train Loss: 0.2617\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2677\n",
      "Epoch: 2040/5000, Train Loss: 0.2617\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2676\n",
      "Epoch: 2041/5000, Train Loss: 0.2616\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2676\n",
      "Epoch: 2042/5000, Train Loss: 0.2616\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2676\n",
      "Epoch: 2043/5000, Train Loss: 0.2616\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2676\n",
      "Epoch: 2044/5000, Train Loss: 0.2615\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2676\n",
      "Epoch: 2045/5000, Train Loss: 0.2615\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2675\n",
      "Epoch: 2046/5000, Train Loss: 0.2615\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2675\n",
      "Epoch: 2047/5000, Train Loss: 0.2615\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2675\n",
      "Epoch: 2048/5000, Train Loss: 0.2614\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2675\n",
      "Epoch: 2049/5000, Train Loss: 0.2614\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2675\n",
      "Epoch: 2050/5000, Train Loss: 0.2614\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2674\n",
      "Epoch: 2051/5000, Train Loss: 0.2613\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2674\n",
      "Epoch: 2052/5000, Train Loss: 0.2613\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2674\n",
      "Epoch: 2053/5000, Train Loss: 0.2613\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2674\n",
      "Epoch: 2054/5000, Train Loss: 0.2613\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2674\n",
      "Epoch: 2055/5000, Train Loss: 0.2612\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2673\n",
      "Epoch: 2056/5000, Train Loss: 0.2612\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2673\n",
      "Epoch: 2057/5000, Train Loss: 0.2612\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2673\n",
      "Epoch: 2058/5000, Train Loss: 0.2611\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2673\n",
      "Epoch: 2059/5000, Train Loss: 0.2611\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2673\n",
      "Epoch: 2060/5000, Train Loss: 0.2611\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2672\n",
      "Epoch: 2061/5000, Train Loss: 0.2611\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2672\n",
      "Epoch: 2062/5000, Train Loss: 0.2610\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2672\n",
      "Epoch: 2063/5000, Train Loss: 0.2610\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2672\n",
      "Epoch: 2064/5000, Train Loss: 0.2610\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2671\n",
      "Epoch: 2065/5000, Train Loss: 0.2609\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2671\n",
      "Epoch: 2066/5000, Train Loss: 0.2609\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2671\n",
      "Epoch: 2067/5000, Train Loss: 0.2609\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2671\n",
      "Epoch: 2068/5000, Train Loss: 0.2609\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2671\n",
      "Epoch: 2069/5000, Train Loss: 0.2608\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2670\n",
      "Epoch: 2070/5000, Train Loss: 0.2608\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2670\n",
      "Epoch: 2071/5000, Train Loss: 0.2608\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2670\n",
      "Epoch: 2072/5000, Train Loss: 0.2607\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2670\n",
      "Epoch: 2073/5000, Train Loss: 0.2607\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2670\n",
      "Epoch: 2074/5000, Train Loss: 0.2607\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2669\n",
      "Epoch: 2075/5000, Train Loss: 0.2607\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2669\n",
      "Epoch: 2076/5000, Train Loss: 0.2606\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2669\n",
      "Epoch: 2077/5000, Train Loss: 0.2606\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2669\n",
      "Epoch: 2078/5000, Train Loss: 0.2606\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2669\n",
      "Epoch: 2079/5000, Train Loss: 0.2605\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2668\n",
      "Epoch: 2080/5000, Train Loss: 0.2605\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2668\n",
      "Epoch: 2081/5000, Train Loss: 0.2605\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2668\n",
      "Epoch: 2082/5000, Train Loss: 0.2605\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2668\n",
      "Epoch: 2083/5000, Train Loss: 0.2604\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2668\n",
      "Epoch: 2084/5000, Train Loss: 0.2604\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2667\n",
      "Epoch: 2085/5000, Train Loss: 0.2604\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2667\n",
      "Epoch: 2086/5000, Train Loss: 0.2603\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2667\n",
      "Epoch: 2087/5000, Train Loss: 0.2603\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2667\n",
      "Epoch: 2088/5000, Train Loss: 0.2603\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2667\n",
      "Epoch: 2089/5000, Train Loss: 0.2603\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2666\n",
      "Epoch: 2090/5000, Train Loss: 0.2602\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2666\n",
      "Epoch: 2091/5000, Train Loss: 0.2602\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2666\n",
      "Epoch: 2092/5000, Train Loss: 0.2602\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2666\n",
      "Epoch: 2093/5000, Train Loss: 0.2601\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2666\n",
      "Epoch: 2094/5000, Train Loss: 0.2601\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2665\n",
      "Epoch: 2095/5000, Train Loss: 0.2601\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2665\n",
      "Epoch: 2096/5000, Train Loss: 0.2601\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2665\n",
      "Epoch: 2097/5000, Train Loss: 0.2600\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2665\n",
      "Epoch: 2098/5000, Train Loss: 0.2600\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2665\n",
      "Epoch: 2099/5000, Train Loss: 0.2600\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2664\n",
      "Epoch: 2100/5000, Train Loss: 0.2599\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2664\n",
      "Epoch: 2101/5000, Train Loss: 0.2599\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2664\n",
      "Epoch: 2102/5000, Train Loss: 0.2599\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2664\n",
      "Epoch: 2103/5000, Train Loss: 0.2599\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2664\n",
      "Epoch: 2104/5000, Train Loss: 0.2598\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2663\n",
      "Epoch: 2105/5000, Train Loss: 0.2598\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2663\n",
      "Epoch: 2106/5000, Train Loss: 0.2598\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2663\n",
      "Epoch: 2107/5000, Train Loss: 0.2598\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2663\n",
      "Epoch: 2108/5000, Train Loss: 0.2597\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2663\n",
      "Epoch: 2109/5000, Train Loss: 0.2597\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2662\n",
      "Epoch: 2110/5000, Train Loss: 0.2597\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2662\n",
      "Epoch: 2111/5000, Train Loss: 0.2596\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2662\n",
      "Epoch: 2112/5000, Train Loss: 0.2596\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2662\n",
      "Epoch: 2113/5000, Train Loss: 0.2596\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2662\n",
      "Epoch: 2114/5000, Train Loss: 0.2596\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2661\n",
      "Epoch: 2115/5000, Train Loss: 0.2595\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2661\n",
      "Epoch: 2116/5000, Train Loss: 0.2595\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2661\n",
      "Epoch: 2117/5000, Train Loss: 0.2595\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2661\n",
      "Epoch: 2118/5000, Train Loss: 0.2595\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2661\n",
      "Epoch: 2119/5000, Train Loss: 0.2594\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2660\n",
      "Epoch: 2120/5000, Train Loss: 0.2594\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2660\n",
      "Epoch: 2121/5000, Train Loss: 0.2594\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2660\n",
      "Epoch: 2122/5000, Train Loss: 0.2593\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2660\n",
      "Epoch: 2123/5000, Train Loss: 0.2593\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2660\n",
      "Epoch: 2124/5000, Train Loss: 0.2593\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2659\n",
      "Epoch: 2125/5000, Train Loss: 0.2593\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2659\n",
      "Epoch: 2126/5000, Train Loss: 0.2592\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2659\n",
      "Epoch: 2127/5000, Train Loss: 0.2592\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2659\n",
      "Epoch: 2128/5000, Train Loss: 0.2592\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2659\n",
      "Epoch: 2129/5000, Train Loss: 0.2592\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2658\n",
      "Epoch: 2130/5000, Train Loss: 0.2591\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2658\n",
      "Epoch: 2131/5000, Train Loss: 0.2591\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2658\n",
      "Epoch: 2132/5000, Train Loss: 0.2591\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2658\n",
      "Epoch: 2133/5000, Train Loss: 0.2590\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2658\n",
      "Epoch: 2134/5000, Train Loss: 0.2590\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2657\n",
      "Epoch: 2135/5000, Train Loss: 0.2590\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2657\n",
      "Epoch: 2136/5000, Train Loss: 0.2590\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2657\n",
      "Epoch: 2137/5000, Train Loss: 0.2589\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2657\n",
      "Epoch: 2138/5000, Train Loss: 0.2589\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2657\n",
      "Epoch: 2139/5000, Train Loss: 0.2589\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2657\n",
      "Epoch: 2140/5000, Train Loss: 0.2589\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2656\n",
      "Epoch: 2141/5000, Train Loss: 0.2588\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2656\n",
      "Epoch: 2142/5000, Train Loss: 0.2588\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2656\n",
      "Epoch: 2143/5000, Train Loss: 0.2588\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2656\n",
      "Epoch: 2144/5000, Train Loss: 0.2587\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2656\n",
      "Epoch: 2145/5000, Train Loss: 0.2587\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2655\n",
      "Epoch: 2146/5000, Train Loss: 0.2587\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2655\n",
      "Epoch: 2147/5000, Train Loss: 0.2587\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2655\n",
      "Epoch: 2148/5000, Train Loss: 0.2586\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2655\n",
      "Epoch: 2149/5000, Train Loss: 0.2586\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2655\n",
      "Epoch: 2150/5000, Train Loss: 0.2586\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2654\n",
      "Epoch: 2151/5000, Train Loss: 0.2586\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2654\n",
      "Epoch: 2152/5000, Train Loss: 0.2585\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2654\n",
      "Epoch: 2153/5000, Train Loss: 0.2585\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2654\n",
      "Epoch: 2154/5000, Train Loss: 0.2585\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2654\n",
      "Epoch: 2155/5000, Train Loss: 0.2585\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2653\n",
      "Epoch: 2156/5000, Train Loss: 0.2584\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2653\n",
      "Epoch: 2157/5000, Train Loss: 0.2584\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2653\n",
      "Epoch: 2158/5000, Train Loss: 0.2584\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2653\n",
      "Epoch: 2159/5000, Train Loss: 0.2583\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2653\n",
      "Epoch: 2160/5000, Train Loss: 0.2583\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2652\n",
      "Epoch: 2161/5000, Train Loss: 0.2583\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2652\n",
      "Epoch: 2162/5000, Train Loss: 0.2583\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2652\n",
      "Epoch: 2163/5000, Train Loss: 0.2582\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2652\n",
      "Epoch: 2164/5000, Train Loss: 0.2582\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2652\n",
      "Epoch: 2165/5000, Train Loss: 0.2582\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2652\n",
      "Epoch: 2166/5000, Train Loss: 0.2582\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2651\n",
      "Epoch: 2167/5000, Train Loss: 0.2581\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2651\n",
      "Epoch: 2168/5000, Train Loss: 0.2581\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2651\n",
      "Epoch: 2169/5000, Train Loss: 0.2581\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2651\n",
      "Epoch: 2170/5000, Train Loss: 0.2581\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2651\n",
      "Epoch: 2171/5000, Train Loss: 0.2580\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2650\n",
      "Epoch: 2172/5000, Train Loss: 0.2580\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2650\n",
      "Epoch: 2173/5000, Train Loss: 0.2580\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2650\n",
      "Epoch: 2174/5000, Train Loss: 0.2579\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2650\n",
      "Epoch: 2175/5000, Train Loss: 0.2579\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2650\n",
      "Epoch: 2176/5000, Train Loss: 0.2579\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2649\n",
      "Epoch: 2177/5000, Train Loss: 0.2579\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2649\n",
      "Epoch: 2178/5000, Train Loss: 0.2578\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2649\n",
      "Epoch: 2179/5000, Train Loss: 0.2578\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2649\n",
      "Epoch: 2180/5000, Train Loss: 0.2578\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2649\n",
      "Epoch: 2181/5000, Train Loss: 0.2578\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2649\n",
      "Epoch: 2182/5000, Train Loss: 0.2577\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2648\n",
      "Epoch: 2183/5000, Train Loss: 0.2577\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2648\n",
      "Epoch: 2184/5000, Train Loss: 0.2577\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2648\n",
      "Epoch: 2185/5000, Train Loss: 0.2577\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2648\n",
      "Epoch: 2186/5000, Train Loss: 0.2576\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2648\n",
      "Epoch: 2187/5000, Train Loss: 0.2576\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2647\n",
      "Epoch: 2188/5000, Train Loss: 0.2576\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2647\n",
      "Epoch: 2189/5000, Train Loss: 0.2576\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2647\n",
      "Epoch: 2190/5000, Train Loss: 0.2575\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2647\n",
      "Epoch: 2191/5000, Train Loss: 0.2575\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2647\n",
      "Epoch: 2192/5000, Train Loss: 0.2575\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2647\n",
      "Epoch: 2193/5000, Train Loss: 0.2575\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2646\n",
      "Epoch: 2194/5000, Train Loss: 0.2574\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2646\n",
      "Epoch: 2195/5000, Train Loss: 0.2574\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2646\n",
      "Epoch: 2196/5000, Train Loss: 0.2574\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2646\n",
      "Epoch: 2197/5000, Train Loss: 0.2573\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2646\n",
      "Epoch: 2198/5000, Train Loss: 0.2573\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2645\n",
      "Epoch: 2199/5000, Train Loss: 0.2573\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2645\n",
      "Epoch: 2200/5000, Train Loss: 0.2573\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2645\n",
      "Epoch: 2201/5000, Train Loss: 0.2572\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2645\n",
      "Epoch: 2202/5000, Train Loss: 0.2572\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2645\n",
      "Epoch: 2203/5000, Train Loss: 0.2572\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2645\n",
      "Epoch: 2204/5000, Train Loss: 0.2572\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2644\n",
      "Epoch: 2205/5000, Train Loss: 0.2571\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2644\n",
      "Epoch: 2206/5000, Train Loss: 0.2571\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2644\n",
      "Epoch: 2207/5000, Train Loss: 0.2571\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2644\n",
      "Epoch: 2208/5000, Train Loss: 0.2571\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2644\n",
      "Epoch: 2209/5000, Train Loss: 0.2570\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2643\n",
      "Epoch: 2210/5000, Train Loss: 0.2570\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2643\n",
      "Epoch: 2211/5000, Train Loss: 0.2570\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2643\n",
      "Epoch: 2212/5000, Train Loss: 0.2570\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2643\n",
      "Epoch: 2213/5000, Train Loss: 0.2569\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2643\n",
      "Epoch: 2214/5000, Train Loss: 0.2569\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2643\n",
      "Epoch: 2215/5000, Train Loss: 0.2569\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2642\n",
      "Epoch: 2216/5000, Train Loss: 0.2569\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2642\n",
      "Epoch: 2217/5000, Train Loss: 0.2568\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2642\n",
      "Epoch: 2218/5000, Train Loss: 0.2568\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2642\n",
      "Epoch: 2219/5000, Train Loss: 0.2568\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2642\n",
      "Epoch: 2220/5000, Train Loss: 0.2568\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2641\n",
      "Epoch: 2221/5000, Train Loss: 0.2567\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2641\n",
      "Epoch: 2222/5000, Train Loss: 0.2567\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2641\n",
      "Epoch: 2223/5000, Train Loss: 0.2567\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2641\n",
      "Epoch: 2224/5000, Train Loss: 0.2567\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2641\n",
      "Epoch: 2225/5000, Train Loss: 0.2566\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2641\n",
      "Epoch: 2226/5000, Train Loss: 0.2566\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2640\n",
      "Epoch: 2227/5000, Train Loss: 0.2566\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2640\n",
      "Epoch: 2228/5000, Train Loss: 0.2566\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2640\n",
      "Epoch: 2229/5000, Train Loss: 0.2565\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2640\n",
      "Epoch: 2230/5000, Train Loss: 0.2565\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2640\n",
      "Epoch: 2231/5000, Train Loss: 0.2565\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2639\n",
      "Epoch: 2232/5000, Train Loss: 0.2565\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2639\n",
      "Epoch: 2233/5000, Train Loss: 0.2564\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2639\n",
      "Epoch: 2234/5000, Train Loss: 0.2564\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2639\n",
      "Epoch: 2235/5000, Train Loss: 0.2564\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2639\n",
      "Epoch: 2236/5000, Train Loss: 0.2564\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2639\n",
      "Epoch: 2237/5000, Train Loss: 0.2563\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2638\n",
      "Epoch: 2238/5000, Train Loss: 0.2563\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2638\n",
      "Epoch: 2239/5000, Train Loss: 0.2563\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2638\n",
      "Epoch: 2240/5000, Train Loss: 0.2563\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2638\n",
      "Epoch: 2241/5000, Train Loss: 0.2562\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2638\n",
      "Epoch: 2242/5000, Train Loss: 0.2562\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2638\n",
      "Epoch: 2243/5000, Train Loss: 0.2562\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2637\n",
      "Epoch: 2244/5000, Train Loss: 0.2562\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2637\n",
      "Epoch: 2245/5000, Train Loss: 0.2561\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2637\n",
      "Epoch: 2246/5000, Train Loss: 0.2561\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2637\n",
      "Epoch: 2247/5000, Train Loss: 0.2561\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2637\n",
      "Epoch: 2248/5000, Train Loss: 0.2561\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2636\n",
      "Epoch: 2249/5000, Train Loss: 0.2560\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2636\n",
      "Epoch: 2250/5000, Train Loss: 0.2560\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2636\n",
      "Epoch: 2251/5000, Train Loss: 0.2560\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2636\n",
      "Epoch: 2252/5000, Train Loss: 0.2560\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2636\n",
      "Epoch: 2253/5000, Train Loss: 0.2559\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2636\n",
      "Epoch: 2254/5000, Train Loss: 0.2559\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2635\n",
      "Epoch: 2255/5000, Train Loss: 0.2559\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2635\n",
      "Epoch: 2256/5000, Train Loss: 0.2559\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2635\n",
      "Epoch: 2257/5000, Train Loss: 0.2558\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2635\n",
      "Epoch: 2258/5000, Train Loss: 0.2558\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2635\n",
      "Epoch: 2259/5000, Train Loss: 0.2558\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2635\n",
      "Epoch: 2260/5000, Train Loss: 0.2558\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2634\n",
      "Epoch: 2261/5000, Train Loss: 0.2557\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2634\n",
      "Epoch: 2262/5000, Train Loss: 0.2557\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2634\n",
      "Epoch: 2263/5000, Train Loss: 0.2557\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2634\n",
      "Epoch: 2264/5000, Train Loss: 0.2557\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2634\n",
      "Epoch: 2265/5000, Train Loss: 0.2556\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2634\n",
      "Epoch: 2266/5000, Train Loss: 0.2556\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2633\n",
      "Epoch: 2267/5000, Train Loss: 0.2556\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2633\n",
      "Epoch: 2268/5000, Train Loss: 0.2556\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2633\n",
      "Epoch: 2269/5000, Train Loss: 0.2555\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2633\n",
      "Epoch: 2270/5000, Train Loss: 0.2555\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2633\n",
      "Epoch: 2271/5000, Train Loss: 0.2555\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2633\n",
      "Epoch: 2272/5000, Train Loss: 0.2555\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2632\n",
      "Epoch: 2273/5000, Train Loss: 0.2554\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2632\n",
      "Epoch: 2274/5000, Train Loss: 0.2554\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2632\n",
      "Epoch: 2275/5000, Train Loss: 0.2554\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2632\n",
      "Epoch: 2276/5000, Train Loss: 0.2554\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2632\n",
      "Epoch: 2277/5000, Train Loss: 0.2553\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2631\n",
      "Epoch: 2278/5000, Train Loss: 0.2553\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2631\n",
      "Epoch: 2279/5000, Train Loss: 0.2553\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2631\n",
      "Epoch: 2280/5000, Train Loss: 0.2553\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2631\n",
      "Epoch: 2281/5000, Train Loss: 0.2552\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2631\n",
      "Epoch: 2282/5000, Train Loss: 0.2552\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2631\n",
      "Epoch: 2283/5000, Train Loss: 0.2552\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2630\n",
      "Epoch: 2284/5000, Train Loss: 0.2552\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2630\n",
      "Epoch: 2285/5000, Train Loss: 0.2552\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2630\n",
      "Epoch: 2286/5000, Train Loss: 0.2551\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2630\n",
      "Epoch: 2287/5000, Train Loss: 0.2551\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2630\n",
      "Epoch: 2288/5000, Train Loss: 0.2551\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2630\n",
      "Epoch: 2289/5000, Train Loss: 0.2551\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2629\n",
      "Epoch: 2290/5000, Train Loss: 0.2550\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2629\n",
      "Epoch: 2291/5000, Train Loss: 0.2550\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2629\n",
      "Epoch: 2292/5000, Train Loss: 0.2550\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2629\n",
      "Epoch: 2293/5000, Train Loss: 0.2550\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2629\n",
      "Epoch: 2294/5000, Train Loss: 0.2549\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2629\n",
      "Epoch: 2295/5000, Train Loss: 0.2549\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2628\n",
      "Epoch: 2296/5000, Train Loss: 0.2549\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2628\n",
      "Epoch: 2297/5000, Train Loss: 0.2549\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2628\n",
      "Epoch: 2298/5000, Train Loss: 0.2548\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2628\n",
      "Epoch: 2299/5000, Train Loss: 0.2548\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2628\n",
      "Epoch: 2300/5000, Train Loss: 0.2548\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2628\n",
      "Epoch: 2301/5000, Train Loss: 0.2548\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2627\n",
      "Epoch: 2302/5000, Train Loss: 0.2547\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2627\n",
      "Epoch: 2303/5000, Train Loss: 0.2547\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2627\n",
      "Epoch: 2304/5000, Train Loss: 0.2547\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2627\n",
      "Epoch: 2305/5000, Train Loss: 0.2547\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2627\n",
      "Epoch: 2306/5000, Train Loss: 0.2546\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2627\n",
      "Epoch: 2307/5000, Train Loss: 0.2546\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2626\n",
      "Epoch: 2308/5000, Train Loss: 0.2546\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2626\n",
      "Epoch: 2309/5000, Train Loss: 0.2546\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2626\n",
      "Epoch: 2310/5000, Train Loss: 0.2546\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2626\n",
      "Epoch: 2311/5000, Train Loss: 0.2545\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2626\n",
      "Epoch: 2312/5000, Train Loss: 0.2545\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2626\n",
      "Epoch: 2313/5000, Train Loss: 0.2545\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2625\n",
      "Epoch: 2314/5000, Train Loss: 0.2545\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2625\n",
      "Epoch: 2315/5000, Train Loss: 0.2544\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2625\n",
      "Epoch: 2316/5000, Train Loss: 0.2544\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2625\n",
      "Epoch: 2317/5000, Train Loss: 0.2544\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2625\n",
      "Epoch: 2318/5000, Train Loss: 0.2544\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2625\n",
      "Epoch: 2319/5000, Train Loss: 0.2543\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2624\n",
      "Epoch: 2320/5000, Train Loss: 0.2543\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2624\n",
      "Epoch: 2321/5000, Train Loss: 0.2543\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2624\n",
      "Epoch: 2322/5000, Train Loss: 0.2543\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2624\n",
      "Epoch: 2323/5000, Train Loss: 0.2542\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2624\n",
      "Epoch: 2324/5000, Train Loss: 0.2542\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2624\n",
      "Epoch: 2325/5000, Train Loss: 0.2542\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2623\n",
      "Epoch: 2326/5000, Train Loss: 0.2542\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2623\n",
      "Epoch: 2327/5000, Train Loss: 0.2541\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2623\n",
      "Epoch: 2328/5000, Train Loss: 0.2541\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2623\n",
      "Epoch: 2329/5000, Train Loss: 0.2541\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2623\n",
      "Epoch: 2330/5000, Train Loss: 0.2541\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2623\n",
      "Epoch: 2331/5000, Train Loss: 0.2541\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2623\n",
      "Epoch: 2332/5000, Train Loss: 0.2540\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2622\n",
      "Epoch: 2333/5000, Train Loss: 0.2540\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2622\n",
      "Epoch: 2334/5000, Train Loss: 0.2540\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2622\n",
      "Epoch: 2335/5000, Train Loss: 0.2540\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2622\n",
      "Epoch: 2336/5000, Train Loss: 0.2539\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2622\n",
      "Epoch: 2337/5000, Train Loss: 0.2539\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2622\n",
      "Epoch: 2338/5000, Train Loss: 0.2539\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2621\n",
      "Epoch: 2339/5000, Train Loss: 0.2539\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2621\n",
      "Epoch: 2340/5000, Train Loss: 0.2538\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2621\n",
      "Epoch: 2341/5000, Train Loss: 0.2538\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2621\n",
      "Epoch: 2342/5000, Train Loss: 0.2538\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2621\n",
      "Epoch: 2343/5000, Train Loss: 0.2538\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2621\n",
      "Epoch: 2344/5000, Train Loss: 0.2538\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2620\n",
      "Epoch: 2345/5000, Train Loss: 0.2537\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2620\n",
      "Epoch: 2346/5000, Train Loss: 0.2537\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2620\n",
      "Epoch: 2347/5000, Train Loss: 0.2537\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2620\n",
      "Epoch: 2348/5000, Train Loss: 0.2537\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2620\n",
      "Epoch: 2349/5000, Train Loss: 0.2536\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2620\n",
      "Epoch: 2350/5000, Train Loss: 0.2536\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2619\n",
      "Epoch: 2351/5000, Train Loss: 0.2536\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2619\n",
      "Epoch: 2352/5000, Train Loss: 0.2536\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2619\n",
      "Epoch: 2353/5000, Train Loss: 0.2535\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2619\n",
      "Epoch: 2354/5000, Train Loss: 0.2535\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2619\n",
      "Epoch: 2355/5000, Train Loss: 0.2535\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2619\n",
      "Epoch: 2356/5000, Train Loss: 0.2535\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2619\n",
      "Epoch: 2357/5000, Train Loss: 0.2535\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2618\n",
      "Epoch: 2358/5000, Train Loss: 0.2534\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2618\n",
      "Epoch: 2359/5000, Train Loss: 0.2534\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2618\n",
      "Epoch: 2360/5000, Train Loss: 0.2534\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2618\n",
      "Epoch: 2361/5000, Train Loss: 0.2534\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2618\n",
      "Epoch: 2362/5000, Train Loss: 0.2533\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2618\n",
      "Epoch: 2363/5000, Train Loss: 0.2533\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2617\n",
      "Epoch: 2364/5000, Train Loss: 0.2533\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2617\n",
      "Epoch: 2365/5000, Train Loss: 0.2533\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2617\n",
      "Epoch: 2366/5000, Train Loss: 0.2532\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2617\n",
      "Epoch: 2367/5000, Train Loss: 0.2532\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2617\n",
      "Epoch: 2368/5000, Train Loss: 0.2532\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2617\n",
      "Epoch: 2369/5000, Train Loss: 0.2532\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2616\n",
      "Epoch: 2370/5000, Train Loss: 0.2532\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2616\n",
      "Epoch: 2371/5000, Train Loss: 0.2531\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2616\n",
      "Epoch: 2372/5000, Train Loss: 0.2531\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2616\n",
      "Epoch: 2373/5000, Train Loss: 0.2531\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2616\n",
      "Epoch: 2374/5000, Train Loss: 0.2531\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2616\n",
      "Epoch: 2375/5000, Train Loss: 0.2530\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2616\n",
      "Epoch: 2376/5000, Train Loss: 0.2530\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2615\n",
      "Epoch: 2377/5000, Train Loss: 0.2530\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2615\n",
      "Epoch: 2378/5000, Train Loss: 0.2530\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2615\n",
      "Epoch: 2379/5000, Train Loss: 0.2530\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2615\n",
      "Epoch: 2380/5000, Train Loss: 0.2529\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2615\n",
      "Epoch: 2381/5000, Train Loss: 0.2529\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2615\n",
      "Epoch: 2382/5000, Train Loss: 0.2529\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2614\n",
      "Epoch: 2383/5000, Train Loss: 0.2529\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2614\n",
      "Epoch: 2384/5000, Train Loss: 0.2528\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2614\n",
      "Epoch: 2385/5000, Train Loss: 0.2528\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2614\n",
      "Epoch: 2386/5000, Train Loss: 0.2528\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2614\n",
      "Epoch: 2387/5000, Train Loss: 0.2528\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2614\n",
      "Epoch: 2388/5000, Train Loss: 0.2527\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2613\n",
      "Epoch: 2389/5000, Train Loss: 0.2527\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2613\n",
      "Epoch: 2390/5000, Train Loss: 0.2527\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2613\n",
      "Epoch: 2391/5000, Train Loss: 0.2527\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2613\n",
      "Epoch: 2392/5000, Train Loss: 0.2527\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2613\n",
      "Epoch: 2393/5000, Train Loss: 0.2526\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2613\n",
      "Epoch: 2394/5000, Train Loss: 0.2526\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2613\n",
      "Epoch: 2395/5000, Train Loss: 0.2526\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2612\n",
      "Epoch: 2396/5000, Train Loss: 0.2526\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2612\n",
      "Epoch: 2397/5000, Train Loss: 0.2525\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2612\n",
      "Epoch: 2398/5000, Train Loss: 0.2525\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2612\n",
      "Epoch: 2399/5000, Train Loss: 0.2525\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2612\n",
      "Epoch: 2400/5000, Train Loss: 0.2525\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2612\n",
      "Epoch: 2401/5000, Train Loss: 0.2525\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2611\n",
      "Epoch: 2402/5000, Train Loss: 0.2524\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2611\n",
      "Epoch: 2403/5000, Train Loss: 0.2524\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2611\n",
      "Epoch: 2404/5000, Train Loss: 0.2524\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2611\n",
      "Epoch: 2405/5000, Train Loss: 0.2524\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2611\n",
      "Epoch: 2406/5000, Train Loss: 0.2523\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2611\n",
      "Epoch: 2407/5000, Train Loss: 0.2523\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2611\n",
      "Epoch: 2408/5000, Train Loss: 0.2523\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2610\n",
      "Epoch: 2409/5000, Train Loss: 0.2523\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2610\n",
      "Epoch: 2410/5000, Train Loss: 0.2523\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2610\n",
      "Epoch: 2411/5000, Train Loss: 0.2522\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2610\n",
      "Epoch: 2412/5000, Train Loss: 0.2522\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2610\n",
      "Epoch: 2413/5000, Train Loss: 0.2522\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2610\n",
      "Epoch: 2414/5000, Train Loss: 0.2522\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2610\n",
      "Epoch: 2415/5000, Train Loss: 0.2521\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2609\n",
      "Epoch: 2416/5000, Train Loss: 0.2521\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2609\n",
      "Epoch: 2417/5000, Train Loss: 0.2521\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2609\n",
      "Epoch: 2418/5000, Train Loss: 0.2521\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2609\n",
      "Epoch: 2419/5000, Train Loss: 0.2521\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2609\n",
      "Epoch: 2420/5000, Train Loss: 0.2520\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2609\n",
      "Epoch: 2421/5000, Train Loss: 0.2520\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2608\n",
      "Epoch: 2422/5000, Train Loss: 0.2520\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2608\n",
      "Epoch: 2423/5000, Train Loss: 0.2520\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2608\n",
      "Epoch: 2424/5000, Train Loss: 0.2519\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2608\n",
      "Epoch: 2425/5000, Train Loss: 0.2519\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2608\n",
      "Epoch: 2426/5000, Train Loss: 0.2519\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2608\n",
      "Epoch: 2427/5000, Train Loss: 0.2519\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2608\n",
      "Epoch: 2428/5000, Train Loss: 0.2519\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2607\n",
      "Epoch: 2429/5000, Train Loss: 0.2518\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2607\n",
      "Epoch: 2430/5000, Train Loss: 0.2518\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2607\n",
      "Epoch: 2431/5000, Train Loss: 0.2518\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2607\n",
      "Epoch: 2432/5000, Train Loss: 0.2518\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2607\n",
      "Epoch: 2433/5000, Train Loss: 0.2518\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2607\n",
      "Epoch: 2434/5000, Train Loss: 0.2517\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2607\n",
      "Epoch: 2435/5000, Train Loss: 0.2517\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2606\n",
      "Epoch: 2436/5000, Train Loss: 0.2517\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2606\n",
      "Epoch: 2437/5000, Train Loss: 0.2517\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2606\n",
      "Epoch: 2438/5000, Train Loss: 0.2516\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2606\n",
      "Epoch: 2439/5000, Train Loss: 0.2516\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2606\n",
      "Epoch: 2440/5000, Train Loss: 0.2516\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2606\n",
      "Epoch: 2441/5000, Train Loss: 0.2516\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2605\n",
      "Epoch: 2442/5000, Train Loss: 0.2516\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2605\n",
      "Epoch: 2443/5000, Train Loss: 0.2515\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2605\n",
      "Epoch: 2444/5000, Train Loss: 0.2515\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2605\n",
      "Epoch: 2445/5000, Train Loss: 0.2515\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2605\n",
      "Epoch: 2446/5000, Train Loss: 0.2515\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2605\n",
      "Epoch: 2447/5000, Train Loss: 0.2514\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2605\n",
      "Epoch: 2448/5000, Train Loss: 0.2514\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2604\n",
      "Epoch: 2449/5000, Train Loss: 0.2514\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2604\n",
      "Epoch: 2450/5000, Train Loss: 0.2514\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2604\n",
      "Epoch: 2451/5000, Train Loss: 0.2514\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2604\n",
      "Epoch: 2452/5000, Train Loss: 0.2513\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2604\n",
      "Epoch: 2453/5000, Train Loss: 0.2513\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2604\n",
      "Epoch: 2454/5000, Train Loss: 0.2513\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2604\n",
      "Epoch: 2455/5000, Train Loss: 0.2513\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2603\n",
      "Epoch: 2456/5000, Train Loss: 0.2513\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2603\n",
      "Epoch: 2457/5000, Train Loss: 0.2512\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2603\n",
      "Epoch: 2458/5000, Train Loss: 0.2512\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2603\n",
      "Epoch: 2459/5000, Train Loss: 0.2512\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2603\n",
      "Epoch: 2460/5000, Train Loss: 0.2512\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2603\n",
      "Epoch: 2461/5000, Train Loss: 0.2511\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2603\n",
      "Epoch: 2462/5000, Train Loss: 0.2511\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2602\n",
      "Epoch: 2463/5000, Train Loss: 0.2511\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2602\n",
      "Epoch: 2464/5000, Train Loss: 0.2511\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2602\n",
      "Epoch: 2465/5000, Train Loss: 0.2511\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2602\n",
      "Epoch: 2466/5000, Train Loss: 0.2510\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2602\n",
      "Epoch: 2467/5000, Train Loss: 0.2510\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2602\n",
      "Epoch: 2468/5000, Train Loss: 0.2510\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2602\n",
      "Epoch: 2469/5000, Train Loss: 0.2510\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2601\n",
      "Epoch: 2470/5000, Train Loss: 0.2510\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2601\n",
      "Epoch: 2471/5000, Train Loss: 0.2509\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2601\n",
      "Epoch: 2472/5000, Train Loss: 0.2509\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2601\n",
      "Epoch: 2473/5000, Train Loss: 0.2509\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2601\n",
      "Epoch: 2474/5000, Train Loss: 0.2509\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2601\n",
      "Epoch: 2475/5000, Train Loss: 0.2509\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2601\n",
      "Epoch: 2476/5000, Train Loss: 0.2508\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2600\n",
      "Epoch: 2477/5000, Train Loss: 0.2508\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2600\n",
      "Epoch: 2478/5000, Train Loss: 0.2508\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2600\n",
      "Epoch: 2479/5000, Train Loss: 0.2508\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2600\n",
      "Epoch: 2480/5000, Train Loss: 0.2507\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2600\n",
      "Epoch: 2481/5000, Train Loss: 0.2507\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2600\n",
      "Epoch: 2482/5000, Train Loss: 0.2507\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2600\n",
      "Epoch: 2483/5000, Train Loss: 0.2507\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2599\n",
      "Epoch: 2484/5000, Train Loss: 0.2507\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2599\n",
      "Epoch: 2485/5000, Train Loss: 0.2506\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2599\n",
      "Epoch: 2486/5000, Train Loss: 0.2506\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2599\n",
      "Epoch: 2487/5000, Train Loss: 0.2506\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2599\n",
      "Epoch: 2488/5000, Train Loss: 0.2506\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2599\n",
      "Epoch: 2489/5000, Train Loss: 0.2506\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2599\n",
      "Epoch: 2490/5000, Train Loss: 0.2505\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2598\n",
      "Epoch: 2491/5000, Train Loss: 0.2505\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2598\n",
      "Epoch: 2492/5000, Train Loss: 0.2505\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2598\n",
      "Epoch: 2493/5000, Train Loss: 0.2505\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2598\n",
      "Epoch: 2494/5000, Train Loss: 0.2505\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2598\n",
      "Epoch: 2495/5000, Train Loss: 0.2504\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2598\n",
      "Epoch: 2496/5000, Train Loss: 0.2504\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2598\n",
      "Epoch: 2497/5000, Train Loss: 0.2504\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2597\n",
      "Epoch: 2498/5000, Train Loss: 0.2504\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2597\n",
      "Epoch: 2499/5000, Train Loss: 0.2503\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2597\n",
      "Epoch: 2500/5000, Train Loss: 0.2503\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2597\n",
      "Epoch: 2501/5000, Train Loss: 0.2503\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2597\n",
      "Epoch: 2502/5000, Train Loss: 0.2503\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2597\n",
      "Epoch: 2503/5000, Train Loss: 0.2503\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2597\n",
      "Epoch: 2504/5000, Train Loss: 0.2502\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2596\n",
      "Epoch: 2505/5000, Train Loss: 0.2502\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2596\n",
      "Epoch: 2506/5000, Train Loss: 0.2502\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2596\n",
      "Epoch: 2507/5000, Train Loss: 0.2502\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2596\n",
      "Epoch: 2508/5000, Train Loss: 0.2502\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2596\n",
      "Epoch: 2509/5000, Train Loss: 0.2501\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2596\n",
      "Epoch: 2510/5000, Train Loss: 0.2501\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2596\n",
      "Epoch: 2511/5000, Train Loss: 0.2501\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2595\n",
      "Epoch: 2512/5000, Train Loss: 0.2501\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2595\n",
      "Epoch: 2513/5000, Train Loss: 0.2501\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2595\n",
      "Epoch: 2514/5000, Train Loss: 0.2500\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2595\n",
      "Epoch: 2515/5000, Train Loss: 0.2500\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2595\n",
      "Epoch: 2516/5000, Train Loss: 0.2500\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2595\n",
      "Epoch: 2517/5000, Train Loss: 0.2500\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2595\n",
      "Epoch: 2518/5000, Train Loss: 0.2500\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2594\n",
      "Epoch: 2519/5000, Train Loss: 0.2499\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2594\n",
      "Epoch: 2520/5000, Train Loss: 0.2499\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2594\n",
      "Epoch: 2521/5000, Train Loss: 0.2499\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2594\n",
      "Epoch: 2522/5000, Train Loss: 0.2499\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2594\n",
      "Epoch: 2523/5000, Train Loss: 0.2499\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2594\n",
      "Epoch: 2524/5000, Train Loss: 0.2498\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2594\n",
      "Epoch: 2525/5000, Train Loss: 0.2498\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2593\n",
      "Epoch: 2526/5000, Train Loss: 0.2498\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2593\n",
      "Epoch: 2527/5000, Train Loss: 0.2498\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2593\n",
      "Epoch: 2528/5000, Train Loss: 0.2497\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2593\n",
      "Epoch: 2529/5000, Train Loss: 0.2497\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2593\n",
      "Epoch: 2530/5000, Train Loss: 0.2497\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2593\n",
      "Epoch: 2531/5000, Train Loss: 0.2497\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2593\n",
      "Epoch: 2532/5000, Train Loss: 0.2497\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2593\n",
      "Epoch: 2533/5000, Train Loss: 0.2496\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2592\n",
      "Epoch: 2534/5000, Train Loss: 0.2496\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2592\n",
      "Epoch: 2535/5000, Train Loss: 0.2496\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2592\n",
      "Epoch: 2536/5000, Train Loss: 0.2496\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2592\n",
      "Epoch: 2537/5000, Train Loss: 0.2496\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2592\n",
      "Epoch: 2538/5000, Train Loss: 0.2495\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2592\n",
      "Epoch: 2539/5000, Train Loss: 0.2495\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2592\n",
      "Epoch: 2540/5000, Train Loss: 0.2495\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2591\n",
      "Epoch: 2541/5000, Train Loss: 0.2495\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2591\n",
      "Epoch: 2542/5000, Train Loss: 0.2495\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2591\n",
      "Epoch: 2543/5000, Train Loss: 0.2494\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2591\n",
      "Epoch: 2544/5000, Train Loss: 0.2494\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2591\n",
      "Epoch: 2545/5000, Train Loss: 0.2494\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2591\n",
      "Epoch: 2546/5000, Train Loss: 0.2494\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2591\n",
      "Epoch: 2547/5000, Train Loss: 0.2494\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2590\n",
      "Epoch: 2548/5000, Train Loss: 0.2493\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2590\n",
      "Epoch: 2549/5000, Train Loss: 0.2493\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2590\n",
      "Epoch: 2550/5000, Train Loss: 0.2493\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2590\n",
      "Epoch: 2551/5000, Train Loss: 0.2493\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2590\n",
      "Epoch: 2552/5000, Train Loss: 0.2493\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2590\n",
      "Epoch: 2553/5000, Train Loss: 0.2492\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2590\n",
      "Epoch: 2554/5000, Train Loss: 0.2492\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2590\n",
      "Epoch: 2555/5000, Train Loss: 0.2492\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2589\n",
      "Epoch: 2556/5000, Train Loss: 0.2492\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2589\n",
      "Epoch: 2557/5000, Train Loss: 0.2492\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2589\n",
      "Epoch: 2558/5000, Train Loss: 0.2491\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2589\n",
      "Epoch: 2559/5000, Train Loss: 0.2491\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2589\n",
      "Epoch: 2560/5000, Train Loss: 0.2491\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2589\n",
      "Epoch: 2561/5000, Train Loss: 0.2491\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2589\n",
      "Epoch: 2562/5000, Train Loss: 0.2491\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2588\n",
      "Epoch: 2563/5000, Train Loss: 0.2490\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2588\n",
      "Epoch: 2564/5000, Train Loss: 0.2490\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2588\n",
      "Epoch: 2565/5000, Train Loss: 0.2490\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2588\n",
      "Epoch: 2566/5000, Train Loss: 0.2490\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2588\n",
      "Epoch: 2567/5000, Train Loss: 0.2490\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2588\n",
      "Epoch: 2568/5000, Train Loss: 0.2489\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2588\n",
      "Epoch: 2569/5000, Train Loss: 0.2489\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2588\n",
      "Epoch: 2570/5000, Train Loss: 0.2489\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2587\n",
      "Epoch: 2571/5000, Train Loss: 0.2489\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2587\n",
      "Epoch: 2572/5000, Train Loss: 0.2489\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2587\n",
      "Epoch: 2573/5000, Train Loss: 0.2488\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2587\n",
      "Epoch: 2574/5000, Train Loss: 0.2488\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2587\n",
      "Epoch: 2575/5000, Train Loss: 0.2488\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2587\n",
      "Epoch: 2576/5000, Train Loss: 0.2488\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2587\n",
      "Epoch: 2577/5000, Train Loss: 0.2488\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2586\n",
      "Epoch: 2578/5000, Train Loss: 0.2487\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2586\n",
      "Epoch: 2579/5000, Train Loss: 0.2487\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2586\n",
      "Epoch: 2580/5000, Train Loss: 0.2487\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2586\n",
      "Epoch: 2581/5000, Train Loss: 0.2487\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2586\n",
      "Epoch: 2582/5000, Train Loss: 0.2487\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2586\n",
      "Epoch: 2583/5000, Train Loss: 0.2486\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2586\n",
      "Epoch: 2584/5000, Train Loss: 0.2486\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2586\n",
      "Epoch: 2585/5000, Train Loss: 0.2486\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2585\n",
      "Epoch: 2586/5000, Train Loss: 0.2486\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2585\n",
      "Epoch: 2587/5000, Train Loss: 0.2486\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2585\n",
      "Epoch: 2588/5000, Train Loss: 0.2485\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2585\n",
      "Epoch: 2589/5000, Train Loss: 0.2485\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2585\n",
      "Epoch: 2590/5000, Train Loss: 0.2485\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2585\n",
      "Epoch: 2591/5000, Train Loss: 0.2485\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2585\n",
      "Epoch: 2592/5000, Train Loss: 0.2485\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2585\n",
      "Epoch: 2593/5000, Train Loss: 0.2484\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2584\n",
      "Epoch: 2594/5000, Train Loss: 0.2484\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2584\n",
      "Epoch: 2595/5000, Train Loss: 0.2484\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2584\n",
      "Epoch: 2596/5000, Train Loss: 0.2484\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2584\n",
      "Epoch: 2597/5000, Train Loss: 0.2484\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2584\n",
      "Epoch: 2598/5000, Train Loss: 0.2484\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2584\n",
      "Epoch: 2599/5000, Train Loss: 0.2483\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2584\n",
      "Epoch: 2600/5000, Train Loss: 0.2483\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2583\n",
      "Epoch: 2601/5000, Train Loss: 0.2483\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2583\n",
      "Epoch: 2602/5000, Train Loss: 0.2483\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2583\n",
      "Epoch: 2603/5000, Train Loss: 0.2483\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2583\n",
      "Epoch: 2604/5000, Train Loss: 0.2482\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2583\n",
      "Epoch: 2605/5000, Train Loss: 0.2482\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2583\n",
      "Epoch: 2606/5000, Train Loss: 0.2482\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2583\n",
      "Epoch: 2607/5000, Train Loss: 0.2482\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2583\n",
      "Epoch: 2608/5000, Train Loss: 0.2482\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2582\n",
      "Epoch: 2609/5000, Train Loss: 0.2481\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2582\n",
      "Epoch: 2610/5000, Train Loss: 0.2481\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2582\n",
      "Epoch: 2611/5000, Train Loss: 0.2481\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2582\n",
      "Epoch: 2612/5000, Train Loss: 0.2481\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2582\n",
      "Epoch: 2613/5000, Train Loss: 0.2481\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2582\n",
      "Epoch: 2614/5000, Train Loss: 0.2480\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2582\n",
      "Epoch: 2615/5000, Train Loss: 0.2480\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2582\n",
      "Epoch: 2616/5000, Train Loss: 0.2480\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2581\n",
      "Epoch: 2617/5000, Train Loss: 0.2480\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2581\n",
      "Epoch: 2618/5000, Train Loss: 0.2480\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2581\n",
      "Epoch: 2619/5000, Train Loss: 0.2479\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2581\n",
      "Epoch: 2620/5000, Train Loss: 0.2479\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2581\n",
      "Epoch: 2621/5000, Train Loss: 0.2479\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2581\n",
      "Epoch: 2622/5000, Train Loss: 0.2479\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2581\n",
      "Epoch: 2623/5000, Train Loss: 0.2479\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2581\n",
      "Epoch: 2624/5000, Train Loss: 0.2478\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2580\n",
      "Epoch: 2625/5000, Train Loss: 0.2478\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2580\n",
      "Epoch: 2626/5000, Train Loss: 0.2478\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2580\n",
      "Epoch: 2627/5000, Train Loss: 0.2478\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2580\n",
      "Epoch: 2628/5000, Train Loss: 0.2478\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2580\n",
      "Epoch: 2629/5000, Train Loss: 0.2478\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2580\n",
      "Epoch: 2630/5000, Train Loss: 0.2477\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2580\n",
      "Epoch: 2631/5000, Train Loss: 0.2477\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2579\n",
      "Epoch: 2632/5000, Train Loss: 0.2477\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2579\n",
      "Epoch: 2633/5000, Train Loss: 0.2477\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2579\n",
      "Epoch: 2634/5000, Train Loss: 0.2477\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2579\n",
      "Epoch: 2635/5000, Train Loss: 0.2476\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2579\n",
      "Epoch: 2636/5000, Train Loss: 0.2476\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2579\n",
      "Epoch: 2637/5000, Train Loss: 0.2476\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2579\n",
      "Epoch: 2638/5000, Train Loss: 0.2476\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2579\n",
      "Epoch: 2639/5000, Train Loss: 0.2476\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2578\n",
      "Epoch: 2640/5000, Train Loss: 0.2475\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2578\n",
      "Epoch: 2641/5000, Train Loss: 0.2475\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2578\n",
      "Epoch: 2642/5000, Train Loss: 0.2475\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2578\n",
      "Epoch: 2643/5000, Train Loss: 0.2475\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2578\n",
      "Epoch: 2644/5000, Train Loss: 0.2475\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2578\n",
      "Epoch: 2645/5000, Train Loss: 0.2474\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2578\n",
      "Epoch: 2646/5000, Train Loss: 0.2474\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2578\n",
      "Epoch: 2647/5000, Train Loss: 0.2474\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2577\n",
      "Epoch: 2648/5000, Train Loss: 0.2474\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2577\n",
      "Epoch: 2649/5000, Train Loss: 0.2474\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2577\n",
      "Epoch: 2650/5000, Train Loss: 0.2474\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2577\n",
      "Epoch: 2651/5000, Train Loss: 0.2473\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2577\n",
      "Epoch: 2652/5000, Train Loss: 0.2473\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2577\n",
      "Epoch: 2653/5000, Train Loss: 0.2473\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2577\n",
      "Epoch: 2654/5000, Train Loss: 0.2473\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2577\n",
      "Epoch: 2655/5000, Train Loss: 0.2473\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2576\n",
      "Epoch: 2656/5000, Train Loss: 0.2472\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2576\n",
      "Epoch: 2657/5000, Train Loss: 0.2472\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2576\n",
      "Epoch: 2658/5000, Train Loss: 0.2472\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2576\n",
      "Epoch: 2659/5000, Train Loss: 0.2472\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2576\n",
      "Epoch: 2660/5000, Train Loss: 0.2472\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2576\n",
      "Epoch: 2661/5000, Train Loss: 0.2471\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2576\n",
      "Epoch: 2662/5000, Train Loss: 0.2471\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2576\n",
      "Epoch: 2663/5000, Train Loss: 0.2471\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2575\n",
      "Epoch: 2664/5000, Train Loss: 0.2471\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2575\n",
      "Epoch: 2665/5000, Train Loss: 0.2471\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2575\n",
      "Epoch: 2666/5000, Train Loss: 0.2471\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2575\n",
      "Epoch: 2667/5000, Train Loss: 0.2470\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2575\n",
      "Epoch: 2668/5000, Train Loss: 0.2470\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2575\n",
      "Epoch: 2669/5000, Train Loss: 0.2470\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2575\n",
      "Epoch: 2670/5000, Train Loss: 0.2470\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2575\n",
      "Epoch: 2671/5000, Train Loss: 0.2470\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2575\n",
      "Epoch: 2672/5000, Train Loss: 0.2469\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2574\n",
      "Epoch: 2673/5000, Train Loss: 0.2469\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2574\n",
      "Epoch: 2674/5000, Train Loss: 0.2469\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2574\n",
      "Epoch: 2675/5000, Train Loss: 0.2469\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2574\n",
      "Epoch: 2676/5000, Train Loss: 0.2469\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2574\n",
      "Epoch: 2677/5000, Train Loss: 0.2468\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2574\n",
      "Epoch: 2678/5000, Train Loss: 0.2468\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2574\n",
      "Epoch: 2679/5000, Train Loss: 0.2468\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2574\n",
      "Epoch: 2680/5000, Train Loss: 0.2468\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2573\n",
      "Epoch: 2681/5000, Train Loss: 0.2468\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2573\n",
      "Epoch: 2682/5000, Train Loss: 0.2468\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2573\n",
      "Epoch: 2683/5000, Train Loss: 0.2467\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2573\n",
      "Epoch: 2684/5000, Train Loss: 0.2467\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2573\n",
      "Epoch: 2685/5000, Train Loss: 0.2467\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2573\n",
      "Epoch: 2686/5000, Train Loss: 0.2467\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2573\n",
      "Epoch: 2687/5000, Train Loss: 0.2467\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2573\n",
      "Epoch: 2688/5000, Train Loss: 0.2466\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2572\n",
      "Epoch: 2689/5000, Train Loss: 0.2466\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2572\n",
      "Epoch: 2690/5000, Train Loss: 0.2466\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2572\n",
      "Epoch: 2691/5000, Train Loss: 0.2466\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2572\n",
      "Epoch: 2692/5000, Train Loss: 0.2466\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2572\n",
      "Epoch: 2693/5000, Train Loss: 0.2466\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2572\n",
      "Epoch: 2694/5000, Train Loss: 0.2465\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2572\n",
      "Epoch: 2695/5000, Train Loss: 0.2465\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2572\n",
      "Epoch: 2696/5000, Train Loss: 0.2465\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2571\n",
      "Epoch: 2697/5000, Train Loss: 0.2465\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2571\n",
      "Epoch: 2698/5000, Train Loss: 0.2465\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2571\n",
      "Epoch: 2699/5000, Train Loss: 0.2464\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2571\n",
      "Epoch: 2700/5000, Train Loss: 0.2464\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2571\n",
      "Epoch: 2701/5000, Train Loss: 0.2464\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2571\n",
      "Epoch: 2702/5000, Train Loss: 0.2464\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2571\n",
      "Epoch: 2703/5000, Train Loss: 0.2464\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2571\n",
      "Epoch: 2704/5000, Train Loss: 0.2464\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2571\n",
      "Epoch: 2705/5000, Train Loss: 0.2463\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2570\n",
      "Epoch: 2706/5000, Train Loss: 0.2463\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2570\n",
      "Epoch: 2707/5000, Train Loss: 0.2463\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2570\n",
      "Epoch: 2708/5000, Train Loss: 0.2463\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2570\n",
      "Epoch: 2709/5000, Train Loss: 0.2463\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2570\n",
      "Epoch: 2710/5000, Train Loss: 0.2462\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2570\n",
      "Epoch: 2711/5000, Train Loss: 0.2462\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2570\n",
      "Epoch: 2712/5000, Train Loss: 0.2462\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2570\n",
      "Epoch: 2713/5000, Train Loss: 0.2462\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2569\n",
      "Epoch: 2714/5000, Train Loss: 0.2462\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2569\n",
      "Epoch: 2715/5000, Train Loss: 0.2462\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2569\n",
      "Epoch: 2716/5000, Train Loss: 0.2461\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2569\n",
      "Epoch: 2717/5000, Train Loss: 0.2461\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2569\n",
      "Epoch: 2718/5000, Train Loss: 0.2461\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2569\n",
      "Epoch: 2719/5000, Train Loss: 0.2461\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2569\n",
      "Epoch: 2720/5000, Train Loss: 0.2461\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2569\n",
      "Epoch: 2721/5000, Train Loss: 0.2460\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2569\n",
      "Epoch: 2722/5000, Train Loss: 0.2460\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2568\n",
      "Epoch: 2723/5000, Train Loss: 0.2460\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2568\n",
      "Epoch: 2724/5000, Train Loss: 0.2460\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2568\n",
      "Epoch: 2725/5000, Train Loss: 0.2460\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2568\n",
      "Epoch: 2726/5000, Train Loss: 0.2460\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2568\n",
      "Epoch: 2727/5000, Train Loss: 0.2459\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2568\n",
      "Epoch: 2728/5000, Train Loss: 0.2459\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2568\n",
      "Epoch: 2729/5000, Train Loss: 0.2459\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2568\n",
      "Epoch: 2730/5000, Train Loss: 0.2459\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2567\n",
      "Epoch: 2731/5000, Train Loss: 0.2459\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2567\n",
      "Epoch: 2732/5000, Train Loss: 0.2458\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2567\n",
      "Epoch: 2733/5000, Train Loss: 0.2458\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2567\n",
      "Epoch: 2734/5000, Train Loss: 0.2458\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2567\n",
      "Epoch: 2735/5000, Train Loss: 0.2458\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2567\n",
      "Epoch: 2736/5000, Train Loss: 0.2458\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2567\n",
      "Epoch: 2737/5000, Train Loss: 0.2458\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2567\n",
      "Epoch: 2738/5000, Train Loss: 0.2457\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2567\n",
      "Epoch: 2739/5000, Train Loss: 0.2457\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2566\n",
      "Epoch: 2740/5000, Train Loss: 0.2457\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2566\n",
      "Epoch: 2741/5000, Train Loss: 0.2457\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2566\n",
      "Epoch: 2742/5000, Train Loss: 0.2457\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2566\n",
      "Epoch: 2743/5000, Train Loss: 0.2456\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2566\n",
      "Epoch: 2744/5000, Train Loss: 0.2456\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2566\n",
      "Epoch: 2745/5000, Train Loss: 0.2456\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2566\n",
      "Epoch: 2746/5000, Train Loss: 0.2456\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2566\n",
      "Epoch: 2747/5000, Train Loss: 0.2456\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2565\n",
      "Epoch: 2748/5000, Train Loss: 0.2456\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2565\n",
      "Epoch: 2749/5000, Train Loss: 0.2455\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2565\n",
      "Epoch: 2750/5000, Train Loss: 0.2455\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2565\n",
      "Epoch: 2751/5000, Train Loss: 0.2455\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2565\n",
      "Epoch: 2752/5000, Train Loss: 0.2455\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2565\n",
      "Epoch: 2753/5000, Train Loss: 0.2455\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2565\n",
      "Epoch: 2754/5000, Train Loss: 0.2455\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2565\n",
      "Epoch: 2755/5000, Train Loss: 0.2454\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2565\n",
      "Epoch: 2756/5000, Train Loss: 0.2454\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2564\n",
      "Epoch: 2757/5000, Train Loss: 0.2454\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2564\n",
      "Epoch: 2758/5000, Train Loss: 0.2454\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2564\n",
      "Epoch: 2759/5000, Train Loss: 0.2454\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2564\n",
      "Epoch: 2760/5000, Train Loss: 0.2453\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2564\n",
      "Epoch: 2761/5000, Train Loss: 0.2453\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2564\n",
      "Epoch: 2762/5000, Train Loss: 0.2453\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2564\n",
      "Epoch: 2763/5000, Train Loss: 0.2453\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2564\n",
      "Epoch: 2764/5000, Train Loss: 0.2453\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2564\n",
      "Epoch: 2765/5000, Train Loss: 0.2453\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2563\n",
      "Epoch: 2766/5000, Train Loss: 0.2452\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2563\n",
      "Epoch: 2767/5000, Train Loss: 0.2452\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2563\n",
      "Epoch: 2768/5000, Train Loss: 0.2452\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2563\n",
      "Epoch: 2769/5000, Train Loss: 0.2452\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2563\n",
      "Epoch: 2770/5000, Train Loss: 0.2452\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2563\n",
      "Epoch: 2771/5000, Train Loss: 0.2452\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2563\n",
      "Epoch: 2772/5000, Train Loss: 0.2451\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2563\n",
      "Epoch: 2773/5000, Train Loss: 0.2451\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2563\n",
      "Epoch: 2774/5000, Train Loss: 0.2451\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2562\n",
      "Epoch: 2775/5000, Train Loss: 0.2451\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2562\n",
      "Epoch: 2776/5000, Train Loss: 0.2451\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2562\n",
      "Epoch: 2777/5000, Train Loss: 0.2451\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2562\n",
      "Epoch: 2778/5000, Train Loss: 0.2450\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2562\n",
      "Epoch: 2779/5000, Train Loss: 0.2450\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2562\n",
      "Epoch: 2780/5000, Train Loss: 0.2450\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2562\n",
      "Epoch: 2781/5000, Train Loss: 0.2450\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2562\n",
      "Epoch: 2782/5000, Train Loss: 0.2450\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2561\n",
      "Epoch: 2783/5000, Train Loss: 0.2449\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2561\n",
      "Epoch: 2784/5000, Train Loss: 0.2449\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2561\n",
      "Epoch: 2785/5000, Train Loss: 0.2449\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2561\n",
      "Epoch: 2786/5000, Train Loss: 0.2449\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2561\n",
      "Epoch: 2787/5000, Train Loss: 0.2449\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2561\n",
      "Epoch: 2788/5000, Train Loss: 0.2449\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2561\n",
      "Epoch: 2789/5000, Train Loss: 0.2448\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2561\n",
      "Epoch: 2790/5000, Train Loss: 0.2448\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2561\n",
      "Epoch: 2791/5000, Train Loss: 0.2448\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2560\n",
      "Epoch: 2792/5000, Train Loss: 0.2448\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2560\n",
      "Epoch: 2793/5000, Train Loss: 0.2448\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2560\n",
      "Epoch: 2794/5000, Train Loss: 0.2448\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2560\n",
      "Epoch: 2795/5000, Train Loss: 0.2447\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2560\n",
      "Epoch: 2796/5000, Train Loss: 0.2447\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2560\n",
      "Epoch: 2797/5000, Train Loss: 0.2447\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2560\n",
      "Epoch: 2798/5000, Train Loss: 0.2447\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2560\n",
      "Epoch: 2799/5000, Train Loss: 0.2447\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2560\n",
      "Epoch: 2800/5000, Train Loss: 0.2447\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2559\n",
      "Epoch: 2801/5000, Train Loss: 0.2446\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2559\n",
      "Epoch: 2802/5000, Train Loss: 0.2446\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2559\n",
      "Epoch: 2803/5000, Train Loss: 0.2446\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2559\n",
      "Epoch: 2804/5000, Train Loss: 0.2446\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2559\n",
      "Epoch: 2805/5000, Train Loss: 0.2446\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2559\n",
      "Epoch: 2806/5000, Train Loss: 0.2445\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2559\n",
      "Epoch: 2807/5000, Train Loss: 0.2445\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2559\n",
      "Epoch: 2808/5000, Train Loss: 0.2445\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2559\n",
      "Epoch: 2809/5000, Train Loss: 0.2445\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2558\n",
      "Epoch: 2810/5000, Train Loss: 0.2445\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2558\n",
      "Epoch: 2811/5000, Train Loss: 0.2445\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2558\n",
      "Epoch: 2812/5000, Train Loss: 0.2444\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2558\n",
      "Epoch: 2813/5000, Train Loss: 0.2444\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2558\n",
      "Epoch: 2814/5000, Train Loss: 0.2444\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2558\n",
      "Epoch: 2815/5000, Train Loss: 0.2444\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2558\n",
      "Epoch: 2816/5000, Train Loss: 0.2444\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2558\n",
      "Epoch: 2817/5000, Train Loss: 0.2444\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2558\n",
      "Epoch: 2818/5000, Train Loss: 0.2443\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2558\n",
      "Epoch: 2819/5000, Train Loss: 0.2443\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2557\n",
      "Epoch: 2820/5000, Train Loss: 0.2443\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2557\n",
      "Epoch: 2821/5000, Train Loss: 0.2443\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2557\n",
      "Epoch: 2822/5000, Train Loss: 0.2443\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2557\n",
      "Epoch: 2823/5000, Train Loss: 0.2443\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2557\n",
      "Epoch: 2824/5000, Train Loss: 0.2442\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2557\n",
      "Epoch: 2825/5000, Train Loss: 0.2442\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2557\n",
      "Epoch: 2826/5000, Train Loss: 0.2442\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2557\n",
      "Epoch: 2827/5000, Train Loss: 0.2442\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2557\n",
      "Epoch: 2828/5000, Train Loss: 0.2442\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2556\n",
      "Epoch: 2829/5000, Train Loss: 0.2442\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2556\n",
      "Epoch: 2830/5000, Train Loss: 0.2441\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2556\n",
      "Epoch: 2831/5000, Train Loss: 0.2441\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2556\n",
      "Epoch: 2832/5000, Train Loss: 0.2441\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2556\n",
      "Epoch: 2833/5000, Train Loss: 0.2441\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2556\n",
      "Epoch: 2834/5000, Train Loss: 0.2441\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2556\n",
      "Epoch: 2835/5000, Train Loss: 0.2441\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2556\n",
      "Epoch: 2836/5000, Train Loss: 0.2440\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2556\n",
      "Epoch: 2837/5000, Train Loss: 0.2440\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2555\n",
      "Epoch: 2838/5000, Train Loss: 0.2440\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2555\n",
      "Epoch: 2839/5000, Train Loss: 0.2440\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2555\n",
      "Epoch: 2840/5000, Train Loss: 0.2440\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2555\n",
      "Epoch: 2841/5000, Train Loss: 0.2440\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2555\n",
      "Epoch: 2842/5000, Train Loss: 0.2439\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2555\n",
      "Epoch: 2843/5000, Train Loss: 0.2439\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2555\n",
      "Epoch: 2844/5000, Train Loss: 0.2439\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2555\n",
      "Epoch: 2845/5000, Train Loss: 0.2439\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2555\n",
      "Epoch: 2846/5000, Train Loss: 0.2439\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2554\n",
      "Epoch: 2847/5000, Train Loss: 0.2439\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2554\n",
      "Epoch: 2848/5000, Train Loss: 0.2438\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2554\n",
      "Epoch: 2849/5000, Train Loss: 0.2438\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2554\n",
      "Epoch: 2850/5000, Train Loss: 0.2438\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2554\n",
      "Epoch: 2851/5000, Train Loss: 0.2438\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2554\n",
      "Epoch: 2852/5000, Train Loss: 0.2438\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2554\n",
      "Epoch: 2853/5000, Train Loss: 0.2438\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2554\n",
      "Epoch: 2854/5000, Train Loss: 0.2437\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2554\n",
      "Epoch: 2855/5000, Train Loss: 0.2437\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2554\n",
      "Epoch: 2856/5000, Train Loss: 0.2437\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2553\n",
      "Epoch: 2857/5000, Train Loss: 0.2437\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2553\n",
      "Epoch: 2858/5000, Train Loss: 0.2437\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2553\n",
      "Epoch: 2859/5000, Train Loss: 0.2437\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2553\n",
      "Epoch: 2860/5000, Train Loss: 0.2436\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2553\n",
      "Epoch: 2861/5000, Train Loss: 0.2436\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2553\n",
      "Epoch: 2862/5000, Train Loss: 0.2436\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2553\n",
      "Epoch: 2863/5000, Train Loss: 0.2436\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2553\n",
      "Epoch: 2864/5000, Train Loss: 0.2436\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2553\n",
      "Epoch: 2865/5000, Train Loss: 0.2436\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2552\n",
      "Epoch: 2866/5000, Train Loss: 0.2435\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2552\n",
      "Epoch: 2867/5000, Train Loss: 0.2435\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2552\n",
      "Epoch: 2868/5000, Train Loss: 0.2435\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2552\n",
      "Epoch: 2869/5000, Train Loss: 0.2435\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2552\n",
      "Epoch: 2870/5000, Train Loss: 0.2435\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2552\n",
      "Epoch: 2871/5000, Train Loss: 0.2435\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2552\n",
      "Epoch: 2872/5000, Train Loss: 0.2434\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2552\n",
      "Epoch: 2873/5000, Train Loss: 0.2434\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2552\n",
      "Epoch: 2874/5000, Train Loss: 0.2434\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2552\n",
      "Epoch: 2875/5000, Train Loss: 0.2434\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2551\n",
      "Epoch: 2876/5000, Train Loss: 0.2434\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2551\n",
      "Epoch: 2877/5000, Train Loss: 0.2434\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2551\n",
      "Epoch: 2878/5000, Train Loss: 0.2433\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2551\n",
      "Epoch: 2879/5000, Train Loss: 0.2433\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2551\n",
      "Epoch: 2880/5000, Train Loss: 0.2433\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2551\n",
      "Epoch: 2881/5000, Train Loss: 0.2433\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2551\n",
      "Epoch: 2882/5000, Train Loss: 0.2433\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2551\n",
      "Epoch: 2883/5000, Train Loss: 0.2433\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2551\n",
      "Epoch: 2884/5000, Train Loss: 0.2432\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2550\n",
      "Epoch: 2885/5000, Train Loss: 0.2432\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2550\n",
      "Epoch: 2886/5000, Train Loss: 0.2432\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2550\n",
      "Epoch: 2887/5000, Train Loss: 0.2432\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2550\n",
      "Epoch: 2888/5000, Train Loss: 0.2432\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2550\n",
      "Epoch: 2889/5000, Train Loss: 0.2432\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2550\n",
      "Epoch: 2890/5000, Train Loss: 0.2431\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2550\n",
      "Epoch: 2891/5000, Train Loss: 0.2431\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2550\n",
      "Epoch: 2892/5000, Train Loss: 0.2431\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2550\n",
      "Epoch: 2893/5000, Train Loss: 0.2431\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2550\n",
      "Epoch: 2894/5000, Train Loss: 0.2431\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2549\n",
      "Epoch: 2895/5000, Train Loss: 0.2431\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2549\n",
      "Epoch: 2896/5000, Train Loss: 0.2430\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2549\n",
      "Epoch: 2897/5000, Train Loss: 0.2430\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2549\n",
      "Epoch: 2898/5000, Train Loss: 0.2430\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2549\n",
      "Epoch: 2899/5000, Train Loss: 0.2430\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2549\n",
      "Epoch: 2900/5000, Train Loss: 0.2430\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2549\n",
      "Epoch: 2901/5000, Train Loss: 0.2430\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2549\n",
      "Epoch: 2902/5000, Train Loss: 0.2430\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2549\n",
      "Epoch: 2903/5000, Train Loss: 0.2429\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2549\n",
      "Epoch: 2904/5000, Train Loss: 0.2429\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2548\n",
      "Epoch: 2905/5000, Train Loss: 0.2429\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2548\n",
      "Epoch: 2906/5000, Train Loss: 0.2429\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2548\n",
      "Epoch: 2907/5000, Train Loss: 0.2429\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2548\n",
      "Epoch: 2908/5000, Train Loss: 0.2429\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2548\n",
      "Epoch: 2909/5000, Train Loss: 0.2428\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2548\n",
      "Epoch: 2910/5000, Train Loss: 0.2428\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2548\n",
      "Epoch: 2911/5000, Train Loss: 0.2428\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2548\n",
      "Epoch: 2912/5000, Train Loss: 0.2428\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2548\n",
      "Epoch: 2913/5000, Train Loss: 0.2428\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2547\n",
      "Epoch: 2914/5000, Train Loss: 0.2428\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2547\n",
      "Epoch: 2915/5000, Train Loss: 0.2427\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2547\n",
      "Epoch: 2916/5000, Train Loss: 0.2427\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2547\n",
      "Epoch: 2917/5000, Train Loss: 0.2427\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2547\n",
      "Epoch: 2918/5000, Train Loss: 0.2427\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2547\n",
      "Epoch: 2919/5000, Train Loss: 0.2427\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2547\n",
      "Epoch: 2920/5000, Train Loss: 0.2427\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2547\n",
      "Epoch: 2921/5000, Train Loss: 0.2426\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2547\n",
      "Epoch: 2922/5000, Train Loss: 0.2426\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2547\n",
      "Epoch: 2923/5000, Train Loss: 0.2426\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2546\n",
      "Epoch: 2924/5000, Train Loss: 0.2426\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2546\n",
      "Epoch: 2925/5000, Train Loss: 0.2426\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2546\n",
      "Epoch: 2926/5000, Train Loss: 0.2426\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2546\n",
      "Epoch: 2927/5000, Train Loss: 0.2426\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2546\n",
      "Epoch: 2928/5000, Train Loss: 0.2425\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2546\n",
      "Epoch: 2929/5000, Train Loss: 0.2425\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2546\n",
      "Epoch: 2930/5000, Train Loss: 0.2425\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2546\n",
      "Epoch: 2931/5000, Train Loss: 0.2425\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2546\n",
      "Epoch: 2932/5000, Train Loss: 0.2425\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2546\n",
      "Epoch: 2933/5000, Train Loss: 0.2425\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2545\n",
      "Epoch: 2934/5000, Train Loss: 0.2424\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2545\n",
      "Epoch: 2935/5000, Train Loss: 0.2424\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2545\n",
      "Epoch: 2936/5000, Train Loss: 0.2424\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2545\n",
      "Epoch: 2937/5000, Train Loss: 0.2424\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2545\n",
      "Epoch: 2938/5000, Train Loss: 0.2424\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2545\n",
      "Epoch: 2939/5000, Train Loss: 0.2424\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2545\n",
      "Epoch: 2940/5000, Train Loss: 0.2423\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2545\n",
      "Epoch: 2941/5000, Train Loss: 0.2423\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2545\n",
      "Epoch: 2942/5000, Train Loss: 0.2423\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2545\n",
      "Epoch: 2943/5000, Train Loss: 0.2423\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2544\n",
      "Epoch: 2944/5000, Train Loss: 0.2423\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2544\n",
      "Epoch: 2945/5000, Train Loss: 0.2423\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2544\n",
      "Epoch: 2946/5000, Train Loss: 0.2423\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2544\n",
      "Epoch: 2947/5000, Train Loss: 0.2422\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2544\n",
      "Epoch: 2948/5000, Train Loss: 0.2422\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2544\n",
      "Epoch: 2949/5000, Train Loss: 0.2422\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2544\n",
      "Epoch: 2950/5000, Train Loss: 0.2422\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2544\n",
      "Epoch: 2951/5000, Train Loss: 0.2422\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2544\n",
      "Epoch: 2952/5000, Train Loss: 0.2422\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2544\n",
      "Epoch: 2953/5000, Train Loss: 0.2421\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2543\n",
      "Epoch: 2954/5000, Train Loss: 0.2421\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2543\n",
      "Epoch: 2955/5000, Train Loss: 0.2421\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2543\n",
      "Epoch: 2956/5000, Train Loss: 0.2421\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2543\n",
      "Epoch: 2957/5000, Train Loss: 0.2421\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2543\n",
      "Epoch: 2958/5000, Train Loss: 0.2421\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2543\n",
      "Epoch: 2959/5000, Train Loss: 0.2420\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2543\n",
      "Epoch: 2960/5000, Train Loss: 0.2420\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2543\n",
      "Epoch: 2961/5000, Train Loss: 0.2420\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2543\n",
      "Epoch: 2962/5000, Train Loss: 0.2420\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2543\n",
      "Epoch: 2963/5000, Train Loss: 0.2420\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2542\n",
      "Epoch: 2964/5000, Train Loss: 0.2420\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2542\n",
      "Epoch: 2965/5000, Train Loss: 0.2420\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2542\n",
      "Epoch: 2966/5000, Train Loss: 0.2419\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2542\n",
      "Epoch: 2967/5000, Train Loss: 0.2419\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2542\n",
      "Epoch: 2968/5000, Train Loss: 0.2419\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2542\n",
      "Epoch: 2969/5000, Train Loss: 0.2419\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2542\n",
      "Epoch: 2970/5000, Train Loss: 0.2419\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2542\n",
      "Epoch: 2971/5000, Train Loss: 0.2419\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2542\n",
      "Epoch: 2972/5000, Train Loss: 0.2418\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2542\n",
      "Epoch: 2973/5000, Train Loss: 0.2418\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2542\n",
      "Epoch: 2974/5000, Train Loss: 0.2418\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2541\n",
      "Epoch: 2975/5000, Train Loss: 0.2418\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2541\n",
      "Epoch: 2976/5000, Train Loss: 0.2418\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2541\n",
      "Epoch: 2977/5000, Train Loss: 0.2418\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2541\n",
      "Epoch: 2978/5000, Train Loss: 0.2418\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2541\n",
      "Epoch: 2979/5000, Train Loss: 0.2417\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2541\n",
      "Epoch: 2980/5000, Train Loss: 0.2417\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2541\n",
      "Epoch: 2981/5000, Train Loss: 0.2417\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2541\n",
      "Epoch: 2982/5000, Train Loss: 0.2417\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2541\n",
      "Epoch: 2983/5000, Train Loss: 0.2417\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2541\n",
      "Epoch: 2984/5000, Train Loss: 0.2417\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2540\n",
      "Epoch: 2985/5000, Train Loss: 0.2416\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2540\n",
      "Epoch: 2986/5000, Train Loss: 0.2416\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2540\n",
      "Epoch: 2987/5000, Train Loss: 0.2416\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2540\n",
      "Epoch: 2988/5000, Train Loss: 0.2416\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2540\n",
      "Epoch: 2989/5000, Train Loss: 0.2416\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2540\n",
      "Epoch: 2990/5000, Train Loss: 0.2416\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2540\n",
      "Epoch: 2991/5000, Train Loss: 0.2416\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2540\n",
      "Epoch: 2992/5000, Train Loss: 0.2415\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2540\n",
      "Epoch: 2993/5000, Train Loss: 0.2415\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2540\n",
      "Epoch: 2994/5000, Train Loss: 0.2415\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2539\n",
      "Epoch: 2995/5000, Train Loss: 0.2415\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2539\n",
      "Epoch: 2996/5000, Train Loss: 0.2415\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2539\n",
      "Epoch: 2997/5000, Train Loss: 0.2415\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2539\n",
      "Epoch: 2998/5000, Train Loss: 0.2414\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2539\n",
      "Epoch: 2999/5000, Train Loss: 0.2414\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2539\n",
      "Epoch: 3000/5000, Train Loss: 0.2414\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2539\n",
      "Epoch: 3001/5000, Train Loss: 0.2414\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2539\n",
      "Epoch: 3002/5000, Train Loss: 0.2414\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2539\n",
      "Epoch: 3003/5000, Train Loss: 0.2414\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2539\n",
      "Epoch: 3004/5000, Train Loss: 0.2414\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2539\n",
      "Epoch: 3005/5000, Train Loss: 0.2413\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2538\n",
      "Epoch: 3006/5000, Train Loss: 0.2413\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2538\n",
      "Epoch: 3007/5000, Train Loss: 0.2413\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2538\n",
      "Epoch: 3008/5000, Train Loss: 0.2413\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2538\n",
      "Epoch: 3009/5000, Train Loss: 0.2413\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2538\n",
      "Epoch: 3010/5000, Train Loss: 0.2413\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2538\n",
      "Epoch: 3011/5000, Train Loss: 0.2412\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2538\n",
      "Epoch: 3012/5000, Train Loss: 0.2412\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2538\n",
      "Epoch: 3013/5000, Train Loss: 0.2412\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2538\n",
      "Epoch: 3014/5000, Train Loss: 0.2412\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2538\n",
      "Epoch: 3015/5000, Train Loss: 0.2412\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2538\n",
      "Epoch: 3016/5000, Train Loss: 0.2412\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2537\n",
      "Epoch: 3017/5000, Train Loss: 0.2412\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2537\n",
      "Epoch: 3018/5000, Train Loss: 0.2411\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2537\n",
      "Epoch: 3019/5000, Train Loss: 0.2411\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2537\n",
      "Epoch: 3020/5000, Train Loss: 0.2411\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2537\n",
      "Epoch: 3021/5000, Train Loss: 0.2411\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2537\n",
      "Epoch: 3022/5000, Train Loss: 0.2411\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2537\n",
      "Epoch: 3023/5000, Train Loss: 0.2411\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2537\n",
      "Epoch: 3024/5000, Train Loss: 0.2410\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2537\n",
      "Epoch: 3025/5000, Train Loss: 0.2410\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2537\n",
      "Epoch: 3026/5000, Train Loss: 0.2410\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2536\n",
      "Epoch: 3027/5000, Train Loss: 0.2410\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2536\n",
      "Epoch: 3028/5000, Train Loss: 0.2410\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2536\n",
      "Epoch: 3029/5000, Train Loss: 0.2410\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2536\n",
      "Epoch: 3030/5000, Train Loss: 0.2410\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2536\n",
      "Epoch: 3031/5000, Train Loss: 0.2409\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2536\n",
      "Epoch: 3032/5000, Train Loss: 0.2409\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2536\n",
      "Epoch: 3033/5000, Train Loss: 0.2409\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2536\n",
      "Epoch: 3034/5000, Train Loss: 0.2409\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2536\n",
      "Epoch: 3035/5000, Train Loss: 0.2409\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2536\n",
      "Epoch: 3036/5000, Train Loss: 0.2409\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2536\n",
      "Epoch: 3037/5000, Train Loss: 0.2409\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2535\n",
      "Epoch: 3038/5000, Train Loss: 0.2408\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2535\n",
      "Epoch: 3039/5000, Train Loss: 0.2408\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2535\n",
      "Epoch: 3040/5000, Train Loss: 0.2408\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2535\n",
      "Epoch: 3041/5000, Train Loss: 0.2408\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2535\n",
      "Epoch: 3042/5000, Train Loss: 0.2408\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2535\n",
      "Epoch: 3043/5000, Train Loss: 0.2408\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2535\n",
      "Epoch: 3044/5000, Train Loss: 0.2407\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2535\n",
      "Epoch: 3045/5000, Train Loss: 0.2407\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2535\n",
      "Epoch: 3046/5000, Train Loss: 0.2407\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2535\n",
      "Epoch: 3047/5000, Train Loss: 0.2407\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2535\n",
      "Epoch: 3048/5000, Train Loss: 0.2407\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2534\n",
      "Epoch: 3049/5000, Train Loss: 0.2407\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2534\n",
      "Epoch: 3050/5000, Train Loss: 0.2407\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2534\n",
      "Epoch: 3051/5000, Train Loss: 0.2406\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2534\n",
      "Epoch: 3052/5000, Train Loss: 0.2406\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2534\n",
      "Epoch: 3053/5000, Train Loss: 0.2406\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2534\n",
      "Epoch: 3054/5000, Train Loss: 0.2406\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2534\n",
      "Epoch: 3055/5000, Train Loss: 0.2406\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2534\n",
      "Epoch: 3056/5000, Train Loss: 0.2406\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2534\n",
      "Epoch: 3057/5000, Train Loss: 0.2406\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2534\n",
      "Epoch: 3058/5000, Train Loss: 0.2405\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2534\n",
      "Epoch: 3059/5000, Train Loss: 0.2405\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2533\n",
      "Epoch: 3060/5000, Train Loss: 0.2405\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2533\n",
      "Epoch: 3061/5000, Train Loss: 0.2405\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2533\n",
      "Epoch: 3062/5000, Train Loss: 0.2405\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2533\n",
      "Epoch: 3063/5000, Train Loss: 0.2405\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2533\n",
      "Epoch: 3064/5000, Train Loss: 0.2405\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2533\n",
      "Epoch: 3065/5000, Train Loss: 0.2404\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2533\n",
      "Epoch: 3066/5000, Train Loss: 0.2404\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2533\n",
      "Epoch: 3067/5000, Train Loss: 0.2404\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2533\n",
      "Epoch: 3068/5000, Train Loss: 0.2404\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2533\n",
      "Epoch: 3069/5000, Train Loss: 0.2404\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2533\n",
      "Epoch: 3070/5000, Train Loss: 0.2404\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2532\n",
      "Epoch: 3071/5000, Train Loss: 0.2404\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2532\n",
      "Epoch: 3072/5000, Train Loss: 0.2403\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2532\n",
      "Epoch: 3073/5000, Train Loss: 0.2403\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2532\n",
      "Epoch: 3074/5000, Train Loss: 0.2403\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2532\n",
      "Epoch: 3075/5000, Train Loss: 0.2403\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2532\n",
      "Epoch: 3076/5000, Train Loss: 0.2403\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2532\n",
      "Epoch: 3077/5000, Train Loss: 0.2403\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2532\n",
      "Epoch: 3078/5000, Train Loss: 0.2402\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2532\n",
      "Epoch: 3079/5000, Train Loss: 0.2402\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2532\n",
      "Epoch: 3080/5000, Train Loss: 0.2402\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2532\n",
      "Epoch: 3081/5000, Train Loss: 0.2402\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2531\n",
      "Epoch: 3082/5000, Train Loss: 0.2402\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2531\n",
      "Epoch: 3083/5000, Train Loss: 0.2402\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2531\n",
      "Epoch: 3084/5000, Train Loss: 0.2402\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2531\n",
      "Epoch: 3085/5000, Train Loss: 0.2401\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2531\n",
      "Epoch: 3086/5000, Train Loss: 0.2401\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2531\n",
      "Epoch: 3087/5000, Train Loss: 0.2401\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2531\n",
      "Epoch: 3088/5000, Train Loss: 0.2401\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2531\n",
      "Epoch: 3089/5000, Train Loss: 0.2401\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2531\n",
      "Epoch: 3090/5000, Train Loss: 0.2401\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2531\n",
      "Epoch: 3091/5000, Train Loss: 0.2401\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2531\n",
      "Epoch: 3092/5000, Train Loss: 0.2400\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2530\n",
      "Epoch: 3093/5000, Train Loss: 0.2400\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2530\n",
      "Epoch: 3094/5000, Train Loss: 0.2400\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2530\n",
      "Epoch: 3095/5000, Train Loss: 0.2400\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2530\n",
      "Epoch: 3096/5000, Train Loss: 0.2400\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2530\n",
      "Epoch: 3097/5000, Train Loss: 0.2400\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2530\n",
      "Epoch: 3098/5000, Train Loss: 0.2400\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2530\n",
      "Epoch: 3099/5000, Train Loss: 0.2399\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2530\n",
      "Epoch: 3100/5000, Train Loss: 0.2399\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2530\n",
      "Epoch: 3101/5000, Train Loss: 0.2399\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2530\n",
      "Epoch: 3102/5000, Train Loss: 0.2399\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2530\n",
      "Epoch: 3103/5000, Train Loss: 0.2399\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2529\n",
      "Epoch: 3104/5000, Train Loss: 0.2399\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2529\n",
      "Epoch: 3105/5000, Train Loss: 0.2399\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2529\n",
      "Epoch: 3106/5000, Train Loss: 0.2398\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2529\n",
      "Epoch: 3107/5000, Train Loss: 0.2398\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2529\n",
      "Epoch: 3108/5000, Train Loss: 0.2398\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2529\n",
      "Epoch: 3109/5000, Train Loss: 0.2398\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2529\n",
      "Epoch: 3110/5000, Train Loss: 0.2398\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2529\n",
      "Epoch: 3111/5000, Train Loss: 0.2398\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2529\n",
      "Epoch: 3112/5000, Train Loss: 0.2398\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2529\n",
      "Epoch: 3113/5000, Train Loss: 0.2397\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2529\n",
      "Epoch: 3114/5000, Train Loss: 0.2397\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2528\n",
      "Epoch: 3115/5000, Train Loss: 0.2397\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2528\n",
      "Epoch: 3116/5000, Train Loss: 0.2397\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2528\n",
      "Epoch: 3117/5000, Train Loss: 0.2397\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2528\n",
      "Epoch: 3118/5000, Train Loss: 0.2397\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2528\n",
      "Epoch: 3119/5000, Train Loss: 0.2397\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2528\n",
      "Epoch: 3120/5000, Train Loss: 0.2396\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2528\n",
      "Epoch: 3121/5000, Train Loss: 0.2396\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2528\n",
      "Epoch: 3122/5000, Train Loss: 0.2396\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2528\n",
      "Epoch: 3123/5000, Train Loss: 0.2396\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2528\n",
      "Epoch: 3124/5000, Train Loss: 0.2396\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2528\n",
      "Epoch: 3125/5000, Train Loss: 0.2396\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2528\n",
      "Epoch: 3126/5000, Train Loss: 0.2396\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2527\n",
      "Epoch: 3127/5000, Train Loss: 0.2395\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2527\n",
      "Epoch: 3128/5000, Train Loss: 0.2395\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2527\n",
      "Epoch: 3129/5000, Train Loss: 0.2395\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2527\n",
      "Epoch: 3130/5000, Train Loss: 0.2395\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2527\n",
      "Epoch: 3131/5000, Train Loss: 0.2395\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2527\n",
      "Epoch: 3132/5000, Train Loss: 0.2395\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2527\n",
      "Epoch: 3133/5000, Train Loss: 0.2395\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2527\n",
      "Epoch: 3134/5000, Train Loss: 0.2394\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2527\n",
      "Epoch: 3135/5000, Train Loss: 0.2394\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2527\n",
      "Epoch: 3136/5000, Train Loss: 0.2394\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2527\n",
      "Epoch: 3137/5000, Train Loss: 0.2394\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2526\n",
      "Epoch: 3138/5000, Train Loss: 0.2394\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2526\n",
      "Epoch: 3139/5000, Train Loss: 0.2394\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2526\n",
      "Epoch: 3140/5000, Train Loss: 0.2394\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2526\n",
      "Epoch: 3141/5000, Train Loss: 0.2393\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2526\n",
      "Epoch: 3142/5000, Train Loss: 0.2393\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2526\n",
      "Epoch: 3143/5000, Train Loss: 0.2393\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2526\n",
      "Epoch: 3144/5000, Train Loss: 0.2393\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2526\n",
      "Epoch: 3145/5000, Train Loss: 0.2393\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2526\n",
      "Epoch: 3146/5000, Train Loss: 0.2393\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2526\n",
      "Epoch: 3147/5000, Train Loss: 0.2393\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2526\n",
      "Epoch: 3148/5000, Train Loss: 0.2392\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2526\n",
      "Epoch: 3149/5000, Train Loss: 0.2392\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2525\n",
      "Epoch: 3150/5000, Train Loss: 0.2392\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2525\n",
      "Epoch: 3151/5000, Train Loss: 0.2392\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2525\n",
      "Epoch: 3152/5000, Train Loss: 0.2392\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2525\n",
      "Epoch: 3153/5000, Train Loss: 0.2392\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2525\n",
      "Epoch: 3154/5000, Train Loss: 0.2392\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2525\n",
      "Epoch: 3155/5000, Train Loss: 0.2391\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2525\n",
      "Epoch: 3156/5000, Train Loss: 0.2391\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2525\n",
      "Epoch: 3157/5000, Train Loss: 0.2391\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2525\n",
      "Epoch: 3158/5000, Train Loss: 0.2391\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2525\n",
      "Epoch: 3159/5000, Train Loss: 0.2391\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2525\n",
      "Epoch: 3160/5000, Train Loss: 0.2391\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2525\n",
      "Epoch: 3161/5000, Train Loss: 0.2391\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2524\n",
      "Epoch: 3162/5000, Train Loss: 0.2390\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2524\n",
      "Epoch: 3163/5000, Train Loss: 0.2390\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2524\n",
      "Epoch: 3164/5000, Train Loss: 0.2390\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2524\n",
      "Epoch: 3165/5000, Train Loss: 0.2390\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2524\n",
      "Epoch: 3166/5000, Train Loss: 0.2390\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2524\n",
      "Epoch: 3167/5000, Train Loss: 0.2390\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2524\n",
      "Epoch: 3168/5000, Train Loss: 0.2390\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2524\n",
      "Epoch: 3169/5000, Train Loss: 0.2390\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2524\n",
      "Epoch: 3170/5000, Train Loss: 0.2389\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2524\n",
      "Epoch: 3171/5000, Train Loss: 0.2389\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2524\n",
      "Epoch: 3172/5000, Train Loss: 0.2389\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2524\n",
      "Epoch: 3173/5000, Train Loss: 0.2389\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2523\n",
      "Epoch: 3174/5000, Train Loss: 0.2389\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2523\n",
      "Epoch: 3175/5000, Train Loss: 0.2389\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2523\n",
      "Epoch: 3176/5000, Train Loss: 0.2389\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2523\n",
      "Epoch: 3177/5000, Train Loss: 0.2388\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2523\n",
      "Epoch: 3178/5000, Train Loss: 0.2388\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2523\n",
      "Epoch: 3179/5000, Train Loss: 0.2388\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2523\n",
      "Epoch: 3180/5000, Train Loss: 0.2388\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2523\n",
      "Epoch: 3181/5000, Train Loss: 0.2388\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2523\n",
      "Epoch: 3182/5000, Train Loss: 0.2388\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2523\n",
      "Epoch: 3183/5000, Train Loss: 0.2388\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2523\n",
      "Epoch: 3184/5000, Train Loss: 0.2387\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2523\n",
      "Epoch: 3185/5000, Train Loss: 0.2387\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2522\n",
      "Epoch: 3186/5000, Train Loss: 0.2387\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2522\n",
      "Epoch: 3187/5000, Train Loss: 0.2387\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2522\n",
      "Epoch: 3188/5000, Train Loss: 0.2387\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2522\n",
      "Epoch: 3189/5000, Train Loss: 0.2387\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2522\n",
      "Epoch: 3190/5000, Train Loss: 0.2387\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2522\n",
      "Epoch: 3191/5000, Train Loss: 0.2386\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2522\n",
      "Epoch: 3192/5000, Train Loss: 0.2386\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2522\n",
      "Epoch: 3193/5000, Train Loss: 0.2386\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2522\n",
      "Epoch: 3194/5000, Train Loss: 0.2386\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2522\n",
      "Epoch: 3195/5000, Train Loss: 0.2386\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2522\n",
      "Epoch: 3196/5000, Train Loss: 0.2386\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2522\n",
      "Epoch: 3197/5000, Train Loss: 0.2386\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2521\n",
      "Epoch: 3198/5000, Train Loss: 0.2386\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2521\n",
      "Epoch: 3199/5000, Train Loss: 0.2385\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2521\n",
      "Epoch: 3200/5000, Train Loss: 0.2385\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2521\n",
      "Epoch: 3201/5000, Train Loss: 0.2385\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2521\n",
      "Epoch: 3202/5000, Train Loss: 0.2385\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2521\n",
      "Epoch: 3203/5000, Train Loss: 0.2385\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2521\n",
      "Epoch: 3204/5000, Train Loss: 0.2385\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2521\n",
      "Epoch: 3205/5000, Train Loss: 0.2385\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2521\n",
      "Epoch: 3206/5000, Train Loss: 0.2384\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2521\n",
      "Epoch: 3207/5000, Train Loss: 0.2384\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2521\n",
      "Epoch: 3208/5000, Train Loss: 0.2384\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2521\n",
      "Epoch: 3209/5000, Train Loss: 0.2384\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2520\n",
      "Epoch: 3210/5000, Train Loss: 0.2384\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2520\n",
      "Epoch: 3211/5000, Train Loss: 0.2384\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2520\n",
      "Epoch: 3212/5000, Train Loss: 0.2384\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2520\n",
      "Epoch: 3213/5000, Train Loss: 0.2383\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2520\n",
      "Epoch: 3214/5000, Train Loss: 0.2383\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2520\n",
      "Epoch: 3215/5000, Train Loss: 0.2383\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2520\n",
      "Epoch: 3216/5000, Train Loss: 0.2383\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2520\n",
      "Epoch: 3217/5000, Train Loss: 0.2383\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2520\n",
      "Epoch: 3218/5000, Train Loss: 0.2383\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2520\n",
      "Epoch: 3219/5000, Train Loss: 0.2383\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2520\n",
      "Epoch: 3220/5000, Train Loss: 0.2383\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2520\n",
      "Epoch: 3221/5000, Train Loss: 0.2382\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2519\n",
      "Epoch: 3222/5000, Train Loss: 0.2382\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2519\n",
      "Epoch: 3223/5000, Train Loss: 0.2382\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2519\n",
      "Epoch: 3224/5000, Train Loss: 0.2382\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2519\n",
      "Epoch: 3225/5000, Train Loss: 0.2382\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2519\n",
      "Epoch: 3226/5000, Train Loss: 0.2382\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2519\n",
      "Epoch: 3227/5000, Train Loss: 0.2382\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2519\n",
      "Epoch: 3228/5000, Train Loss: 0.2381\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2519\n",
      "Epoch: 3229/5000, Train Loss: 0.2381\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2519\n",
      "Epoch: 3230/5000, Train Loss: 0.2381\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2519\n",
      "Epoch: 3231/5000, Train Loss: 0.2381\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2519\n",
      "Epoch: 3232/5000, Train Loss: 0.2381\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2519\n",
      "Epoch: 3233/5000, Train Loss: 0.2381\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2518\n",
      "Epoch: 3234/5000, Train Loss: 0.2381\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2518\n",
      "Epoch: 3235/5000, Train Loss: 0.2381\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2518\n",
      "Epoch: 3236/5000, Train Loss: 0.2380\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2518\n",
      "Epoch: 3237/5000, Train Loss: 0.2380\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2518\n",
      "Epoch: 3238/5000, Train Loss: 0.2380\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2518\n",
      "Epoch: 3239/5000, Train Loss: 0.2380\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2518\n",
      "Epoch: 3240/5000, Train Loss: 0.2380\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2518\n",
      "Epoch: 3241/5000, Train Loss: 0.2380\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2518\n",
      "Epoch: 3242/5000, Train Loss: 0.2380\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2518\n",
      "Epoch: 3243/5000, Train Loss: 0.2379\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2518\n",
      "Epoch: 3244/5000, Train Loss: 0.2379\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2518\n",
      "Epoch: 3245/5000, Train Loss: 0.2379\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2518\n",
      "Epoch: 3246/5000, Train Loss: 0.2379\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2517\n",
      "Epoch: 3247/5000, Train Loss: 0.2379\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2517\n",
      "Epoch: 3248/5000, Train Loss: 0.2379\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2517\n",
      "Epoch: 3249/5000, Train Loss: 0.2379\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2517\n",
      "Epoch: 3250/5000, Train Loss: 0.2379\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2517\n",
      "Epoch: 3251/5000, Train Loss: 0.2378\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2517\n",
      "Epoch: 3252/5000, Train Loss: 0.2378\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2517\n",
      "Epoch: 3253/5000, Train Loss: 0.2378\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2517\n",
      "Epoch: 3254/5000, Train Loss: 0.2378\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2517\n",
      "Epoch: 3255/5000, Train Loss: 0.2378\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2517\n",
      "Epoch: 3256/5000, Train Loss: 0.2378\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2517\n",
      "Epoch: 3257/5000, Train Loss: 0.2378\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2517\n",
      "Epoch: 3258/5000, Train Loss: 0.2377\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2516\n",
      "Epoch: 3259/5000, Train Loss: 0.2377\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2516\n",
      "Epoch: 3260/5000, Train Loss: 0.2377\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2516\n",
      "Epoch: 3261/5000, Train Loss: 0.2377\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2516\n",
      "Epoch: 3262/5000, Train Loss: 0.2377\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2516\n",
      "Epoch: 3263/5000, Train Loss: 0.2377\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2516\n",
      "Epoch: 3264/5000, Train Loss: 0.2377\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2516\n",
      "Epoch: 3265/5000, Train Loss: 0.2377\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2516\n",
      "Epoch: 3266/5000, Train Loss: 0.2376\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2516\n",
      "Epoch: 3267/5000, Train Loss: 0.2376\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2516\n",
      "Epoch: 3268/5000, Train Loss: 0.2376\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2516\n",
      "Epoch: 3269/5000, Train Loss: 0.2376\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2516\n",
      "Epoch: 3270/5000, Train Loss: 0.2376\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2516\n",
      "Epoch: 3271/5000, Train Loss: 0.2376\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2515\n",
      "Epoch: 3272/5000, Train Loss: 0.2376\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2515\n",
      "Epoch: 3273/5000, Train Loss: 0.2375\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2515\n",
      "Epoch: 3274/5000, Train Loss: 0.2375\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2515\n",
      "Epoch: 3275/5000, Train Loss: 0.2375\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2515\n",
      "Epoch: 3276/5000, Train Loss: 0.2375\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2515\n",
      "Epoch: 3277/5000, Train Loss: 0.2375\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2515\n",
      "Epoch: 3278/5000, Train Loss: 0.2375\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2515\n",
      "Epoch: 3279/5000, Train Loss: 0.2375\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2515\n",
      "Epoch: 3280/5000, Train Loss: 0.2375\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2515\n",
      "Epoch: 3281/5000, Train Loss: 0.2374\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2515\n",
      "Epoch: 3282/5000, Train Loss: 0.2374\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2515\n",
      "Epoch: 3283/5000, Train Loss: 0.2374\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2515\n",
      "Epoch: 3284/5000, Train Loss: 0.2374\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2514\n",
      "Epoch: 3285/5000, Train Loss: 0.2374\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2514\n",
      "Epoch: 3286/5000, Train Loss: 0.2374\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2514\n",
      "Epoch: 3287/5000, Train Loss: 0.2374\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2514\n",
      "Epoch: 3288/5000, Train Loss: 0.2374\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2514\n",
      "Epoch: 3289/5000, Train Loss: 0.2373\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2514\n",
      "Epoch: 3290/5000, Train Loss: 0.2373\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2514\n",
      "Epoch: 3291/5000, Train Loss: 0.2373\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2514\n",
      "Epoch: 3292/5000, Train Loss: 0.2373\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2514\n",
      "Epoch: 3293/5000, Train Loss: 0.2373\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2514\n",
      "Epoch: 3294/5000, Train Loss: 0.2373\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2514\n",
      "Epoch: 3295/5000, Train Loss: 0.2373\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2514\n",
      "Epoch: 3296/5000, Train Loss: 0.2372\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2514\n",
      "Epoch: 3297/5000, Train Loss: 0.2372\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2513\n",
      "Epoch: 3298/5000, Train Loss: 0.2372\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2513\n",
      "Epoch: 3299/5000, Train Loss: 0.2372\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2513\n",
      "Epoch: 3300/5000, Train Loss: 0.2372\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2513\n",
      "Epoch: 3301/5000, Train Loss: 0.2372\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2513\n",
      "Epoch: 3302/5000, Train Loss: 0.2372\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2513\n",
      "Epoch: 3303/5000, Train Loss: 0.2372\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2513\n",
      "Epoch: 3304/5000, Train Loss: 0.2371\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2513\n",
      "Epoch: 3305/5000, Train Loss: 0.2371\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2513\n",
      "Epoch: 3306/5000, Train Loss: 0.2371\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2513\n",
      "Epoch: 3307/5000, Train Loss: 0.2371\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2513\n",
      "Epoch: 3308/5000, Train Loss: 0.2371\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2513\n",
      "Epoch: 3309/5000, Train Loss: 0.2371\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2513\n",
      "Epoch: 3310/5000, Train Loss: 0.2371\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2512\n",
      "Epoch: 3311/5000, Train Loss: 0.2371\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2512\n",
      "Epoch: 3312/5000, Train Loss: 0.2370\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2512\n",
      "Epoch: 3313/5000, Train Loss: 0.2370\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2512\n",
      "Epoch: 3314/5000, Train Loss: 0.2370\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2512\n",
      "Epoch: 3315/5000, Train Loss: 0.2370\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2512\n",
      "Epoch: 3316/5000, Train Loss: 0.2370\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2512\n",
      "Epoch: 3317/5000, Train Loss: 0.2370\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2512\n",
      "Epoch: 3318/5000, Train Loss: 0.2370\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2512\n",
      "Epoch: 3319/5000, Train Loss: 0.2369\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2512\n",
      "Epoch: 3320/5000, Train Loss: 0.2369\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2512\n",
      "Epoch: 3321/5000, Train Loss: 0.2369\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2512\n",
      "Epoch: 3322/5000, Train Loss: 0.2369\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2512\n",
      "Epoch: 3323/5000, Train Loss: 0.2369\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2511\n",
      "Epoch: 3324/5000, Train Loss: 0.2369\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2511\n",
      "Epoch: 3325/5000, Train Loss: 0.2369\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2511\n",
      "Epoch: 3326/5000, Train Loss: 0.2369\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2511\n",
      "Epoch: 3327/5000, Train Loss: 0.2368\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2511\n",
      "Epoch: 3328/5000, Train Loss: 0.2368\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2511\n",
      "Epoch: 3329/5000, Train Loss: 0.2368\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2511\n",
      "Epoch: 3330/5000, Train Loss: 0.2368\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2511\n",
      "Epoch: 3331/5000, Train Loss: 0.2368\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2511\n",
      "Epoch: 3332/5000, Train Loss: 0.2368\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2511\n",
      "Epoch: 3333/5000, Train Loss: 0.2368\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2511\n",
      "Epoch: 3334/5000, Train Loss: 0.2368\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2511\n",
      "Epoch: 3335/5000, Train Loss: 0.2367\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2511\n",
      "Epoch: 3336/5000, Train Loss: 0.2367\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 3337/5000, Train Loss: 0.2367\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 3338/5000, Train Loss: 0.2367\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 3339/5000, Train Loss: 0.2367\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 3340/5000, Train Loss: 0.2367\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 3341/5000, Train Loss: 0.2367\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 3342/5000, Train Loss: 0.2367\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 3343/5000, Train Loss: 0.2366\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 3344/5000, Train Loss: 0.2366\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 3345/5000, Train Loss: 0.2366\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 3346/5000, Train Loss: 0.2366\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 3347/5000, Train Loss: 0.2366\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 3348/5000, Train Loss: 0.2366\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 3349/5000, Train Loss: 0.2366\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2510\n",
      "Epoch: 3350/5000, Train Loss: 0.2366\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2509\n",
      "Epoch: 3351/5000, Train Loss: 0.2365\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2509\n",
      "Epoch: 3352/5000, Train Loss: 0.2365\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2509\n",
      "Epoch: 3353/5000, Train Loss: 0.2365\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2509\n",
      "Epoch: 3354/5000, Train Loss: 0.2365\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2509\n",
      "Epoch: 3355/5000, Train Loss: 0.2365\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2509\n",
      "Epoch: 3356/5000, Train Loss: 0.2365\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2509\n",
      "Epoch: 3357/5000, Train Loss: 0.2365\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2509\n",
      "Epoch: 3358/5000, Train Loss: 0.2365\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2509\n",
      "Epoch: 3359/5000, Train Loss: 0.2364\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2509\n",
      "Epoch: 3360/5000, Train Loss: 0.2364\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2509\n",
      "Epoch: 3361/5000, Train Loss: 0.2364\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2509\n",
      "Epoch: 3362/5000, Train Loss: 0.2364\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2509\n",
      "Epoch: 3363/5000, Train Loss: 0.2364\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2508\n",
      "Epoch: 3364/5000, Train Loss: 0.2364\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2508\n",
      "Epoch: 3365/5000, Train Loss: 0.2364\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2508\n",
      "Epoch: 3366/5000, Train Loss: 0.2364\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2508\n",
      "Epoch: 3367/5000, Train Loss: 0.2363\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2508\n",
      "Epoch: 3368/5000, Train Loss: 0.2363\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2508\n",
      "Epoch: 3369/5000, Train Loss: 0.2363\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2508\n",
      "Epoch: 3370/5000, Train Loss: 0.2363\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2508\n",
      "Epoch: 3371/5000, Train Loss: 0.2363\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2508\n",
      "Epoch: 3372/5000, Train Loss: 0.2363\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2508\n",
      "Epoch: 3373/5000, Train Loss: 0.2363\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2508\n",
      "Epoch: 3374/5000, Train Loss: 0.2363\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2508\n",
      "Epoch: 3375/5000, Train Loss: 0.2362\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2508\n",
      "Epoch: 3376/5000, Train Loss: 0.2362\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2508\n",
      "Epoch: 3377/5000, Train Loss: 0.2362\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 3378/5000, Train Loss: 0.2362\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 3379/5000, Train Loss: 0.2362\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 3380/5000, Train Loss: 0.2362\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 3381/5000, Train Loss: 0.2362\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 3382/5000, Train Loss: 0.2362\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 3383/5000, Train Loss: 0.2361\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 3384/5000, Train Loss: 0.2361\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 3385/5000, Train Loss: 0.2361\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 3386/5000, Train Loss: 0.2361\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 3387/5000, Train Loss: 0.2361\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 3388/5000, Train Loss: 0.2361\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 3389/5000, Train Loss: 0.2361\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 3390/5000, Train Loss: 0.2361\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2507\n",
      "Epoch: 3391/5000, Train Loss: 0.2360\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2506\n",
      "Epoch: 3392/5000, Train Loss: 0.2360\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2506\n",
      "Epoch: 3393/5000, Train Loss: 0.2360\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2506\n",
      "Epoch: 3394/5000, Train Loss: 0.2360\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2506\n",
      "Epoch: 3395/5000, Train Loss: 0.2360\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2506\n",
      "Epoch: 3396/5000, Train Loss: 0.2360\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2506\n",
      "Epoch: 3397/5000, Train Loss: 0.2360\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2506\n",
      "Epoch: 3398/5000, Train Loss: 0.2360\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2506\n",
      "Epoch: 3399/5000, Train Loss: 0.2359\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2506\n",
      "Epoch: 3400/5000, Train Loss: 0.2359\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2506\n",
      "Epoch: 3401/5000, Train Loss: 0.2359\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2506\n",
      "Epoch: 3402/5000, Train Loss: 0.2359\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2506\n",
      "Epoch: 3403/5000, Train Loss: 0.2359\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2506\n",
      "Epoch: 3404/5000, Train Loss: 0.2359\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2506\n",
      "Epoch: 3405/5000, Train Loss: 0.2359\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2505\n",
      "Epoch: 3406/5000, Train Loss: 0.2359\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2505\n",
      "Epoch: 3407/5000, Train Loss: 0.2358\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2505\n",
      "Epoch: 3408/5000, Train Loss: 0.2358\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2505\n",
      "Epoch: 3409/5000, Train Loss: 0.2358\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2505\n",
      "Epoch: 3410/5000, Train Loss: 0.2358\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2505\n",
      "Epoch: 3411/5000, Train Loss: 0.2358\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2505\n",
      "Epoch: 3412/5000, Train Loss: 0.2358\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2505\n",
      "Epoch: 3413/5000, Train Loss: 0.2358\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2505\n",
      "Epoch: 3414/5000, Train Loss: 0.2358\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2505\n",
      "Epoch: 3415/5000, Train Loss: 0.2357\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2505\n",
      "Epoch: 3416/5000, Train Loss: 0.2357\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2505\n",
      "Epoch: 3417/5000, Train Loss: 0.2357\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2505\n",
      "Epoch: 3418/5000, Train Loss: 0.2357\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2505\n",
      "Epoch: 3419/5000, Train Loss: 0.2357\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 3420/5000, Train Loss: 0.2357\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 3421/5000, Train Loss: 0.2357\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 3422/5000, Train Loss: 0.2357\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 3423/5000, Train Loss: 0.2357\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 3424/5000, Train Loss: 0.2356\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 3425/5000, Train Loss: 0.2356\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 3426/5000, Train Loss: 0.2356\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 3427/5000, Train Loss: 0.2356\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 3428/5000, Train Loss: 0.2356\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 3429/5000, Train Loss: 0.2356\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 3430/5000, Train Loss: 0.2356\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 3431/5000, Train Loss: 0.2356\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 3432/5000, Train Loss: 0.2355\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2504\n",
      "Epoch: 3433/5000, Train Loss: 0.2355\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2503\n",
      "Epoch: 3434/5000, Train Loss: 0.2355\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2503\n",
      "Epoch: 3435/5000, Train Loss: 0.2355\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2503\n",
      "Epoch: 3436/5000, Train Loss: 0.2355\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2503\n",
      "Epoch: 3437/5000, Train Loss: 0.2355\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2503\n",
      "Epoch: 3438/5000, Train Loss: 0.2355\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2503\n",
      "Epoch: 3439/5000, Train Loss: 0.2355\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2503\n",
      "Epoch: 3440/5000, Train Loss: 0.2354\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2503\n",
      "Epoch: 3441/5000, Train Loss: 0.2354\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2503\n",
      "Epoch: 3442/5000, Train Loss: 0.2354\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2503\n",
      "Epoch: 3443/5000, Train Loss: 0.2354\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2503\n",
      "Epoch: 3444/5000, Train Loss: 0.2354\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2503\n",
      "Epoch: 3445/5000, Train Loss: 0.2354\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2503\n",
      "Epoch: 3446/5000, Train Loss: 0.2354\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2503\n",
      "Epoch: 3447/5000, Train Loss: 0.2354\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3448/5000, Train Loss: 0.2354\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3449/5000, Train Loss: 0.2353\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3450/5000, Train Loss: 0.2353\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3451/5000, Train Loss: 0.2353\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3452/5000, Train Loss: 0.2353\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3453/5000, Train Loss: 0.2353\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3454/5000, Train Loss: 0.2353\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3455/5000, Train Loss: 0.2353\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3456/5000, Train Loss: 0.2353\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3457/5000, Train Loss: 0.2352\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3458/5000, Train Loss: 0.2352\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3459/5000, Train Loss: 0.2352\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3460/5000, Train Loss: 0.2352\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3461/5000, Train Loss: 0.2352\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2502\n",
      "Epoch: 3462/5000, Train Loss: 0.2352\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2501\n",
      "Epoch: 3463/5000, Train Loss: 0.2352\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2501\n",
      "Epoch: 3464/5000, Train Loss: 0.2352\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2501\n",
      "Epoch: 3465/5000, Train Loss: 0.2351\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2501\n",
      "Epoch: 3466/5000, Train Loss: 0.2351\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2501\n",
      "Epoch: 3467/5000, Train Loss: 0.2351\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2501\n",
      "Epoch: 3468/5000, Train Loss: 0.2351\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2501\n",
      "Epoch: 3469/5000, Train Loss: 0.2351\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2501\n",
      "Epoch: 3470/5000, Train Loss: 0.2351\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2501\n",
      "Epoch: 3471/5000, Train Loss: 0.2351\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2501\n",
      "Epoch: 3472/5000, Train Loss: 0.2351\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2501\n",
      "Epoch: 3473/5000, Train Loss: 0.2351\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2501\n",
      "Epoch: 3474/5000, Train Loss: 0.2350\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2501\n",
      "Epoch: 3475/5000, Train Loss: 0.2350\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2501\n",
      "Epoch: 3476/5000, Train Loss: 0.2350\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3477/5000, Train Loss: 0.2350\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3478/5000, Train Loss: 0.2350\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3479/5000, Train Loss: 0.2350\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3480/5000, Train Loss: 0.2350\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3481/5000, Train Loss: 0.2350\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3482/5000, Train Loss: 0.2349\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3483/5000, Train Loss: 0.2349\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3484/5000, Train Loss: 0.2349\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3485/5000, Train Loss: 0.2349\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3486/5000, Train Loss: 0.2349\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3487/5000, Train Loss: 0.2349\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3488/5000, Train Loss: 0.2349\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3489/5000, Train Loss: 0.2349\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3490/5000, Train Loss: 0.2349\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2500\n",
      "Epoch: 3491/5000, Train Loss: 0.2348\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3492/5000, Train Loss: 0.2348\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3493/5000, Train Loss: 0.2348\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3494/5000, Train Loss: 0.2348\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3495/5000, Train Loss: 0.2348\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3496/5000, Train Loss: 0.2348\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3497/5000, Train Loss: 0.2348\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3498/5000, Train Loss: 0.2348\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3499/5000, Train Loss: 0.2347\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3500/5000, Train Loss: 0.2347\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3501/5000, Train Loss: 0.2347\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3502/5000, Train Loss: 0.2347\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3503/5000, Train Loss: 0.2347\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3504/5000, Train Loss: 0.2347\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3505/5000, Train Loss: 0.2347\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2499\n",
      "Epoch: 3506/5000, Train Loss: 0.2347\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3507/5000, Train Loss: 0.2347\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3508/5000, Train Loss: 0.2346\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3509/5000, Train Loss: 0.2346\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3510/5000, Train Loss: 0.2346\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3511/5000, Train Loss: 0.2346\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3512/5000, Train Loss: 0.2346\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3513/5000, Train Loss: 0.2346\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3514/5000, Train Loss: 0.2346\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3515/5000, Train Loss: 0.2346\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3516/5000, Train Loss: 0.2345\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3517/5000, Train Loss: 0.2345\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3518/5000, Train Loss: 0.2345\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3519/5000, Train Loss: 0.2345\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3520/5000, Train Loss: 0.2345\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2498\n",
      "Epoch: 3521/5000, Train Loss: 0.2345\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3522/5000, Train Loss: 0.2345\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3523/5000, Train Loss: 0.2345\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3524/5000, Train Loss: 0.2345\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3525/5000, Train Loss: 0.2344\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3526/5000, Train Loss: 0.2344\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3527/5000, Train Loss: 0.2344\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3528/5000, Train Loss: 0.2344\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3529/5000, Train Loss: 0.2344\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3530/5000, Train Loss: 0.2344\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3531/5000, Train Loss: 0.2344\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3532/5000, Train Loss: 0.2344\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3533/5000, Train Loss: 0.2344\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3534/5000, Train Loss: 0.2343\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3535/5000, Train Loss: 0.2343\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2497\n",
      "Epoch: 3536/5000, Train Loss: 0.2343\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3537/5000, Train Loss: 0.2343\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3538/5000, Train Loss: 0.2343\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3539/5000, Train Loss: 0.2343\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3540/5000, Train Loss: 0.2343\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3541/5000, Train Loss: 0.2343\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3542/5000, Train Loss: 0.2342\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3543/5000, Train Loss: 0.2342\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3544/5000, Train Loss: 0.2342\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3545/5000, Train Loss: 0.2342\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3546/5000, Train Loss: 0.2342\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3547/5000, Train Loss: 0.2342\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3548/5000, Train Loss: 0.2342\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3549/5000, Train Loss: 0.2342\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3550/5000, Train Loss: 0.2342\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3551/5000, Train Loss: 0.2341\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2496\n",
      "Epoch: 3552/5000, Train Loss: 0.2341\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3553/5000, Train Loss: 0.2341\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3554/5000, Train Loss: 0.2341\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3555/5000, Train Loss: 0.2341\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3556/5000, Train Loss: 0.2341\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3557/5000, Train Loss: 0.2341\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3558/5000, Train Loss: 0.2341\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3559/5000, Train Loss: 0.2341\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3560/5000, Train Loss: 0.2340\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3561/5000, Train Loss: 0.2340\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3562/5000, Train Loss: 0.2340\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3563/5000, Train Loss: 0.2340\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3564/5000, Train Loss: 0.2340\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3565/5000, Train Loss: 0.2340\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3566/5000, Train Loss: 0.2340\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2495\n",
      "Epoch: 3567/5000, Train Loss: 0.2340\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3568/5000, Train Loss: 0.2340\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3569/5000, Train Loss: 0.2339\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3570/5000, Train Loss: 0.2339\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3571/5000, Train Loss: 0.2339\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3572/5000, Train Loss: 0.2339\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3573/5000, Train Loss: 0.2339\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3574/5000, Train Loss: 0.2339\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3575/5000, Train Loss: 0.2339\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3576/5000, Train Loss: 0.2339\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3577/5000, Train Loss: 0.2339\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3578/5000, Train Loss: 0.2338\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3579/5000, Train Loss: 0.2338\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3580/5000, Train Loss: 0.2338\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3581/5000, Train Loss: 0.2338\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3582/5000, Train Loss: 0.2338\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2494\n",
      "Epoch: 3583/5000, Train Loss: 0.2338\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3584/5000, Train Loss: 0.2338\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3585/5000, Train Loss: 0.2338\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3586/5000, Train Loss: 0.2338\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3587/5000, Train Loss: 0.2337\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3588/5000, Train Loss: 0.2337\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3589/5000, Train Loss: 0.2337\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3590/5000, Train Loss: 0.2337\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3591/5000, Train Loss: 0.2337\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3592/5000, Train Loss: 0.2337\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3593/5000, Train Loss: 0.2337\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3594/5000, Train Loss: 0.2337\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3595/5000, Train Loss: 0.2337\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3596/5000, Train Loss: 0.2336\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3597/5000, Train Loss: 0.2336\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3598/5000, Train Loss: 0.2336\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2493\n",
      "Epoch: 3599/5000, Train Loss: 0.2336\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3600/5000, Train Loss: 0.2336\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3601/5000, Train Loss: 0.2336\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3602/5000, Train Loss: 0.2336\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3603/5000, Train Loss: 0.2336\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3604/5000, Train Loss: 0.2336\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3605/5000, Train Loss: 0.2335\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3606/5000, Train Loss: 0.2335\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3607/5000, Train Loss: 0.2335\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3608/5000, Train Loss: 0.2335\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3609/5000, Train Loss: 0.2335\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3610/5000, Train Loss: 0.2335\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3611/5000, Train Loss: 0.2335\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3612/5000, Train Loss: 0.2335\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3613/5000, Train Loss: 0.2335\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3614/5000, Train Loss: 0.2334\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2492\n",
      "Epoch: 3615/5000, Train Loss: 0.2334\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3616/5000, Train Loss: 0.2334\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3617/5000, Train Loss: 0.2334\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3618/5000, Train Loss: 0.2334\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3619/5000, Train Loss: 0.2334\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3620/5000, Train Loss: 0.2334\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3621/5000, Train Loss: 0.2334\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3622/5000, Train Loss: 0.2334\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3623/5000, Train Loss: 0.2333\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3624/5000, Train Loss: 0.2333\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3625/5000, Train Loss: 0.2333\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3626/5000, Train Loss: 0.2333\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3627/5000, Train Loss: 0.2333\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3628/5000, Train Loss: 0.2333\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3629/5000, Train Loss: 0.2333\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3630/5000, Train Loss: 0.2333\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2491\n",
      "Epoch: 3631/5000, Train Loss: 0.2333\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3632/5000, Train Loss: 0.2332\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3633/5000, Train Loss: 0.2332\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3634/5000, Train Loss: 0.2332\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3635/5000, Train Loss: 0.2332\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3636/5000, Train Loss: 0.2332\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3637/5000, Train Loss: 0.2332\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3638/5000, Train Loss: 0.2332\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3639/5000, Train Loss: 0.2332\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3640/5000, Train Loss: 0.2332\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3641/5000, Train Loss: 0.2331\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3642/5000, Train Loss: 0.2331\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3643/5000, Train Loss: 0.2331\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3644/5000, Train Loss: 0.2331\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3645/5000, Train Loss: 0.2331\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3646/5000, Train Loss: 0.2331\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2490\n",
      "Epoch: 3647/5000, Train Loss: 0.2331\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3648/5000, Train Loss: 0.2331\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3649/5000, Train Loss: 0.2331\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3650/5000, Train Loss: 0.2330\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3651/5000, Train Loss: 0.2330\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3652/5000, Train Loss: 0.2330\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3653/5000, Train Loss: 0.2330\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3654/5000, Train Loss: 0.2330\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3655/5000, Train Loss: 0.2330\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3656/5000, Train Loss: 0.2330\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3657/5000, Train Loss: 0.2330\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3658/5000, Train Loss: 0.2330\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3659/5000, Train Loss: 0.2329\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3660/5000, Train Loss: 0.2329\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3661/5000, Train Loss: 0.2329\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3662/5000, Train Loss: 0.2329\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3663/5000, Train Loss: 0.2329\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2489\n",
      "Epoch: 3664/5000, Train Loss: 0.2329\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3665/5000, Train Loss: 0.2329\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3666/5000, Train Loss: 0.2329\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3667/5000, Train Loss: 0.2329\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3668/5000, Train Loss: 0.2329\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3669/5000, Train Loss: 0.2328\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3670/5000, Train Loss: 0.2328\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3671/5000, Train Loss: 0.2328\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3672/5000, Train Loss: 0.2328\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3673/5000, Train Loss: 0.2328\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3674/5000, Train Loss: 0.2328\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3675/5000, Train Loss: 0.2328\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3676/5000, Train Loss: 0.2328\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3677/5000, Train Loss: 0.2328\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3678/5000, Train Loss: 0.2327\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3679/5000, Train Loss: 0.2327\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3680/5000, Train Loss: 0.2327\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2488\n",
      "Epoch: 3681/5000, Train Loss: 0.2327\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3682/5000, Train Loss: 0.2327\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3683/5000, Train Loss: 0.2327\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3684/5000, Train Loss: 0.2327\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3685/5000, Train Loss: 0.2327\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3686/5000, Train Loss: 0.2327\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3687/5000, Train Loss: 0.2326\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3688/5000, Train Loss: 0.2326\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3689/5000, Train Loss: 0.2326\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3690/5000, Train Loss: 0.2326\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3691/5000, Train Loss: 0.2326\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3692/5000, Train Loss: 0.2326\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3693/5000, Train Loss: 0.2326\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3694/5000, Train Loss: 0.2326\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3695/5000, Train Loss: 0.2326\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3696/5000, Train Loss: 0.2326\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3697/5000, Train Loss: 0.2325\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2487\n",
      "Epoch: 3698/5000, Train Loss: 0.2325\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3699/5000, Train Loss: 0.2325\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3700/5000, Train Loss: 0.2325\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3701/5000, Train Loss: 0.2325\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3702/5000, Train Loss: 0.2325\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3703/5000, Train Loss: 0.2325\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3704/5000, Train Loss: 0.2325\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3705/5000, Train Loss: 0.2325\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3706/5000, Train Loss: 0.2324\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3707/5000, Train Loss: 0.2324\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3708/5000, Train Loss: 0.2324\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3709/5000, Train Loss: 0.2324\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3710/5000, Train Loss: 0.2324\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3711/5000, Train Loss: 0.2324\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3712/5000, Train Loss: 0.2324\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3713/5000, Train Loss: 0.2324\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3714/5000, Train Loss: 0.2324\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2486\n",
      "Epoch: 3715/5000, Train Loss: 0.2324\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3716/5000, Train Loss: 0.2323\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3717/5000, Train Loss: 0.2323\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3718/5000, Train Loss: 0.2323\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3719/5000, Train Loss: 0.2323\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3720/5000, Train Loss: 0.2323\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3721/5000, Train Loss: 0.2323\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3722/5000, Train Loss: 0.2323\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3723/5000, Train Loss: 0.2323\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3724/5000, Train Loss: 0.2323\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3725/5000, Train Loss: 0.2322\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3726/5000, Train Loss: 0.2322\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3727/5000, Train Loss: 0.2322\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3728/5000, Train Loss: 0.2322\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3729/5000, Train Loss: 0.2322\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3730/5000, Train Loss: 0.2322\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3731/5000, Train Loss: 0.2322\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2485\n",
      "Epoch: 3732/5000, Train Loss: 0.2322\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3733/5000, Train Loss: 0.2322\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3734/5000, Train Loss: 0.2322\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3735/5000, Train Loss: 0.2321\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3736/5000, Train Loss: 0.2321\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3737/5000, Train Loss: 0.2321\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3738/5000, Train Loss: 0.2321\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3739/5000, Train Loss: 0.2321\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3740/5000, Train Loss: 0.2321\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3741/5000, Train Loss: 0.2321\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3742/5000, Train Loss: 0.2321\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3743/5000, Train Loss: 0.2321\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3744/5000, Train Loss: 0.2320\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3745/5000, Train Loss: 0.2320\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3746/5000, Train Loss: 0.2320\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3747/5000, Train Loss: 0.2320\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3748/5000, Train Loss: 0.2320\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3749/5000, Train Loss: 0.2320\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2484\n",
      "Epoch: 3750/5000, Train Loss: 0.2320\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3751/5000, Train Loss: 0.2320\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3752/5000, Train Loss: 0.2320\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3753/5000, Train Loss: 0.2320\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3754/5000, Train Loss: 0.2319\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3755/5000, Train Loss: 0.2319\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3756/5000, Train Loss: 0.2319\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3757/5000, Train Loss: 0.2319\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3758/5000, Train Loss: 0.2319\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3759/5000, Train Loss: 0.2319\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3760/5000, Train Loss: 0.2319\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3761/5000, Train Loss: 0.2319\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3762/5000, Train Loss: 0.2319\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3763/5000, Train Loss: 0.2319\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3764/5000, Train Loss: 0.2318\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3765/5000, Train Loss: 0.2318\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3766/5000, Train Loss: 0.2318\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2483\n",
      "Epoch: 3767/5000, Train Loss: 0.2318\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3768/5000, Train Loss: 0.2318\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3769/5000, Train Loss: 0.2318\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3770/5000, Train Loss: 0.2318\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3771/5000, Train Loss: 0.2318\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3772/5000, Train Loss: 0.2318\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3773/5000, Train Loss: 0.2318\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3774/5000, Train Loss: 0.2317\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3775/5000, Train Loss: 0.2317\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3776/5000, Train Loss: 0.2317\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3777/5000, Train Loss: 0.2317\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3778/5000, Train Loss: 0.2317\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3779/5000, Train Loss: 0.2317\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3780/5000, Train Loss: 0.2317\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3781/5000, Train Loss: 0.2317\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3782/5000, Train Loss: 0.2317\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3783/5000, Train Loss: 0.2316\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3784/5000, Train Loss: 0.2316\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2482\n",
      "Epoch: 3785/5000, Train Loss: 0.2316\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3786/5000, Train Loss: 0.2316\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3787/5000, Train Loss: 0.2316\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3788/5000, Train Loss: 0.2316\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3789/5000, Train Loss: 0.2316\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3790/5000, Train Loss: 0.2316\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3791/5000, Train Loss: 0.2316\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3792/5000, Train Loss: 0.2316\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3793/5000, Train Loss: 0.2315\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3794/5000, Train Loss: 0.2315\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3795/5000, Train Loss: 0.2315\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3796/5000, Train Loss: 0.2315\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3797/5000, Train Loss: 0.2315\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3798/5000, Train Loss: 0.2315\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3799/5000, Train Loss: 0.2315\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3800/5000, Train Loss: 0.2315\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3801/5000, Train Loss: 0.2315\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3802/5000, Train Loss: 0.2315\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3803/5000, Train Loss: 0.2314\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2481\n",
      "Epoch: 3804/5000, Train Loss: 0.2314\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3805/5000, Train Loss: 0.2314\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3806/5000, Train Loss: 0.2314\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3807/5000, Train Loss: 0.2314\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3808/5000, Train Loss: 0.2314\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3809/5000, Train Loss: 0.2314\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3810/5000, Train Loss: 0.2314\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3811/5000, Train Loss: 0.2314\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3812/5000, Train Loss: 0.2314\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3813/5000, Train Loss: 0.2313\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3814/5000, Train Loss: 0.2313\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3815/5000, Train Loss: 0.2313\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3816/5000, Train Loss: 0.2313\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3817/5000, Train Loss: 0.2313\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3818/5000, Train Loss: 0.2313\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3819/5000, Train Loss: 0.2313\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3820/5000, Train Loss: 0.2313\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3821/5000, Train Loss: 0.2313\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2480\n",
      "Epoch: 3822/5000, Train Loss: 0.2313\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3823/5000, Train Loss: 0.2312\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3824/5000, Train Loss: 0.2312\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3825/5000, Train Loss: 0.2312\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3826/5000, Train Loss: 0.2312\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3827/5000, Train Loss: 0.2312\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3828/5000, Train Loss: 0.2312\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3829/5000, Train Loss: 0.2312\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3830/5000, Train Loss: 0.2312\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3831/5000, Train Loss: 0.2312\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3832/5000, Train Loss: 0.2312\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3833/5000, Train Loss: 0.2311\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3834/5000, Train Loss: 0.2311\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3835/5000, Train Loss: 0.2311\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3836/5000, Train Loss: 0.2311\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3837/5000, Train Loss: 0.2311\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3838/5000, Train Loss: 0.2311\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3839/5000, Train Loss: 0.2311\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2479\n",
      "Epoch: 3840/5000, Train Loss: 0.2311\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3841/5000, Train Loss: 0.2311\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3842/5000, Train Loss: 0.2311\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3843/5000, Train Loss: 0.2310\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3844/5000, Train Loss: 0.2310\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3845/5000, Train Loss: 0.2310\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3846/5000, Train Loss: 0.2310\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3847/5000, Train Loss: 0.2310\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3848/5000, Train Loss: 0.2310\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3849/5000, Train Loss: 0.2310\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3850/5000, Train Loss: 0.2310\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3851/5000, Train Loss: 0.2310\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3852/5000, Train Loss: 0.2310\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3853/5000, Train Loss: 0.2309\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3854/5000, Train Loss: 0.2309\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3855/5000, Train Loss: 0.2309\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3856/5000, Train Loss: 0.2309\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3857/5000, Train Loss: 0.2309\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3858/5000, Train Loss: 0.2309\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2478\n",
      "Epoch: 3859/5000, Train Loss: 0.2309\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3860/5000, Train Loss: 0.2309\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3861/5000, Train Loss: 0.2309\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3862/5000, Train Loss: 0.2309\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3863/5000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3864/5000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3865/5000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3866/5000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3867/5000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3868/5000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3869/5000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3870/5000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3871/5000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3872/5000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3873/5000, Train Loss: 0.2308\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3874/5000, Train Loss: 0.2307\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3875/5000, Train Loss: 0.2307\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3876/5000, Train Loss: 0.2307\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3877/5000, Train Loss: 0.2307\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2477\n",
      "Epoch: 3878/5000, Train Loss: 0.2307\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3879/5000, Train Loss: 0.2307\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3880/5000, Train Loss: 0.2307\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3881/5000, Train Loss: 0.2307\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3882/5000, Train Loss: 0.2307\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3883/5000, Train Loss: 0.2307\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3884/5000, Train Loss: 0.2306\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3885/5000, Train Loss: 0.2306\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3886/5000, Train Loss: 0.2306\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3887/5000, Train Loss: 0.2306\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3888/5000, Train Loss: 0.2306\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3889/5000, Train Loss: 0.2306\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3890/5000, Train Loss: 0.2306\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3891/5000, Train Loss: 0.2306\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3892/5000, Train Loss: 0.2306\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3893/5000, Train Loss: 0.2306\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3894/5000, Train Loss: 0.2305\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3895/5000, Train Loss: 0.2305\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3896/5000, Train Loss: 0.2305\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3897/5000, Train Loss: 0.2305\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2476\n",
      "Epoch: 3898/5000, Train Loss: 0.2305\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3899/5000, Train Loss: 0.2305\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3900/5000, Train Loss: 0.2305\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3901/5000, Train Loss: 0.2305\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3902/5000, Train Loss: 0.2305\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3903/5000, Train Loss: 0.2305\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3904/5000, Train Loss: 0.2305\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3905/5000, Train Loss: 0.2304\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3906/5000, Train Loss: 0.2304\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3907/5000, Train Loss: 0.2304\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3908/5000, Train Loss: 0.2304\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3909/5000, Train Loss: 0.2304\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3910/5000, Train Loss: 0.2304\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3911/5000, Train Loss: 0.2304\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3912/5000, Train Loss: 0.2304\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3913/5000, Train Loss: 0.2304\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3914/5000, Train Loss: 0.2304\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3915/5000, Train Loss: 0.2303\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3916/5000, Train Loss: 0.2303\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2475\n",
      "Epoch: 3917/5000, Train Loss: 0.2303\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3918/5000, Train Loss: 0.2303\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3919/5000, Train Loss: 0.2303\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3920/5000, Train Loss: 0.2303\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3921/5000, Train Loss: 0.2303\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3922/5000, Train Loss: 0.2303\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3923/5000, Train Loss: 0.2303\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3924/5000, Train Loss: 0.2303\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3925/5000, Train Loss: 0.2303\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3926/5000, Train Loss: 0.2302\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3927/5000, Train Loss: 0.2302\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3928/5000, Train Loss: 0.2302\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3929/5000, Train Loss: 0.2302\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3930/5000, Train Loss: 0.2302\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3931/5000, Train Loss: 0.2302\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3932/5000, Train Loss: 0.2302\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3933/5000, Train Loss: 0.2302\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3934/5000, Train Loss: 0.2302\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3935/5000, Train Loss: 0.2302\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3936/5000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2474\n",
      "Epoch: 3937/5000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3938/5000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3939/5000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3940/5000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3941/5000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3942/5000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3943/5000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3944/5000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3945/5000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3946/5000, Train Loss: 0.2301\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3947/5000, Train Loss: 0.2300\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3948/5000, Train Loss: 0.2300\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3949/5000, Train Loss: 0.2300\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3950/5000, Train Loss: 0.2300\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3951/5000, Train Loss: 0.2300\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3952/5000, Train Loss: 0.2300\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3953/5000, Train Loss: 0.2300\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3954/5000, Train Loss: 0.2300\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3955/5000, Train Loss: 0.2300\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3956/5000, Train Loss: 0.2300\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2473\n",
      "Epoch: 3957/5000, Train Loss: 0.2299\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3958/5000, Train Loss: 0.2299\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3959/5000, Train Loss: 0.2299\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3960/5000, Train Loss: 0.2299\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3961/5000, Train Loss: 0.2299\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3962/5000, Train Loss: 0.2299\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3963/5000, Train Loss: 0.2299\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3964/5000, Train Loss: 0.2299\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3965/5000, Train Loss: 0.2299\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3966/5000, Train Loss: 0.2299\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3967/5000, Train Loss: 0.2299\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3968/5000, Train Loss: 0.2298\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3969/5000, Train Loss: 0.2298\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3970/5000, Train Loss: 0.2298\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3971/5000, Train Loss: 0.2298\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3972/5000, Train Loss: 0.2298\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3973/5000, Train Loss: 0.2298\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3974/5000, Train Loss: 0.2298\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3975/5000, Train Loss: 0.2298\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3976/5000, Train Loss: 0.2298\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2472\n",
      "Epoch: 3977/5000, Train Loss: 0.2298\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3978/5000, Train Loss: 0.2298\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3979/5000, Train Loss: 0.2297\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3980/5000, Train Loss: 0.2297\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3981/5000, Train Loss: 0.2297\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3982/5000, Train Loss: 0.2297\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3983/5000, Train Loss: 0.2297\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3984/5000, Train Loss: 0.2297\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3985/5000, Train Loss: 0.2297\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3986/5000, Train Loss: 0.2297\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3987/5000, Train Loss: 0.2297\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3988/5000, Train Loss: 0.2297\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3989/5000, Train Loss: 0.2296\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3990/5000, Train Loss: 0.2296\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3991/5000, Train Loss: 0.2296\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3992/5000, Train Loss: 0.2296\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3993/5000, Train Loss: 0.2296\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3994/5000, Train Loss: 0.2296\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3995/5000, Train Loss: 0.2296\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3996/5000, Train Loss: 0.2296\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3997/5000, Train Loss: 0.2296\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2471\n",
      "Epoch: 3998/5000, Train Loss: 0.2296\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 3999/5000, Train Loss: 0.2296\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4000/5000, Train Loss: 0.2295\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4001/5000, Train Loss: 0.2295\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4002/5000, Train Loss: 0.2295\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4003/5000, Train Loss: 0.2295\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4004/5000, Train Loss: 0.2295\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4005/5000, Train Loss: 0.2295\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4006/5000, Train Loss: 0.2295\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4007/5000, Train Loss: 0.2295\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4008/5000, Train Loss: 0.2295\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4009/5000, Train Loss: 0.2295\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4010/5000, Train Loss: 0.2295\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4011/5000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4012/5000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4013/5000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4014/5000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4015/5000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4016/5000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4017/5000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4018/5000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2470\n",
      "Epoch: 4019/5000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4020/5000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4021/5000, Train Loss: 0.2294\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4022/5000, Train Loss: 0.2293\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4023/5000, Train Loss: 0.2293\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4024/5000, Train Loss: 0.2293\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4025/5000, Train Loss: 0.2293\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4026/5000, Train Loss: 0.2293\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4027/5000, Train Loss: 0.2293\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4028/5000, Train Loss: 0.2293\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4029/5000, Train Loss: 0.2293\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4030/5000, Train Loss: 0.2293\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4031/5000, Train Loss: 0.2293\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4032/5000, Train Loss: 0.2293\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4033/5000, Train Loss: 0.2292\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4034/5000, Train Loss: 0.2292\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4035/5000, Train Loss: 0.2292\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4036/5000, Train Loss: 0.2292\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4037/5000, Train Loss: 0.2292\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4038/5000, Train Loss: 0.2292\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4039/5000, Train Loss: 0.2292\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2469\n",
      "Epoch: 4040/5000, Train Loss: 0.2292\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4041/5000, Train Loss: 0.2292\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4042/5000, Train Loss: 0.2292\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4043/5000, Train Loss: 0.2292\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4044/5000, Train Loss: 0.2291\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4045/5000, Train Loss: 0.2291\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4046/5000, Train Loss: 0.2291\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4047/5000, Train Loss: 0.2291\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4048/5000, Train Loss: 0.2291\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4049/5000, Train Loss: 0.2291\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4050/5000, Train Loss: 0.2291\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4051/5000, Train Loss: 0.2291\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4052/5000, Train Loss: 0.2291\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4053/5000, Train Loss: 0.2291\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4054/5000, Train Loss: 0.2291\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4055/5000, Train Loss: 0.2290\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4056/5000, Train Loss: 0.2290\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4057/5000, Train Loss: 0.2290\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4058/5000, Train Loss: 0.2290\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4059/5000, Train Loss: 0.2290\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4060/5000, Train Loss: 0.2290\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2468\n",
      "Epoch: 4061/5000, Train Loss: 0.2290\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4062/5000, Train Loss: 0.2290\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4063/5000, Train Loss: 0.2290\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4064/5000, Train Loss: 0.2290\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4065/5000, Train Loss: 0.2290\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4066/5000, Train Loss: 0.2289\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4067/5000, Train Loss: 0.2289\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4068/5000, Train Loss: 0.2289\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4069/5000, Train Loss: 0.2289\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4070/5000, Train Loss: 0.2289\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4071/5000, Train Loss: 0.2289\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4072/5000, Train Loss: 0.2289\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4073/5000, Train Loss: 0.2289\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4074/5000, Train Loss: 0.2289\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4075/5000, Train Loss: 0.2289\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4076/5000, Train Loss: 0.2289\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4077/5000, Train Loss: 0.2288\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4078/5000, Train Loss: 0.2288\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4079/5000, Train Loss: 0.2288\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4080/5000, Train Loss: 0.2288\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4081/5000, Train Loss: 0.2288\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4082/5000, Train Loss: 0.2288\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2467\n",
      "Epoch: 4083/5000, Train Loss: 0.2288\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4084/5000, Train Loss: 0.2288\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4085/5000, Train Loss: 0.2288\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4086/5000, Train Loss: 0.2288\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4087/5000, Train Loss: 0.2288\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4088/5000, Train Loss: 0.2288\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4089/5000, Train Loss: 0.2287\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4090/5000, Train Loss: 0.2287\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4091/5000, Train Loss: 0.2287\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4092/5000, Train Loss: 0.2287\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4093/5000, Train Loss: 0.2287\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4094/5000, Train Loss: 0.2287\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4095/5000, Train Loss: 0.2287\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4096/5000, Train Loss: 0.2287\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4097/5000, Train Loss: 0.2287\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4098/5000, Train Loss: 0.2287\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4099/5000, Train Loss: 0.2287\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4100/5000, Train Loss: 0.2286\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4101/5000, Train Loss: 0.2286\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4102/5000, Train Loss: 0.2286\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4103/5000, Train Loss: 0.2286\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4104/5000, Train Loss: 0.2286\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2466\n",
      "Epoch: 4105/5000, Train Loss: 0.2286\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4106/5000, Train Loss: 0.2286\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4107/5000, Train Loss: 0.2286\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4108/5000, Train Loss: 0.2286\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4109/5000, Train Loss: 0.2286\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4110/5000, Train Loss: 0.2286\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4111/5000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4112/5000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4113/5000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4114/5000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4115/5000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4116/5000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4117/5000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4118/5000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4119/5000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4120/5000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4121/5000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4122/5000, Train Loss: 0.2285\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4123/5000, Train Loss: 0.2284\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4124/5000, Train Loss: 0.2284\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4125/5000, Train Loss: 0.2284\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4126/5000, Train Loss: 0.2284\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4127/5000, Train Loss: 0.2284\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2465\n",
      "Epoch: 4128/5000, Train Loss: 0.2284\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4129/5000, Train Loss: 0.2284\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4130/5000, Train Loss: 0.2284\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4131/5000, Train Loss: 0.2284\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4132/5000, Train Loss: 0.2284\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4133/5000, Train Loss: 0.2284\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4134/5000, Train Loss: 0.2283\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4135/5000, Train Loss: 0.2283\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4136/5000, Train Loss: 0.2283\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4137/5000, Train Loss: 0.2283\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4138/5000, Train Loss: 0.2283\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4139/5000, Train Loss: 0.2283\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4140/5000, Train Loss: 0.2283\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4141/5000, Train Loss: 0.2283\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4142/5000, Train Loss: 0.2283\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4143/5000, Train Loss: 0.2283\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4144/5000, Train Loss: 0.2283\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4145/5000, Train Loss: 0.2283\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4146/5000, Train Loss: 0.2282\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4147/5000, Train Loss: 0.2282\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4148/5000, Train Loss: 0.2282\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4149/5000, Train Loss: 0.2282\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2464\n",
      "Epoch: 4150/5000, Train Loss: 0.2282\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4151/5000, Train Loss: 0.2282\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4152/5000, Train Loss: 0.2282\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4153/5000, Train Loss: 0.2282\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4154/5000, Train Loss: 0.2282\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4155/5000, Train Loss: 0.2282\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4156/5000, Train Loss: 0.2282\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4157/5000, Train Loss: 0.2282\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4158/5000, Train Loss: 0.2281\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4159/5000, Train Loss: 0.2281\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4160/5000, Train Loss: 0.2281\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4161/5000, Train Loss: 0.2281\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4162/5000, Train Loss: 0.2281\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4163/5000, Train Loss: 0.2281\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4164/5000, Train Loss: 0.2281\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4165/5000, Train Loss: 0.2281\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4166/5000, Train Loss: 0.2281\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4167/5000, Train Loss: 0.2281\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4168/5000, Train Loss: 0.2281\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4169/5000, Train Loss: 0.2280\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4170/5000, Train Loss: 0.2280\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4171/5000, Train Loss: 0.2280\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4172/5000, Train Loss: 0.2280\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2463\n",
      "Epoch: 4173/5000, Train Loss: 0.2280\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4174/5000, Train Loss: 0.2280\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4175/5000, Train Loss: 0.2280\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4176/5000, Train Loss: 0.2280\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4177/5000, Train Loss: 0.2280\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4178/5000, Train Loss: 0.2280\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4179/5000, Train Loss: 0.2280\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4180/5000, Train Loss: 0.2280\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4181/5000, Train Loss: 0.2279\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4182/5000, Train Loss: 0.2279\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4183/5000, Train Loss: 0.2279\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4184/5000, Train Loss: 0.2279\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4185/5000, Train Loss: 0.2279\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4186/5000, Train Loss: 0.2279\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4187/5000, Train Loss: 0.2279\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4188/5000, Train Loss: 0.2279\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4189/5000, Train Loss: 0.2279\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4190/5000, Train Loss: 0.2279\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4191/5000, Train Loss: 0.2279\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4192/5000, Train Loss: 0.2279\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4193/5000, Train Loss: 0.2278\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4194/5000, Train Loss: 0.2278\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4195/5000, Train Loss: 0.2278\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4196/5000, Train Loss: 0.2278\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2462\n",
      "Epoch: 4197/5000, Train Loss: 0.2278\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4198/5000, Train Loss: 0.2278\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4199/5000, Train Loss: 0.2278\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4200/5000, Train Loss: 0.2278\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4201/5000, Train Loss: 0.2278\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4202/5000, Train Loss: 0.2278\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4203/5000, Train Loss: 0.2278\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4204/5000, Train Loss: 0.2278\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4205/5000, Train Loss: 0.2277\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4206/5000, Train Loss: 0.2277\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4207/5000, Train Loss: 0.2277\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4208/5000, Train Loss: 0.2277\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4209/5000, Train Loss: 0.2277\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4210/5000, Train Loss: 0.2277\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4211/5000, Train Loss: 0.2277\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4212/5000, Train Loss: 0.2277\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4213/5000, Train Loss: 0.2277\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4214/5000, Train Loss: 0.2277\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4215/5000, Train Loss: 0.2277\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4216/5000, Train Loss: 0.2276\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4217/5000, Train Loss: 0.2276\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4218/5000, Train Loss: 0.2276\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4219/5000, Train Loss: 0.2276\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2461\n",
      "Epoch: 4220/5000, Train Loss: 0.2276\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4221/5000, Train Loss: 0.2276\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4222/5000, Train Loss: 0.2276\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4223/5000, Train Loss: 0.2276\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4224/5000, Train Loss: 0.2276\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4225/5000, Train Loss: 0.2276\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4226/5000, Train Loss: 0.2276\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4227/5000, Train Loss: 0.2276\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4228/5000, Train Loss: 0.2275\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4229/5000, Train Loss: 0.2275\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4230/5000, Train Loss: 0.2275\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4231/5000, Train Loss: 0.2275\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4232/5000, Train Loss: 0.2275\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4233/5000, Train Loss: 0.2275\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4234/5000, Train Loss: 0.2275\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4235/5000, Train Loss: 0.2275\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4236/5000, Train Loss: 0.2275\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4237/5000, Train Loss: 0.2275\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4238/5000, Train Loss: 0.2275\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4239/5000, Train Loss: 0.2275\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4240/5000, Train Loss: 0.2274\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4241/5000, Train Loss: 0.2274\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4242/5000, Train Loss: 0.2274\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4243/5000, Train Loss: 0.2274\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2460\n",
      "Epoch: 4244/5000, Train Loss: 0.2274\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4245/5000, Train Loss: 0.2274\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4246/5000, Train Loss: 0.2274\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4247/5000, Train Loss: 0.2274\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4248/5000, Train Loss: 0.2274\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4249/5000, Train Loss: 0.2274\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4250/5000, Train Loss: 0.2274\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4251/5000, Train Loss: 0.2274\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4252/5000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4253/5000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4254/5000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4255/5000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4256/5000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4257/5000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4258/5000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4259/5000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4260/5000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4261/5000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4262/5000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4263/5000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4264/5000, Train Loss: 0.2273\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4265/5000, Train Loss: 0.2272\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4266/5000, Train Loss: 0.2272\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4267/5000, Train Loss: 0.2272\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4268/5000, Train Loss: 0.2272\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2459\n",
      "Epoch: 4269/5000, Train Loss: 0.2272\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4270/5000, Train Loss: 0.2272\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4271/5000, Train Loss: 0.2272\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4272/5000, Train Loss: 0.2272\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4273/5000, Train Loss: 0.2272\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4274/5000, Train Loss: 0.2272\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4275/5000, Train Loss: 0.2272\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4276/5000, Train Loss: 0.2272\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4277/5000, Train Loss: 0.2271\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4278/5000, Train Loss: 0.2271\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4279/5000, Train Loss: 0.2271\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4280/5000, Train Loss: 0.2271\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4281/5000, Train Loss: 0.2271\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4282/5000, Train Loss: 0.2271\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4283/5000, Train Loss: 0.2271\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4284/5000, Train Loss: 0.2271\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4285/5000, Train Loss: 0.2271\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4286/5000, Train Loss: 0.2271\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4287/5000, Train Loss: 0.2271\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4288/5000, Train Loss: 0.2271\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4289/5000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4290/5000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4291/5000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4292/5000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4293/5000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2458\n",
      "Epoch: 4294/5000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4295/5000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4296/5000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4297/5000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4298/5000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4299/5000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4300/5000, Train Loss: 0.2270\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4301/5000, Train Loss: 0.2269\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4302/5000, Train Loss: 0.2269\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4303/5000, Train Loss: 0.2269\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4304/5000, Train Loss: 0.2269\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4305/5000, Train Loss: 0.2269\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4306/5000, Train Loss: 0.2269\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4307/5000, Train Loss: 0.2269\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4308/5000, Train Loss: 0.2269\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4309/5000, Train Loss: 0.2269\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4310/5000, Train Loss: 0.2269\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4311/5000, Train Loss: 0.2269\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4312/5000, Train Loss: 0.2269\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4313/5000, Train Loss: 0.2269\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4314/5000, Train Loss: 0.2268\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4315/5000, Train Loss: 0.2268\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4316/5000, Train Loss: 0.2268\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4317/5000, Train Loss: 0.2268\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4318/5000, Train Loss: 0.2268\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2457\n",
      "Epoch: 4319/5000, Train Loss: 0.2268\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4320/5000, Train Loss: 0.2268\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4321/5000, Train Loss: 0.2268\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4322/5000, Train Loss: 0.2268\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4323/5000, Train Loss: 0.2268\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4324/5000, Train Loss: 0.2268\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4325/5000, Train Loss: 0.2268\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4326/5000, Train Loss: 0.2267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4327/5000, Train Loss: 0.2267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4328/5000, Train Loss: 0.2267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4329/5000, Train Loss: 0.2267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4330/5000, Train Loss: 0.2267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4331/5000, Train Loss: 0.2267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4332/5000, Train Loss: 0.2267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4333/5000, Train Loss: 0.2267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4334/5000, Train Loss: 0.2267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4335/5000, Train Loss: 0.2267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4336/5000, Train Loss: 0.2267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4337/5000, Train Loss: 0.2267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4338/5000, Train Loss: 0.2267\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4339/5000, Train Loss: 0.2266\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4340/5000, Train Loss: 0.2266\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4341/5000, Train Loss: 0.2266\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4342/5000, Train Loss: 0.2266\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4343/5000, Train Loss: 0.2266\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2456\n",
      "Epoch: 4344/5000, Train Loss: 0.2266\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4345/5000, Train Loss: 0.2266\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4346/5000, Train Loss: 0.2266\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4347/5000, Train Loss: 0.2266\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4348/5000, Train Loss: 0.2266\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4349/5000, Train Loss: 0.2266\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4350/5000, Train Loss: 0.2266\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4351/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4352/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4353/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4354/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4355/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4356/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4357/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4358/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4359/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4360/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4361/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4362/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4363/5000, Train Loss: 0.2265\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4364/5000, Train Loss: 0.2264\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4365/5000, Train Loss: 0.2264\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4366/5000, Train Loss: 0.2264\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4367/5000, Train Loss: 0.2264\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4368/5000, Train Loss: 0.2264\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4369/5000, Train Loss: 0.2264\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2455\n",
      "Epoch: 4370/5000, Train Loss: 0.2264\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4371/5000, Train Loss: 0.2264\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4372/5000, Train Loss: 0.2264\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4373/5000, Train Loss: 0.2264\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4374/5000, Train Loss: 0.2264\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4375/5000, Train Loss: 0.2264\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4376/5000, Train Loss: 0.2264\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4377/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4378/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4379/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4380/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4381/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4382/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4383/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4384/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4385/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4386/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4387/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4388/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4389/5000, Train Loss: 0.2263\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4390/5000, Train Loss: 0.2262\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4391/5000, Train Loss: 0.2262\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4392/5000, Train Loss: 0.2262\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4393/5000, Train Loss: 0.2262\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4394/5000, Train Loss: 0.2262\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4395/5000, Train Loss: 0.2262\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4396/5000, Train Loss: 0.2262\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2454\n",
      "Epoch: 4397/5000, Train Loss: 0.2262\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4398/5000, Train Loss: 0.2262\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4399/5000, Train Loss: 0.2262\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4400/5000, Train Loss: 0.2262\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4401/5000, Train Loss: 0.2262\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4402/5000, Train Loss: 0.2262\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4403/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4404/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4405/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4406/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4407/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4408/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4409/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4410/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4411/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4412/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4413/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4414/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4415/5000, Train Loss: 0.2261\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4416/5000, Train Loss: 0.2260\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4417/5000, Train Loss: 0.2260\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4418/5000, Train Loss: 0.2260\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4419/5000, Train Loss: 0.2260\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4420/5000, Train Loss: 0.2260\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4421/5000, Train Loss: 0.2260\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4422/5000, Train Loss: 0.2260\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4423/5000, Train Loss: 0.2260\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2453\n",
      "Epoch: 4424/5000, Train Loss: 0.2260\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4425/5000, Train Loss: 0.2260\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4426/5000, Train Loss: 0.2260\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4427/5000, Train Loss: 0.2260\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4428/5000, Train Loss: 0.2260\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4429/5000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4430/5000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4431/5000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4432/5000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4433/5000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4434/5000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4435/5000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4436/5000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4437/5000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4438/5000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4439/5000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4440/5000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4441/5000, Train Loss: 0.2259\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4442/5000, Train Loss: 0.2258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4443/5000, Train Loss: 0.2258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4444/5000, Train Loss: 0.2258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4445/5000, Train Loss: 0.2258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4446/5000, Train Loss: 0.2258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4447/5000, Train Loss: 0.2258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4448/5000, Train Loss: 0.2258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4449/5000, Train Loss: 0.2258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4450/5000, Train Loss: 0.2258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2452\n",
      "Epoch: 4451/5000, Train Loss: 0.2258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4452/5000, Train Loss: 0.2258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4453/5000, Train Loss: 0.2258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4454/5000, Train Loss: 0.2258\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4455/5000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4456/5000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4457/5000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4458/5000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4459/5000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4460/5000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4461/5000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4462/5000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4463/5000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4464/5000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4465/5000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4466/5000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4467/5000, Train Loss: 0.2257\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4468/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4469/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4470/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4471/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4472/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4473/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4474/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4475/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4476/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4477/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4478/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2451\n",
      "Epoch: 4479/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4480/5000, Train Loss: 0.2256\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4481/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4482/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4483/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4484/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4485/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4486/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4487/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4488/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4489/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4490/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4491/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4492/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4493/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4494/5000, Train Loss: 0.2255\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4495/5000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4496/5000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4497/5000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4498/5000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4499/5000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4500/5000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4501/5000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4502/5000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4503/5000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4504/5000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4505/5000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4506/5000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2450\n",
      "Epoch: 4507/5000, Train Loss: 0.2254\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4508/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4509/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4510/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4511/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4512/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4513/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4514/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4515/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4516/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4517/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4518/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4519/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4520/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4521/5000, Train Loss: 0.2253\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4522/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4523/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4524/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4525/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4526/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4527/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4528/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4529/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4530/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4531/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4532/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4533/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4534/5000, Train Loss: 0.2252\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4535/5000, Train Loss: 0.2251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2449\n",
      "Epoch: 4536/5000, Train Loss: 0.2251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4537/5000, Train Loss: 0.2251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4538/5000, Train Loss: 0.2251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4539/5000, Train Loss: 0.2251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4540/5000, Train Loss: 0.2251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4541/5000, Train Loss: 0.2251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4542/5000, Train Loss: 0.2251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4543/5000, Train Loss: 0.2251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4544/5000, Train Loss: 0.2251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4545/5000, Train Loss: 0.2251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4546/5000, Train Loss: 0.2251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4547/5000, Train Loss: 0.2251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4548/5000, Train Loss: 0.2251\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4549/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4550/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4551/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4552/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4553/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4554/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4555/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4556/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4557/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4558/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4559/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4560/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4561/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4562/5000, Train Loss: 0.2250\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4563/5000, Train Loss: 0.2249\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4564/5000, Train Loss: 0.2249\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2448\n",
      "Epoch: 4565/5000, Train Loss: 0.2249\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4566/5000, Train Loss: 0.2249\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4567/5000, Train Loss: 0.2249\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4568/5000, Train Loss: 0.2249\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4569/5000, Train Loss: 0.2249\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4570/5000, Train Loss: 0.2249\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4571/5000, Train Loss: 0.2249\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4572/5000, Train Loss: 0.2249\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4573/5000, Train Loss: 0.2249\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4574/5000, Train Loss: 0.2249\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4575/5000, Train Loss: 0.2249\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4576/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4577/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4578/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4579/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4580/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4581/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4582/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4583/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4584/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4585/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4586/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4587/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4588/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4589/5000, Train Loss: 0.2248\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4590/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4591/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4592/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4593/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4594/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2447\n",
      "Epoch: 4595/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4596/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4597/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4598/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4599/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4600/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4601/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4602/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4603/5000, Train Loss: 0.2247\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4604/5000, Train Loss: 0.2246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4605/5000, Train Loss: 0.2246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4606/5000, Train Loss: 0.2246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4607/5000, Train Loss: 0.2246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4608/5000, Train Loss: 0.2246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4609/5000, Train Loss: 0.2246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4610/5000, Train Loss: 0.2246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4611/5000, Train Loss: 0.2246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4612/5000, Train Loss: 0.2246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4613/5000, Train Loss: 0.2246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4614/5000, Train Loss: 0.2246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4615/5000, Train Loss: 0.2246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4616/5000, Train Loss: 0.2246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4617/5000, Train Loss: 0.2246\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4618/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4619/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4620/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4621/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4622/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4623/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4624/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4625/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2446\n",
      "Epoch: 4626/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4627/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4628/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4629/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4630/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4631/5000, Train Loss: 0.2245\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4632/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4633/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4634/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4635/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4636/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4637/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4638/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4639/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4640/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4641/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4642/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4643/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4644/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4645/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4646/5000, Train Loss: 0.2244\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4647/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4648/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4649/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4650/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4651/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4652/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4653/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4654/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4655/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4656/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2445\n",
      "Epoch: 4657/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4658/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4659/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4660/5000, Train Loss: 0.2243\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4661/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4662/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4663/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4664/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4665/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4666/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4667/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4668/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4669/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4670/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4671/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4672/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4673/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4674/5000, Train Loss: 0.2242\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4675/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4676/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4677/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4678/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4679/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4680/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4681/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4682/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4683/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4684/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4685/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4686/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4687/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2444\n",
      "Epoch: 4688/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4689/5000, Train Loss: 0.2241\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4690/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4691/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4692/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4693/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4694/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4695/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4696/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4697/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4698/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4699/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4700/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4701/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4702/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4703/5000, Train Loss: 0.2240\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4704/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4705/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4706/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4707/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4708/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4709/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4710/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4711/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4712/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4713/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4714/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4715/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4716/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4717/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4718/5000, Train Loss: 0.2239\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4719/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4720/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2443\n",
      "Epoch: 4721/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4722/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4723/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4724/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4725/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4726/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4727/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4728/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4729/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4730/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4731/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4732/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4733/5000, Train Loss: 0.2238\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4734/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4735/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4736/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4737/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4738/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4739/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4740/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4741/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4742/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4743/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4744/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4745/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4746/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4747/5000, Train Loss: 0.2237\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4748/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4749/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4750/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4751/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4752/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4753/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2442\n",
      "Epoch: 4754/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4755/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4756/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4757/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4758/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4759/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4760/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4761/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4762/5000, Train Loss: 0.2236\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4763/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4764/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4765/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4766/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4767/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4768/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4769/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4770/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4771/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4772/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4773/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4774/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4775/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4776/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4777/5000, Train Loss: 0.2235\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4778/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4779/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4780/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4781/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4782/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4783/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4784/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4785/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4786/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2441\n",
      "Epoch: 4787/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4788/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4789/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4790/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4791/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4792/5000, Train Loss: 0.2234\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4793/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4794/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4795/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4796/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4797/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4798/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4799/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4800/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4801/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4802/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4803/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4804/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4805/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4806/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4807/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4808/5000, Train Loss: 0.2233\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4809/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4810/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4811/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4812/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4813/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4814/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4815/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4816/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4817/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4818/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4819/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4820/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4821/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2440\n",
      "Epoch: 4822/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4823/5000, Train Loss: 0.2232\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4824/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4825/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4826/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4827/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4828/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4829/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4830/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4831/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4832/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4833/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4834/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4835/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4836/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4837/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4838/5000, Train Loss: 0.2231\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4839/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4840/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4841/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4842/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4843/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4844/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4845/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4846/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4847/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4848/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4849/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4850/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4851/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4852/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4853/5000, Train Loss: 0.2230\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4854/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4855/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4856/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2439\n",
      "Epoch: 4857/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4858/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4859/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4860/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4861/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4862/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4863/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4864/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4865/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4866/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4867/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4868/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4869/5000, Train Loss: 0.2229\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4870/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4871/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4872/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4873/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4874/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4875/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4876/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4877/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4878/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4879/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4880/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4881/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4882/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4883/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4884/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4885/5000, Train Loss: 0.2228\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4886/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4887/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4888/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4889/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4890/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4891/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2438\n",
      "Epoch: 4892/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4893/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4894/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4895/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4896/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4897/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4898/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4899/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4900/5000, Train Loss: 0.2227\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4901/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4902/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4903/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4904/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4905/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4906/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4907/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4908/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4909/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4910/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4911/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4912/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4913/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4914/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4915/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4916/5000, Train Loss: 0.2226\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4917/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4918/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4919/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4920/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4921/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4922/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4923/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4924/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4925/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4926/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4927/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4928/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2437\n",
      "Epoch: 4929/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4930/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4931/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4932/5000, Train Loss: 0.2225\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4933/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4934/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4935/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4936/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4937/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4938/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4939/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4940/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4941/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4942/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4943/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4944/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4945/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4946/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4947/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4948/5000, Train Loss: 0.2224\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4949/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4950/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4951/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4952/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4953/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4954/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4955/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4956/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4957/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4958/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4959/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4960/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4961/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4962/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4963/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4964/5000, Train Loss: 0.2223\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4965/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4966/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2436\n",
      "Epoch: 4967/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4968/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4969/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4970/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4971/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4972/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4973/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4974/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4975/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4976/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4977/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4978/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4979/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4980/5000, Train Loss: 0.2222\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4981/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4982/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4983/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4984/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4985/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4986/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4987/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4988/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4989/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4990/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4991/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4992/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4993/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4994/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4995/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4996/5000, Train Loss: 0.2221\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4997/5000, Train Loss: 0.2220\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4998/5000, Train Loss: 0.2220\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 4999/5000, Train Loss: 0.2220\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n",
      "Epoch: 5000/5000, Train Loss: 0.2220\n",
      "Accuracy on Val set: 90.00%\tLoss on Val set: 0.2435\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([[-15.66858226,   0.13398352,   0.11939763]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from LogisticRegression import LogisticRegression\n",
    "\n",
    "epochs = 5000\n",
    "alpha = 0.01\n",
    "logistic_reg = LogisticRegression(x=train_x,y=train_y_ex,val_x=val_x,val_y=val_y_ex,epoch=epochs,lr=alpha)\n",
    "theta,train_loss,val_loss = logistic_reg.train()\n",
    "theta"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看准确率、损失和F1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 95.00%\n",
      "My F1 Score: 0.9600\n"
     ]
    }
   ],
   "source": [
    "acc = logistic_reg.test(val_x,val_y_ex)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(acc * 100))\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_true=val_y_ex,y_pred=logistic_reg.predict(val_x))\n",
    "print(\"My F1 Score: {:.4f}\".format(f1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "调用库函数验证"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Accuracy: 95.00%\n",
      "Sklearn Val Loss: 2.4798\n",
      "SKlearn Parameters:  [[-26.03020301   0.22033166   0.20158534]]\n",
      "Sklearn F1 Score: 0.9600\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sk_lr = LogisticRegression(max_iter=50000)\n",
    "sk_lr.fit(train_x,train_y)\n",
    "sk_pred = sk_lr.predict(val_x)\n",
    "count = np.sum(np.equal(sk_pred,val_y))\n",
    "sk_acc = count/val_y.shape[0]\n",
    "sk_prob = sk_lr.predict_proba(val_x)\n",
    "\n",
    "from LogisticRegression import bce_loss\n",
    "sk_loss = bce_loss(sk_prob[:,1], val_y_ex)\n",
    "sk_theta = np.array([[sk_lr.intercept_[0],sk_lr.coef_[0,0],sk_lr.coef_[0,1]]])\n",
    "sk_f1 = f1_score(y_true=val_y_ex,y_pred=sk_pred)\n",
    "print(\"Sklearn Accuracy: {:.2f}%\".format(sk_acc * 100))\n",
    "print(\"Sklearn Val Loss: {:.4f}\".format(sk_loss))\n",
    "print(\"SKlearn Parameters: \",sk_theta)\n",
    "print(\"Sklearn F1 Score: {:.4f}\".format(sk_f1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "决策边界可视化"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[131.23026024  -1.12216233  -1.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "coef = -(theta / theta[0,2])  # find the\n",
    "coef1 = -(sk_theta / sk_theta[0,2])\n",
    "print(coef)\n",
    "\n",
    "x = np.arange(data[:,0].min(), data[:,0].max(), step=1)\n",
    "y = coef[0,0] + coef[0,1]*x\n",
    "y1 = coef1[0,0] + coef[0,1]*x\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(x,y,label=\"My Prediction\")\n",
    "ax.plot(x,y1,label=\"Sklearn\")\n",
    "ax.scatter(x=positive_data[:, 0], y=positive_data[:, 1], s=10, color=\"red\",label=\"positive\")\n",
    "ax.scatter(x=negative_data[:, 0], y=negative_data[:, 1], s=10, color=\"blue\",label=\"negative\")\n",
    "ax.set_title(\"Decision Boundary\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "画出训练过程"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(np.arange(1,epochs+1), train_loss, 'r', label=\"Train Loss\")\n",
    "ax.plot(np.arange(1,epochs+1), val_loss, 'b', label=\"Val Loss\")\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.set_title('Train Curve')\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 正则化\n",
    "### regularized cost（正则化代价函数）\n",
    "$$J\\left( \\theta  \\right)=\\frac{1}{m}\\sum\\limits_{i=1}^{m}{[-{{y}^{(i)}}\\log \\left( {{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)-\\left( 1-{{y}^{(i)}} \\right)\\log \\left( 1-{{h}_{\\theta }}\\left( {{x}^{(i)}} \\right) \\right)]}+\\frac{\\lambda }{2m}\\sum\\limits_{j=1}^{n}{\\theta _{j}^{2}}$$\n",
    "正则化项实现了对参数的缩小，使得某些导致过拟合的特征的参数变小。\n",
    "从另一个角度来说，使得对损失不敏感的参数缩小较大，对损失敏感的参数缩小较小。详见Deep Learning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.051267 ,  0.69956  ,  1.       ],\n       [-0.092742 ,  0.68494  ,  1.       ],\n       [-0.21371  ,  0.69225  ,  1.       ],\n       [-0.375    ,  0.50219  ,  1.       ],\n       [-0.51325  ,  0.46564  ,  1.       ],\n       [-0.52477  ,  0.2098   ,  1.       ],\n       [-0.39804  ,  0.034357 ,  1.       ],\n       [-0.30588  , -0.19225  ,  1.       ],\n       [ 0.016705 , -0.40424  ,  1.       ],\n       [ 0.13191  , -0.51389  ,  1.       ],\n       [ 0.38537  , -0.56506  ,  1.       ],\n       [ 0.52938  , -0.5212   ,  1.       ],\n       [ 0.63882  , -0.24342  ,  1.       ],\n       [ 0.73675  , -0.18494  ,  1.       ],\n       [ 0.54666  ,  0.48757  ,  1.       ],\n       [ 0.322    ,  0.5826   ,  1.       ],\n       [ 0.16647  ,  0.53874  ,  1.       ],\n       [-0.046659 ,  0.81652  ,  1.       ],\n       [-0.17339  ,  0.69956  ,  1.       ],\n       [-0.47869  ,  0.63377  ,  1.       ],\n       [-0.60541  ,  0.59722  ,  1.       ],\n       [-0.62846  ,  0.33406  ,  1.       ],\n       [-0.59389  ,  0.005117 ,  1.       ],\n       [-0.42108  , -0.27266  ,  1.       ],\n       [-0.11578  , -0.39693  ,  1.       ],\n       [ 0.20104  , -0.60161  ,  1.       ],\n       [ 0.46601  , -0.53582  ,  1.       ],\n       [ 0.67339  , -0.53582  ,  1.       ],\n       [-0.13882  ,  0.54605  ,  1.       ],\n       [-0.29435  ,  0.77997  ,  1.       ],\n       [-0.26555  ,  0.96272  ,  1.       ],\n       [-0.16187  ,  0.8019   ,  1.       ],\n       [-0.17339  ,  0.64839  ,  1.       ],\n       [-0.28283  ,  0.47295  ,  1.       ],\n       [-0.36348  ,  0.31213  ,  1.       ],\n       [-0.30012  ,  0.027047 ,  1.       ],\n       [-0.23675  , -0.21418  ,  1.       ],\n       [-0.06394  , -0.18494  ,  1.       ],\n       [ 0.062788 , -0.16301  ,  1.       ],\n       [ 0.22984  , -0.41155  ,  1.       ],\n       [ 0.2932   , -0.2288   ,  1.       ],\n       [ 0.48329  , -0.18494  ,  1.       ],\n       [ 0.64459  , -0.14108  ,  1.       ],\n       [ 0.46025  ,  0.012427 ,  1.       ],\n       [ 0.6273   ,  0.15863  ,  1.       ],\n       [ 0.57546  ,  0.26827  ,  1.       ],\n       [ 0.72523  ,  0.44371  ,  1.       ],\n       [ 0.22408  ,  0.52412  ,  1.       ],\n       [ 0.44297  ,  0.67032  ,  1.       ],\n       [ 0.322    ,  0.69225  ,  1.       ],\n       [ 0.13767  ,  0.57529  ,  1.       ],\n       [-0.0063364,  0.39985  ,  1.       ],\n       [-0.092742 ,  0.55336  ,  1.       ],\n       [-0.20795  ,  0.35599  ,  1.       ],\n       [-0.20795  ,  0.17325  ,  1.       ],\n       [-0.43836  ,  0.21711  ,  1.       ],\n       [-0.21947  , -0.016813 ,  1.       ],\n       [-0.13882  , -0.27266  ,  1.       ],\n       [ 0.18376  ,  0.93348  ,  0.       ],\n       [ 0.22408  ,  0.77997  ,  0.       ],\n       [ 0.29896  ,  0.61915  ,  0.       ],\n       [ 0.50634  ,  0.75804  ,  0.       ],\n       [ 0.61578  ,  0.7288   ,  0.       ],\n       [ 0.60426  ,  0.59722  ,  0.       ],\n       [ 0.76555  ,  0.50219  ,  0.       ],\n       [ 0.92684  ,  0.3633   ,  0.       ],\n       [ 0.82316  ,  0.27558  ,  0.       ],\n       [ 0.96141  ,  0.085526 ,  0.       ],\n       [ 0.93836  ,  0.012427 ,  0.       ],\n       [ 0.86348  , -0.082602 ,  0.       ],\n       [ 0.89804  , -0.20687  ,  0.       ],\n       [ 0.85196  , -0.36769  ,  0.       ],\n       [ 0.82892  , -0.5212   ,  0.       ],\n       [ 0.79435  , -0.55775  ,  0.       ],\n       [ 0.59274  , -0.7405   ,  0.       ],\n       [ 0.51786  , -0.5943   ,  0.       ],\n       [ 0.46601  , -0.41886  ,  0.       ],\n       [ 0.35081  , -0.57968  ,  0.       ],\n       [ 0.28744  , -0.76974  ,  0.       ],\n       [ 0.085829 , -0.75512  ,  0.       ],\n       [ 0.14919  , -0.57968  ,  0.       ],\n       [-0.13306  , -0.4481   ,  0.       ],\n       [-0.40956  , -0.41155  ,  0.       ],\n       [-0.39228  , -0.25804  ,  0.       ],\n       [-0.74366  , -0.25804  ,  0.       ],\n       [-0.69758  ,  0.041667 ,  0.       ],\n       [-0.75518  ,  0.2902   ,  0.       ],\n       [-0.69758  ,  0.68494  ,  0.       ],\n       [-0.4038   ,  0.70687  ,  0.       ],\n       [-0.38076  ,  0.91886  ,  0.       ],\n       [-0.50749  ,  0.90424  ,  0.       ],\n       [-0.54781  ,  0.70687  ,  0.       ],\n       [ 0.10311  ,  0.77997  ,  0.       ],\n       [ 0.057028 ,  0.91886  ,  0.       ],\n       [-0.10426  ,  0.99196  ,  0.       ],\n       [-0.081221 ,  1.1089   ,  0.       ],\n       [ 0.28744  ,  1.087    ,  0.       ],\n       [ 0.39689  ,  0.82383  ,  0.       ],\n       [ 0.63882  ,  0.88962  ,  0.       ],\n       [ 0.82316  ,  0.66301  ,  0.       ],\n       [ 0.67339  ,  0.64108  ,  0.       ],\n       [ 1.0709   ,  0.10015  ,  0.       ],\n       [-0.046659 , -0.57968  ,  0.       ],\n       [-0.23675  , -0.63816  ,  0.       ],\n       [-0.15035  , -0.36769  ,  0.       ],\n       [-0.49021  , -0.3019   ,  0.       ],\n       [-0.46717  , -0.13377  ,  0.       ],\n       [-0.28859  , -0.060673 ,  0.       ],\n       [-0.61118  , -0.067982 ,  0.       ],\n       [-0.66302  , -0.21418  ,  0.       ],\n       [-0.59965  , -0.41886  ,  0.       ],\n       [-0.72638  , -0.082602 ,  0.       ],\n       [-0.83007  ,  0.31213  ,  0.       ],\n       [-0.72062  ,  0.53874  ,  0.       ],\n       [-0.59389  ,  0.49488  ,  0.       ],\n       [-0.48445  ,  0.99927  ,  0.       ],\n       [-0.0063364,  0.99927  ,  0.       ],\n       [ 0.63265  , -0.030612 ,  0.       ]])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.loadtxt('ex2data2.txt', delimiter=',')\n",
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看数据集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "positive_data_idx= np.where(data[:,2]==1)\n",
    "positive_data = data[positive_data_idx]\n",
    "negative_data_idx= np.where(data[:, 2] == 0)\n",
    "negative_data = data[negative_data_idx]\n",
    "ax.scatter(x=positive_data[:, 0], y=positive_data[:, 1], s=10, color=\"red\",label=\"positive\")\n",
    "ax.scatter(x=negative_data[:, 0], y=negative_data[:, 1], s=10, label=\"negative\")\n",
    "ax.set_title(\"Dataset\")\n",
    "plt.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "划分训练集和验证集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y = train_test_split(data[:, :-1], data[:, -1], test_size=0.2)\n",
    "# train_x, val_x, train_y, val_y = data[:, :-1], data[:, :-1], data[:, -1], data[:, -1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=train_x[:,0], y=train_x[:,1], s=10, label=\"Train\")\n",
    "ax.scatter(x=val_x[:,0], y=val_x[:,1], s=10, color=\"red\", label=\"Validation\")\n",
    "ax.set_title('Dataset for Train and Validation')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看训练集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "positive_train_data = train_x[np.where(train_y[:]==1)]\n",
    "negative_train_data = train_x[np.where(train_y[:]==0)]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=positive_train_data[:,0], y=positive_train_data[:,1], s=10, label=\"Positive\")\n",
    "ax.scatter(x=negative_train_data[:,0], y=negative_train_data[:,1], s=10, label=\"Negative\")\n",
    "ax.set_title('Train Set')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看测试集"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()\n",
    "positive_val_data = val_x[np.where(val_y[:] == 1)]\n",
    "negative_val_data = val_x[np.where(val_y[:] == 0)]\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.scatter(x=positive_val_data[:, 0], y=positive_val_data[:, 1], s=10, label=\"Positive\")\n",
    "ax.scatter(x=negative_val_data[:, 0], y=negative_val_data[:, 1], s=10, label=\"Negative\")\n",
    "ax.legend(loc=2)\n",
    "ax.set_title('Validation Set')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "整理维度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(24, 1)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_ex = np.expand_dims(train_y,axis=1)\n",
    "val_y_ex = np.expand_dims(val_y,axis=1)\n",
    "val_y_ex.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "特征映射\n",
    "$$\\mathbf{X}=[x_{1}, x_{2}, x_{1}^{2}, x_{1}x_{2}, x_{2}^{2}, x_{1}^{3}, x_{1}^{2}x_{2},\\cdots]$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-3.96930000e-01,  1.57553425e-01, -6.25376809e-02, ...,\n        -2.08050003e-05,  8.25812876e-06,  2.40880293e-06],\n       [-1.84940000e-01,  3.42028036e-02, -6.32546650e-03, ...,\n         2.17070458e-01, -4.01450105e-02,  1.59926660e-01],\n       [ 9.18860000e-01,  8.44303700e-01,  7.75796897e-01, ...,\n        -8.00306954e-03, -7.35370048e-03,  3.04724876e-03],\n       ...,\n       [ 5.38740000e-01,  2.90240788e-01,  1.56364322e-01, ...,\n         1.27843867e-04,  6.88746048e-05,  2.12821685e-05],\n       [-3.01900000e-01,  9.11436100e-02, -2.75162559e-02, ...,\n        -2.83081072e-02,  8.54621757e-03,  1.38769172e-02],\n       [ 5.02190000e-01,  2.52194796e-01,  1.26649705e-01, ...,\n         2.62946748e-01,  1.32049227e-01,  2.01298883e-01]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def feature_mapping(x, degree):\n",
    "    feature = np.zeros([x.shape[0],1])\n",
    "    for i in range(0, 1 + degree):\n",
    "        for j in range(0, 1 + degree - i):\n",
    "            if i==0 and j==0: continue\n",
    "            feature=np.concatenate((feature, np.expand_dims(np.multiply(np.power(x[:, 0], i) , np.power(x[:, 1], j)), axis=1)),axis=1)\n",
    "    return feature[:,1:]\n",
    "\n",
    "train_x_map = feature_mapping(train_x,degree=6)\n",
    "val_x_map = feature_mapping(val_x,degree=6)\n",
    "train_x_map"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "训练逻辑回归"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/8000, Train Loss: 0.6931\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.6263\n",
      "Epoch: 2/8000, Train Loss: 0.5872\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5905\n",
      "Epoch: 3/8000, Train Loss: 0.5605\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5642\n",
      "Epoch: 4/8000, Train Loss: 0.5419\n",
      "Accuracy on Val set: 75.00%\tLoss on Val set: 0.5442\n",
      "Epoch: 5/8000, Train Loss: 0.5268\n",
      "Accuracy on Val set: 79.17%\tLoss on Val set: 0.5281\n",
      "Epoch: 6/8000, Train Loss: 0.5139\n",
      "Accuracy on Val set: 79.17%\tLoss on Val set: 0.5149\n",
      "Epoch: 7/8000, Train Loss: 0.5025\n",
      "Accuracy on Val set: 79.17%\tLoss on Val set: 0.5037\n",
      "Epoch: 8/8000, Train Loss: 0.4924\n",
      "Accuracy on Val set: 79.17%\tLoss on Val set: 0.4940\n",
      "Epoch: 9/8000, Train Loss: 0.4833\n",
      "Accuracy on Val set: 79.17%\tLoss on Val set: 0.4854\n",
      "Epoch: 10/8000, Train Loss: 0.4751\n",
      "Accuracy on Val set: 79.17%\tLoss on Val set: 0.4779\n",
      "Epoch: 11/8000, Train Loss: 0.4676\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4711\n",
      "Epoch: 12/8000, Train Loss: 0.4607\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4650\n",
      "Epoch: 13/8000, Train Loss: 0.4544\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4595\n",
      "Epoch: 14/8000, Train Loss: 0.4486\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4545\n",
      "Epoch: 15/8000, Train Loss: 0.4432\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4499\n",
      "Epoch: 16/8000, Train Loss: 0.4381\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4458\n",
      "Epoch: 17/8000, Train Loss: 0.4335\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4419\n",
      "Epoch: 18/8000, Train Loss: 0.4291\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4384\n",
      "Epoch: 19/8000, Train Loss: 0.4250\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4351\n",
      "Epoch: 20/8000, Train Loss: 0.4212\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4320\n",
      "Epoch: 21/8000, Train Loss: 0.4176\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4292\n",
      "Epoch: 22/8000, Train Loss: 0.4142\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4266\n",
      "Epoch: 23/8000, Train Loss: 0.4110\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4242\n",
      "Epoch: 24/8000, Train Loss: 0.4079\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4219\n",
      "Epoch: 25/8000, Train Loss: 0.4050\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4198\n",
      "Epoch: 26/8000, Train Loss: 0.4023\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4179\n",
      "Epoch: 27/8000, Train Loss: 0.3997\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4161\n",
      "Epoch: 28/8000, Train Loss: 0.3973\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4143\n",
      "Epoch: 29/8000, Train Loss: 0.3949\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4127\n",
      "Epoch: 30/8000, Train Loss: 0.3927\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4112\n",
      "Epoch: 31/8000, Train Loss: 0.3905\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4098\n",
      "Epoch: 32/8000, Train Loss: 0.3885\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4085\n",
      "Epoch: 33/8000, Train Loss: 0.3865\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4073\n",
      "Epoch: 34/8000, Train Loss: 0.3847\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4061\n",
      "Epoch: 35/8000, Train Loss: 0.3829\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4051\n",
      "Epoch: 36/8000, Train Loss: 0.3811\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4040\n",
      "Epoch: 37/8000, Train Loss: 0.3795\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4031\n",
      "Epoch: 38/8000, Train Loss: 0.3779\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4022\n",
      "Epoch: 39/8000, Train Loss: 0.3764\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4013\n",
      "Epoch: 40/8000, Train Loss: 0.3749\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.4006\n",
      "Epoch: 41/8000, Train Loss: 0.3735\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3998\n",
      "Epoch: 42/8000, Train Loss: 0.3721\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3991\n",
      "Epoch: 43/8000, Train Loss: 0.3708\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3985\n",
      "Epoch: 44/8000, Train Loss: 0.3695\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3979\n",
      "Epoch: 45/8000, Train Loss: 0.3683\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3973\n",
      "Epoch: 46/8000, Train Loss: 0.3671\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3967\n",
      "Epoch: 47/8000, Train Loss: 0.3660\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3962\n",
      "Epoch: 48/8000, Train Loss: 0.3648\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3958\n",
      "Epoch: 49/8000, Train Loss: 0.3638\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3953\n",
      "Epoch: 50/8000, Train Loss: 0.3627\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3949\n",
      "Epoch: 51/8000, Train Loss: 0.3617\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3945\n",
      "Epoch: 52/8000, Train Loss: 0.3607\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3942\n",
      "Epoch: 53/8000, Train Loss: 0.3598\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3938\n",
      "Epoch: 54/8000, Train Loss: 0.3589\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3935\n",
      "Epoch: 55/8000, Train Loss: 0.3580\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3932\n",
      "Epoch: 56/8000, Train Loss: 0.3571\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3929\n",
      "Epoch: 57/8000, Train Loss: 0.3562\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3927\n",
      "Epoch: 58/8000, Train Loss: 0.3554\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3925\n",
      "Epoch: 59/8000, Train Loss: 0.3546\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3923\n",
      "Epoch: 60/8000, Train Loss: 0.3538\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3921\n",
      "Epoch: 61/8000, Train Loss: 0.3531\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3919\n",
      "Epoch: 62/8000, Train Loss: 0.3523\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3917\n",
      "Epoch: 63/8000, Train Loss: 0.3516\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3916\n",
      "Epoch: 64/8000, Train Loss: 0.3509\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3914\n",
      "Epoch: 65/8000, Train Loss: 0.3502\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3913\n",
      "Epoch: 66/8000, Train Loss: 0.3496\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3912\n",
      "Epoch: 67/8000, Train Loss: 0.3489\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3911\n",
      "Epoch: 68/8000, Train Loss: 0.3483\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3910\n",
      "Epoch: 69/8000, Train Loss: 0.3477\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3910\n",
      "Epoch: 70/8000, Train Loss: 0.3471\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3909\n",
      "Epoch: 71/8000, Train Loss: 0.3465\n",
      "Accuracy on Val set: 83.33%\tLoss on Val set: 0.3908\n",
      "Epoch: 72/8000, Train Loss: 0.3459\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3908\n",
      "Epoch: 73/8000, Train Loss: 0.3453\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3908\n",
      "Epoch: 74/8000, Train Loss: 0.3448\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3907\n",
      "Epoch: 75/8000, Train Loss: 0.3443\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3907\n",
      "Epoch: 76/8000, Train Loss: 0.3437\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3907\n",
      "Epoch: 77/8000, Train Loss: 0.3432\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3907\n",
      "Epoch: 78/8000, Train Loss: 0.3427\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3907\n",
      "Epoch: 79/8000, Train Loss: 0.3422\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3908\n",
      "Epoch: 80/8000, Train Loss: 0.3417\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3908\n",
      "Epoch: 81/8000, Train Loss: 0.3413\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3908\n",
      "Epoch: 82/8000, Train Loss: 0.3408\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3909\n",
      "Epoch: 83/8000, Train Loss: 0.3404\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3909\n",
      "Epoch: 84/8000, Train Loss: 0.3399\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3910\n",
      "Epoch: 85/8000, Train Loss: 0.3395\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3910\n",
      "Epoch: 86/8000, Train Loss: 0.3391\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3911\n",
      "Epoch: 87/8000, Train Loss: 0.3386\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3912\n",
      "Epoch: 88/8000, Train Loss: 0.3382\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3912\n",
      "Epoch: 89/8000, Train Loss: 0.3378\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3913\n",
      "Epoch: 90/8000, Train Loss: 0.3374\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3914\n",
      "Epoch: 91/8000, Train Loss: 0.3371\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3915\n",
      "Epoch: 92/8000, Train Loss: 0.3367\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3916\n",
      "Epoch: 93/8000, Train Loss: 0.3363\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3917\n",
      "Epoch: 94/8000, Train Loss: 0.3359\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3918\n",
      "Epoch: 95/8000, Train Loss: 0.3356\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3919\n",
      "Epoch: 96/8000, Train Loss: 0.3352\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3920\n",
      "Epoch: 97/8000, Train Loss: 0.3349\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3921\n",
      "Epoch: 98/8000, Train Loss: 0.3346\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3922\n",
      "Epoch: 99/8000, Train Loss: 0.3342\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3923\n",
      "Epoch: 100/8000, Train Loss: 0.3339\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3925\n",
      "Epoch: 101/8000, Train Loss: 0.3336\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3926\n",
      "Epoch: 102/8000, Train Loss: 0.3333\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3927\n",
      "Epoch: 103/8000, Train Loss: 0.3330\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3929\n",
      "Epoch: 104/8000, Train Loss: 0.3326\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3930\n",
      "Epoch: 105/8000, Train Loss: 0.3323\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3931\n",
      "Epoch: 106/8000, Train Loss: 0.3321\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3933\n",
      "Epoch: 107/8000, Train Loss: 0.3318\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3934\n",
      "Epoch: 108/8000, Train Loss: 0.3315\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3936\n",
      "Epoch: 109/8000, Train Loss: 0.3312\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3937\n",
      "Epoch: 110/8000, Train Loss: 0.3309\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3939\n",
      "Epoch: 111/8000, Train Loss: 0.3307\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3940\n",
      "Epoch: 112/8000, Train Loss: 0.3304\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3942\n",
      "Epoch: 113/8000, Train Loss: 0.3301\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3943\n",
      "Epoch: 114/8000, Train Loss: 0.3299\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3945\n",
      "Epoch: 115/8000, Train Loss: 0.3296\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3946\n",
      "Epoch: 116/8000, Train Loss: 0.3294\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3948\n",
      "Epoch: 117/8000, Train Loss: 0.3291\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3950\n",
      "Epoch: 118/8000, Train Loss: 0.3289\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3951\n",
      "Epoch: 119/8000, Train Loss: 0.3286\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3953\n",
      "Epoch: 120/8000, Train Loss: 0.3284\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3955\n",
      "Epoch: 121/8000, Train Loss: 0.3282\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3956\n",
      "Epoch: 122/8000, Train Loss: 0.3279\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3958\n",
      "Epoch: 123/8000, Train Loss: 0.3277\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3960\n",
      "Epoch: 124/8000, Train Loss: 0.3275\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3962\n",
      "Epoch: 125/8000, Train Loss: 0.3273\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3963\n",
      "Epoch: 126/8000, Train Loss: 0.3270\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3965\n",
      "Epoch: 127/8000, Train Loss: 0.3268\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3967\n",
      "Epoch: 128/8000, Train Loss: 0.3266\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3969\n",
      "Epoch: 129/8000, Train Loss: 0.3264\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3970\n",
      "Epoch: 130/8000, Train Loss: 0.3262\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3972\n",
      "Epoch: 131/8000, Train Loss: 0.3260\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3974\n",
      "Epoch: 132/8000, Train Loss: 0.3258\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3976\n",
      "Epoch: 133/8000, Train Loss: 0.3256\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3978\n",
      "Epoch: 134/8000, Train Loss: 0.3254\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3980\n",
      "Epoch: 135/8000, Train Loss: 0.3252\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3981\n",
      "Epoch: 136/8000, Train Loss: 0.3250\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3983\n",
      "Epoch: 137/8000, Train Loss: 0.3249\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3985\n",
      "Epoch: 138/8000, Train Loss: 0.3247\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3987\n",
      "Epoch: 139/8000, Train Loss: 0.3245\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3989\n",
      "Epoch: 140/8000, Train Loss: 0.3243\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3991\n",
      "Epoch: 141/8000, Train Loss: 0.3241\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3993\n",
      "Epoch: 142/8000, Train Loss: 0.3240\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3995\n",
      "Epoch: 143/8000, Train Loss: 0.3238\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3997\n",
      "Epoch: 144/8000, Train Loss: 0.3236\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.3999\n",
      "Epoch: 145/8000, Train Loss: 0.3235\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4001\n",
      "Epoch: 146/8000, Train Loss: 0.3233\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4002\n",
      "Epoch: 147/8000, Train Loss: 0.3231\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4004\n",
      "Epoch: 148/8000, Train Loss: 0.3230\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4006\n",
      "Epoch: 149/8000, Train Loss: 0.3228\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4008\n",
      "Epoch: 150/8000, Train Loss: 0.3226\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4010\n",
      "Epoch: 151/8000, Train Loss: 0.3225\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4012\n",
      "Epoch: 152/8000, Train Loss: 0.3223\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4014\n",
      "Epoch: 153/8000, Train Loss: 0.3222\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4016\n",
      "Epoch: 154/8000, Train Loss: 0.3220\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4018\n",
      "Epoch: 155/8000, Train Loss: 0.3219\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4020\n",
      "Epoch: 156/8000, Train Loss: 0.3217\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4022\n",
      "Epoch: 157/8000, Train Loss: 0.3216\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4024\n",
      "Epoch: 158/8000, Train Loss: 0.3215\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4026\n",
      "Epoch: 159/8000, Train Loss: 0.3213\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4028\n",
      "Epoch: 160/8000, Train Loss: 0.3212\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4030\n",
      "Epoch: 161/8000, Train Loss: 0.3210\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4032\n",
      "Epoch: 162/8000, Train Loss: 0.3209\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4034\n",
      "Epoch: 163/8000, Train Loss: 0.3208\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.4036\n",
      "Epoch: 164/8000, Train Loss: 0.3206\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4038\n",
      "Epoch: 165/8000, Train Loss: 0.3205\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4040\n",
      "Epoch: 166/8000, Train Loss: 0.3204\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4042\n",
      "Epoch: 167/8000, Train Loss: 0.3202\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4044\n",
      "Epoch: 168/8000, Train Loss: 0.3201\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4046\n",
      "Epoch: 169/8000, Train Loss: 0.3200\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4048\n",
      "Epoch: 170/8000, Train Loss: 0.3199\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4050\n",
      "Epoch: 171/8000, Train Loss: 0.3197\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4052\n",
      "Epoch: 172/8000, Train Loss: 0.3196\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4054\n",
      "Epoch: 173/8000, Train Loss: 0.3195\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4056\n",
      "Epoch: 174/8000, Train Loss: 0.3194\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4058\n",
      "Epoch: 175/8000, Train Loss: 0.3192\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4060\n",
      "Epoch: 176/8000, Train Loss: 0.3191\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4062\n",
      "Epoch: 177/8000, Train Loss: 0.3190\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4064\n",
      "Epoch: 178/8000, Train Loss: 0.3189\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4066\n",
      "Epoch: 179/8000, Train Loss: 0.3188\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4068\n",
      "Epoch: 180/8000, Train Loss: 0.3187\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4070\n",
      "Epoch: 181/8000, Train Loss: 0.3186\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4072\n",
      "Epoch: 182/8000, Train Loss: 0.3185\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4074\n",
      "Epoch: 183/8000, Train Loss: 0.3183\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4076\n",
      "Epoch: 184/8000, Train Loss: 0.3182\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4078\n",
      "Epoch: 185/8000, Train Loss: 0.3181\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4080\n",
      "Epoch: 186/8000, Train Loss: 0.3180\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4082\n",
      "Epoch: 187/8000, Train Loss: 0.3179\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4085\n",
      "Epoch: 188/8000, Train Loss: 0.3178\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4087\n",
      "Epoch: 189/8000, Train Loss: 0.3177\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4089\n",
      "Epoch: 190/8000, Train Loss: 0.3176\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4091\n",
      "Epoch: 191/8000, Train Loss: 0.3175\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4093\n",
      "Epoch: 192/8000, Train Loss: 0.3174\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4095\n",
      "Epoch: 193/8000, Train Loss: 0.3173\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4097\n",
      "Epoch: 194/8000, Train Loss: 0.3172\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4099\n",
      "Epoch: 195/8000, Train Loss: 0.3171\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4101\n",
      "Epoch: 196/8000, Train Loss: 0.3170\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4103\n",
      "Epoch: 197/8000, Train Loss: 0.3169\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4105\n",
      "Epoch: 198/8000, Train Loss: 0.3168\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4107\n",
      "Epoch: 199/8000, Train Loss: 0.3167\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4109\n",
      "Epoch: 200/8000, Train Loss: 0.3166\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4111\n",
      "Epoch: 201/8000, Train Loss: 0.3165\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4113\n",
      "Epoch: 202/8000, Train Loss: 0.3165\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4115\n",
      "Epoch: 203/8000, Train Loss: 0.3164\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4117\n",
      "Epoch: 204/8000, Train Loss: 0.3163\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4119\n",
      "Epoch: 205/8000, Train Loss: 0.3162\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4121\n",
      "Epoch: 206/8000, Train Loss: 0.3161\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4123\n",
      "Epoch: 207/8000, Train Loss: 0.3160\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4125\n",
      "Epoch: 208/8000, Train Loss: 0.3159\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4127\n",
      "Epoch: 209/8000, Train Loss: 0.3158\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4129\n",
      "Epoch: 210/8000, Train Loss: 0.3158\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4131\n",
      "Epoch: 211/8000, Train Loss: 0.3157\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4133\n",
      "Epoch: 212/8000, Train Loss: 0.3156\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4135\n",
      "Epoch: 213/8000, Train Loss: 0.3155\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4137\n",
      "Epoch: 214/8000, Train Loss: 0.3154\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4139\n",
      "Epoch: 215/8000, Train Loss: 0.3153\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4141\n",
      "Epoch: 216/8000, Train Loss: 0.3153\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4143\n",
      "Epoch: 217/8000, Train Loss: 0.3152\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4145\n",
      "Epoch: 218/8000, Train Loss: 0.3151\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4147\n",
      "Epoch: 219/8000, Train Loss: 0.3150\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4149\n",
      "Epoch: 220/8000, Train Loss: 0.3149\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4151\n",
      "Epoch: 221/8000, Train Loss: 0.3149\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4153\n",
      "Epoch: 222/8000, Train Loss: 0.3148\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4155\n",
      "Epoch: 223/8000, Train Loss: 0.3147\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4157\n",
      "Epoch: 224/8000, Train Loss: 0.3146\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4159\n",
      "Epoch: 225/8000, Train Loss: 0.3146\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4161\n",
      "Epoch: 226/8000, Train Loss: 0.3145\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4163\n",
      "Epoch: 227/8000, Train Loss: 0.3144\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4165\n",
      "Epoch: 228/8000, Train Loss: 0.3143\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4167\n",
      "Epoch: 229/8000, Train Loss: 0.3143\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4169\n",
      "Epoch: 230/8000, Train Loss: 0.3142\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4171\n",
      "Epoch: 231/8000, Train Loss: 0.3141\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4173\n",
      "Epoch: 232/8000, Train Loss: 0.3141\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4175\n",
      "Epoch: 233/8000, Train Loss: 0.3140\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4177\n",
      "Epoch: 234/8000, Train Loss: 0.3139\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4179\n",
      "Epoch: 235/8000, Train Loss: 0.3138\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4181\n",
      "Epoch: 236/8000, Train Loss: 0.3138\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4183\n",
      "Epoch: 237/8000, Train Loss: 0.3137\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4184\n",
      "Epoch: 238/8000, Train Loss: 0.3136\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4186\n",
      "Epoch: 239/8000, Train Loss: 0.3136\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4188\n",
      "Epoch: 240/8000, Train Loss: 0.3135\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4190\n",
      "Epoch: 241/8000, Train Loss: 0.3134\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4192\n",
      "Epoch: 242/8000, Train Loss: 0.3134\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4194\n",
      "Epoch: 243/8000, Train Loss: 0.3133\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4196\n",
      "Epoch: 244/8000, Train Loss: 0.3132\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4198\n",
      "Epoch: 245/8000, Train Loss: 0.3132\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4200\n",
      "Epoch: 246/8000, Train Loss: 0.3131\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4202\n",
      "Epoch: 247/8000, Train Loss: 0.3130\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4204\n",
      "Epoch: 248/8000, Train Loss: 0.3130\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4206\n",
      "Epoch: 249/8000, Train Loss: 0.3129\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4208\n",
      "Epoch: 250/8000, Train Loss: 0.3129\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4210\n",
      "Epoch: 251/8000, Train Loss: 0.3128\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4212\n",
      "Epoch: 252/8000, Train Loss: 0.3127\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4214\n",
      "Epoch: 253/8000, Train Loss: 0.3127\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4216\n",
      "Epoch: 254/8000, Train Loss: 0.3126\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4218\n",
      "Epoch: 255/8000, Train Loss: 0.3126\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4219\n",
      "Epoch: 256/8000, Train Loss: 0.3125\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4221\n",
      "Epoch: 257/8000, Train Loss: 0.3124\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4223\n",
      "Epoch: 258/8000, Train Loss: 0.3124\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4225\n",
      "Epoch: 259/8000, Train Loss: 0.3123\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4227\n",
      "Epoch: 260/8000, Train Loss: 0.3123\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4229\n",
      "Epoch: 261/8000, Train Loss: 0.3122\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4231\n",
      "Epoch: 262/8000, Train Loss: 0.3121\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4233\n",
      "Epoch: 263/8000, Train Loss: 0.3121\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4235\n",
      "Epoch: 264/8000, Train Loss: 0.3120\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4237\n",
      "Epoch: 265/8000, Train Loss: 0.3120\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4239\n",
      "Epoch: 266/8000, Train Loss: 0.3119\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4240\n",
      "Epoch: 267/8000, Train Loss: 0.3119\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4242\n",
      "Epoch: 268/8000, Train Loss: 0.3118\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4244\n",
      "Epoch: 269/8000, Train Loss: 0.3118\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4246\n",
      "Epoch: 270/8000, Train Loss: 0.3117\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4248\n",
      "Epoch: 271/8000, Train Loss: 0.3117\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4250\n",
      "Epoch: 272/8000, Train Loss: 0.3116\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4252\n",
      "Epoch: 273/8000, Train Loss: 0.3115\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4254\n",
      "Epoch: 274/8000, Train Loss: 0.3115\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4256\n",
      "Epoch: 275/8000, Train Loss: 0.3114\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4257\n",
      "Epoch: 276/8000, Train Loss: 0.3114\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4259\n",
      "Epoch: 277/8000, Train Loss: 0.3113\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4261\n",
      "Epoch: 278/8000, Train Loss: 0.3113\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4263\n",
      "Epoch: 279/8000, Train Loss: 0.3112\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4265\n",
      "Epoch: 280/8000, Train Loss: 0.3112\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4267\n",
      "Epoch: 281/8000, Train Loss: 0.3111\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4269\n",
      "Epoch: 282/8000, Train Loss: 0.3111\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4271\n",
      "Epoch: 283/8000, Train Loss: 0.3110\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4272\n",
      "Epoch: 284/8000, Train Loss: 0.3110\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4274\n",
      "Epoch: 285/8000, Train Loss: 0.3109\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4276\n",
      "Epoch: 286/8000, Train Loss: 0.3109\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4278\n",
      "Epoch: 287/8000, Train Loss: 0.3108\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4280\n",
      "Epoch: 288/8000, Train Loss: 0.3108\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4282\n",
      "Epoch: 289/8000, Train Loss: 0.3107\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4284\n",
      "Epoch: 290/8000, Train Loss: 0.3107\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4285\n",
      "Epoch: 291/8000, Train Loss: 0.3106\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4287\n",
      "Epoch: 292/8000, Train Loss: 0.3106\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4289\n",
      "Epoch: 293/8000, Train Loss: 0.3106\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4291\n",
      "Epoch: 294/8000, Train Loss: 0.3105\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4293\n",
      "Epoch: 295/8000, Train Loss: 0.3105\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4295\n",
      "Epoch: 296/8000, Train Loss: 0.3104\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4297\n",
      "Epoch: 297/8000, Train Loss: 0.3104\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4298\n",
      "Epoch: 298/8000, Train Loss: 0.3103\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4300\n",
      "Epoch: 299/8000, Train Loss: 0.3103\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4302\n",
      "Epoch: 300/8000, Train Loss: 0.3102\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4304\n",
      "Epoch: 301/8000, Train Loss: 0.3102\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4306\n",
      "Epoch: 302/8000, Train Loss: 0.3101\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4307\n",
      "Epoch: 303/8000, Train Loss: 0.3101\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4309\n",
      "Epoch: 304/8000, Train Loss: 0.3101\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4311\n",
      "Epoch: 305/8000, Train Loss: 0.3100\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4313\n",
      "Epoch: 306/8000, Train Loss: 0.3100\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4315\n",
      "Epoch: 307/8000, Train Loss: 0.3099\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4317\n",
      "Epoch: 308/8000, Train Loss: 0.3099\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4318\n",
      "Epoch: 309/8000, Train Loss: 0.3098\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4320\n",
      "Epoch: 310/8000, Train Loss: 0.3098\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4322\n",
      "Epoch: 311/8000, Train Loss: 0.3098\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4324\n",
      "Epoch: 312/8000, Train Loss: 0.3097\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4326\n",
      "Epoch: 313/8000, Train Loss: 0.3097\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4327\n",
      "Epoch: 314/8000, Train Loss: 0.3096\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4329\n",
      "Epoch: 315/8000, Train Loss: 0.3096\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4331\n",
      "Epoch: 316/8000, Train Loss: 0.3095\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4333\n",
      "Epoch: 317/8000, Train Loss: 0.3095\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4335\n",
      "Epoch: 318/8000, Train Loss: 0.3095\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4336\n",
      "Epoch: 319/8000, Train Loss: 0.3094\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4338\n",
      "Epoch: 320/8000, Train Loss: 0.3094\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4340\n",
      "Epoch: 321/8000, Train Loss: 0.3093\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4342\n",
      "Epoch: 322/8000, Train Loss: 0.3093\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4343\n",
      "Epoch: 323/8000, Train Loss: 0.3093\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4345\n",
      "Epoch: 324/8000, Train Loss: 0.3092\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4347\n",
      "Epoch: 325/8000, Train Loss: 0.3092\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4349\n",
      "Epoch: 326/8000, Train Loss: 0.3091\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4351\n",
      "Epoch: 327/8000, Train Loss: 0.3091\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4352\n",
      "Epoch: 328/8000, Train Loss: 0.3091\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4354\n",
      "Epoch: 329/8000, Train Loss: 0.3090\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4356\n",
      "Epoch: 330/8000, Train Loss: 0.3090\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4358\n",
      "Epoch: 331/8000, Train Loss: 0.3090\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4359\n",
      "Epoch: 332/8000, Train Loss: 0.3089\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4361\n",
      "Epoch: 333/8000, Train Loss: 0.3089\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4363\n",
      "Epoch: 334/8000, Train Loss: 0.3088\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4365\n",
      "Epoch: 335/8000, Train Loss: 0.3088\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4366\n",
      "Epoch: 336/8000, Train Loss: 0.3088\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4368\n",
      "Epoch: 337/8000, Train Loss: 0.3087\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4370\n",
      "Epoch: 338/8000, Train Loss: 0.3087\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4372\n",
      "Epoch: 339/8000, Train Loss: 0.3087\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4373\n",
      "Epoch: 340/8000, Train Loss: 0.3086\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4375\n",
      "Epoch: 341/8000, Train Loss: 0.3086\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4377\n",
      "Epoch: 342/8000, Train Loss: 0.3085\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4379\n",
      "Epoch: 343/8000, Train Loss: 0.3085\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4380\n",
      "Epoch: 344/8000, Train Loss: 0.3085\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4382\n",
      "Epoch: 345/8000, Train Loss: 0.3084\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4384\n",
      "Epoch: 346/8000, Train Loss: 0.3084\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4385\n",
      "Epoch: 347/8000, Train Loss: 0.3084\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4387\n",
      "Epoch: 348/8000, Train Loss: 0.3083\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4389\n",
      "Epoch: 349/8000, Train Loss: 0.3083\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4391\n",
      "Epoch: 350/8000, Train Loss: 0.3083\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4392\n",
      "Epoch: 351/8000, Train Loss: 0.3082\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4394\n",
      "Epoch: 352/8000, Train Loss: 0.3082\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4396\n",
      "Epoch: 353/8000, Train Loss: 0.3082\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4397\n",
      "Epoch: 354/8000, Train Loss: 0.3081\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4399\n",
      "Epoch: 355/8000, Train Loss: 0.3081\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4401\n",
      "Epoch: 356/8000, Train Loss: 0.3081\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4403\n",
      "Epoch: 357/8000, Train Loss: 0.3080\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4404\n",
      "Epoch: 358/8000, Train Loss: 0.3080\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4406\n",
      "Epoch: 359/8000, Train Loss: 0.3080\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4408\n",
      "Epoch: 360/8000, Train Loss: 0.3079\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4409\n",
      "Epoch: 361/8000, Train Loss: 0.3079\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4411\n",
      "Epoch: 362/8000, Train Loss: 0.3079\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4413\n",
      "Epoch: 363/8000, Train Loss: 0.3078\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4414\n",
      "Epoch: 364/8000, Train Loss: 0.3078\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4416\n",
      "Epoch: 365/8000, Train Loss: 0.3078\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4418\n",
      "Epoch: 366/8000, Train Loss: 0.3077\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4420\n",
      "Epoch: 367/8000, Train Loss: 0.3077\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4421\n",
      "Epoch: 368/8000, Train Loss: 0.3077\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4423\n",
      "Epoch: 369/8000, Train Loss: 0.3076\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4425\n",
      "Epoch: 370/8000, Train Loss: 0.3076\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4426\n",
      "Epoch: 371/8000, Train Loss: 0.3076\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4428\n",
      "Epoch: 372/8000, Train Loss: 0.3075\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4430\n",
      "Epoch: 373/8000, Train Loss: 0.3075\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4431\n",
      "Epoch: 374/8000, Train Loss: 0.3075\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4433\n",
      "Epoch: 375/8000, Train Loss: 0.3074\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4435\n",
      "Epoch: 376/8000, Train Loss: 0.3074\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4436\n",
      "Epoch: 377/8000, Train Loss: 0.3074\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4438\n",
      "Epoch: 378/8000, Train Loss: 0.3074\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4440\n",
      "Epoch: 379/8000, Train Loss: 0.3073\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4441\n",
      "Epoch: 380/8000, Train Loss: 0.3073\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4443\n",
      "Epoch: 381/8000, Train Loss: 0.3073\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4445\n",
      "Epoch: 382/8000, Train Loss: 0.3072\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4446\n",
      "Epoch: 383/8000, Train Loss: 0.3072\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4448\n",
      "Epoch: 384/8000, Train Loss: 0.3072\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4450\n",
      "Epoch: 385/8000, Train Loss: 0.3071\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4451\n",
      "Epoch: 386/8000, Train Loss: 0.3071\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4453\n",
      "Epoch: 387/8000, Train Loss: 0.3071\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4454\n",
      "Epoch: 388/8000, Train Loss: 0.3071\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4456\n",
      "Epoch: 389/8000, Train Loss: 0.3070\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4458\n",
      "Epoch: 390/8000, Train Loss: 0.3070\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4459\n",
      "Epoch: 391/8000, Train Loss: 0.3070\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4461\n",
      "Epoch: 392/8000, Train Loss: 0.3069\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4463\n",
      "Epoch: 393/8000, Train Loss: 0.3069\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4464\n",
      "Epoch: 394/8000, Train Loss: 0.3069\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4466\n",
      "Epoch: 395/8000, Train Loss: 0.3068\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4468\n",
      "Epoch: 396/8000, Train Loss: 0.3068\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4469\n",
      "Epoch: 397/8000, Train Loss: 0.3068\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4471\n",
      "Epoch: 398/8000, Train Loss: 0.3068\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4472\n",
      "Epoch: 399/8000, Train Loss: 0.3067\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4474\n",
      "Epoch: 400/8000, Train Loss: 0.3067\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4476\n",
      "Epoch: 401/8000, Train Loss: 0.3067\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4477\n",
      "Epoch: 402/8000, Train Loss: 0.3067\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4479\n",
      "Epoch: 403/8000, Train Loss: 0.3066\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4481\n",
      "Epoch: 404/8000, Train Loss: 0.3066\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4482\n",
      "Epoch: 405/8000, Train Loss: 0.3066\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4484\n",
      "Epoch: 406/8000, Train Loss: 0.3065\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4485\n",
      "Epoch: 407/8000, Train Loss: 0.3065\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4487\n",
      "Epoch: 408/8000, Train Loss: 0.3065\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4489\n",
      "Epoch: 409/8000, Train Loss: 0.3065\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4490\n",
      "Epoch: 410/8000, Train Loss: 0.3064\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4492\n",
      "Epoch: 411/8000, Train Loss: 0.3064\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4493\n",
      "Epoch: 412/8000, Train Loss: 0.3064\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4495\n",
      "Epoch: 413/8000, Train Loss: 0.3064\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4497\n",
      "Epoch: 414/8000, Train Loss: 0.3063\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4498\n",
      "Epoch: 415/8000, Train Loss: 0.3063\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4500\n",
      "Epoch: 416/8000, Train Loss: 0.3063\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4501\n",
      "Epoch: 417/8000, Train Loss: 0.3062\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4503\n",
      "Epoch: 418/8000, Train Loss: 0.3062\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4504\n",
      "Epoch: 419/8000, Train Loss: 0.3062\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4506\n",
      "Epoch: 420/8000, Train Loss: 0.3062\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4508\n",
      "Epoch: 421/8000, Train Loss: 0.3061\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4509\n",
      "Epoch: 422/8000, Train Loss: 0.3061\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4511\n",
      "Epoch: 423/8000, Train Loss: 0.3061\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4512\n",
      "Epoch: 424/8000, Train Loss: 0.3061\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4514\n",
      "Epoch: 425/8000, Train Loss: 0.3060\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4516\n",
      "Epoch: 426/8000, Train Loss: 0.3060\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4517\n",
      "Epoch: 427/8000, Train Loss: 0.3060\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4519\n",
      "Epoch: 428/8000, Train Loss: 0.3060\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4520\n",
      "Epoch: 429/8000, Train Loss: 0.3059\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4522\n",
      "Epoch: 430/8000, Train Loss: 0.3059\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4523\n",
      "Epoch: 431/8000, Train Loss: 0.3059\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4525\n",
      "Epoch: 432/8000, Train Loss: 0.3059\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4526\n",
      "Epoch: 433/8000, Train Loss: 0.3058\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4528\n",
      "Epoch: 434/8000, Train Loss: 0.3058\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4530\n",
      "Epoch: 435/8000, Train Loss: 0.3058\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4531\n",
      "Epoch: 436/8000, Train Loss: 0.3058\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4533\n",
      "Epoch: 437/8000, Train Loss: 0.3057\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4534\n",
      "Epoch: 438/8000, Train Loss: 0.3057\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4536\n",
      "Epoch: 439/8000, Train Loss: 0.3057\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4537\n",
      "Epoch: 440/8000, Train Loss: 0.3057\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4539\n",
      "Epoch: 441/8000, Train Loss: 0.3056\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4540\n",
      "Epoch: 442/8000, Train Loss: 0.3056\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4542\n",
      "Epoch: 443/8000, Train Loss: 0.3056\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4544\n",
      "Epoch: 444/8000, Train Loss: 0.3056\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4545\n",
      "Epoch: 445/8000, Train Loss: 0.3055\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4547\n",
      "Epoch: 446/8000, Train Loss: 0.3055\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4548\n",
      "Epoch: 447/8000, Train Loss: 0.3055\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4550\n",
      "Epoch: 448/8000, Train Loss: 0.3055\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4551\n",
      "Epoch: 449/8000, Train Loss: 0.3055\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4553\n",
      "Epoch: 450/8000, Train Loss: 0.3054\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4554\n",
      "Epoch: 451/8000, Train Loss: 0.3054\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4556\n",
      "Epoch: 452/8000, Train Loss: 0.3054\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4557\n",
      "Epoch: 453/8000, Train Loss: 0.3054\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4559\n",
      "Epoch: 454/8000, Train Loss: 0.3053\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4560\n",
      "Epoch: 455/8000, Train Loss: 0.3053\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4562\n",
      "Epoch: 456/8000, Train Loss: 0.3053\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4563\n",
      "Epoch: 457/8000, Train Loss: 0.3053\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4565\n",
      "Epoch: 458/8000, Train Loss: 0.3052\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4566\n",
      "Epoch: 459/8000, Train Loss: 0.3052\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4568\n",
      "Epoch: 460/8000, Train Loss: 0.3052\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4569\n",
      "Epoch: 461/8000, Train Loss: 0.3052\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4571\n",
      "Epoch: 462/8000, Train Loss: 0.3052\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4572\n",
      "Epoch: 463/8000, Train Loss: 0.3051\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4574\n",
      "Epoch: 464/8000, Train Loss: 0.3051\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4575\n",
      "Epoch: 465/8000, Train Loss: 0.3051\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4577\n",
      "Epoch: 466/8000, Train Loss: 0.3051\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4578\n",
      "Epoch: 467/8000, Train Loss: 0.3050\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4580\n",
      "Epoch: 468/8000, Train Loss: 0.3050\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4581\n",
      "Epoch: 469/8000, Train Loss: 0.3050\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4583\n",
      "Epoch: 470/8000, Train Loss: 0.3050\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4584\n",
      "Epoch: 471/8000, Train Loss: 0.3050\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4586\n",
      "Epoch: 472/8000, Train Loss: 0.3049\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4587\n",
      "Epoch: 473/8000, Train Loss: 0.3049\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4589\n",
      "Epoch: 474/8000, Train Loss: 0.3049\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4590\n",
      "Epoch: 475/8000, Train Loss: 0.3049\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4592\n",
      "Epoch: 476/8000, Train Loss: 0.3048\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4593\n",
      "Epoch: 477/8000, Train Loss: 0.3048\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4595\n",
      "Epoch: 478/8000, Train Loss: 0.3048\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4596\n",
      "Epoch: 479/8000, Train Loss: 0.3048\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4598\n",
      "Epoch: 480/8000, Train Loss: 0.3048\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4599\n",
      "Epoch: 481/8000, Train Loss: 0.3047\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4601\n",
      "Epoch: 482/8000, Train Loss: 0.3047\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4602\n",
      "Epoch: 483/8000, Train Loss: 0.3047\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4604\n",
      "Epoch: 484/8000, Train Loss: 0.3047\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4605\n",
      "Epoch: 485/8000, Train Loss: 0.3047\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4607\n",
      "Epoch: 486/8000, Train Loss: 0.3046\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4608\n",
      "Epoch: 487/8000, Train Loss: 0.3046\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4610\n",
      "Epoch: 488/8000, Train Loss: 0.3046\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4611\n",
      "Epoch: 489/8000, Train Loss: 0.3046\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4613\n",
      "Epoch: 490/8000, Train Loss: 0.3046\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4614\n",
      "Epoch: 491/8000, Train Loss: 0.3045\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4615\n",
      "Epoch: 492/8000, Train Loss: 0.3045\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4617\n",
      "Epoch: 493/8000, Train Loss: 0.3045\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4618\n",
      "Epoch: 494/8000, Train Loss: 0.3045\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4620\n",
      "Epoch: 495/8000, Train Loss: 0.3044\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4621\n",
      "Epoch: 496/8000, Train Loss: 0.3044\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4623\n",
      "Epoch: 497/8000, Train Loss: 0.3044\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4624\n",
      "Epoch: 498/8000, Train Loss: 0.3044\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4626\n",
      "Epoch: 499/8000, Train Loss: 0.3044\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4627\n",
      "Epoch: 500/8000, Train Loss: 0.3043\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4629\n",
      "Epoch: 501/8000, Train Loss: 0.3043\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4630\n",
      "Epoch: 502/8000, Train Loss: 0.3043\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4631\n",
      "Epoch: 503/8000, Train Loss: 0.3043\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4633\n",
      "Epoch: 504/8000, Train Loss: 0.3043\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4634\n",
      "Epoch: 505/8000, Train Loss: 0.3042\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4636\n",
      "Epoch: 506/8000, Train Loss: 0.3042\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4637\n",
      "Epoch: 507/8000, Train Loss: 0.3042\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4639\n",
      "Epoch: 508/8000, Train Loss: 0.3042\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4640\n",
      "Epoch: 509/8000, Train Loss: 0.3042\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4642\n",
      "Epoch: 510/8000, Train Loss: 0.3041\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4643\n",
      "Epoch: 511/8000, Train Loss: 0.3041\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4644\n",
      "Epoch: 512/8000, Train Loss: 0.3041\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4646\n",
      "Epoch: 513/8000, Train Loss: 0.3041\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4647\n",
      "Epoch: 514/8000, Train Loss: 0.3041\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4649\n",
      "Epoch: 515/8000, Train Loss: 0.3041\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4650\n",
      "Epoch: 516/8000, Train Loss: 0.3040\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4652\n",
      "Epoch: 517/8000, Train Loss: 0.3040\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4653\n",
      "Epoch: 518/8000, Train Loss: 0.3040\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4654\n",
      "Epoch: 519/8000, Train Loss: 0.3040\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4656\n",
      "Epoch: 520/8000, Train Loss: 0.3040\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4657\n",
      "Epoch: 521/8000, Train Loss: 0.3039\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4659\n",
      "Epoch: 522/8000, Train Loss: 0.3039\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4660\n",
      "Epoch: 523/8000, Train Loss: 0.3039\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4661\n",
      "Epoch: 524/8000, Train Loss: 0.3039\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4663\n",
      "Epoch: 525/8000, Train Loss: 0.3039\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4664\n",
      "Epoch: 526/8000, Train Loss: 0.3038\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4666\n",
      "Epoch: 527/8000, Train Loss: 0.3038\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4667\n",
      "Epoch: 528/8000, Train Loss: 0.3038\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4669\n",
      "Epoch: 529/8000, Train Loss: 0.3038\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4670\n",
      "Epoch: 530/8000, Train Loss: 0.3038\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4671\n",
      "Epoch: 531/8000, Train Loss: 0.3037\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4673\n",
      "Epoch: 532/8000, Train Loss: 0.3037\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4674\n",
      "Epoch: 533/8000, Train Loss: 0.3037\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4676\n",
      "Epoch: 534/8000, Train Loss: 0.3037\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4677\n",
      "Epoch: 535/8000, Train Loss: 0.3037\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4678\n",
      "Epoch: 536/8000, Train Loss: 0.3037\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4680\n",
      "Epoch: 537/8000, Train Loss: 0.3036\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4681\n",
      "Epoch: 538/8000, Train Loss: 0.3036\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4683\n",
      "Epoch: 539/8000, Train Loss: 0.3036\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4684\n",
      "Epoch: 540/8000, Train Loss: 0.3036\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4685\n",
      "Epoch: 541/8000, Train Loss: 0.3036\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4687\n",
      "Epoch: 542/8000, Train Loss: 0.3035\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4688\n",
      "Epoch: 543/8000, Train Loss: 0.3035\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4689\n",
      "Epoch: 544/8000, Train Loss: 0.3035\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4691\n",
      "Epoch: 545/8000, Train Loss: 0.3035\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4692\n",
      "Epoch: 546/8000, Train Loss: 0.3035\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4694\n",
      "Epoch: 547/8000, Train Loss: 0.3035\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4695\n",
      "Epoch: 548/8000, Train Loss: 0.3034\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4696\n",
      "Epoch: 549/8000, Train Loss: 0.3034\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4698\n",
      "Epoch: 550/8000, Train Loss: 0.3034\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4699\n",
      "Epoch: 551/8000, Train Loss: 0.3034\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4701\n",
      "Epoch: 552/8000, Train Loss: 0.3034\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4702\n",
      "Epoch: 553/8000, Train Loss: 0.3034\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4703\n",
      "Epoch: 554/8000, Train Loss: 0.3033\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4705\n",
      "Epoch: 555/8000, Train Loss: 0.3033\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4706\n",
      "Epoch: 556/8000, Train Loss: 0.3033\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4707\n",
      "Epoch: 557/8000, Train Loss: 0.3033\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4709\n",
      "Epoch: 558/8000, Train Loss: 0.3033\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4710\n",
      "Epoch: 559/8000, Train Loss: 0.3032\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4712\n",
      "Epoch: 560/8000, Train Loss: 0.3032\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4713\n",
      "Epoch: 561/8000, Train Loss: 0.3032\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4714\n",
      "Epoch: 562/8000, Train Loss: 0.3032\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4716\n",
      "Epoch: 563/8000, Train Loss: 0.3032\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4717\n",
      "Epoch: 564/8000, Train Loss: 0.3032\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4718\n",
      "Epoch: 565/8000, Train Loss: 0.3031\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4720\n",
      "Epoch: 566/8000, Train Loss: 0.3031\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4721\n",
      "Epoch: 567/8000, Train Loss: 0.3031\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4722\n",
      "Epoch: 568/8000, Train Loss: 0.3031\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4724\n",
      "Epoch: 569/8000, Train Loss: 0.3031\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4725\n",
      "Epoch: 570/8000, Train Loss: 0.3031\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4726\n",
      "Epoch: 571/8000, Train Loss: 0.3030\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4728\n",
      "Epoch: 572/8000, Train Loss: 0.3030\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4729\n",
      "Epoch: 573/8000, Train Loss: 0.3030\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4730\n",
      "Epoch: 574/8000, Train Loss: 0.3030\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4732\n",
      "Epoch: 575/8000, Train Loss: 0.3030\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4733\n",
      "Epoch: 576/8000, Train Loss: 0.3030\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4735\n",
      "Epoch: 577/8000, Train Loss: 0.3029\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4736\n",
      "Epoch: 578/8000, Train Loss: 0.3029\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4737\n",
      "Epoch: 579/8000, Train Loss: 0.3029\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4739\n",
      "Epoch: 580/8000, Train Loss: 0.3029\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4740\n",
      "Epoch: 581/8000, Train Loss: 0.3029\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4741\n",
      "Epoch: 582/8000, Train Loss: 0.3029\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4743\n",
      "Epoch: 583/8000, Train Loss: 0.3028\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4744\n",
      "Epoch: 584/8000, Train Loss: 0.3028\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4745\n",
      "Epoch: 585/8000, Train Loss: 0.3028\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4747\n",
      "Epoch: 586/8000, Train Loss: 0.3028\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4748\n",
      "Epoch: 587/8000, Train Loss: 0.3028\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4749\n",
      "Epoch: 588/8000, Train Loss: 0.3028\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4751\n",
      "Epoch: 589/8000, Train Loss: 0.3028\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4752\n",
      "Epoch: 590/8000, Train Loss: 0.3027\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4753\n",
      "Epoch: 591/8000, Train Loss: 0.3027\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4755\n",
      "Epoch: 592/8000, Train Loss: 0.3027\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4756\n",
      "Epoch: 593/8000, Train Loss: 0.3027\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4757\n",
      "Epoch: 594/8000, Train Loss: 0.3027\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4759\n",
      "Epoch: 595/8000, Train Loss: 0.3027\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4760\n",
      "Epoch: 596/8000, Train Loss: 0.3026\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4761\n",
      "Epoch: 597/8000, Train Loss: 0.3026\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4762\n",
      "Epoch: 598/8000, Train Loss: 0.3026\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4764\n",
      "Epoch: 599/8000, Train Loss: 0.3026\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4765\n",
      "Epoch: 600/8000, Train Loss: 0.3026\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4766\n",
      "Epoch: 601/8000, Train Loss: 0.3026\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4768\n",
      "Epoch: 602/8000, Train Loss: 0.3025\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4769\n",
      "Epoch: 603/8000, Train Loss: 0.3025\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4770\n",
      "Epoch: 604/8000, Train Loss: 0.3025\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4772\n",
      "Epoch: 605/8000, Train Loss: 0.3025\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4773\n",
      "Epoch: 606/8000, Train Loss: 0.3025\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4774\n",
      "Epoch: 607/8000, Train Loss: 0.3025\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4776\n",
      "Epoch: 608/8000, Train Loss: 0.3025\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4777\n",
      "Epoch: 609/8000, Train Loss: 0.3024\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4778\n",
      "Epoch: 610/8000, Train Loss: 0.3024\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4780\n",
      "Epoch: 611/8000, Train Loss: 0.3024\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4781\n",
      "Epoch: 612/8000, Train Loss: 0.3024\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4782\n",
      "Epoch: 613/8000, Train Loss: 0.3024\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4783\n",
      "Epoch: 614/8000, Train Loss: 0.3024\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4785\n",
      "Epoch: 615/8000, Train Loss: 0.3023\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4786\n",
      "Epoch: 616/8000, Train Loss: 0.3023\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4787\n",
      "Epoch: 617/8000, Train Loss: 0.3023\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4789\n",
      "Epoch: 618/8000, Train Loss: 0.3023\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4790\n",
      "Epoch: 619/8000, Train Loss: 0.3023\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4791\n",
      "Epoch: 620/8000, Train Loss: 0.3023\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4792\n",
      "Epoch: 621/8000, Train Loss: 0.3023\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4794\n",
      "Epoch: 622/8000, Train Loss: 0.3022\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4795\n",
      "Epoch: 623/8000, Train Loss: 0.3022\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4796\n",
      "Epoch: 624/8000, Train Loss: 0.3022\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4798\n",
      "Epoch: 625/8000, Train Loss: 0.3022\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4799\n",
      "Epoch: 626/8000, Train Loss: 0.3022\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4800\n",
      "Epoch: 627/8000, Train Loss: 0.3022\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4801\n",
      "Epoch: 628/8000, Train Loss: 0.3021\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4803\n",
      "Epoch: 629/8000, Train Loss: 0.3021\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4804\n",
      "Epoch: 630/8000, Train Loss: 0.3021\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4805\n",
      "Epoch: 631/8000, Train Loss: 0.3021\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4807\n",
      "Epoch: 632/8000, Train Loss: 0.3021\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4808\n",
      "Epoch: 633/8000, Train Loss: 0.3021\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4809\n",
      "Epoch: 634/8000, Train Loss: 0.3021\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4810\n",
      "Epoch: 635/8000, Train Loss: 0.3020\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4812\n",
      "Epoch: 636/8000, Train Loss: 0.3020\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4813\n",
      "Epoch: 637/8000, Train Loss: 0.3020\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4814\n",
      "Epoch: 638/8000, Train Loss: 0.3020\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4816\n",
      "Epoch: 639/8000, Train Loss: 0.3020\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4817\n",
      "Epoch: 640/8000, Train Loss: 0.3020\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4818\n",
      "Epoch: 641/8000, Train Loss: 0.3020\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4819\n",
      "Epoch: 642/8000, Train Loss: 0.3019\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4821\n",
      "Epoch: 643/8000, Train Loss: 0.3019\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4822\n",
      "Epoch: 644/8000, Train Loss: 0.3019\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4823\n",
      "Epoch: 645/8000, Train Loss: 0.3019\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4824\n",
      "Epoch: 646/8000, Train Loss: 0.3019\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4826\n",
      "Epoch: 647/8000, Train Loss: 0.3019\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4827\n",
      "Epoch: 648/8000, Train Loss: 0.3019\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4828\n",
      "Epoch: 649/8000, Train Loss: 0.3018\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4829\n",
      "Epoch: 650/8000, Train Loss: 0.3018\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4831\n",
      "Epoch: 651/8000, Train Loss: 0.3018\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4832\n",
      "Epoch: 652/8000, Train Loss: 0.3018\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4833\n",
      "Epoch: 653/8000, Train Loss: 0.3018\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4835\n",
      "Epoch: 654/8000, Train Loss: 0.3018\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4836\n",
      "Epoch: 655/8000, Train Loss: 0.3018\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4837\n",
      "Epoch: 656/8000, Train Loss: 0.3017\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4838\n",
      "Epoch: 657/8000, Train Loss: 0.3017\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4840\n",
      "Epoch: 658/8000, Train Loss: 0.3017\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4841\n",
      "Epoch: 659/8000, Train Loss: 0.3017\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4842\n",
      "Epoch: 660/8000, Train Loss: 0.3017\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4843\n",
      "Epoch: 661/8000, Train Loss: 0.3017\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4845\n",
      "Epoch: 662/8000, Train Loss: 0.3017\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4846\n",
      "Epoch: 663/8000, Train Loss: 0.3016\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4847\n",
      "Epoch: 664/8000, Train Loss: 0.3016\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4848\n",
      "Epoch: 665/8000, Train Loss: 0.3016\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4849\n",
      "Epoch: 666/8000, Train Loss: 0.3016\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4851\n",
      "Epoch: 667/8000, Train Loss: 0.3016\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4852\n",
      "Epoch: 668/8000, Train Loss: 0.3016\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4853\n",
      "Epoch: 669/8000, Train Loss: 0.3016\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4854\n",
      "Epoch: 670/8000, Train Loss: 0.3016\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4856\n",
      "Epoch: 671/8000, Train Loss: 0.3015\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4857\n",
      "Epoch: 672/8000, Train Loss: 0.3015\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4858\n",
      "Epoch: 673/8000, Train Loss: 0.3015\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4859\n",
      "Epoch: 674/8000, Train Loss: 0.3015\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4861\n",
      "Epoch: 675/8000, Train Loss: 0.3015\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4862\n",
      "Epoch: 676/8000, Train Loss: 0.3015\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4863\n",
      "Epoch: 677/8000, Train Loss: 0.3015\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4864\n",
      "Epoch: 678/8000, Train Loss: 0.3014\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4866\n",
      "Epoch: 679/8000, Train Loss: 0.3014\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4867\n",
      "Epoch: 680/8000, Train Loss: 0.3014\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4868\n",
      "Epoch: 681/8000, Train Loss: 0.3014\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4869\n",
      "Epoch: 682/8000, Train Loss: 0.3014\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4870\n",
      "Epoch: 683/8000, Train Loss: 0.3014\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4872\n",
      "Epoch: 684/8000, Train Loss: 0.3014\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4873\n",
      "Epoch: 685/8000, Train Loss: 0.3014\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4874\n",
      "Epoch: 686/8000, Train Loss: 0.3013\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4875\n",
      "Epoch: 687/8000, Train Loss: 0.3013\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4877\n",
      "Epoch: 688/8000, Train Loss: 0.3013\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4878\n",
      "Epoch: 689/8000, Train Loss: 0.3013\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4879\n",
      "Epoch: 690/8000, Train Loss: 0.3013\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4880\n",
      "Epoch: 691/8000, Train Loss: 0.3013\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4881\n",
      "Epoch: 692/8000, Train Loss: 0.3013\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4883\n",
      "Epoch: 693/8000, Train Loss: 0.3012\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4884\n",
      "Epoch: 694/8000, Train Loss: 0.3012\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4885\n",
      "Epoch: 695/8000, Train Loss: 0.3012\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4886\n",
      "Epoch: 696/8000, Train Loss: 0.3012\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4888\n",
      "Epoch: 697/8000, Train Loss: 0.3012\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4889\n",
      "Epoch: 698/8000, Train Loss: 0.3012\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4890\n",
      "Epoch: 699/8000, Train Loss: 0.3012\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4891\n",
      "Epoch: 700/8000, Train Loss: 0.3012\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4892\n",
      "Epoch: 701/8000, Train Loss: 0.3011\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4894\n",
      "Epoch: 702/8000, Train Loss: 0.3011\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4895\n",
      "Epoch: 703/8000, Train Loss: 0.3011\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4896\n",
      "Epoch: 704/8000, Train Loss: 0.3011\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4897\n",
      "Epoch: 705/8000, Train Loss: 0.3011\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4898\n",
      "Epoch: 706/8000, Train Loss: 0.3011\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4900\n",
      "Epoch: 707/8000, Train Loss: 0.3011\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4901\n",
      "Epoch: 708/8000, Train Loss: 0.3011\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4902\n",
      "Epoch: 709/8000, Train Loss: 0.3010\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4903\n",
      "Epoch: 710/8000, Train Loss: 0.3010\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4904\n",
      "Epoch: 711/8000, Train Loss: 0.3010\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4906\n",
      "Epoch: 712/8000, Train Loss: 0.3010\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4907\n",
      "Epoch: 713/8000, Train Loss: 0.3010\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4908\n",
      "Epoch: 714/8000, Train Loss: 0.3010\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4909\n",
      "Epoch: 715/8000, Train Loss: 0.3010\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4910\n",
      "Epoch: 716/8000, Train Loss: 0.3009\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4912\n",
      "Epoch: 717/8000, Train Loss: 0.3009\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4913\n",
      "Epoch: 718/8000, Train Loss: 0.3009\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4914\n",
      "Epoch: 719/8000, Train Loss: 0.3009\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4915\n",
      "Epoch: 720/8000, Train Loss: 0.3009\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4916\n",
      "Epoch: 721/8000, Train Loss: 0.3009\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4918\n",
      "Epoch: 722/8000, Train Loss: 0.3009\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4919\n",
      "Epoch: 723/8000, Train Loss: 0.3009\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4920\n",
      "Epoch: 724/8000, Train Loss: 0.3008\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4921\n",
      "Epoch: 725/8000, Train Loss: 0.3008\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4922\n",
      "Epoch: 726/8000, Train Loss: 0.3008\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4924\n",
      "Epoch: 727/8000, Train Loss: 0.3008\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4925\n",
      "Epoch: 728/8000, Train Loss: 0.3008\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4926\n",
      "Epoch: 729/8000, Train Loss: 0.3008\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4927\n",
      "Epoch: 730/8000, Train Loss: 0.3008\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4928\n",
      "Epoch: 731/8000, Train Loss: 0.3008\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4929\n",
      "Epoch: 732/8000, Train Loss: 0.3008\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4931\n",
      "Epoch: 733/8000, Train Loss: 0.3007\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4932\n",
      "Epoch: 734/8000, Train Loss: 0.3007\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4933\n",
      "Epoch: 735/8000, Train Loss: 0.3007\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4934\n",
      "Epoch: 736/8000, Train Loss: 0.3007\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4935\n",
      "Epoch: 737/8000, Train Loss: 0.3007\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4937\n",
      "Epoch: 738/8000, Train Loss: 0.3007\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4938\n",
      "Epoch: 739/8000, Train Loss: 0.3007\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4939\n",
      "Epoch: 740/8000, Train Loss: 0.3007\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4940\n",
      "Epoch: 741/8000, Train Loss: 0.3006\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4941\n",
      "Epoch: 742/8000, Train Loss: 0.3006\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4942\n",
      "Epoch: 743/8000, Train Loss: 0.3006\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4944\n",
      "Epoch: 744/8000, Train Loss: 0.3006\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4945\n",
      "Epoch: 745/8000, Train Loss: 0.3006\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4946\n",
      "Epoch: 746/8000, Train Loss: 0.3006\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4947\n",
      "Epoch: 747/8000, Train Loss: 0.3006\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4948\n",
      "Epoch: 748/8000, Train Loss: 0.3006\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4949\n",
      "Epoch: 749/8000, Train Loss: 0.3005\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4951\n",
      "Epoch: 750/8000, Train Loss: 0.3005\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4952\n",
      "Epoch: 751/8000, Train Loss: 0.3005\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4953\n",
      "Epoch: 752/8000, Train Loss: 0.3005\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4954\n",
      "Epoch: 753/8000, Train Loss: 0.3005\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4955\n",
      "Epoch: 754/8000, Train Loss: 0.3005\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4956\n",
      "Epoch: 755/8000, Train Loss: 0.3005\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4958\n",
      "Epoch: 756/8000, Train Loss: 0.3005\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4959\n",
      "Epoch: 757/8000, Train Loss: 0.3005\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4960\n",
      "Epoch: 758/8000, Train Loss: 0.3004\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4961\n",
      "Epoch: 759/8000, Train Loss: 0.3004\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4962\n",
      "Epoch: 760/8000, Train Loss: 0.3004\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4963\n",
      "Epoch: 761/8000, Train Loss: 0.3004\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4965\n",
      "Epoch: 762/8000, Train Loss: 0.3004\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4966\n",
      "Epoch: 763/8000, Train Loss: 0.3004\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4967\n",
      "Epoch: 764/8000, Train Loss: 0.3004\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4968\n",
      "Epoch: 765/8000, Train Loss: 0.3004\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4969\n",
      "Epoch: 766/8000, Train Loss: 0.3003\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4970\n",
      "Epoch: 767/8000, Train Loss: 0.3003\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4971\n",
      "Epoch: 768/8000, Train Loss: 0.3003\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4973\n",
      "Epoch: 769/8000, Train Loss: 0.3003\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4974\n",
      "Epoch: 770/8000, Train Loss: 0.3003\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4975\n",
      "Epoch: 771/8000, Train Loss: 0.3003\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4976\n",
      "Epoch: 772/8000, Train Loss: 0.3003\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4977\n",
      "Epoch: 773/8000, Train Loss: 0.3003\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4978\n",
      "Epoch: 774/8000, Train Loss: 0.3003\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4979\n",
      "Epoch: 775/8000, Train Loss: 0.3002\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4981\n",
      "Epoch: 776/8000, Train Loss: 0.3002\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4982\n",
      "Epoch: 777/8000, Train Loss: 0.3002\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4983\n",
      "Epoch: 778/8000, Train Loss: 0.3002\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4984\n",
      "Epoch: 779/8000, Train Loss: 0.3002\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4985\n",
      "Epoch: 780/8000, Train Loss: 0.3002\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4986\n",
      "Epoch: 781/8000, Train Loss: 0.3002\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4987\n",
      "Epoch: 782/8000, Train Loss: 0.3002\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4989\n",
      "Epoch: 783/8000, Train Loss: 0.3001\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4990\n",
      "Epoch: 784/8000, Train Loss: 0.3001\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4991\n",
      "Epoch: 785/8000, Train Loss: 0.3001\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4992\n",
      "Epoch: 786/8000, Train Loss: 0.3001\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4993\n",
      "Epoch: 787/8000, Train Loss: 0.3001\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4994\n",
      "Epoch: 788/8000, Train Loss: 0.3001\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4995\n",
      "Epoch: 789/8000, Train Loss: 0.3001\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4997\n",
      "Epoch: 790/8000, Train Loss: 0.3001\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4998\n",
      "Epoch: 791/8000, Train Loss: 0.3001\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.4999\n",
      "Epoch: 792/8000, Train Loss: 0.3000\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5000\n",
      "Epoch: 793/8000, Train Loss: 0.3000\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5001\n",
      "Epoch: 794/8000, Train Loss: 0.3000\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5002\n",
      "Epoch: 795/8000, Train Loss: 0.3000\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5003\n",
      "Epoch: 796/8000, Train Loss: 0.3000\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5005\n",
      "Epoch: 797/8000, Train Loss: 0.3000\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5006\n",
      "Epoch: 798/8000, Train Loss: 0.3000\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5007\n",
      "Epoch: 799/8000, Train Loss: 0.3000\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5008\n",
      "Epoch: 800/8000, Train Loss: 0.3000\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5009\n",
      "Epoch: 801/8000, Train Loss: 0.2999\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5010\n",
      "Epoch: 802/8000, Train Loss: 0.2999\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5011\n",
      "Epoch: 803/8000, Train Loss: 0.2999\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5012\n",
      "Epoch: 804/8000, Train Loss: 0.2999\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5014\n",
      "Epoch: 805/8000, Train Loss: 0.2999\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5015\n",
      "Epoch: 806/8000, Train Loss: 0.2999\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5016\n",
      "Epoch: 807/8000, Train Loss: 0.2999\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5017\n",
      "Epoch: 808/8000, Train Loss: 0.2999\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5018\n",
      "Epoch: 809/8000, Train Loss: 0.2999\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5019\n",
      "Epoch: 810/8000, Train Loss: 0.2998\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5020\n",
      "Epoch: 811/8000, Train Loss: 0.2998\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5021\n",
      "Epoch: 812/8000, Train Loss: 0.2998\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5022\n",
      "Epoch: 813/8000, Train Loss: 0.2998\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5024\n",
      "Epoch: 814/8000, Train Loss: 0.2998\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5025\n",
      "Epoch: 815/8000, Train Loss: 0.2998\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5026\n",
      "Epoch: 816/8000, Train Loss: 0.2998\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5027\n",
      "Epoch: 817/8000, Train Loss: 0.2998\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5028\n",
      "Epoch: 818/8000, Train Loss: 0.2998\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5029\n",
      "Epoch: 819/8000, Train Loss: 0.2998\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5030\n",
      "Epoch: 820/8000, Train Loss: 0.2997\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5031\n",
      "Epoch: 821/8000, Train Loss: 0.2997\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5032\n",
      "Epoch: 822/8000, Train Loss: 0.2997\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5034\n",
      "Epoch: 823/8000, Train Loss: 0.2997\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5035\n",
      "Epoch: 824/8000, Train Loss: 0.2997\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5036\n",
      "Epoch: 825/8000, Train Loss: 0.2997\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5037\n",
      "Epoch: 826/8000, Train Loss: 0.2997\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5038\n",
      "Epoch: 827/8000, Train Loss: 0.2997\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5039\n",
      "Epoch: 828/8000, Train Loss: 0.2997\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5040\n",
      "Epoch: 829/8000, Train Loss: 0.2996\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5041\n",
      "Epoch: 830/8000, Train Loss: 0.2996\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5042\n",
      "Epoch: 831/8000, Train Loss: 0.2996\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5044\n",
      "Epoch: 832/8000, Train Loss: 0.2996\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5045\n",
      "Epoch: 833/8000, Train Loss: 0.2996\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5046\n",
      "Epoch: 834/8000, Train Loss: 0.2996\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5047\n",
      "Epoch: 835/8000, Train Loss: 0.2996\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5048\n",
      "Epoch: 836/8000, Train Loss: 0.2996\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5049\n",
      "Epoch: 837/8000, Train Loss: 0.2996\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5050\n",
      "Epoch: 838/8000, Train Loss: 0.2995\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5051\n",
      "Epoch: 839/8000, Train Loss: 0.2995\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5052\n",
      "Epoch: 840/8000, Train Loss: 0.2995\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5053\n",
      "Epoch: 841/8000, Train Loss: 0.2995\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5055\n",
      "Epoch: 842/8000, Train Loss: 0.2995\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5056\n",
      "Epoch: 843/8000, Train Loss: 0.2995\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5057\n",
      "Epoch: 844/8000, Train Loss: 0.2995\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5058\n",
      "Epoch: 845/8000, Train Loss: 0.2995\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5059\n",
      "Epoch: 846/8000, Train Loss: 0.2995\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5060\n",
      "Epoch: 847/8000, Train Loss: 0.2995\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5061\n",
      "Epoch: 848/8000, Train Loss: 0.2994\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5062\n",
      "Epoch: 849/8000, Train Loss: 0.2994\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5063\n",
      "Epoch: 850/8000, Train Loss: 0.2994\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5064\n",
      "Epoch: 851/8000, Train Loss: 0.2994\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5065\n",
      "Epoch: 852/8000, Train Loss: 0.2994\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5067\n",
      "Epoch: 853/8000, Train Loss: 0.2994\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5068\n",
      "Epoch: 854/8000, Train Loss: 0.2994\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5069\n",
      "Epoch: 855/8000, Train Loss: 0.2994\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5070\n",
      "Epoch: 856/8000, Train Loss: 0.2994\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5071\n",
      "Epoch: 857/8000, Train Loss: 0.2994\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5072\n",
      "Epoch: 858/8000, Train Loss: 0.2993\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5073\n",
      "Epoch: 859/8000, Train Loss: 0.2993\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5074\n",
      "Epoch: 860/8000, Train Loss: 0.2993\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5075\n",
      "Epoch: 861/8000, Train Loss: 0.2993\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5076\n",
      "Epoch: 862/8000, Train Loss: 0.2993\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5077\n",
      "Epoch: 863/8000, Train Loss: 0.2993\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5079\n",
      "Epoch: 864/8000, Train Loss: 0.2993\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5080\n",
      "Epoch: 865/8000, Train Loss: 0.2993\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5081\n",
      "Epoch: 866/8000, Train Loss: 0.2993\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5082\n",
      "Epoch: 867/8000, Train Loss: 0.2993\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5083\n",
      "Epoch: 868/8000, Train Loss: 0.2992\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5084\n",
      "Epoch: 869/8000, Train Loss: 0.2992\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5085\n",
      "Epoch: 870/8000, Train Loss: 0.2992\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5086\n",
      "Epoch: 871/8000, Train Loss: 0.2992\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5087\n",
      "Epoch: 872/8000, Train Loss: 0.2992\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5088\n",
      "Epoch: 873/8000, Train Loss: 0.2992\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5089\n",
      "Epoch: 874/8000, Train Loss: 0.2992\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5090\n",
      "Epoch: 875/8000, Train Loss: 0.2992\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5091\n",
      "Epoch: 876/8000, Train Loss: 0.2992\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5093\n",
      "Epoch: 877/8000, Train Loss: 0.2992\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5094\n",
      "Epoch: 878/8000, Train Loss: 0.2991\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5095\n",
      "Epoch: 879/8000, Train Loss: 0.2991\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5096\n",
      "Epoch: 880/8000, Train Loss: 0.2991\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5097\n",
      "Epoch: 881/8000, Train Loss: 0.2991\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5098\n",
      "Epoch: 882/8000, Train Loss: 0.2991\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5099\n",
      "Epoch: 883/8000, Train Loss: 0.2991\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5100\n",
      "Epoch: 884/8000, Train Loss: 0.2991\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5101\n",
      "Epoch: 885/8000, Train Loss: 0.2991\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5102\n",
      "Epoch: 886/8000, Train Loss: 0.2991\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5103\n",
      "Epoch: 887/8000, Train Loss: 0.2991\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5104\n",
      "Epoch: 888/8000, Train Loss: 0.2990\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5105\n",
      "Epoch: 889/8000, Train Loss: 0.2990\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5106\n",
      "Epoch: 890/8000, Train Loss: 0.2990\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5108\n",
      "Epoch: 891/8000, Train Loss: 0.2990\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5109\n",
      "Epoch: 892/8000, Train Loss: 0.2990\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5110\n",
      "Epoch: 893/8000, Train Loss: 0.2990\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5111\n",
      "Epoch: 894/8000, Train Loss: 0.2990\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5112\n",
      "Epoch: 895/8000, Train Loss: 0.2990\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5113\n",
      "Epoch: 896/8000, Train Loss: 0.2990\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5114\n",
      "Epoch: 897/8000, Train Loss: 0.2990\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5115\n",
      "Epoch: 898/8000, Train Loss: 0.2989\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5116\n",
      "Epoch: 899/8000, Train Loss: 0.2989\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5117\n",
      "Epoch: 900/8000, Train Loss: 0.2989\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5118\n",
      "Epoch: 901/8000, Train Loss: 0.2989\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5119\n",
      "Epoch: 902/8000, Train Loss: 0.2989\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5120\n",
      "Epoch: 903/8000, Train Loss: 0.2989\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5121\n",
      "Epoch: 904/8000, Train Loss: 0.2989\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5122\n",
      "Epoch: 905/8000, Train Loss: 0.2989\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5123\n",
      "Epoch: 906/8000, Train Loss: 0.2989\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5124\n",
      "Epoch: 907/8000, Train Loss: 0.2989\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5126\n",
      "Epoch: 908/8000, Train Loss: 0.2988\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5127\n",
      "Epoch: 909/8000, Train Loss: 0.2988\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5128\n",
      "Epoch: 910/8000, Train Loss: 0.2988\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5129\n",
      "Epoch: 911/8000, Train Loss: 0.2988\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5130\n",
      "Epoch: 912/8000, Train Loss: 0.2988\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5131\n",
      "Epoch: 913/8000, Train Loss: 0.2988\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5132\n",
      "Epoch: 914/8000, Train Loss: 0.2988\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5133\n",
      "Epoch: 915/8000, Train Loss: 0.2988\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5134\n",
      "Epoch: 916/8000, Train Loss: 0.2988\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5135\n",
      "Epoch: 917/8000, Train Loss: 0.2988\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5136\n",
      "Epoch: 918/8000, Train Loss: 0.2988\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5137\n",
      "Epoch: 919/8000, Train Loss: 0.2987\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5138\n",
      "Epoch: 920/8000, Train Loss: 0.2987\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5139\n",
      "Epoch: 921/8000, Train Loss: 0.2987\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5140\n",
      "Epoch: 922/8000, Train Loss: 0.2987\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5141\n",
      "Epoch: 923/8000, Train Loss: 0.2987\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5142\n",
      "Epoch: 924/8000, Train Loss: 0.2987\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5143\n",
      "Epoch: 925/8000, Train Loss: 0.2987\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5144\n",
      "Epoch: 926/8000, Train Loss: 0.2987\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5145\n",
      "Epoch: 927/8000, Train Loss: 0.2987\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5146\n",
      "Epoch: 928/8000, Train Loss: 0.2987\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5148\n",
      "Epoch: 929/8000, Train Loss: 0.2986\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5149\n",
      "Epoch: 930/8000, Train Loss: 0.2986\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5150\n",
      "Epoch: 931/8000, Train Loss: 0.2986\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5151\n",
      "Epoch: 932/8000, Train Loss: 0.2986\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5152\n",
      "Epoch: 933/8000, Train Loss: 0.2986\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5153\n",
      "Epoch: 934/8000, Train Loss: 0.2986\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5154\n",
      "Epoch: 935/8000, Train Loss: 0.2986\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5155\n",
      "Epoch: 936/8000, Train Loss: 0.2986\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5156\n",
      "Epoch: 937/8000, Train Loss: 0.2986\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5157\n",
      "Epoch: 938/8000, Train Loss: 0.2986\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5158\n",
      "Epoch: 939/8000, Train Loss: 0.2986\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5159\n",
      "Epoch: 940/8000, Train Loss: 0.2985\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5160\n",
      "Epoch: 941/8000, Train Loss: 0.2985\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5161\n",
      "Epoch: 942/8000, Train Loss: 0.2985\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5162\n",
      "Epoch: 943/8000, Train Loss: 0.2985\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5163\n",
      "Epoch: 944/8000, Train Loss: 0.2985\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5164\n",
      "Epoch: 945/8000, Train Loss: 0.2985\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5165\n",
      "Epoch: 946/8000, Train Loss: 0.2985\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5166\n",
      "Epoch: 947/8000, Train Loss: 0.2985\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5167\n",
      "Epoch: 948/8000, Train Loss: 0.2985\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5168\n",
      "Epoch: 949/8000, Train Loss: 0.2985\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5169\n",
      "Epoch: 950/8000, Train Loss: 0.2985\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5170\n",
      "Epoch: 951/8000, Train Loss: 0.2984\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5171\n",
      "Epoch: 952/8000, Train Loss: 0.2984\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5172\n",
      "Epoch: 953/8000, Train Loss: 0.2984\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5173\n",
      "Epoch: 954/8000, Train Loss: 0.2984\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5174\n",
      "Epoch: 955/8000, Train Loss: 0.2984\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5175\n",
      "Epoch: 956/8000, Train Loss: 0.2984\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5176\n",
      "Epoch: 957/8000, Train Loss: 0.2984\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5178\n",
      "Epoch: 958/8000, Train Loss: 0.2984\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5179\n",
      "Epoch: 959/8000, Train Loss: 0.2984\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5180\n",
      "Epoch: 960/8000, Train Loss: 0.2984\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5181\n",
      "Epoch: 961/8000, Train Loss: 0.2984\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5182\n",
      "Epoch: 962/8000, Train Loss: 0.2983\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5183\n",
      "Epoch: 963/8000, Train Loss: 0.2983\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5184\n",
      "Epoch: 964/8000, Train Loss: 0.2983\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5185\n",
      "Epoch: 965/8000, Train Loss: 0.2983\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5186\n",
      "Epoch: 966/8000, Train Loss: 0.2983\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5187\n",
      "Epoch: 967/8000, Train Loss: 0.2983\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5188\n",
      "Epoch: 968/8000, Train Loss: 0.2983\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5189\n",
      "Epoch: 969/8000, Train Loss: 0.2983\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5190\n",
      "Epoch: 970/8000, Train Loss: 0.2983\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5191\n",
      "Epoch: 971/8000, Train Loss: 0.2983\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5192\n",
      "Epoch: 972/8000, Train Loss: 0.2983\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5193\n",
      "Epoch: 973/8000, Train Loss: 0.2982\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5194\n",
      "Epoch: 974/8000, Train Loss: 0.2982\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5195\n",
      "Epoch: 975/8000, Train Loss: 0.2982\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5196\n",
      "Epoch: 976/8000, Train Loss: 0.2982\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5197\n",
      "Epoch: 977/8000, Train Loss: 0.2982\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5198\n",
      "Epoch: 978/8000, Train Loss: 0.2982\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5199\n",
      "Epoch: 979/8000, Train Loss: 0.2982\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5200\n",
      "Epoch: 980/8000, Train Loss: 0.2982\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5201\n",
      "Epoch: 981/8000, Train Loss: 0.2982\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5202\n",
      "Epoch: 982/8000, Train Loss: 0.2982\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5203\n",
      "Epoch: 983/8000, Train Loss: 0.2982\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5204\n",
      "Epoch: 984/8000, Train Loss: 0.2981\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5205\n",
      "Epoch: 985/8000, Train Loss: 0.2981\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5206\n",
      "Epoch: 986/8000, Train Loss: 0.2981\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5207\n",
      "Epoch: 987/8000, Train Loss: 0.2981\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5208\n",
      "Epoch: 988/8000, Train Loss: 0.2981\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5209\n",
      "Epoch: 989/8000, Train Loss: 0.2981\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5210\n",
      "Epoch: 990/8000, Train Loss: 0.2981\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5211\n",
      "Epoch: 991/8000, Train Loss: 0.2981\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5212\n",
      "Epoch: 992/8000, Train Loss: 0.2981\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5213\n",
      "Epoch: 993/8000, Train Loss: 0.2981\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5214\n",
      "Epoch: 994/8000, Train Loss: 0.2981\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5215\n",
      "Epoch: 995/8000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5216\n",
      "Epoch: 996/8000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5217\n",
      "Epoch: 997/8000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5218\n",
      "Epoch: 998/8000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5219\n",
      "Epoch: 999/8000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5220\n",
      "Epoch: 1000/8000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5221\n",
      "Epoch: 1001/8000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5222\n",
      "Epoch: 1002/8000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5223\n",
      "Epoch: 1003/8000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5224\n",
      "Epoch: 1004/8000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5225\n",
      "Epoch: 1005/8000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5226\n",
      "Epoch: 1006/8000, Train Loss: 0.2980\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5227\n",
      "Epoch: 1007/8000, Train Loss: 0.2979\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5228\n",
      "Epoch: 1008/8000, Train Loss: 0.2979\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5229\n",
      "Epoch: 1009/8000, Train Loss: 0.2979\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5230\n",
      "Epoch: 1010/8000, Train Loss: 0.2979\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5231\n",
      "Epoch: 1011/8000, Train Loss: 0.2979\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5232\n",
      "Epoch: 1012/8000, Train Loss: 0.2979\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5233\n",
      "Epoch: 1013/8000, Train Loss: 0.2979\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5234\n",
      "Epoch: 1014/8000, Train Loss: 0.2979\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5235\n",
      "Epoch: 1015/8000, Train Loss: 0.2979\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5236\n",
      "Epoch: 1016/8000, Train Loss: 0.2979\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5237\n",
      "Epoch: 1017/8000, Train Loss: 0.2979\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5238\n",
      "Epoch: 1018/8000, Train Loss: 0.2978\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5239\n",
      "Epoch: 1019/8000, Train Loss: 0.2978\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5240\n",
      "Epoch: 1020/8000, Train Loss: 0.2978\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5241\n",
      "Epoch: 1021/8000, Train Loss: 0.2978\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5242\n",
      "Epoch: 1022/8000, Train Loss: 0.2978\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5243\n",
      "Epoch: 1023/8000, Train Loss: 0.2978\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5244\n",
      "Epoch: 1024/8000, Train Loss: 0.2978\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5245\n",
      "Epoch: 1025/8000, Train Loss: 0.2978\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5246\n",
      "Epoch: 1026/8000, Train Loss: 0.2978\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5247\n",
      "Epoch: 1027/8000, Train Loss: 0.2978\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5248\n",
      "Epoch: 1028/8000, Train Loss: 0.2978\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5249\n",
      "Epoch: 1029/8000, Train Loss: 0.2978\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5250\n",
      "Epoch: 1030/8000, Train Loss: 0.2977\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5251\n",
      "Epoch: 1031/8000, Train Loss: 0.2977\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5252\n",
      "Epoch: 1032/8000, Train Loss: 0.2977\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5253\n",
      "Epoch: 1033/8000, Train Loss: 0.2977\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5254\n",
      "Epoch: 1034/8000, Train Loss: 0.2977\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5255\n",
      "Epoch: 1035/8000, Train Loss: 0.2977\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5256\n",
      "Epoch: 1036/8000, Train Loss: 0.2977\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5257\n",
      "Epoch: 1037/8000, Train Loss: 0.2977\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5258\n",
      "Epoch: 1038/8000, Train Loss: 0.2977\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5259\n",
      "Epoch: 1039/8000, Train Loss: 0.2977\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5260\n",
      "Epoch: 1040/8000, Train Loss: 0.2977\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5261\n",
      "Epoch: 1041/8000, Train Loss: 0.2977\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5262\n",
      "Epoch: 1042/8000, Train Loss: 0.2976\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5263\n",
      "Epoch: 1043/8000, Train Loss: 0.2976\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5264\n",
      "Epoch: 1044/8000, Train Loss: 0.2976\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5265\n",
      "Epoch: 1045/8000, Train Loss: 0.2976\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5266\n",
      "Epoch: 1046/8000, Train Loss: 0.2976\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5267\n",
      "Epoch: 1047/8000, Train Loss: 0.2976\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5268\n",
      "Epoch: 1048/8000, Train Loss: 0.2976\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5269\n",
      "Epoch: 1049/8000, Train Loss: 0.2976\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5270\n",
      "Epoch: 1050/8000, Train Loss: 0.2976\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5271\n",
      "Epoch: 1051/8000, Train Loss: 0.2976\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5272\n",
      "Epoch: 1052/8000, Train Loss: 0.2976\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5273\n",
      "Epoch: 1053/8000, Train Loss: 0.2976\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5274\n",
      "Epoch: 1054/8000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5275\n",
      "Epoch: 1055/8000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5276\n",
      "Epoch: 1056/8000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5277\n",
      "Epoch: 1057/8000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5278\n",
      "Epoch: 1058/8000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5279\n",
      "Epoch: 1059/8000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5280\n",
      "Epoch: 1060/8000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5281\n",
      "Epoch: 1061/8000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5282\n",
      "Epoch: 1062/8000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5282\n",
      "Epoch: 1063/8000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5283\n",
      "Epoch: 1064/8000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5284\n",
      "Epoch: 1065/8000, Train Loss: 0.2975\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5285\n",
      "Epoch: 1066/8000, Train Loss: 0.2974\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5286\n",
      "Epoch: 1067/8000, Train Loss: 0.2974\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5287\n",
      "Epoch: 1068/8000, Train Loss: 0.2974\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5288\n",
      "Epoch: 1069/8000, Train Loss: 0.2974\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5289\n",
      "Epoch: 1070/8000, Train Loss: 0.2974\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5290\n",
      "Epoch: 1071/8000, Train Loss: 0.2974\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5291\n",
      "Epoch: 1072/8000, Train Loss: 0.2974\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5292\n",
      "Epoch: 1073/8000, Train Loss: 0.2974\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5293\n",
      "Epoch: 1074/8000, Train Loss: 0.2974\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5294\n",
      "Epoch: 1075/8000, Train Loss: 0.2974\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5295\n",
      "Epoch: 1076/8000, Train Loss: 0.2974\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5296\n",
      "Epoch: 1077/8000, Train Loss: 0.2974\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5297\n",
      "Epoch: 1078/8000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5298\n",
      "Epoch: 1079/8000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5299\n",
      "Epoch: 1080/8000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5300\n",
      "Epoch: 1081/8000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5301\n",
      "Epoch: 1082/8000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5302\n",
      "Epoch: 1083/8000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5303\n",
      "Epoch: 1084/8000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5304\n",
      "Epoch: 1085/8000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5305\n",
      "Epoch: 1086/8000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5306\n",
      "Epoch: 1087/8000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5307\n",
      "Epoch: 1088/8000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5308\n",
      "Epoch: 1089/8000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5309\n",
      "Epoch: 1090/8000, Train Loss: 0.2973\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5310\n",
      "Epoch: 1091/8000, Train Loss: 0.2972\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5311\n",
      "Epoch: 1092/8000, Train Loss: 0.2972\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5312\n",
      "Epoch: 1093/8000, Train Loss: 0.2972\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5313\n",
      "Epoch: 1094/8000, Train Loss: 0.2972\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5313\n",
      "Epoch: 1095/8000, Train Loss: 0.2972\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5314\n",
      "Epoch: 1096/8000, Train Loss: 0.2972\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5315\n",
      "Epoch: 1097/8000, Train Loss: 0.2972\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5316\n",
      "Epoch: 1098/8000, Train Loss: 0.2972\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5317\n",
      "Epoch: 1099/8000, Train Loss: 0.2972\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5318\n",
      "Epoch: 1100/8000, Train Loss: 0.2972\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5319\n",
      "Epoch: 1101/8000, Train Loss: 0.2972\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5320\n",
      "Epoch: 1102/8000, Train Loss: 0.2972\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5321\n",
      "Epoch: 1103/8000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5322\n",
      "Epoch: 1104/8000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5323\n",
      "Epoch: 1105/8000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5324\n",
      "Epoch: 1106/8000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5325\n",
      "Epoch: 1107/8000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5326\n",
      "Epoch: 1108/8000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5327\n",
      "Epoch: 1109/8000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5328\n",
      "Epoch: 1110/8000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5329\n",
      "Epoch: 1111/8000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5330\n",
      "Epoch: 1112/8000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5331\n",
      "Epoch: 1113/8000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5332\n",
      "Epoch: 1114/8000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5333\n",
      "Epoch: 1115/8000, Train Loss: 0.2971\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5334\n",
      "Epoch: 1116/8000, Train Loss: 0.2970\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5335\n",
      "Epoch: 1117/8000, Train Loss: 0.2970\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5335\n",
      "Epoch: 1118/8000, Train Loss: 0.2970\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5336\n",
      "Epoch: 1119/8000, Train Loss: 0.2970\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5337\n",
      "Epoch: 1120/8000, Train Loss: 0.2970\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5338\n",
      "Epoch: 1121/8000, Train Loss: 0.2970\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5339\n",
      "Epoch: 1122/8000, Train Loss: 0.2970\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5340\n",
      "Epoch: 1123/8000, Train Loss: 0.2970\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5341\n",
      "Epoch: 1124/8000, Train Loss: 0.2970\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5342\n",
      "Epoch: 1125/8000, Train Loss: 0.2970\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5343\n",
      "Epoch: 1126/8000, Train Loss: 0.2970\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5344\n",
      "Epoch: 1127/8000, Train Loss: 0.2970\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5345\n",
      "Epoch: 1128/8000, Train Loss: 0.2970\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5346\n",
      "Epoch: 1129/8000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5347\n",
      "Epoch: 1130/8000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5348\n",
      "Epoch: 1131/8000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5349\n",
      "Epoch: 1132/8000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5350\n",
      "Epoch: 1133/8000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5351\n",
      "Epoch: 1134/8000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5352\n",
      "Epoch: 1135/8000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5353\n",
      "Epoch: 1136/8000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5353\n",
      "Epoch: 1137/8000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5354\n",
      "Epoch: 1138/8000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5355\n",
      "Epoch: 1139/8000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5356\n",
      "Epoch: 1140/8000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5357\n",
      "Epoch: 1141/8000, Train Loss: 0.2969\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5358\n",
      "Epoch: 1142/8000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5359\n",
      "Epoch: 1143/8000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5360\n",
      "Epoch: 1144/8000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5361\n",
      "Epoch: 1145/8000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5362\n",
      "Epoch: 1146/8000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5363\n",
      "Epoch: 1147/8000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5364\n",
      "Epoch: 1148/8000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5365\n",
      "Epoch: 1149/8000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5366\n",
      "Epoch: 1150/8000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5367\n",
      "Epoch: 1151/8000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5368\n",
      "Epoch: 1152/8000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5369\n",
      "Epoch: 1153/8000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5369\n",
      "Epoch: 1154/8000, Train Loss: 0.2968\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5370\n",
      "Epoch: 1155/8000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5371\n",
      "Epoch: 1156/8000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5372\n",
      "Epoch: 1157/8000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5373\n",
      "Epoch: 1158/8000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5374\n",
      "Epoch: 1159/8000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5375\n",
      "Epoch: 1160/8000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5376\n",
      "Epoch: 1161/8000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5377\n",
      "Epoch: 1162/8000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5378\n",
      "Epoch: 1163/8000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5379\n",
      "Epoch: 1164/8000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5380\n",
      "Epoch: 1165/8000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5381\n",
      "Epoch: 1166/8000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5382\n",
      "Epoch: 1167/8000, Train Loss: 0.2967\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5383\n",
      "Epoch: 1168/8000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5383\n",
      "Epoch: 1169/8000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5384\n",
      "Epoch: 1170/8000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5385\n",
      "Epoch: 1171/8000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5386\n",
      "Epoch: 1172/8000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5387\n",
      "Epoch: 1173/8000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5388\n",
      "Epoch: 1174/8000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5389\n",
      "Epoch: 1175/8000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5390\n",
      "Epoch: 1176/8000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5391\n",
      "Epoch: 1177/8000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5392\n",
      "Epoch: 1178/8000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5393\n",
      "Epoch: 1179/8000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5394\n",
      "Epoch: 1180/8000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5395\n",
      "Epoch: 1181/8000, Train Loss: 0.2966\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5396\n",
      "Epoch: 1182/8000, Train Loss: 0.2965\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5397\n",
      "Epoch: 1183/8000, Train Loss: 0.2965\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5397\n",
      "Epoch: 1184/8000, Train Loss: 0.2965\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5398\n",
      "Epoch: 1185/8000, Train Loss: 0.2965\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5399\n",
      "Epoch: 1186/8000, Train Loss: 0.2965\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5400\n",
      "Epoch: 1187/8000, Train Loss: 0.2965\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5401\n",
      "Epoch: 1188/8000, Train Loss: 0.2965\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5402\n",
      "Epoch: 1189/8000, Train Loss: 0.2965\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5403\n",
      "Epoch: 1190/8000, Train Loss: 0.2965\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5404\n",
      "Epoch: 1191/8000, Train Loss: 0.2965\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5405\n",
      "Epoch: 1192/8000, Train Loss: 0.2965\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5406\n",
      "Epoch: 1193/8000, Train Loss: 0.2965\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5407\n",
      "Epoch: 1194/8000, Train Loss: 0.2965\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5408\n",
      "Epoch: 1195/8000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5409\n",
      "Epoch: 1196/8000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5409\n",
      "Epoch: 1197/8000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5410\n",
      "Epoch: 1198/8000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5411\n",
      "Epoch: 1199/8000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5412\n",
      "Epoch: 1200/8000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5413\n",
      "Epoch: 1201/8000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5414\n",
      "Epoch: 1202/8000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5415\n",
      "Epoch: 1203/8000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5416\n",
      "Epoch: 1204/8000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5417\n",
      "Epoch: 1205/8000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5418\n",
      "Epoch: 1206/8000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5419\n",
      "Epoch: 1207/8000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5420\n",
      "Epoch: 1208/8000, Train Loss: 0.2964\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5420\n",
      "Epoch: 1209/8000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5421\n",
      "Epoch: 1210/8000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5422\n",
      "Epoch: 1211/8000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5423\n",
      "Epoch: 1212/8000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5424\n",
      "Epoch: 1213/8000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5425\n",
      "Epoch: 1214/8000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5426\n",
      "Epoch: 1215/8000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5427\n",
      "Epoch: 1216/8000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5428\n",
      "Epoch: 1217/8000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5429\n",
      "Epoch: 1218/8000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5430\n",
      "Epoch: 1219/8000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5431\n",
      "Epoch: 1220/8000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5431\n",
      "Epoch: 1221/8000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5432\n",
      "Epoch: 1222/8000, Train Loss: 0.2963\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5433\n",
      "Epoch: 1223/8000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5434\n",
      "Epoch: 1224/8000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5435\n",
      "Epoch: 1225/8000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5436\n",
      "Epoch: 1226/8000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5437\n",
      "Epoch: 1227/8000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5438\n",
      "Epoch: 1228/8000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5439\n",
      "Epoch: 1229/8000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5440\n",
      "Epoch: 1230/8000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5441\n",
      "Epoch: 1231/8000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5442\n",
      "Epoch: 1232/8000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5442\n",
      "Epoch: 1233/8000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5443\n",
      "Epoch: 1234/8000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5444\n",
      "Epoch: 1235/8000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5445\n",
      "Epoch: 1236/8000, Train Loss: 0.2962\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5446\n",
      "Epoch: 1237/8000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5447\n",
      "Epoch: 1238/8000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5448\n",
      "Epoch: 1239/8000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5449\n",
      "Epoch: 1240/8000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5450\n",
      "Epoch: 1241/8000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5451\n",
      "Epoch: 1242/8000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5452\n",
      "Epoch: 1243/8000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5452\n",
      "Epoch: 1244/8000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5453\n",
      "Epoch: 1245/8000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5454\n",
      "Epoch: 1246/8000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5455\n",
      "Epoch: 1247/8000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5456\n",
      "Epoch: 1248/8000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5457\n",
      "Epoch: 1249/8000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5458\n",
      "Epoch: 1250/8000, Train Loss: 0.2961\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5459\n",
      "Epoch: 1251/8000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5460\n",
      "Epoch: 1252/8000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5461\n",
      "Epoch: 1253/8000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5461\n",
      "Epoch: 1254/8000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5462\n",
      "Epoch: 1255/8000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5463\n",
      "Epoch: 1256/8000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5464\n",
      "Epoch: 1257/8000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5465\n",
      "Epoch: 1258/8000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5466\n",
      "Epoch: 1259/8000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5467\n",
      "Epoch: 1260/8000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5468\n",
      "Epoch: 1261/8000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5469\n",
      "Epoch: 1262/8000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5470\n",
      "Epoch: 1263/8000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5470\n",
      "Epoch: 1264/8000, Train Loss: 0.2960\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5471\n",
      "Epoch: 1265/8000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5472\n",
      "Epoch: 1266/8000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5473\n",
      "Epoch: 1267/8000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5474\n",
      "Epoch: 1268/8000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5475\n",
      "Epoch: 1269/8000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5476\n",
      "Epoch: 1270/8000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5477\n",
      "Epoch: 1271/8000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5478\n",
      "Epoch: 1272/8000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5479\n",
      "Epoch: 1273/8000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5479\n",
      "Epoch: 1274/8000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5480\n",
      "Epoch: 1275/8000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5481\n",
      "Epoch: 1276/8000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5482\n",
      "Epoch: 1277/8000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5483\n",
      "Epoch: 1278/8000, Train Loss: 0.2959\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5484\n",
      "Epoch: 1279/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5485\n",
      "Epoch: 1280/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5486\n",
      "Epoch: 1281/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5487\n",
      "Epoch: 1282/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5488\n",
      "Epoch: 1283/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5488\n",
      "Epoch: 1284/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5489\n",
      "Epoch: 1285/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5490\n",
      "Epoch: 1286/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5491\n",
      "Epoch: 1287/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5492\n",
      "Epoch: 1288/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5493\n",
      "Epoch: 1289/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5494\n",
      "Epoch: 1290/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5495\n",
      "Epoch: 1291/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5496\n",
      "Epoch: 1292/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5496\n",
      "Epoch: 1293/8000, Train Loss: 0.2958\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5497\n",
      "Epoch: 1294/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5498\n",
      "Epoch: 1295/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5499\n",
      "Epoch: 1296/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5500\n",
      "Epoch: 1297/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5501\n",
      "Epoch: 1298/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5502\n",
      "Epoch: 1299/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5503\n",
      "Epoch: 1300/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5504\n",
      "Epoch: 1301/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5504\n",
      "Epoch: 1302/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5505\n",
      "Epoch: 1303/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5506\n",
      "Epoch: 1304/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5507\n",
      "Epoch: 1305/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5508\n",
      "Epoch: 1306/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5509\n",
      "Epoch: 1307/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5510\n",
      "Epoch: 1308/8000, Train Loss: 0.2957\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5511\n",
      "Epoch: 1309/8000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5512\n",
      "Epoch: 1310/8000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5512\n",
      "Epoch: 1311/8000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5513\n",
      "Epoch: 1312/8000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5514\n",
      "Epoch: 1313/8000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5515\n",
      "Epoch: 1314/8000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5516\n",
      "Epoch: 1315/8000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5517\n",
      "Epoch: 1316/8000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5518\n",
      "Epoch: 1317/8000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5519\n",
      "Epoch: 1318/8000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5519\n",
      "Epoch: 1319/8000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5520\n",
      "Epoch: 1320/8000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5521\n",
      "Epoch: 1321/8000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5522\n",
      "Epoch: 1322/8000, Train Loss: 0.2956\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5523\n",
      "Epoch: 1323/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5524\n",
      "Epoch: 1324/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5525\n",
      "Epoch: 1325/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5526\n",
      "Epoch: 1326/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5527\n",
      "Epoch: 1327/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5527\n",
      "Epoch: 1328/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5528\n",
      "Epoch: 1329/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5529\n",
      "Epoch: 1330/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5530\n",
      "Epoch: 1331/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5531\n",
      "Epoch: 1332/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5532\n",
      "Epoch: 1333/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5533\n",
      "Epoch: 1334/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5534\n",
      "Epoch: 1335/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5534\n",
      "Epoch: 1336/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5535\n",
      "Epoch: 1337/8000, Train Loss: 0.2955\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5536\n",
      "Epoch: 1338/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5537\n",
      "Epoch: 1339/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5538\n",
      "Epoch: 1340/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5539\n",
      "Epoch: 1341/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5540\n",
      "Epoch: 1342/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5541\n",
      "Epoch: 1343/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5541\n",
      "Epoch: 1344/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5542\n",
      "Epoch: 1345/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5543\n",
      "Epoch: 1346/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5544\n",
      "Epoch: 1347/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5545\n",
      "Epoch: 1348/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5546\n",
      "Epoch: 1349/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5547\n",
      "Epoch: 1350/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5548\n",
      "Epoch: 1351/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5548\n",
      "Epoch: 1352/8000, Train Loss: 0.2954\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5549\n",
      "Epoch: 1353/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5550\n",
      "Epoch: 1354/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5551\n",
      "Epoch: 1355/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5552\n",
      "Epoch: 1356/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5553\n",
      "Epoch: 1357/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5554\n",
      "Epoch: 1358/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5555\n",
      "Epoch: 1359/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5555\n",
      "Epoch: 1360/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5556\n",
      "Epoch: 1361/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5557\n",
      "Epoch: 1362/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5558\n",
      "Epoch: 1363/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5559\n",
      "Epoch: 1364/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5560\n",
      "Epoch: 1365/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5561\n",
      "Epoch: 1366/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5562\n",
      "Epoch: 1367/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5562\n",
      "Epoch: 1368/8000, Train Loss: 0.2953\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5563\n",
      "Epoch: 1369/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5564\n",
      "Epoch: 1370/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5565\n",
      "Epoch: 1371/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5566\n",
      "Epoch: 1372/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5567\n",
      "Epoch: 1373/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5568\n",
      "Epoch: 1374/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5568\n",
      "Epoch: 1375/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5569\n",
      "Epoch: 1376/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5570\n",
      "Epoch: 1377/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5571\n",
      "Epoch: 1378/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5572\n",
      "Epoch: 1379/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5573\n",
      "Epoch: 1380/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5574\n",
      "Epoch: 1381/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5575\n",
      "Epoch: 1382/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5575\n",
      "Epoch: 1383/8000, Train Loss: 0.2952\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5576\n",
      "Epoch: 1384/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5577\n",
      "Epoch: 1385/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5578\n",
      "Epoch: 1386/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5579\n",
      "Epoch: 1387/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5580\n",
      "Epoch: 1388/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5581\n",
      "Epoch: 1389/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5581\n",
      "Epoch: 1390/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5582\n",
      "Epoch: 1391/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5583\n",
      "Epoch: 1392/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5584\n",
      "Epoch: 1393/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5585\n",
      "Epoch: 1394/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5586\n",
      "Epoch: 1395/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5587\n",
      "Epoch: 1396/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5588\n",
      "Epoch: 1397/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5588\n",
      "Epoch: 1398/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5589\n",
      "Epoch: 1399/8000, Train Loss: 0.2951\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5590\n",
      "Epoch: 1400/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5591\n",
      "Epoch: 1401/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5592\n",
      "Epoch: 1402/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5593\n",
      "Epoch: 1403/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5594\n",
      "Epoch: 1404/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5594\n",
      "Epoch: 1405/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5595\n",
      "Epoch: 1406/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5596\n",
      "Epoch: 1407/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5597\n",
      "Epoch: 1408/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5598\n",
      "Epoch: 1409/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5599\n",
      "Epoch: 1410/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5600\n",
      "Epoch: 1411/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5600\n",
      "Epoch: 1412/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5601\n",
      "Epoch: 1413/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5602\n",
      "Epoch: 1414/8000, Train Loss: 0.2950\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5603\n",
      "Epoch: 1415/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5604\n",
      "Epoch: 1416/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5605\n",
      "Epoch: 1417/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5606\n",
      "Epoch: 1418/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5606\n",
      "Epoch: 1419/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5607\n",
      "Epoch: 1420/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5608\n",
      "Epoch: 1421/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5609\n",
      "Epoch: 1422/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5610\n",
      "Epoch: 1423/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5611\n",
      "Epoch: 1424/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5612\n",
      "Epoch: 1425/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5612\n",
      "Epoch: 1426/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5613\n",
      "Epoch: 1427/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5614\n",
      "Epoch: 1428/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5615\n",
      "Epoch: 1429/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5616\n",
      "Epoch: 1430/8000, Train Loss: 0.2949\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5617\n",
      "Epoch: 1431/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5618\n",
      "Epoch: 1432/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5618\n",
      "Epoch: 1433/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5619\n",
      "Epoch: 1434/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5620\n",
      "Epoch: 1435/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5621\n",
      "Epoch: 1436/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5622\n",
      "Epoch: 1437/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5623\n",
      "Epoch: 1438/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5623\n",
      "Epoch: 1439/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5624\n",
      "Epoch: 1440/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5625\n",
      "Epoch: 1441/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5626\n",
      "Epoch: 1442/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5627\n",
      "Epoch: 1443/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5628\n",
      "Epoch: 1444/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5629\n",
      "Epoch: 1445/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5629\n",
      "Epoch: 1446/8000, Train Loss: 0.2948\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5630\n",
      "Epoch: 1447/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5631\n",
      "Epoch: 1448/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5632\n",
      "Epoch: 1449/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5633\n",
      "Epoch: 1450/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5634\n",
      "Epoch: 1451/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5635\n",
      "Epoch: 1452/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5635\n",
      "Epoch: 1453/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5636\n",
      "Epoch: 1454/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5637\n",
      "Epoch: 1455/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5638\n",
      "Epoch: 1456/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5639\n",
      "Epoch: 1457/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5640\n",
      "Epoch: 1458/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5640\n",
      "Epoch: 1459/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5641\n",
      "Epoch: 1460/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5642\n",
      "Epoch: 1461/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5643\n",
      "Epoch: 1462/8000, Train Loss: 0.2947\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5644\n",
      "Epoch: 1463/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5645\n",
      "Epoch: 1464/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5646\n",
      "Epoch: 1465/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5646\n",
      "Epoch: 1466/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5647\n",
      "Epoch: 1467/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5648\n",
      "Epoch: 1468/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5649\n",
      "Epoch: 1469/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5650\n",
      "Epoch: 1470/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5651\n",
      "Epoch: 1471/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5651\n",
      "Epoch: 1472/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5652\n",
      "Epoch: 1473/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5653\n",
      "Epoch: 1474/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5654\n",
      "Epoch: 1475/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5655\n",
      "Epoch: 1476/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5656\n",
      "Epoch: 1477/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5656\n",
      "Epoch: 1478/8000, Train Loss: 0.2946\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5657\n",
      "Epoch: 1479/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5658\n",
      "Epoch: 1480/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5659\n",
      "Epoch: 1481/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5660\n",
      "Epoch: 1482/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5661\n",
      "Epoch: 1483/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5662\n",
      "Epoch: 1484/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5662\n",
      "Epoch: 1485/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5663\n",
      "Epoch: 1486/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5664\n",
      "Epoch: 1487/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5665\n",
      "Epoch: 1488/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5666\n",
      "Epoch: 1489/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5667\n",
      "Epoch: 1490/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5667\n",
      "Epoch: 1491/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5668\n",
      "Epoch: 1492/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5669\n",
      "Epoch: 1493/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5670\n",
      "Epoch: 1494/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5671\n",
      "Epoch: 1495/8000, Train Loss: 0.2945\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5672\n",
      "Epoch: 1496/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5672\n",
      "Epoch: 1497/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5673\n",
      "Epoch: 1498/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5674\n",
      "Epoch: 1499/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5675\n",
      "Epoch: 1500/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5676\n",
      "Epoch: 1501/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5677\n",
      "Epoch: 1502/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5677\n",
      "Epoch: 1503/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5678\n",
      "Epoch: 1504/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5679\n",
      "Epoch: 1505/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5680\n",
      "Epoch: 1506/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5681\n",
      "Epoch: 1507/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5682\n",
      "Epoch: 1508/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5682\n",
      "Epoch: 1509/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5683\n",
      "Epoch: 1510/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5684\n",
      "Epoch: 1511/8000, Train Loss: 0.2944\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5685\n",
      "Epoch: 1512/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5686\n",
      "Epoch: 1513/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5687\n",
      "Epoch: 1514/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5687\n",
      "Epoch: 1515/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5688\n",
      "Epoch: 1516/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5689\n",
      "Epoch: 1517/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5690\n",
      "Epoch: 1518/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5691\n",
      "Epoch: 1519/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5692\n",
      "Epoch: 1520/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5692\n",
      "Epoch: 1521/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5693\n",
      "Epoch: 1522/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5694\n",
      "Epoch: 1523/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5695\n",
      "Epoch: 1524/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5696\n",
      "Epoch: 1525/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5697\n",
      "Epoch: 1526/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5697\n",
      "Epoch: 1527/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5698\n",
      "Epoch: 1528/8000, Train Loss: 0.2943\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5699\n",
      "Epoch: 1529/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5700\n",
      "Epoch: 1530/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5701\n",
      "Epoch: 1531/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5702\n",
      "Epoch: 1532/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5702\n",
      "Epoch: 1533/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5703\n",
      "Epoch: 1534/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5704\n",
      "Epoch: 1535/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5705\n",
      "Epoch: 1536/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5706\n",
      "Epoch: 1537/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5707\n",
      "Epoch: 1538/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5707\n",
      "Epoch: 1539/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5708\n",
      "Epoch: 1540/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5709\n",
      "Epoch: 1541/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5710\n",
      "Epoch: 1542/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5711\n",
      "Epoch: 1543/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5712\n",
      "Epoch: 1544/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5712\n",
      "Epoch: 1545/8000, Train Loss: 0.2942\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5713\n",
      "Epoch: 1546/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5714\n",
      "Epoch: 1547/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5715\n",
      "Epoch: 1548/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5716\n",
      "Epoch: 1549/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5717\n",
      "Epoch: 1550/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5717\n",
      "Epoch: 1551/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5718\n",
      "Epoch: 1552/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5719\n",
      "Epoch: 1553/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5720\n",
      "Epoch: 1554/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5721\n",
      "Epoch: 1555/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5721\n",
      "Epoch: 1556/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5722\n",
      "Epoch: 1557/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5723\n",
      "Epoch: 1558/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5724\n",
      "Epoch: 1559/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5725\n",
      "Epoch: 1560/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5726\n",
      "Epoch: 1561/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5726\n",
      "Epoch: 1562/8000, Train Loss: 0.2941\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5727\n",
      "Epoch: 1563/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5728\n",
      "Epoch: 1564/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5729\n",
      "Epoch: 1565/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5730\n",
      "Epoch: 1566/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5731\n",
      "Epoch: 1567/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5731\n",
      "Epoch: 1568/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5732\n",
      "Epoch: 1569/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5733\n",
      "Epoch: 1570/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5734\n",
      "Epoch: 1571/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5735\n",
      "Epoch: 1572/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5735\n",
      "Epoch: 1573/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5736\n",
      "Epoch: 1574/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5737\n",
      "Epoch: 1575/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5738\n",
      "Epoch: 1576/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5739\n",
      "Epoch: 1577/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5740\n",
      "Epoch: 1578/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5740\n",
      "Epoch: 1579/8000, Train Loss: 0.2940\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5741\n",
      "Epoch: 1580/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5742\n",
      "Epoch: 1581/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5743\n",
      "Epoch: 1582/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5744\n",
      "Epoch: 1583/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5744\n",
      "Epoch: 1584/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5745\n",
      "Epoch: 1585/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5746\n",
      "Epoch: 1586/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5747\n",
      "Epoch: 1587/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5748\n",
      "Epoch: 1588/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5749\n",
      "Epoch: 1589/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5749\n",
      "Epoch: 1590/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5750\n",
      "Epoch: 1591/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5751\n",
      "Epoch: 1592/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5752\n",
      "Epoch: 1593/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5753\n",
      "Epoch: 1594/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5753\n",
      "Epoch: 1595/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5754\n",
      "Epoch: 1596/8000, Train Loss: 0.2939\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5755\n",
      "Epoch: 1597/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5756\n",
      "Epoch: 1598/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5757\n",
      "Epoch: 1599/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5758\n",
      "Epoch: 1600/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5758\n",
      "Epoch: 1601/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5759\n",
      "Epoch: 1602/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5760\n",
      "Epoch: 1603/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5761\n",
      "Epoch: 1604/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5762\n",
      "Epoch: 1605/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5762\n",
      "Epoch: 1606/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5763\n",
      "Epoch: 1607/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5764\n",
      "Epoch: 1608/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5765\n",
      "Epoch: 1609/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5766\n",
      "Epoch: 1610/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5767\n",
      "Epoch: 1611/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5767\n",
      "Epoch: 1612/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5768\n",
      "Epoch: 1613/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5769\n",
      "Epoch: 1614/8000, Train Loss: 0.2938\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5770\n",
      "Epoch: 1615/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5771\n",
      "Epoch: 1616/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5771\n",
      "Epoch: 1617/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5772\n",
      "Epoch: 1618/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5773\n",
      "Epoch: 1619/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5774\n",
      "Epoch: 1620/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5775\n",
      "Epoch: 1621/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5775\n",
      "Epoch: 1622/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5776\n",
      "Epoch: 1623/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5777\n",
      "Epoch: 1624/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5778\n",
      "Epoch: 1625/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5779\n",
      "Epoch: 1626/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5780\n",
      "Epoch: 1627/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5780\n",
      "Epoch: 1628/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5781\n",
      "Epoch: 1629/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5782\n",
      "Epoch: 1630/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5783\n",
      "Epoch: 1631/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5784\n",
      "Epoch: 1632/8000, Train Loss: 0.2937\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5784\n",
      "Epoch: 1633/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5785\n",
      "Epoch: 1634/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5786\n",
      "Epoch: 1635/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5787\n",
      "Epoch: 1636/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5788\n",
      "Epoch: 1637/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5788\n",
      "Epoch: 1638/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5789\n",
      "Epoch: 1639/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5790\n",
      "Epoch: 1640/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5791\n",
      "Epoch: 1641/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5792\n",
      "Epoch: 1642/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5792\n",
      "Epoch: 1643/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5793\n",
      "Epoch: 1644/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5794\n",
      "Epoch: 1645/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5795\n",
      "Epoch: 1646/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5796\n",
      "Epoch: 1647/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5796\n",
      "Epoch: 1648/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5797\n",
      "Epoch: 1649/8000, Train Loss: 0.2936\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5798\n",
      "Epoch: 1650/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5799\n",
      "Epoch: 1651/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5800\n",
      "Epoch: 1652/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5801\n",
      "Epoch: 1653/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5801\n",
      "Epoch: 1654/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5802\n",
      "Epoch: 1655/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5803\n",
      "Epoch: 1656/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5804\n",
      "Epoch: 1657/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5805\n",
      "Epoch: 1658/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5805\n",
      "Epoch: 1659/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5806\n",
      "Epoch: 1660/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5807\n",
      "Epoch: 1661/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5808\n",
      "Epoch: 1662/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5809\n",
      "Epoch: 1663/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5809\n",
      "Epoch: 1664/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5810\n",
      "Epoch: 1665/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5811\n",
      "Epoch: 1666/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5812\n",
      "Epoch: 1667/8000, Train Loss: 0.2935\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5813\n",
      "Epoch: 1668/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5813\n",
      "Epoch: 1669/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5814\n",
      "Epoch: 1670/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5815\n",
      "Epoch: 1671/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5816\n",
      "Epoch: 1672/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5817\n",
      "Epoch: 1673/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5817\n",
      "Epoch: 1674/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5818\n",
      "Epoch: 1675/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5819\n",
      "Epoch: 1676/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5820\n",
      "Epoch: 1677/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5821\n",
      "Epoch: 1678/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5821\n",
      "Epoch: 1679/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5822\n",
      "Epoch: 1680/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5823\n",
      "Epoch: 1681/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5824\n",
      "Epoch: 1682/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5825\n",
      "Epoch: 1683/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5825\n",
      "Epoch: 1684/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5826\n",
      "Epoch: 1685/8000, Train Loss: 0.2934\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5827\n",
      "Epoch: 1686/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5828\n",
      "Epoch: 1687/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5829\n",
      "Epoch: 1688/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5829\n",
      "Epoch: 1689/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5830\n",
      "Epoch: 1690/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5831\n",
      "Epoch: 1691/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5832\n",
      "Epoch: 1692/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5833\n",
      "Epoch: 1693/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5833\n",
      "Epoch: 1694/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5834\n",
      "Epoch: 1695/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5835\n",
      "Epoch: 1696/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5836\n",
      "Epoch: 1697/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5837\n",
      "Epoch: 1698/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5837\n",
      "Epoch: 1699/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5838\n",
      "Epoch: 1700/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5839\n",
      "Epoch: 1701/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5840\n",
      "Epoch: 1702/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5841\n",
      "Epoch: 1703/8000, Train Loss: 0.2933\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5841\n",
      "Epoch: 1704/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5842\n",
      "Epoch: 1705/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5843\n",
      "Epoch: 1706/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5844\n",
      "Epoch: 1707/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5845\n",
      "Epoch: 1708/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5845\n",
      "Epoch: 1709/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5846\n",
      "Epoch: 1710/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5847\n",
      "Epoch: 1711/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5848\n",
      "Epoch: 1712/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5849\n",
      "Epoch: 1713/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5849\n",
      "Epoch: 1714/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5850\n",
      "Epoch: 1715/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5851\n",
      "Epoch: 1716/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5852\n",
      "Epoch: 1717/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5852\n",
      "Epoch: 1718/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5853\n",
      "Epoch: 1719/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5854\n",
      "Epoch: 1720/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5855\n",
      "Epoch: 1721/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5856\n",
      "Epoch: 1722/8000, Train Loss: 0.2932\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5856\n",
      "Epoch: 1723/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5857\n",
      "Epoch: 1724/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5858\n",
      "Epoch: 1725/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5859\n",
      "Epoch: 1726/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5860\n",
      "Epoch: 1727/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5860\n",
      "Epoch: 1728/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5861\n",
      "Epoch: 1729/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5862\n",
      "Epoch: 1730/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5863\n",
      "Epoch: 1731/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5864\n",
      "Epoch: 1732/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5864\n",
      "Epoch: 1733/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5865\n",
      "Epoch: 1734/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5866\n",
      "Epoch: 1735/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5867\n",
      "Epoch: 1736/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5868\n",
      "Epoch: 1737/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5868\n",
      "Epoch: 1738/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5869\n",
      "Epoch: 1739/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5870\n",
      "Epoch: 1740/8000, Train Loss: 0.2931\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5871\n",
      "Epoch: 1741/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5871\n",
      "Epoch: 1742/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5872\n",
      "Epoch: 1743/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5873\n",
      "Epoch: 1744/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5874\n",
      "Epoch: 1745/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5875\n",
      "Epoch: 1746/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5875\n",
      "Epoch: 1747/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5876\n",
      "Epoch: 1748/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5877\n",
      "Epoch: 1749/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5878\n",
      "Epoch: 1750/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5879\n",
      "Epoch: 1751/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5879\n",
      "Epoch: 1752/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5880\n",
      "Epoch: 1753/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5881\n",
      "Epoch: 1754/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5882\n",
      "Epoch: 1755/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5883\n",
      "Epoch: 1756/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5883\n",
      "Epoch: 1757/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5884\n",
      "Epoch: 1758/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5885\n",
      "Epoch: 1759/8000, Train Loss: 0.2930\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5886\n",
      "Epoch: 1760/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5886\n",
      "Epoch: 1761/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5887\n",
      "Epoch: 1762/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5888\n",
      "Epoch: 1763/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5889\n",
      "Epoch: 1764/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5890\n",
      "Epoch: 1765/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5890\n",
      "Epoch: 1766/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5891\n",
      "Epoch: 1767/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5892\n",
      "Epoch: 1768/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5893\n",
      "Epoch: 1769/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5894\n",
      "Epoch: 1770/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5894\n",
      "Epoch: 1771/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5895\n",
      "Epoch: 1772/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5896\n",
      "Epoch: 1773/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5897\n",
      "Epoch: 1774/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5897\n",
      "Epoch: 1775/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5898\n",
      "Epoch: 1776/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5899\n",
      "Epoch: 1777/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5900\n",
      "Epoch: 1778/8000, Train Loss: 0.2929\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5901\n",
      "Epoch: 1779/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5901\n",
      "Epoch: 1780/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5902\n",
      "Epoch: 1781/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5903\n",
      "Epoch: 1782/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5904\n",
      "Epoch: 1783/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5904\n",
      "Epoch: 1784/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5905\n",
      "Epoch: 1785/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5906\n",
      "Epoch: 1786/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5907\n",
      "Epoch: 1787/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5908\n",
      "Epoch: 1788/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5908\n",
      "Epoch: 1789/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5909\n",
      "Epoch: 1790/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5910\n",
      "Epoch: 1791/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5911\n",
      "Epoch: 1792/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5912\n",
      "Epoch: 1793/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5912\n",
      "Epoch: 1794/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5913\n",
      "Epoch: 1795/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5914\n",
      "Epoch: 1796/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5915\n",
      "Epoch: 1797/8000, Train Loss: 0.2928\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5915\n",
      "Epoch: 1798/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5916\n",
      "Epoch: 1799/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5917\n",
      "Epoch: 1800/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5918\n",
      "Epoch: 1801/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5919\n",
      "Epoch: 1802/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5919\n",
      "Epoch: 1803/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5920\n",
      "Epoch: 1804/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5921\n",
      "Epoch: 1805/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5922\n",
      "Epoch: 1806/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5922\n",
      "Epoch: 1807/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5923\n",
      "Epoch: 1808/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5924\n",
      "Epoch: 1809/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5925\n",
      "Epoch: 1810/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5926\n",
      "Epoch: 1811/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5926\n",
      "Epoch: 1812/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5927\n",
      "Epoch: 1813/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5928\n",
      "Epoch: 1814/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5929\n",
      "Epoch: 1815/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5929\n",
      "Epoch: 1816/8000, Train Loss: 0.2927\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5930\n",
      "Epoch: 1817/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5931\n",
      "Epoch: 1818/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5932\n",
      "Epoch: 1819/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5933\n",
      "Epoch: 1820/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5933\n",
      "Epoch: 1821/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5934\n",
      "Epoch: 1822/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5935\n",
      "Epoch: 1823/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5936\n",
      "Epoch: 1824/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5936\n",
      "Epoch: 1825/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5937\n",
      "Epoch: 1826/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5938\n",
      "Epoch: 1827/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5939\n",
      "Epoch: 1828/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5940\n",
      "Epoch: 1829/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5940\n",
      "Epoch: 1830/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5941\n",
      "Epoch: 1831/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5942\n",
      "Epoch: 1832/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5943\n",
      "Epoch: 1833/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5943\n",
      "Epoch: 1834/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5944\n",
      "Epoch: 1835/8000, Train Loss: 0.2926\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5945\n",
      "Epoch: 1836/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5946\n",
      "Epoch: 1837/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5947\n",
      "Epoch: 1838/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5947\n",
      "Epoch: 1839/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5948\n",
      "Epoch: 1840/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5949\n",
      "Epoch: 1841/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5950\n",
      "Epoch: 1842/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5950\n",
      "Epoch: 1843/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5951\n",
      "Epoch: 1844/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5952\n",
      "Epoch: 1845/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5953\n",
      "Epoch: 1846/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5953\n",
      "Epoch: 1847/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5954\n",
      "Epoch: 1848/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5955\n",
      "Epoch: 1849/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5956\n",
      "Epoch: 1850/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5957\n",
      "Epoch: 1851/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5957\n",
      "Epoch: 1852/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5958\n",
      "Epoch: 1853/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5959\n",
      "Epoch: 1854/8000, Train Loss: 0.2925\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5960\n",
      "Epoch: 1855/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5960\n",
      "Epoch: 1856/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5961\n",
      "Epoch: 1857/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5962\n",
      "Epoch: 1858/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5963\n",
      "Epoch: 1859/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5964\n",
      "Epoch: 1860/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5964\n",
      "Epoch: 1861/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5965\n",
      "Epoch: 1862/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5966\n",
      "Epoch: 1863/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5967\n",
      "Epoch: 1864/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5967\n",
      "Epoch: 1865/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5968\n",
      "Epoch: 1866/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5969\n",
      "Epoch: 1867/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5970\n",
      "Epoch: 1868/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5970\n",
      "Epoch: 1869/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5971\n",
      "Epoch: 1870/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5972\n",
      "Epoch: 1871/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5973\n",
      "Epoch: 1872/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5974\n",
      "Epoch: 1873/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5974\n",
      "Epoch: 1874/8000, Train Loss: 0.2924\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5975\n",
      "Epoch: 1875/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5976\n",
      "Epoch: 1876/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5977\n",
      "Epoch: 1877/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5977\n",
      "Epoch: 1878/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5978\n",
      "Epoch: 1879/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5979\n",
      "Epoch: 1880/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5980\n",
      "Epoch: 1881/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5980\n",
      "Epoch: 1882/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5981\n",
      "Epoch: 1883/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5982\n",
      "Epoch: 1884/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5983\n",
      "Epoch: 1885/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5984\n",
      "Epoch: 1886/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5984\n",
      "Epoch: 1887/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5985\n",
      "Epoch: 1888/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5986\n",
      "Epoch: 1889/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5987\n",
      "Epoch: 1890/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5987\n",
      "Epoch: 1891/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5988\n",
      "Epoch: 1892/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5989\n",
      "Epoch: 1893/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5990\n",
      "Epoch: 1894/8000, Train Loss: 0.2923\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5990\n",
      "Epoch: 1895/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5991\n",
      "Epoch: 1896/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5992\n",
      "Epoch: 1897/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5993\n",
      "Epoch: 1898/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5993\n",
      "Epoch: 1899/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5994\n",
      "Epoch: 1900/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5995\n",
      "Epoch: 1901/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5996\n",
      "Epoch: 1902/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5997\n",
      "Epoch: 1903/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5997\n",
      "Epoch: 1904/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5998\n",
      "Epoch: 1905/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.5999\n",
      "Epoch: 1906/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6000\n",
      "Epoch: 1907/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6000\n",
      "Epoch: 1908/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6001\n",
      "Epoch: 1909/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6002\n",
      "Epoch: 1910/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6003\n",
      "Epoch: 1911/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6003\n",
      "Epoch: 1912/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6004\n",
      "Epoch: 1913/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6005\n",
      "Epoch: 1914/8000, Train Loss: 0.2922\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6006\n",
      "Epoch: 1915/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6006\n",
      "Epoch: 1916/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6007\n",
      "Epoch: 1917/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6008\n",
      "Epoch: 1918/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6009\n",
      "Epoch: 1919/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6010\n",
      "Epoch: 1920/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6010\n",
      "Epoch: 1921/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6011\n",
      "Epoch: 1922/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6012\n",
      "Epoch: 1923/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6013\n",
      "Epoch: 1924/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6013\n",
      "Epoch: 1925/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6014\n",
      "Epoch: 1926/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6015\n",
      "Epoch: 1927/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6016\n",
      "Epoch: 1928/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6016\n",
      "Epoch: 1929/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6017\n",
      "Epoch: 1930/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6018\n",
      "Epoch: 1931/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6019\n",
      "Epoch: 1932/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6019\n",
      "Epoch: 1933/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6020\n",
      "Epoch: 1934/8000, Train Loss: 0.2921\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6021\n",
      "Epoch: 1935/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6022\n",
      "Epoch: 1936/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6022\n",
      "Epoch: 1937/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6023\n",
      "Epoch: 1938/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6024\n",
      "Epoch: 1939/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6025\n",
      "Epoch: 1940/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6026\n",
      "Epoch: 1941/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6026\n",
      "Epoch: 1942/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6027\n",
      "Epoch: 1943/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6028\n",
      "Epoch: 1944/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6029\n",
      "Epoch: 1945/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6029\n",
      "Epoch: 1946/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6030\n",
      "Epoch: 1947/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6031\n",
      "Epoch: 1948/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6032\n",
      "Epoch: 1949/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6032\n",
      "Epoch: 1950/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6033\n",
      "Epoch: 1951/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6034\n",
      "Epoch: 1952/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6035\n",
      "Epoch: 1953/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6035\n",
      "Epoch: 1954/8000, Train Loss: 0.2920\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6036\n",
      "Epoch: 1955/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6037\n",
      "Epoch: 1956/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6038\n",
      "Epoch: 1957/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6038\n",
      "Epoch: 1958/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6039\n",
      "Epoch: 1959/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6040\n",
      "Epoch: 1960/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6041\n",
      "Epoch: 1961/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6041\n",
      "Epoch: 1962/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6042\n",
      "Epoch: 1963/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6043\n",
      "Epoch: 1964/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6044\n",
      "Epoch: 1965/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6044\n",
      "Epoch: 1966/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6045\n",
      "Epoch: 1967/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6046\n",
      "Epoch: 1968/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6047\n",
      "Epoch: 1969/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6047\n",
      "Epoch: 1970/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6048\n",
      "Epoch: 1971/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6049\n",
      "Epoch: 1972/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6050\n",
      "Epoch: 1973/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6051\n",
      "Epoch: 1974/8000, Train Loss: 0.2919\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6051\n",
      "Epoch: 1975/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6052\n",
      "Epoch: 1976/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6053\n",
      "Epoch: 1977/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6054\n",
      "Epoch: 1978/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6054\n",
      "Epoch: 1979/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6055\n",
      "Epoch: 1980/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6056\n",
      "Epoch: 1981/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6057\n",
      "Epoch: 1982/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6057\n",
      "Epoch: 1983/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6058\n",
      "Epoch: 1984/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6059\n",
      "Epoch: 1985/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6060\n",
      "Epoch: 1986/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6060\n",
      "Epoch: 1987/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6061\n",
      "Epoch: 1988/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6062\n",
      "Epoch: 1989/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6063\n",
      "Epoch: 1990/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6063\n",
      "Epoch: 1991/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6064\n",
      "Epoch: 1992/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6065\n",
      "Epoch: 1993/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6066\n",
      "Epoch: 1994/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6066\n",
      "Epoch: 1995/8000, Train Loss: 0.2918\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6067\n",
      "Epoch: 1996/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6068\n",
      "Epoch: 1997/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6069\n",
      "Epoch: 1998/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6069\n",
      "Epoch: 1999/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6070\n",
      "Epoch: 2000/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6071\n",
      "Epoch: 2001/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6072\n",
      "Epoch: 2002/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6072\n",
      "Epoch: 2003/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6073\n",
      "Epoch: 2004/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6074\n",
      "Epoch: 2005/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6075\n",
      "Epoch: 2006/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6075\n",
      "Epoch: 2007/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6076\n",
      "Epoch: 2008/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6077\n",
      "Epoch: 2009/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6078\n",
      "Epoch: 2010/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6078\n",
      "Epoch: 2011/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6079\n",
      "Epoch: 2012/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6080\n",
      "Epoch: 2013/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6081\n",
      "Epoch: 2014/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6081\n",
      "Epoch: 2015/8000, Train Loss: 0.2917\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6082\n",
      "Epoch: 2016/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6083\n",
      "Epoch: 2017/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6084\n",
      "Epoch: 2018/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6084\n",
      "Epoch: 2019/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6085\n",
      "Epoch: 2020/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6086\n",
      "Epoch: 2021/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6087\n",
      "Epoch: 2022/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6087\n",
      "Epoch: 2023/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6088\n",
      "Epoch: 2024/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6089\n",
      "Epoch: 2025/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6090\n",
      "Epoch: 2026/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6090\n",
      "Epoch: 2027/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6091\n",
      "Epoch: 2028/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6092\n",
      "Epoch: 2029/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6093\n",
      "Epoch: 2030/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6093\n",
      "Epoch: 2031/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6094\n",
      "Epoch: 2032/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6095\n",
      "Epoch: 2033/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6096\n",
      "Epoch: 2034/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6096\n",
      "Epoch: 2035/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6097\n",
      "Epoch: 2036/8000, Train Loss: 0.2916\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6098\n",
      "Epoch: 2037/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6099\n",
      "Epoch: 2038/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6099\n",
      "Epoch: 2039/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6100\n",
      "Epoch: 2040/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6101\n",
      "Epoch: 2041/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6102\n",
      "Epoch: 2042/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6102\n",
      "Epoch: 2043/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6103\n",
      "Epoch: 2044/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6104\n",
      "Epoch: 2045/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6105\n",
      "Epoch: 2046/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6105\n",
      "Epoch: 2047/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6106\n",
      "Epoch: 2048/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6107\n",
      "Epoch: 2049/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6108\n",
      "Epoch: 2050/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6108\n",
      "Epoch: 2051/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6109\n",
      "Epoch: 2052/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6110\n",
      "Epoch: 2053/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6111\n",
      "Epoch: 2054/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6111\n",
      "Epoch: 2055/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6112\n",
      "Epoch: 2056/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6113\n",
      "Epoch: 2057/8000, Train Loss: 0.2915\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6113\n",
      "Epoch: 2058/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6114\n",
      "Epoch: 2059/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6115\n",
      "Epoch: 2060/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6116\n",
      "Epoch: 2061/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6116\n",
      "Epoch: 2062/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6117\n",
      "Epoch: 2063/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6118\n",
      "Epoch: 2064/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6119\n",
      "Epoch: 2065/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6119\n",
      "Epoch: 2066/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6120\n",
      "Epoch: 2067/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6121\n",
      "Epoch: 2068/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6122\n",
      "Epoch: 2069/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6122\n",
      "Epoch: 2070/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6123\n",
      "Epoch: 2071/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6124\n",
      "Epoch: 2072/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6125\n",
      "Epoch: 2073/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6125\n",
      "Epoch: 2074/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6126\n",
      "Epoch: 2075/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6127\n",
      "Epoch: 2076/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6128\n",
      "Epoch: 2077/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6128\n",
      "Epoch: 2078/8000, Train Loss: 0.2914\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6129\n",
      "Epoch: 2079/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6130\n",
      "Epoch: 2080/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6131\n",
      "Epoch: 2081/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6131\n",
      "Epoch: 2082/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6132\n",
      "Epoch: 2083/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6133\n",
      "Epoch: 2084/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6134\n",
      "Epoch: 2085/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6134\n",
      "Epoch: 2086/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6135\n",
      "Epoch: 2087/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6136\n",
      "Epoch: 2088/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6137\n",
      "Epoch: 2089/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6137\n",
      "Epoch: 2090/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6138\n",
      "Epoch: 2091/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6139\n",
      "Epoch: 2092/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6139\n",
      "Epoch: 2093/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6140\n",
      "Epoch: 2094/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6141\n",
      "Epoch: 2095/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6142\n",
      "Epoch: 2096/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6142\n",
      "Epoch: 2097/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6143\n",
      "Epoch: 2098/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6144\n",
      "Epoch: 2099/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6145\n",
      "Epoch: 2100/8000, Train Loss: 0.2913\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6145\n",
      "Epoch: 2101/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6146\n",
      "Epoch: 2102/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6147\n",
      "Epoch: 2103/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6148\n",
      "Epoch: 2104/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6148\n",
      "Epoch: 2105/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6149\n",
      "Epoch: 2106/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6150\n",
      "Epoch: 2107/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6151\n",
      "Epoch: 2108/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6151\n",
      "Epoch: 2109/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6152\n",
      "Epoch: 2110/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6153\n",
      "Epoch: 2111/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6154\n",
      "Epoch: 2112/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6154\n",
      "Epoch: 2113/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6155\n",
      "Epoch: 2114/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6156\n",
      "Epoch: 2115/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6156\n",
      "Epoch: 2116/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6157\n",
      "Epoch: 2117/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6158\n",
      "Epoch: 2118/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6159\n",
      "Epoch: 2119/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6159\n",
      "Epoch: 2120/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6160\n",
      "Epoch: 2121/8000, Train Loss: 0.2912\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6161\n",
      "Epoch: 2122/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6162\n",
      "Epoch: 2123/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6162\n",
      "Epoch: 2124/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6163\n",
      "Epoch: 2125/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6164\n",
      "Epoch: 2126/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6165\n",
      "Epoch: 2127/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6165\n",
      "Epoch: 2128/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6166\n",
      "Epoch: 2129/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6167\n",
      "Epoch: 2130/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6168\n",
      "Epoch: 2131/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6168\n",
      "Epoch: 2132/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6169\n",
      "Epoch: 2133/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6170\n",
      "Epoch: 2134/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6170\n",
      "Epoch: 2135/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6171\n",
      "Epoch: 2136/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6172\n",
      "Epoch: 2137/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6173\n",
      "Epoch: 2138/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6173\n",
      "Epoch: 2139/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6174\n",
      "Epoch: 2140/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6175\n",
      "Epoch: 2141/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6176\n",
      "Epoch: 2142/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6176\n",
      "Epoch: 2143/8000, Train Loss: 0.2911\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6177\n",
      "Epoch: 2144/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6178\n",
      "Epoch: 2145/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6179\n",
      "Epoch: 2146/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6179\n",
      "Epoch: 2147/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6180\n",
      "Epoch: 2148/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6181\n",
      "Epoch: 2149/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6181\n",
      "Epoch: 2150/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6182\n",
      "Epoch: 2151/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6183\n",
      "Epoch: 2152/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6184\n",
      "Epoch: 2153/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6184\n",
      "Epoch: 2154/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6185\n",
      "Epoch: 2155/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6186\n",
      "Epoch: 2156/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6187\n",
      "Epoch: 2157/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6187\n",
      "Epoch: 2158/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6188\n",
      "Epoch: 2159/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6189\n",
      "Epoch: 2160/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6190\n",
      "Epoch: 2161/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6190\n",
      "Epoch: 2162/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6191\n",
      "Epoch: 2163/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6192\n",
      "Epoch: 2164/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6192\n",
      "Epoch: 2165/8000, Train Loss: 0.2910\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6193\n",
      "Epoch: 2166/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6194\n",
      "Epoch: 2167/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6195\n",
      "Epoch: 2168/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6195\n",
      "Epoch: 2169/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6196\n",
      "Epoch: 2170/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6197\n",
      "Epoch: 2171/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6198\n",
      "Epoch: 2172/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6198\n",
      "Epoch: 2173/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6199\n",
      "Epoch: 2174/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6200\n",
      "Epoch: 2175/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6201\n",
      "Epoch: 2176/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6201\n",
      "Epoch: 2177/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6202\n",
      "Epoch: 2178/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6203\n",
      "Epoch: 2179/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6203\n",
      "Epoch: 2180/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6204\n",
      "Epoch: 2181/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6205\n",
      "Epoch: 2182/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6206\n",
      "Epoch: 2183/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6206\n",
      "Epoch: 2184/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6207\n",
      "Epoch: 2185/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6208\n",
      "Epoch: 2186/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6209\n",
      "Epoch: 2187/8000, Train Loss: 0.2909\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6209\n",
      "Epoch: 2188/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6210\n",
      "Epoch: 2189/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6211\n",
      "Epoch: 2190/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6211\n",
      "Epoch: 2191/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6212\n",
      "Epoch: 2192/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6213\n",
      "Epoch: 2193/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6214\n",
      "Epoch: 2194/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6214\n",
      "Epoch: 2195/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6215\n",
      "Epoch: 2196/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6216\n",
      "Epoch: 2197/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6217\n",
      "Epoch: 2198/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6217\n",
      "Epoch: 2199/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6218\n",
      "Epoch: 2200/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6219\n",
      "Epoch: 2201/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6220\n",
      "Epoch: 2202/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6220\n",
      "Epoch: 2203/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6221\n",
      "Epoch: 2204/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6222\n",
      "Epoch: 2205/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6222\n",
      "Epoch: 2206/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6223\n",
      "Epoch: 2207/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6224\n",
      "Epoch: 2208/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6225\n",
      "Epoch: 2209/8000, Train Loss: 0.2908\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6225\n",
      "Epoch: 2210/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6226\n",
      "Epoch: 2211/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6227\n",
      "Epoch: 2212/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6228\n",
      "Epoch: 2213/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6228\n",
      "Epoch: 2214/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6229\n",
      "Epoch: 2215/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6230\n",
      "Epoch: 2216/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6230\n",
      "Epoch: 2217/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6231\n",
      "Epoch: 2218/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6232\n",
      "Epoch: 2219/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6233\n",
      "Epoch: 2220/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6233\n",
      "Epoch: 2221/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6234\n",
      "Epoch: 2222/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6235\n",
      "Epoch: 2223/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6236\n",
      "Epoch: 2224/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6236\n",
      "Epoch: 2225/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6237\n",
      "Epoch: 2226/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6238\n",
      "Epoch: 2227/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6238\n",
      "Epoch: 2228/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6239\n",
      "Epoch: 2229/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6240\n",
      "Epoch: 2230/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6241\n",
      "Epoch: 2231/8000, Train Loss: 0.2907\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6241\n",
      "Epoch: 2232/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6242\n",
      "Epoch: 2233/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6243\n",
      "Epoch: 2234/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6243\n",
      "Epoch: 2235/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6244\n",
      "Epoch: 2236/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6245\n",
      "Epoch: 2237/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6246\n",
      "Epoch: 2238/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6246\n",
      "Epoch: 2239/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6247\n",
      "Epoch: 2240/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6248\n",
      "Epoch: 2241/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6249\n",
      "Epoch: 2242/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6249\n",
      "Epoch: 2243/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6250\n",
      "Epoch: 2244/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6251\n",
      "Epoch: 2245/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6251\n",
      "Epoch: 2246/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6252\n",
      "Epoch: 2247/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6253\n",
      "Epoch: 2248/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6254\n",
      "Epoch: 2249/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6254\n",
      "Epoch: 2250/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6255\n",
      "Epoch: 2251/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6256\n",
      "Epoch: 2252/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6257\n",
      "Epoch: 2253/8000, Train Loss: 0.2906\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6257\n",
      "Epoch: 2254/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6258\n",
      "Epoch: 2255/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6259\n",
      "Epoch: 2256/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6259\n",
      "Epoch: 2257/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6260\n",
      "Epoch: 2258/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6261\n",
      "Epoch: 2259/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6262\n",
      "Epoch: 2260/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6262\n",
      "Epoch: 2261/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6263\n",
      "Epoch: 2262/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6264\n",
      "Epoch: 2263/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6264\n",
      "Epoch: 2264/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6265\n",
      "Epoch: 2265/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6266\n",
      "Epoch: 2266/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6267\n",
      "Epoch: 2267/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6267\n",
      "Epoch: 2268/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6268\n",
      "Epoch: 2269/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6269\n",
      "Epoch: 2270/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6270\n",
      "Epoch: 2271/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6270\n",
      "Epoch: 2272/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6271\n",
      "Epoch: 2273/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6272\n",
      "Epoch: 2274/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6272\n",
      "Epoch: 2275/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6273\n",
      "Epoch: 2276/8000, Train Loss: 0.2905\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6274\n",
      "Epoch: 2277/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6275\n",
      "Epoch: 2278/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6275\n",
      "Epoch: 2279/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6276\n",
      "Epoch: 2280/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6277\n",
      "Epoch: 2281/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6277\n",
      "Epoch: 2282/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6278\n",
      "Epoch: 2283/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6279\n",
      "Epoch: 2284/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6280\n",
      "Epoch: 2285/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6280\n",
      "Epoch: 2286/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6281\n",
      "Epoch: 2287/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6282\n",
      "Epoch: 2288/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6282\n",
      "Epoch: 2289/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6283\n",
      "Epoch: 2290/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6284\n",
      "Epoch: 2291/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6285\n",
      "Epoch: 2292/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6285\n",
      "Epoch: 2293/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6286\n",
      "Epoch: 2294/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6287\n",
      "Epoch: 2295/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6288\n",
      "Epoch: 2296/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6288\n",
      "Epoch: 2297/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6289\n",
      "Epoch: 2298/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6290\n",
      "Epoch: 2299/8000, Train Loss: 0.2904\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6290\n",
      "Epoch: 2300/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6291\n",
      "Epoch: 2301/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6292\n",
      "Epoch: 2302/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6293\n",
      "Epoch: 2303/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6293\n",
      "Epoch: 2304/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6294\n",
      "Epoch: 2305/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6295\n",
      "Epoch: 2306/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6295\n",
      "Epoch: 2307/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6296\n",
      "Epoch: 2308/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6297\n",
      "Epoch: 2309/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6298\n",
      "Epoch: 2310/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6298\n",
      "Epoch: 2311/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6299\n",
      "Epoch: 2312/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6300\n",
      "Epoch: 2313/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6300\n",
      "Epoch: 2314/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6301\n",
      "Epoch: 2315/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6302\n",
      "Epoch: 2316/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6303\n",
      "Epoch: 2317/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6303\n",
      "Epoch: 2318/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6304\n",
      "Epoch: 2319/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6305\n",
      "Epoch: 2320/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6305\n",
      "Epoch: 2321/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6306\n",
      "Epoch: 2322/8000, Train Loss: 0.2903\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6307\n",
      "Epoch: 2323/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6308\n",
      "Epoch: 2324/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6308\n",
      "Epoch: 2325/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6309\n",
      "Epoch: 2326/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6310\n",
      "Epoch: 2327/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6310\n",
      "Epoch: 2328/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6311\n",
      "Epoch: 2329/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6312\n",
      "Epoch: 2330/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6313\n",
      "Epoch: 2331/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6313\n",
      "Epoch: 2332/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6314\n",
      "Epoch: 2333/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6315\n",
      "Epoch: 2334/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6315\n",
      "Epoch: 2335/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6316\n",
      "Epoch: 2336/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6317\n",
      "Epoch: 2337/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6318\n",
      "Epoch: 2338/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6318\n",
      "Epoch: 2339/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6319\n",
      "Epoch: 2340/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6320\n",
      "Epoch: 2341/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6320\n",
      "Epoch: 2342/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6321\n",
      "Epoch: 2343/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6322\n",
      "Epoch: 2344/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6323\n",
      "Epoch: 2345/8000, Train Loss: 0.2902\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6323\n",
      "Epoch: 2346/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6324\n",
      "Epoch: 2347/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6325\n",
      "Epoch: 2348/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6325\n",
      "Epoch: 2349/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6326\n",
      "Epoch: 2350/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6327\n",
      "Epoch: 2351/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6328\n",
      "Epoch: 2352/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6328\n",
      "Epoch: 2353/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6329\n",
      "Epoch: 2354/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6330\n",
      "Epoch: 2355/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6330\n",
      "Epoch: 2356/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6331\n",
      "Epoch: 2357/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6332\n",
      "Epoch: 2358/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6333\n",
      "Epoch: 2359/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6333\n",
      "Epoch: 2360/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6334\n",
      "Epoch: 2361/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6335\n",
      "Epoch: 2362/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6335\n",
      "Epoch: 2363/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6336\n",
      "Epoch: 2364/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6337\n",
      "Epoch: 2365/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6338\n",
      "Epoch: 2366/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6338\n",
      "Epoch: 2367/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6339\n",
      "Epoch: 2368/8000, Train Loss: 0.2901\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6340\n",
      "Epoch: 2369/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6340\n",
      "Epoch: 2370/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6341\n",
      "Epoch: 2371/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6342\n",
      "Epoch: 2372/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6343\n",
      "Epoch: 2373/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6343\n",
      "Epoch: 2374/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6344\n",
      "Epoch: 2375/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6345\n",
      "Epoch: 2376/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6345\n",
      "Epoch: 2377/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6346\n",
      "Epoch: 2378/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6347\n",
      "Epoch: 2379/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6348\n",
      "Epoch: 2380/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6348\n",
      "Epoch: 2381/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6349\n",
      "Epoch: 2382/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6350\n",
      "Epoch: 2383/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6350\n",
      "Epoch: 2384/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6351\n",
      "Epoch: 2385/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6352\n",
      "Epoch: 2386/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6353\n",
      "Epoch: 2387/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6353\n",
      "Epoch: 2388/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6354\n",
      "Epoch: 2389/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6355\n",
      "Epoch: 2390/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6355\n",
      "Epoch: 2391/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6356\n",
      "Epoch: 2392/8000, Train Loss: 0.2900\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6357\n",
      "Epoch: 2393/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6357\n",
      "Epoch: 2394/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6358\n",
      "Epoch: 2395/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6359\n",
      "Epoch: 2396/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6360\n",
      "Epoch: 2397/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6360\n",
      "Epoch: 2398/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6361\n",
      "Epoch: 2399/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6362\n",
      "Epoch: 2400/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6362\n",
      "Epoch: 2401/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6363\n",
      "Epoch: 2402/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6364\n",
      "Epoch: 2403/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6365\n",
      "Epoch: 2404/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6365\n",
      "Epoch: 2405/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6366\n",
      "Epoch: 2406/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6367\n",
      "Epoch: 2407/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6367\n",
      "Epoch: 2408/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6368\n",
      "Epoch: 2409/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6369\n",
      "Epoch: 2410/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6370\n",
      "Epoch: 2411/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6370\n",
      "Epoch: 2412/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6371\n",
      "Epoch: 2413/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6372\n",
      "Epoch: 2414/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6372\n",
      "Epoch: 2415/8000, Train Loss: 0.2899\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6373\n",
      "Epoch: 2416/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6374\n",
      "Epoch: 2417/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6374\n",
      "Epoch: 2418/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6375\n",
      "Epoch: 2419/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6376\n",
      "Epoch: 2420/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6377\n",
      "Epoch: 2421/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6377\n",
      "Epoch: 2422/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6378\n",
      "Epoch: 2423/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6379\n",
      "Epoch: 2424/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6379\n",
      "Epoch: 2425/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6380\n",
      "Epoch: 2426/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6381\n",
      "Epoch: 2427/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6382\n",
      "Epoch: 2428/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6382\n",
      "Epoch: 2429/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6383\n",
      "Epoch: 2430/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6384\n",
      "Epoch: 2431/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6384\n",
      "Epoch: 2432/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6385\n",
      "Epoch: 2433/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6386\n",
      "Epoch: 2434/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6386\n",
      "Epoch: 2435/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6387\n",
      "Epoch: 2436/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6388\n",
      "Epoch: 2437/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6389\n",
      "Epoch: 2438/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6389\n",
      "Epoch: 2439/8000, Train Loss: 0.2898\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6390\n",
      "Epoch: 2440/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6391\n",
      "Epoch: 2441/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6391\n",
      "Epoch: 2442/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6392\n",
      "Epoch: 2443/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6393\n",
      "Epoch: 2444/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6394\n",
      "Epoch: 2445/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6394\n",
      "Epoch: 2446/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6395\n",
      "Epoch: 2447/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6396\n",
      "Epoch: 2448/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6396\n",
      "Epoch: 2449/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6397\n",
      "Epoch: 2450/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6398\n",
      "Epoch: 2451/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6398\n",
      "Epoch: 2452/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6399\n",
      "Epoch: 2453/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6400\n",
      "Epoch: 2454/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6401\n",
      "Epoch: 2455/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6401\n",
      "Epoch: 2456/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6402\n",
      "Epoch: 2457/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6403\n",
      "Epoch: 2458/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6403\n",
      "Epoch: 2459/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6404\n",
      "Epoch: 2460/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6405\n",
      "Epoch: 2461/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6406\n",
      "Epoch: 2462/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6406\n",
      "Epoch: 2463/8000, Train Loss: 0.2897\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6407\n",
      "Epoch: 2464/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6408\n",
      "Epoch: 2465/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6408\n",
      "Epoch: 2466/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6409\n",
      "Epoch: 2467/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6410\n",
      "Epoch: 2468/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6410\n",
      "Epoch: 2469/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6411\n",
      "Epoch: 2470/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6412\n",
      "Epoch: 2471/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6413\n",
      "Epoch: 2472/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6413\n",
      "Epoch: 2473/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6414\n",
      "Epoch: 2474/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6415\n",
      "Epoch: 2475/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6415\n",
      "Epoch: 2476/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6416\n",
      "Epoch: 2477/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6417\n",
      "Epoch: 2478/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6417\n",
      "Epoch: 2479/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6418\n",
      "Epoch: 2480/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6419\n",
      "Epoch: 2481/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6420\n",
      "Epoch: 2482/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6420\n",
      "Epoch: 2483/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6421\n",
      "Epoch: 2484/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6422\n",
      "Epoch: 2485/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6422\n",
      "Epoch: 2486/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6423\n",
      "Epoch: 2487/8000, Train Loss: 0.2896\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6424\n",
      "Epoch: 2488/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6424\n",
      "Epoch: 2489/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6425\n",
      "Epoch: 2490/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6426\n",
      "Epoch: 2491/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6427\n",
      "Epoch: 2492/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6427\n",
      "Epoch: 2493/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6428\n",
      "Epoch: 2494/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6429\n",
      "Epoch: 2495/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6429\n",
      "Epoch: 2496/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6430\n",
      "Epoch: 2497/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6431\n",
      "Epoch: 2498/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6431\n",
      "Epoch: 2499/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6432\n",
      "Epoch: 2500/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6433\n",
      "Epoch: 2501/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6434\n",
      "Epoch: 2502/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6434\n",
      "Epoch: 2503/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6435\n",
      "Epoch: 2504/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6436\n",
      "Epoch: 2505/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6436\n",
      "Epoch: 2506/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6437\n",
      "Epoch: 2507/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6438\n",
      "Epoch: 2508/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6438\n",
      "Epoch: 2509/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6439\n",
      "Epoch: 2510/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6440\n",
      "Epoch: 2511/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6441\n",
      "Epoch: 2512/8000, Train Loss: 0.2895\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6441\n",
      "Epoch: 2513/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6442\n",
      "Epoch: 2514/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6443\n",
      "Epoch: 2515/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6443\n",
      "Epoch: 2516/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6444\n",
      "Epoch: 2517/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6445\n",
      "Epoch: 2518/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6445\n",
      "Epoch: 2519/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6446\n",
      "Epoch: 2520/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6447\n",
      "Epoch: 2521/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6448\n",
      "Epoch: 2522/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6448\n",
      "Epoch: 2523/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6449\n",
      "Epoch: 2524/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6450\n",
      "Epoch: 2525/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6450\n",
      "Epoch: 2526/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6451\n",
      "Epoch: 2527/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6452\n",
      "Epoch: 2528/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6452\n",
      "Epoch: 2529/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6453\n",
      "Epoch: 2530/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6454\n",
      "Epoch: 2531/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6455\n",
      "Epoch: 2532/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6455\n",
      "Epoch: 2533/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6456\n",
      "Epoch: 2534/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6457\n",
      "Epoch: 2535/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6457\n",
      "Epoch: 2536/8000, Train Loss: 0.2894\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6458\n",
      "Epoch: 2537/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6459\n",
      "Epoch: 2538/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6459\n",
      "Epoch: 2539/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6460\n",
      "Epoch: 2540/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6461\n",
      "Epoch: 2541/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6462\n",
      "Epoch: 2542/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6462\n",
      "Epoch: 2543/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6463\n",
      "Epoch: 2544/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6464\n",
      "Epoch: 2545/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6464\n",
      "Epoch: 2546/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6465\n",
      "Epoch: 2547/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6466\n",
      "Epoch: 2548/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6466\n",
      "Epoch: 2549/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6467\n",
      "Epoch: 2550/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6468\n",
      "Epoch: 2551/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6469\n",
      "Epoch: 2552/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6469\n",
      "Epoch: 2553/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6470\n",
      "Epoch: 2554/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6471\n",
      "Epoch: 2555/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6471\n",
      "Epoch: 2556/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6472\n",
      "Epoch: 2557/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6473\n",
      "Epoch: 2558/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6473\n",
      "Epoch: 2559/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6474\n",
      "Epoch: 2560/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6475\n",
      "Epoch: 2561/8000, Train Loss: 0.2893\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6475\n",
      "Epoch: 2562/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6476\n",
      "Epoch: 2563/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6477\n",
      "Epoch: 2564/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6478\n",
      "Epoch: 2565/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6478\n",
      "Epoch: 2566/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6479\n",
      "Epoch: 2567/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6480\n",
      "Epoch: 2568/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6480\n",
      "Epoch: 2569/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6481\n",
      "Epoch: 2570/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6482\n",
      "Epoch: 2571/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6482\n",
      "Epoch: 2572/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6483\n",
      "Epoch: 2573/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6484\n",
      "Epoch: 2574/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6484\n",
      "Epoch: 2575/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6485\n",
      "Epoch: 2576/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6486\n",
      "Epoch: 2577/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6487\n",
      "Epoch: 2578/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6487\n",
      "Epoch: 2579/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6488\n",
      "Epoch: 2580/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6489\n",
      "Epoch: 2581/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6489\n",
      "Epoch: 2582/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6490\n",
      "Epoch: 2583/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6491\n",
      "Epoch: 2584/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6491\n",
      "Epoch: 2585/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6492\n",
      "Epoch: 2586/8000, Train Loss: 0.2892\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6493\n",
      "Epoch: 2587/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6494\n",
      "Epoch: 2588/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6494\n",
      "Epoch: 2589/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6495\n",
      "Epoch: 2590/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6496\n",
      "Epoch: 2591/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6496\n",
      "Epoch: 2592/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6497\n",
      "Epoch: 2593/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6498\n",
      "Epoch: 2594/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6498\n",
      "Epoch: 2595/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6499\n",
      "Epoch: 2596/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6500\n",
      "Epoch: 2597/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6500\n",
      "Epoch: 2598/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6501\n",
      "Epoch: 2599/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6502\n",
      "Epoch: 2600/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6503\n",
      "Epoch: 2601/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6503\n",
      "Epoch: 2602/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6504\n",
      "Epoch: 2603/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6505\n",
      "Epoch: 2604/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6505\n",
      "Epoch: 2605/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6506\n",
      "Epoch: 2606/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6507\n",
      "Epoch: 2607/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6507\n",
      "Epoch: 2608/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6508\n",
      "Epoch: 2609/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6509\n",
      "Epoch: 2610/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6509\n",
      "Epoch: 2611/8000, Train Loss: 0.2891\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6510\n",
      "Epoch: 2612/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6511\n",
      "Epoch: 2613/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6512\n",
      "Epoch: 2614/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6512\n",
      "Epoch: 2615/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6513\n",
      "Epoch: 2616/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6514\n",
      "Epoch: 2617/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6514\n",
      "Epoch: 2618/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6515\n",
      "Epoch: 2619/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6516\n",
      "Epoch: 2620/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6516\n",
      "Epoch: 2621/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6517\n",
      "Epoch: 2622/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6518\n",
      "Epoch: 2623/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6518\n",
      "Epoch: 2624/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6519\n",
      "Epoch: 2625/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6520\n",
      "Epoch: 2626/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6521\n",
      "Epoch: 2627/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6521\n",
      "Epoch: 2628/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6522\n",
      "Epoch: 2629/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6523\n",
      "Epoch: 2630/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6523\n",
      "Epoch: 2631/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6524\n",
      "Epoch: 2632/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6525\n",
      "Epoch: 2633/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6525\n",
      "Epoch: 2634/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6526\n",
      "Epoch: 2635/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6527\n",
      "Epoch: 2636/8000, Train Loss: 0.2890\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6527\n",
      "Epoch: 2637/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6528\n",
      "Epoch: 2638/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6529\n",
      "Epoch: 2639/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6529\n",
      "Epoch: 2640/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6530\n",
      "Epoch: 2641/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6531\n",
      "Epoch: 2642/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6532\n",
      "Epoch: 2643/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6532\n",
      "Epoch: 2644/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6533\n",
      "Epoch: 2645/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6534\n",
      "Epoch: 2646/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6534\n",
      "Epoch: 2647/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6535\n",
      "Epoch: 2648/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6536\n",
      "Epoch: 2649/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6536\n",
      "Epoch: 2650/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6537\n",
      "Epoch: 2651/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6538\n",
      "Epoch: 2652/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6538\n",
      "Epoch: 2653/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6539\n",
      "Epoch: 2654/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6540\n",
      "Epoch: 2655/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6540\n",
      "Epoch: 2656/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6541\n",
      "Epoch: 2657/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6542\n",
      "Epoch: 2658/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6543\n",
      "Epoch: 2659/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6543\n",
      "Epoch: 2660/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6544\n",
      "Epoch: 2661/8000, Train Loss: 0.2889\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6545\n",
      "Epoch: 2662/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6545\n",
      "Epoch: 2663/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6546\n",
      "Epoch: 2664/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6547\n",
      "Epoch: 2665/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6547\n",
      "Epoch: 2666/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6548\n",
      "Epoch: 2667/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6549\n",
      "Epoch: 2668/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6549\n",
      "Epoch: 2669/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6550\n",
      "Epoch: 2670/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6551\n",
      "Epoch: 2671/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6551\n",
      "Epoch: 2672/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6552\n",
      "Epoch: 2673/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6553\n",
      "Epoch: 2674/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6554\n",
      "Epoch: 2675/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6554\n",
      "Epoch: 2676/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6555\n",
      "Epoch: 2677/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6556\n",
      "Epoch: 2678/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6556\n",
      "Epoch: 2679/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6557\n",
      "Epoch: 2680/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6558\n",
      "Epoch: 2681/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6558\n",
      "Epoch: 2682/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6559\n",
      "Epoch: 2683/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6560\n",
      "Epoch: 2684/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6560\n",
      "Epoch: 2685/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6561\n",
      "Epoch: 2686/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6562\n",
      "Epoch: 2687/8000, Train Loss: 0.2888\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6562\n",
      "Epoch: 2688/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6563\n",
      "Epoch: 2689/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6564\n",
      "Epoch: 2690/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6565\n",
      "Epoch: 2691/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6565\n",
      "Epoch: 2692/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6566\n",
      "Epoch: 2693/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6567\n",
      "Epoch: 2694/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6567\n",
      "Epoch: 2695/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6568\n",
      "Epoch: 2696/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6569\n",
      "Epoch: 2697/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6569\n",
      "Epoch: 2698/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6570\n",
      "Epoch: 2699/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6571\n",
      "Epoch: 2700/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6571\n",
      "Epoch: 2701/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6572\n",
      "Epoch: 2702/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6573\n",
      "Epoch: 2703/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6573\n",
      "Epoch: 2704/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6574\n",
      "Epoch: 2705/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6575\n",
      "Epoch: 2706/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6576\n",
      "Epoch: 2707/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6576\n",
      "Epoch: 2708/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6577\n",
      "Epoch: 2709/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6578\n",
      "Epoch: 2710/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6578\n",
      "Epoch: 2711/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6579\n",
      "Epoch: 2712/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6580\n",
      "Epoch: 2713/8000, Train Loss: 0.2887\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6580\n",
      "Epoch: 2714/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6581\n",
      "Epoch: 2715/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6582\n",
      "Epoch: 2716/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6582\n",
      "Epoch: 2717/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6583\n",
      "Epoch: 2718/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6584\n",
      "Epoch: 2719/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6584\n",
      "Epoch: 2720/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6585\n",
      "Epoch: 2721/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6586\n",
      "Epoch: 2722/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6586\n",
      "Epoch: 2723/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6587\n",
      "Epoch: 2724/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6588\n",
      "Epoch: 2725/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6588\n",
      "Epoch: 2726/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6589\n",
      "Epoch: 2727/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6590\n",
      "Epoch: 2728/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6591\n",
      "Epoch: 2729/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6591\n",
      "Epoch: 2730/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6592\n",
      "Epoch: 2731/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6593\n",
      "Epoch: 2732/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6593\n",
      "Epoch: 2733/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6594\n",
      "Epoch: 2734/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6595\n",
      "Epoch: 2735/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6595\n",
      "Epoch: 2736/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6596\n",
      "Epoch: 2737/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6597\n",
      "Epoch: 2738/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6597\n",
      "Epoch: 2739/8000, Train Loss: 0.2886\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6598\n",
      "Epoch: 2740/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6599\n",
      "Epoch: 2741/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6599\n",
      "Epoch: 2742/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6600\n",
      "Epoch: 2743/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6601\n",
      "Epoch: 2744/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6601\n",
      "Epoch: 2745/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6602\n",
      "Epoch: 2746/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6603\n",
      "Epoch: 2747/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6604\n",
      "Epoch: 2748/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6604\n",
      "Epoch: 2749/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6605\n",
      "Epoch: 2750/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6606\n",
      "Epoch: 2751/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6606\n",
      "Epoch: 2752/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6607\n",
      "Epoch: 2753/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6608\n",
      "Epoch: 2754/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6608\n",
      "Epoch: 2755/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6609\n",
      "Epoch: 2756/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6610\n",
      "Epoch: 2757/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6610\n",
      "Epoch: 2758/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6611\n",
      "Epoch: 2759/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6612\n",
      "Epoch: 2760/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6612\n",
      "Epoch: 2761/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6613\n",
      "Epoch: 2762/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6614\n",
      "Epoch: 2763/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6614\n",
      "Epoch: 2764/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6615\n",
      "Epoch: 2765/8000, Train Loss: 0.2885\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6616\n",
      "Epoch: 2766/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6616\n",
      "Epoch: 2767/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6617\n",
      "Epoch: 2768/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6618\n",
      "Epoch: 2769/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6618\n",
      "Epoch: 2770/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6619\n",
      "Epoch: 2771/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6620\n",
      "Epoch: 2772/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6621\n",
      "Epoch: 2773/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6621\n",
      "Epoch: 2774/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6622\n",
      "Epoch: 2775/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6623\n",
      "Epoch: 2776/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6623\n",
      "Epoch: 2777/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6624\n",
      "Epoch: 2778/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6625\n",
      "Epoch: 2779/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6625\n",
      "Epoch: 2780/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6626\n",
      "Epoch: 2781/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6627\n",
      "Epoch: 2782/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6627\n",
      "Epoch: 2783/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6628\n",
      "Epoch: 2784/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6629\n",
      "Epoch: 2785/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6629\n",
      "Epoch: 2786/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6630\n",
      "Epoch: 2787/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6631\n",
      "Epoch: 2788/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6631\n",
      "Epoch: 2789/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6632\n",
      "Epoch: 2790/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6633\n",
      "Epoch: 2791/8000, Train Loss: 0.2884\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6633\n",
      "Epoch: 2792/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6634\n",
      "Epoch: 2793/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6635\n",
      "Epoch: 2794/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6635\n",
      "Epoch: 2795/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6636\n",
      "Epoch: 2796/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6637\n",
      "Epoch: 2797/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6638\n",
      "Epoch: 2798/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6638\n",
      "Epoch: 2799/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6639\n",
      "Epoch: 2800/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6640\n",
      "Epoch: 2801/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6640\n",
      "Epoch: 2802/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6641\n",
      "Epoch: 2803/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6642\n",
      "Epoch: 2804/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6642\n",
      "Epoch: 2805/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6643\n",
      "Epoch: 2806/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6644\n",
      "Epoch: 2807/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6644\n",
      "Epoch: 2808/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6645\n",
      "Epoch: 2809/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6646\n",
      "Epoch: 2810/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6646\n",
      "Epoch: 2811/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6647\n",
      "Epoch: 2812/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6648\n",
      "Epoch: 2813/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6648\n",
      "Epoch: 2814/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6649\n",
      "Epoch: 2815/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6650\n",
      "Epoch: 2816/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6650\n",
      "Epoch: 2817/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6651\n",
      "Epoch: 2818/8000, Train Loss: 0.2883\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6652\n",
      "Epoch: 2819/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6652\n",
      "Epoch: 2820/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6653\n",
      "Epoch: 2821/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6654\n",
      "Epoch: 2822/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6654\n",
      "Epoch: 2823/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6655\n",
      "Epoch: 2824/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6656\n",
      "Epoch: 2825/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6656\n",
      "Epoch: 2826/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6657\n",
      "Epoch: 2827/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6658\n",
      "Epoch: 2828/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6659\n",
      "Epoch: 2829/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6659\n",
      "Epoch: 2830/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6660\n",
      "Epoch: 2831/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6661\n",
      "Epoch: 2832/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6661\n",
      "Epoch: 2833/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6662\n",
      "Epoch: 2834/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6663\n",
      "Epoch: 2835/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6663\n",
      "Epoch: 2836/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6664\n",
      "Epoch: 2837/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6665\n",
      "Epoch: 2838/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6665\n",
      "Epoch: 2839/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6666\n",
      "Epoch: 2840/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6667\n",
      "Epoch: 2841/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6667\n",
      "Epoch: 2842/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6668\n",
      "Epoch: 2843/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6669\n",
      "Epoch: 2844/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6669\n",
      "Epoch: 2845/8000, Train Loss: 0.2882\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6670\n",
      "Epoch: 2846/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6671\n",
      "Epoch: 2847/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6671\n",
      "Epoch: 2848/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6672\n",
      "Epoch: 2849/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6673\n",
      "Epoch: 2850/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6673\n",
      "Epoch: 2851/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6674\n",
      "Epoch: 2852/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6675\n",
      "Epoch: 2853/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6675\n",
      "Epoch: 2854/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6676\n",
      "Epoch: 2855/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6677\n",
      "Epoch: 2856/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6677\n",
      "Epoch: 2857/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6678\n",
      "Epoch: 2858/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6679\n",
      "Epoch: 2859/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6679\n",
      "Epoch: 2860/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6680\n",
      "Epoch: 2861/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6681\n",
      "Epoch: 2862/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6681\n",
      "Epoch: 2863/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6682\n",
      "Epoch: 2864/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6683\n",
      "Epoch: 2865/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6684\n",
      "Epoch: 2866/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6684\n",
      "Epoch: 2867/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6685\n",
      "Epoch: 2868/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6686\n",
      "Epoch: 2869/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6686\n",
      "Epoch: 2870/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6687\n",
      "Epoch: 2871/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6688\n",
      "Epoch: 2872/8000, Train Loss: 0.2881\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6688\n",
      "Epoch: 2873/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6689\n",
      "Epoch: 2874/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6690\n",
      "Epoch: 2875/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6690\n",
      "Epoch: 2876/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6691\n",
      "Epoch: 2877/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6692\n",
      "Epoch: 2878/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6692\n",
      "Epoch: 2879/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6693\n",
      "Epoch: 2880/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6694\n",
      "Epoch: 2881/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6694\n",
      "Epoch: 2882/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6695\n",
      "Epoch: 2883/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6696\n",
      "Epoch: 2884/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6696\n",
      "Epoch: 2885/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6697\n",
      "Epoch: 2886/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6698\n",
      "Epoch: 2887/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6698\n",
      "Epoch: 2888/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6699\n",
      "Epoch: 2889/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6700\n",
      "Epoch: 2890/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6700\n",
      "Epoch: 2891/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6701\n",
      "Epoch: 2892/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6702\n",
      "Epoch: 2893/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6702\n",
      "Epoch: 2894/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6703\n",
      "Epoch: 2895/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6704\n",
      "Epoch: 2896/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6704\n",
      "Epoch: 2897/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6705\n",
      "Epoch: 2898/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6706\n",
      "Epoch: 2899/8000, Train Loss: 0.2880\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6706\n",
      "Epoch: 2900/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6707\n",
      "Epoch: 2901/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6708\n",
      "Epoch: 2902/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6708\n",
      "Epoch: 2903/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6709\n",
      "Epoch: 2904/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6710\n",
      "Epoch: 2905/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6710\n",
      "Epoch: 2906/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6711\n",
      "Epoch: 2907/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6712\n",
      "Epoch: 2908/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6712\n",
      "Epoch: 2909/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6713\n",
      "Epoch: 2910/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6714\n",
      "Epoch: 2911/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6714\n",
      "Epoch: 2912/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6715\n",
      "Epoch: 2913/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6716\n",
      "Epoch: 2914/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6716\n",
      "Epoch: 2915/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6717\n",
      "Epoch: 2916/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6718\n",
      "Epoch: 2917/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6718\n",
      "Epoch: 2918/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6719\n",
      "Epoch: 2919/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6720\n",
      "Epoch: 2920/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6720\n",
      "Epoch: 2921/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6721\n",
      "Epoch: 2922/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6722\n",
      "Epoch: 2923/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6722\n",
      "Epoch: 2924/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6723\n",
      "Epoch: 2925/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6724\n",
      "Epoch: 2926/8000, Train Loss: 0.2879\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6725\n",
      "Epoch: 2927/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6725\n",
      "Epoch: 2928/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6726\n",
      "Epoch: 2929/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6727\n",
      "Epoch: 2930/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6727\n",
      "Epoch: 2931/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6728\n",
      "Epoch: 2932/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6729\n",
      "Epoch: 2933/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6729\n",
      "Epoch: 2934/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6730\n",
      "Epoch: 2935/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6731\n",
      "Epoch: 2936/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6731\n",
      "Epoch: 2937/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6732\n",
      "Epoch: 2938/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6733\n",
      "Epoch: 2939/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6733\n",
      "Epoch: 2940/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6734\n",
      "Epoch: 2941/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6735\n",
      "Epoch: 2942/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6735\n",
      "Epoch: 2943/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6736\n",
      "Epoch: 2944/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6737\n",
      "Epoch: 2945/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6737\n",
      "Epoch: 2946/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6738\n",
      "Epoch: 2947/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6739\n",
      "Epoch: 2948/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6739\n",
      "Epoch: 2949/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6740\n",
      "Epoch: 2950/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6741\n",
      "Epoch: 2951/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6741\n",
      "Epoch: 2952/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6742\n",
      "Epoch: 2953/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6743\n",
      "Epoch: 2954/8000, Train Loss: 0.2878\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6743\n",
      "Epoch: 2955/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6744\n",
      "Epoch: 2956/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6745\n",
      "Epoch: 2957/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6745\n",
      "Epoch: 2958/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6746\n",
      "Epoch: 2959/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6747\n",
      "Epoch: 2960/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6747\n",
      "Epoch: 2961/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6748\n",
      "Epoch: 2962/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6749\n",
      "Epoch: 2963/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6749\n",
      "Epoch: 2964/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6750\n",
      "Epoch: 2965/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6751\n",
      "Epoch: 2966/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6751\n",
      "Epoch: 2967/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6752\n",
      "Epoch: 2968/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6753\n",
      "Epoch: 2969/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6753\n",
      "Epoch: 2970/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6754\n",
      "Epoch: 2971/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6755\n",
      "Epoch: 2972/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6755\n",
      "Epoch: 2973/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6756\n",
      "Epoch: 2974/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6757\n",
      "Epoch: 2975/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6757\n",
      "Epoch: 2976/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6758\n",
      "Epoch: 2977/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6759\n",
      "Epoch: 2978/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6759\n",
      "Epoch: 2979/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6760\n",
      "Epoch: 2980/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6761\n",
      "Epoch: 2981/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6761\n",
      "Epoch: 2982/8000, Train Loss: 0.2877\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6762\n",
      "Epoch: 2983/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6763\n",
      "Epoch: 2984/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6763\n",
      "Epoch: 2985/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6764\n",
      "Epoch: 2986/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6765\n",
      "Epoch: 2987/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6765\n",
      "Epoch: 2988/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6766\n",
      "Epoch: 2989/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6767\n",
      "Epoch: 2990/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6767\n",
      "Epoch: 2991/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6768\n",
      "Epoch: 2992/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6769\n",
      "Epoch: 2993/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6769\n",
      "Epoch: 2994/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6770\n",
      "Epoch: 2995/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6771\n",
      "Epoch: 2996/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6771\n",
      "Epoch: 2997/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6772\n",
      "Epoch: 2998/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6773\n",
      "Epoch: 2999/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6773\n",
      "Epoch: 3000/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6774\n",
      "Epoch: 3001/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6775\n",
      "Epoch: 3002/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6775\n",
      "Epoch: 3003/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6776\n",
      "Epoch: 3004/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6777\n",
      "Epoch: 3005/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6777\n",
      "Epoch: 3006/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6778\n",
      "Epoch: 3007/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6779\n",
      "Epoch: 3008/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6779\n",
      "Epoch: 3009/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6780\n",
      "Epoch: 3010/8000, Train Loss: 0.2876\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6781\n",
      "Epoch: 3011/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6781\n",
      "Epoch: 3012/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6782\n",
      "Epoch: 3013/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6783\n",
      "Epoch: 3014/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6783\n",
      "Epoch: 3015/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6784\n",
      "Epoch: 3016/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6785\n",
      "Epoch: 3017/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6785\n",
      "Epoch: 3018/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6786\n",
      "Epoch: 3019/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6787\n",
      "Epoch: 3020/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6787\n",
      "Epoch: 3021/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6788\n",
      "Epoch: 3022/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6789\n",
      "Epoch: 3023/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6789\n",
      "Epoch: 3024/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6790\n",
      "Epoch: 3025/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6791\n",
      "Epoch: 3026/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6791\n",
      "Epoch: 3027/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6792\n",
      "Epoch: 3028/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6793\n",
      "Epoch: 3029/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6793\n",
      "Epoch: 3030/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6794\n",
      "Epoch: 3031/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6795\n",
      "Epoch: 3032/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6795\n",
      "Epoch: 3033/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6796\n",
      "Epoch: 3034/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6797\n",
      "Epoch: 3035/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6797\n",
      "Epoch: 3036/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6798\n",
      "Epoch: 3037/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6799\n",
      "Epoch: 3038/8000, Train Loss: 0.2875\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6799\n",
      "Epoch: 3039/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6800\n",
      "Epoch: 3040/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6801\n",
      "Epoch: 3041/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6801\n",
      "Epoch: 3042/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6802\n",
      "Epoch: 3043/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6803\n",
      "Epoch: 3044/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6803\n",
      "Epoch: 3045/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6804\n",
      "Epoch: 3046/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6805\n",
      "Epoch: 3047/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6805\n",
      "Epoch: 3048/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6806\n",
      "Epoch: 3049/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6807\n",
      "Epoch: 3050/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6807\n",
      "Epoch: 3051/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6808\n",
      "Epoch: 3052/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6808\n",
      "Epoch: 3053/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6809\n",
      "Epoch: 3054/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6810\n",
      "Epoch: 3055/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6810\n",
      "Epoch: 3056/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6811\n",
      "Epoch: 3057/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6812\n",
      "Epoch: 3058/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6812\n",
      "Epoch: 3059/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6813\n",
      "Epoch: 3060/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6814\n",
      "Epoch: 3061/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6814\n",
      "Epoch: 3062/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6815\n",
      "Epoch: 3063/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6816\n",
      "Epoch: 3064/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6816\n",
      "Epoch: 3065/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6817\n",
      "Epoch: 3066/8000, Train Loss: 0.2874\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6818\n",
      "Epoch: 3067/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6818\n",
      "Epoch: 3068/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6819\n",
      "Epoch: 3069/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6820\n",
      "Epoch: 3070/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6820\n",
      "Epoch: 3071/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6821\n",
      "Epoch: 3072/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6822\n",
      "Epoch: 3073/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6822\n",
      "Epoch: 3074/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6823\n",
      "Epoch: 3075/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6824\n",
      "Epoch: 3076/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6824\n",
      "Epoch: 3077/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6825\n",
      "Epoch: 3078/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6826\n",
      "Epoch: 3079/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6826\n",
      "Epoch: 3080/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6827\n",
      "Epoch: 3081/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6828\n",
      "Epoch: 3082/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6828\n",
      "Epoch: 3083/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6829\n",
      "Epoch: 3084/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6830\n",
      "Epoch: 3085/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6830\n",
      "Epoch: 3086/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6831\n",
      "Epoch: 3087/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6832\n",
      "Epoch: 3088/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6832\n",
      "Epoch: 3089/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6833\n",
      "Epoch: 3090/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6834\n",
      "Epoch: 3091/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6834\n",
      "Epoch: 3092/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6835\n",
      "Epoch: 3093/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6836\n",
      "Epoch: 3094/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6836\n",
      "Epoch: 3095/8000, Train Loss: 0.2873\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6837\n",
      "Epoch: 3096/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6838\n",
      "Epoch: 3097/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6838\n",
      "Epoch: 3098/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6839\n",
      "Epoch: 3099/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6840\n",
      "Epoch: 3100/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6840\n",
      "Epoch: 3101/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6841\n",
      "Epoch: 3102/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6842\n",
      "Epoch: 3103/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6842\n",
      "Epoch: 3104/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6843\n",
      "Epoch: 3105/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6844\n",
      "Epoch: 3106/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6844\n",
      "Epoch: 3107/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6845\n",
      "Epoch: 3108/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6846\n",
      "Epoch: 3109/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6846\n",
      "Epoch: 3110/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6847\n",
      "Epoch: 3111/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6848\n",
      "Epoch: 3112/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6848\n",
      "Epoch: 3113/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6849\n",
      "Epoch: 3114/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6849\n",
      "Epoch: 3115/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6850\n",
      "Epoch: 3116/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6851\n",
      "Epoch: 3117/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6851\n",
      "Epoch: 3118/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6852\n",
      "Epoch: 3119/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6853\n",
      "Epoch: 3120/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6853\n",
      "Epoch: 3121/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6854\n",
      "Epoch: 3122/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6855\n",
      "Epoch: 3123/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6855\n",
      "Epoch: 3124/8000, Train Loss: 0.2872\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6856\n",
      "Epoch: 3125/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6857\n",
      "Epoch: 3126/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6857\n",
      "Epoch: 3127/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6858\n",
      "Epoch: 3128/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6859\n",
      "Epoch: 3129/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6859\n",
      "Epoch: 3130/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6860\n",
      "Epoch: 3131/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6861\n",
      "Epoch: 3132/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6861\n",
      "Epoch: 3133/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6862\n",
      "Epoch: 3134/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6863\n",
      "Epoch: 3135/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6863\n",
      "Epoch: 3136/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6864\n",
      "Epoch: 3137/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6865\n",
      "Epoch: 3138/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6865\n",
      "Epoch: 3139/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6866\n",
      "Epoch: 3140/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6867\n",
      "Epoch: 3141/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6867\n",
      "Epoch: 3142/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6868\n",
      "Epoch: 3143/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6869\n",
      "Epoch: 3144/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6869\n",
      "Epoch: 3145/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6870\n",
      "Epoch: 3146/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6871\n",
      "Epoch: 3147/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6871\n",
      "Epoch: 3148/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 91.67%\tLoss on Val set: 0.6872\n",
      "Epoch: 3149/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6873\n",
      "Epoch: 3150/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6873\n",
      "Epoch: 3151/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6874\n",
      "Epoch: 3152/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6875\n",
      "Epoch: 3153/8000, Train Loss: 0.2871\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6875\n",
      "Epoch: 3154/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6876\n",
      "Epoch: 3155/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6876\n",
      "Epoch: 3156/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6877\n",
      "Epoch: 3157/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6878\n",
      "Epoch: 3158/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6878\n",
      "Epoch: 3159/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6879\n",
      "Epoch: 3160/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6880\n",
      "Epoch: 3161/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6880\n",
      "Epoch: 3162/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6881\n",
      "Epoch: 3163/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6882\n",
      "Epoch: 3164/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6882\n",
      "Epoch: 3165/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6883\n",
      "Epoch: 3166/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6884\n",
      "Epoch: 3167/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6884\n",
      "Epoch: 3168/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6885\n",
      "Epoch: 3169/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6886\n",
      "Epoch: 3170/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6886\n",
      "Epoch: 3171/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6887\n",
      "Epoch: 3172/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6888\n",
      "Epoch: 3173/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6888\n",
      "Epoch: 3174/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6889\n",
      "Epoch: 3175/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6890\n",
      "Epoch: 3176/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6890\n",
      "Epoch: 3177/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6891\n",
      "Epoch: 3178/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6892\n",
      "Epoch: 3179/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6892\n",
      "Epoch: 3180/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6893\n",
      "Epoch: 3181/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6894\n",
      "Epoch: 3182/8000, Train Loss: 0.2870\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6894\n",
      "Epoch: 3183/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6895\n",
      "Epoch: 3184/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6896\n",
      "Epoch: 3185/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6896\n",
      "Epoch: 3186/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6897\n",
      "Epoch: 3187/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6898\n",
      "Epoch: 3188/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6898\n",
      "Epoch: 3189/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6899\n",
      "Epoch: 3190/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6899\n",
      "Epoch: 3191/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6900\n",
      "Epoch: 3192/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6901\n",
      "Epoch: 3193/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6901\n",
      "Epoch: 3194/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6902\n",
      "Epoch: 3195/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6903\n",
      "Epoch: 3196/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6903\n",
      "Epoch: 3197/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6904\n",
      "Epoch: 3198/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6905\n",
      "Epoch: 3199/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6905\n",
      "Epoch: 3200/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6906\n",
      "Epoch: 3201/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6907\n",
      "Epoch: 3202/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6907\n",
      "Epoch: 3203/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6908\n",
      "Epoch: 3204/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6909\n",
      "Epoch: 3205/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6909\n",
      "Epoch: 3206/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6910\n",
      "Epoch: 3207/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6911\n",
      "Epoch: 3208/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6911\n",
      "Epoch: 3209/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6912\n",
      "Epoch: 3210/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6913\n",
      "Epoch: 3211/8000, Train Loss: 0.2869\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6913\n",
      "Epoch: 3212/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6914\n",
      "Epoch: 3213/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6915\n",
      "Epoch: 3214/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6915\n",
      "Epoch: 3215/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6916\n",
      "Epoch: 3216/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6917\n",
      "Epoch: 3217/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6917\n",
      "Epoch: 3218/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6918\n",
      "Epoch: 3219/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6918\n",
      "Epoch: 3220/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6919\n",
      "Epoch: 3221/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6920\n",
      "Epoch: 3222/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6920\n",
      "Epoch: 3223/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6921\n",
      "Epoch: 3224/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6922\n",
      "Epoch: 3225/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6922\n",
      "Epoch: 3226/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6923\n",
      "Epoch: 3227/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6924\n",
      "Epoch: 3228/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6924\n",
      "Epoch: 3229/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6925\n",
      "Epoch: 3230/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6926\n",
      "Epoch: 3231/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6926\n",
      "Epoch: 3232/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6927\n",
      "Epoch: 3233/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6928\n",
      "Epoch: 3234/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6928\n",
      "Epoch: 3235/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6929\n",
      "Epoch: 3236/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6930\n",
      "Epoch: 3237/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6930\n",
      "Epoch: 3238/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6931\n",
      "Epoch: 3239/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6932\n",
      "Epoch: 3240/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6932\n",
      "Epoch: 3241/8000, Train Loss: 0.2868\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6933\n",
      "Epoch: 3242/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6933\n",
      "Epoch: 3243/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6934\n",
      "Epoch: 3244/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6935\n",
      "Epoch: 3245/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6935\n",
      "Epoch: 3246/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6936\n",
      "Epoch: 3247/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6937\n",
      "Epoch: 3248/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6937\n",
      "Epoch: 3249/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6938\n",
      "Epoch: 3250/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6939\n",
      "Epoch: 3251/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6939\n",
      "Epoch: 3252/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6940\n",
      "Epoch: 3253/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6941\n",
      "Epoch: 3254/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6941\n",
      "Epoch: 3255/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6942\n",
      "Epoch: 3256/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6943\n",
      "Epoch: 3257/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6943\n",
      "Epoch: 3258/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6944\n",
      "Epoch: 3259/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6945\n",
      "Epoch: 3260/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6945\n",
      "Epoch: 3261/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6946\n",
      "Epoch: 3262/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6947\n",
      "Epoch: 3263/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6947\n",
      "Epoch: 3264/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6948\n",
      "Epoch: 3265/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6949\n",
      "Epoch: 3266/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6949\n",
      "Epoch: 3267/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6950\n",
      "Epoch: 3268/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6950\n",
      "Epoch: 3269/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6951\n",
      "Epoch: 3270/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6952\n",
      "Epoch: 3271/8000, Train Loss: 0.2867\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6952\n",
      "Epoch: 3272/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6953\n",
      "Epoch: 3273/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6954\n",
      "Epoch: 3274/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6954\n",
      "Epoch: 3275/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6955\n",
      "Epoch: 3276/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6956\n",
      "Epoch: 3277/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6956\n",
      "Epoch: 3278/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6957\n",
      "Epoch: 3279/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6958\n",
      "Epoch: 3280/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6958\n",
      "Epoch: 3281/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6959\n",
      "Epoch: 3282/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6960\n",
      "Epoch: 3283/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6960\n",
      "Epoch: 3284/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6961\n",
      "Epoch: 3285/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6962\n",
      "Epoch: 3286/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6962\n",
      "Epoch: 3287/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6963\n",
      "Epoch: 3288/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6963\n",
      "Epoch: 3289/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6964\n",
      "Epoch: 3290/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6965\n",
      "Epoch: 3291/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6965\n",
      "Epoch: 3292/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6966\n",
      "Epoch: 3293/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6967\n",
      "Epoch: 3294/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6967\n",
      "Epoch: 3295/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6968\n",
      "Epoch: 3296/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6969\n",
      "Epoch: 3297/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6969\n",
      "Epoch: 3298/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6970\n",
      "Epoch: 3299/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6971\n",
      "Epoch: 3300/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6971\n",
      "Epoch: 3301/8000, Train Loss: 0.2866\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6972\n",
      "Epoch: 3302/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6973\n",
      "Epoch: 3303/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6973\n",
      "Epoch: 3304/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6974\n",
      "Epoch: 3305/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6975\n",
      "Epoch: 3306/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6975\n",
      "Epoch: 3307/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6976\n",
      "Epoch: 3308/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6976\n",
      "Epoch: 3309/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6977\n",
      "Epoch: 3310/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6978\n",
      "Epoch: 3311/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6978\n",
      "Epoch: 3312/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6979\n",
      "Epoch: 3313/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6980\n",
      "Epoch: 3314/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6980\n",
      "Epoch: 3315/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6981\n",
      "Epoch: 3316/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6982\n",
      "Epoch: 3317/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6982\n",
      "Epoch: 3318/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6983\n",
      "Epoch: 3319/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6984\n",
      "Epoch: 3320/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6984\n",
      "Epoch: 3321/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6985\n",
      "Epoch: 3322/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6986\n",
      "Epoch: 3323/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6986\n",
      "Epoch: 3324/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6987\n",
      "Epoch: 3325/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6988\n",
      "Epoch: 3326/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6988\n",
      "Epoch: 3327/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6989\n",
      "Epoch: 3328/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6989\n",
      "Epoch: 3329/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6990\n",
      "Epoch: 3330/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6991\n",
      "Epoch: 3331/8000, Train Loss: 0.2865\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6991\n",
      "Epoch: 3332/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6992\n",
      "Epoch: 3333/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6993\n",
      "Epoch: 3334/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6993\n",
      "Epoch: 3335/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6994\n",
      "Epoch: 3336/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6995\n",
      "Epoch: 3337/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6995\n",
      "Epoch: 3338/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6996\n",
      "Epoch: 3339/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6997\n",
      "Epoch: 3340/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6997\n",
      "Epoch: 3341/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6998\n",
      "Epoch: 3342/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6999\n",
      "Epoch: 3343/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.6999\n",
      "Epoch: 3344/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7000\n",
      "Epoch: 3345/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7001\n",
      "Epoch: 3346/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7001\n",
      "Epoch: 3347/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7002\n",
      "Epoch: 3348/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7002\n",
      "Epoch: 3349/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7003\n",
      "Epoch: 3350/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7004\n",
      "Epoch: 3351/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7004\n",
      "Epoch: 3352/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7005\n",
      "Epoch: 3353/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7006\n",
      "Epoch: 3354/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7006\n",
      "Epoch: 3355/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7007\n",
      "Epoch: 3356/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7008\n",
      "Epoch: 3357/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7008\n",
      "Epoch: 3358/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7009\n",
      "Epoch: 3359/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7010\n",
      "Epoch: 3360/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7010\n",
      "Epoch: 3361/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7011\n",
      "Epoch: 3362/8000, Train Loss: 0.2864\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7012\n",
      "Epoch: 3363/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7012\n",
      "Epoch: 3364/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7013\n",
      "Epoch: 3365/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7013\n",
      "Epoch: 3366/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7014\n",
      "Epoch: 3367/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7015\n",
      "Epoch: 3368/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7015\n",
      "Epoch: 3369/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7016\n",
      "Epoch: 3370/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7017\n",
      "Epoch: 3371/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7017\n",
      "Epoch: 3372/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7018\n",
      "Epoch: 3373/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7019\n",
      "Epoch: 3374/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7019\n",
      "Epoch: 3375/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7020\n",
      "Epoch: 3376/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7021\n",
      "Epoch: 3377/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7021\n",
      "Epoch: 3378/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7022\n",
      "Epoch: 3379/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7023\n",
      "Epoch: 3380/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7023\n",
      "Epoch: 3381/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7024\n",
      "Epoch: 3382/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7024\n",
      "Epoch: 3383/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7025\n",
      "Epoch: 3384/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7026\n",
      "Epoch: 3385/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7026\n",
      "Epoch: 3386/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7027\n",
      "Epoch: 3387/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7028\n",
      "Epoch: 3388/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7028\n",
      "Epoch: 3389/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7029\n",
      "Epoch: 3390/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7030\n",
      "Epoch: 3391/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7030\n",
      "Epoch: 3392/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7031\n",
      "Epoch: 3393/8000, Train Loss: 0.2863\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7032\n",
      "Epoch: 3394/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7032\n",
      "Epoch: 3395/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7033\n",
      "Epoch: 3396/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7033\n",
      "Epoch: 3397/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7034\n",
      "Epoch: 3398/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7035\n",
      "Epoch: 3399/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7035\n",
      "Epoch: 3400/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7036\n",
      "Epoch: 3401/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7037\n",
      "Epoch: 3402/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7037\n",
      "Epoch: 3403/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7038\n",
      "Epoch: 3404/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7039\n",
      "Epoch: 3405/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7039\n",
      "Epoch: 3406/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7040\n",
      "Epoch: 3407/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7041\n",
      "Epoch: 3408/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7041\n",
      "Epoch: 3409/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7042\n",
      "Epoch: 3410/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7043\n",
      "Epoch: 3411/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7043\n",
      "Epoch: 3412/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7044\n",
      "Epoch: 3413/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7044\n",
      "Epoch: 3414/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7045\n",
      "Epoch: 3415/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7046\n",
      "Epoch: 3416/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7046\n",
      "Epoch: 3417/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7047\n",
      "Epoch: 3418/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7048\n",
      "Epoch: 3419/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7048\n",
      "Epoch: 3420/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7049\n",
      "Epoch: 3421/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7050\n",
      "Epoch: 3422/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7050\n",
      "Epoch: 3423/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7051\n",
      "Epoch: 3424/8000, Train Loss: 0.2862\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7052\n",
      "Epoch: 3425/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7052\n",
      "Epoch: 3426/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7053\n",
      "Epoch: 3427/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7053\n",
      "Epoch: 3428/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7054\n",
      "Epoch: 3429/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7055\n",
      "Epoch: 3430/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7055\n",
      "Epoch: 3431/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7056\n",
      "Epoch: 3432/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7057\n",
      "Epoch: 3433/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7057\n",
      "Epoch: 3434/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7058\n",
      "Epoch: 3435/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7059\n",
      "Epoch: 3436/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7059\n",
      "Epoch: 3437/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7060\n",
      "Epoch: 3438/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7061\n",
      "Epoch: 3439/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7061\n",
      "Epoch: 3440/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7062\n",
      "Epoch: 3441/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7063\n",
      "Epoch: 3442/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7063\n",
      "Epoch: 3443/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7064\n",
      "Epoch: 3444/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7064\n",
      "Epoch: 3445/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7065\n",
      "Epoch: 3446/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7066\n",
      "Epoch: 3447/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7066\n",
      "Epoch: 3448/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7067\n",
      "Epoch: 3449/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7068\n",
      "Epoch: 3450/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7068\n",
      "Epoch: 3451/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7069\n",
      "Epoch: 3452/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7070\n",
      "Epoch: 3453/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7070\n",
      "Epoch: 3454/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7071\n",
      "Epoch: 3455/8000, Train Loss: 0.2861\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7072\n",
      "Epoch: 3456/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7072\n",
      "Epoch: 3457/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7073\n",
      "Epoch: 3458/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7073\n",
      "Epoch: 3459/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7074\n",
      "Epoch: 3460/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7075\n",
      "Epoch: 3461/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7075\n",
      "Epoch: 3462/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7076\n",
      "Epoch: 3463/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7077\n",
      "Epoch: 3464/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7077\n",
      "Epoch: 3465/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7078\n",
      "Epoch: 3466/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7079\n",
      "Epoch: 3467/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7079\n",
      "Epoch: 3468/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7080\n",
      "Epoch: 3469/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7081\n",
      "Epoch: 3470/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7081\n",
      "Epoch: 3471/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7082\n",
      "Epoch: 3472/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7082\n",
      "Epoch: 3473/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7083\n",
      "Epoch: 3474/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7084\n",
      "Epoch: 3475/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7084\n",
      "Epoch: 3476/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7085\n",
      "Epoch: 3477/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7086\n",
      "Epoch: 3478/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7086\n",
      "Epoch: 3479/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7087\n",
      "Epoch: 3480/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7088\n",
      "Epoch: 3481/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7088\n",
      "Epoch: 3482/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7089\n",
      "Epoch: 3483/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7089\n",
      "Epoch: 3484/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7090\n",
      "Epoch: 3485/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7091\n",
      "Epoch: 3486/8000, Train Loss: 0.2860\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7091\n",
      "Epoch: 3487/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7092\n",
      "Epoch: 3488/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7093\n",
      "Epoch: 3489/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7093\n",
      "Epoch: 3490/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7094\n",
      "Epoch: 3491/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7095\n",
      "Epoch: 3492/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7095\n",
      "Epoch: 3493/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7096\n",
      "Epoch: 3494/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7097\n",
      "Epoch: 3495/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7097\n",
      "Epoch: 3496/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7098\n",
      "Epoch: 3497/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7098\n",
      "Epoch: 3498/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7099\n",
      "Epoch: 3499/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7100\n",
      "Epoch: 3500/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7100\n",
      "Epoch: 3501/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7101\n",
      "Epoch: 3502/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7102\n",
      "Epoch: 3503/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7102\n",
      "Epoch: 3504/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7103\n",
      "Epoch: 3505/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7104\n",
      "Epoch: 3506/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7104\n",
      "Epoch: 3507/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7105\n",
      "Epoch: 3508/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7106\n",
      "Epoch: 3509/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7106\n",
      "Epoch: 3510/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7107\n",
      "Epoch: 3511/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7107\n",
      "Epoch: 3512/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7108\n",
      "Epoch: 3513/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7109\n",
      "Epoch: 3514/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7109\n",
      "Epoch: 3515/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7110\n",
      "Epoch: 3516/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7111\n",
      "Epoch: 3517/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7111\n",
      "Epoch: 3518/8000, Train Loss: 0.2859\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7112\n",
      "Epoch: 3519/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7113\n",
      "Epoch: 3520/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7113\n",
      "Epoch: 3521/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7114\n",
      "Epoch: 3522/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7114\n",
      "Epoch: 3523/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7115\n",
      "Epoch: 3524/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7116\n",
      "Epoch: 3525/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7116\n",
      "Epoch: 3526/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7117\n",
      "Epoch: 3527/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7118\n",
      "Epoch: 3528/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7118\n",
      "Epoch: 3529/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7119\n",
      "Epoch: 3530/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7120\n",
      "Epoch: 3531/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7120\n",
      "Epoch: 3532/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7121\n",
      "Epoch: 3533/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7122\n",
      "Epoch: 3534/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7122\n",
      "Epoch: 3535/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7123\n",
      "Epoch: 3536/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7123\n",
      "Epoch: 3537/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7124\n",
      "Epoch: 3538/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7125\n",
      "Epoch: 3539/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7125\n",
      "Epoch: 3540/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7126\n",
      "Epoch: 3541/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7127\n",
      "Epoch: 3542/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7127\n",
      "Epoch: 3543/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7128\n",
      "Epoch: 3544/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7129\n",
      "Epoch: 3545/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7129\n",
      "Epoch: 3546/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7130\n",
      "Epoch: 3547/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7130\n",
      "Epoch: 3548/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7131\n",
      "Epoch: 3549/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7132\n",
      "Epoch: 3550/8000, Train Loss: 0.2858\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7132\n",
      "Epoch: 3551/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7133\n",
      "Epoch: 3552/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7134\n",
      "Epoch: 3553/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7134\n",
      "Epoch: 3554/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7135\n",
      "Epoch: 3555/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7136\n",
      "Epoch: 3556/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7136\n",
      "Epoch: 3557/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7137\n",
      "Epoch: 3558/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7138\n",
      "Epoch: 3559/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7138\n",
      "Epoch: 3560/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7139\n",
      "Epoch: 3561/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7139\n",
      "Epoch: 3562/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7140\n",
      "Epoch: 3563/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7141\n",
      "Epoch: 3564/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7141\n",
      "Epoch: 3565/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7142\n",
      "Epoch: 3566/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7143\n",
      "Epoch: 3567/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7143\n",
      "Epoch: 3568/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7144\n",
      "Epoch: 3569/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7145\n",
      "Epoch: 3570/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7145\n",
      "Epoch: 3571/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7146\n",
      "Epoch: 3572/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7146\n",
      "Epoch: 3573/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7147\n",
      "Epoch: 3574/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7148\n",
      "Epoch: 3575/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7148\n",
      "Epoch: 3576/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7149\n",
      "Epoch: 3577/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7150\n",
      "Epoch: 3578/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7150\n",
      "Epoch: 3579/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7151\n",
      "Epoch: 3580/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7152\n",
      "Epoch: 3581/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7152\n",
      "Epoch: 3582/8000, Train Loss: 0.2857\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7153\n",
      "Epoch: 3583/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7153\n",
      "Epoch: 3584/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7154\n",
      "Epoch: 3585/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7155\n",
      "Epoch: 3586/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7155\n",
      "Epoch: 3587/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7156\n",
      "Epoch: 3588/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7157\n",
      "Epoch: 3589/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7157\n",
      "Epoch: 3590/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7158\n",
      "Epoch: 3591/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7159\n",
      "Epoch: 3592/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7159\n",
      "Epoch: 3593/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7160\n",
      "Epoch: 3594/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7160\n",
      "Epoch: 3595/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7161\n",
      "Epoch: 3596/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7162\n",
      "Epoch: 3597/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7162\n",
      "Epoch: 3598/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7163\n",
      "Epoch: 3599/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7164\n",
      "Epoch: 3600/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7164\n",
      "Epoch: 3601/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7165\n",
      "Epoch: 3602/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7166\n",
      "Epoch: 3603/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7166\n",
      "Epoch: 3604/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7167\n",
      "Epoch: 3605/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7167\n",
      "Epoch: 3606/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7168\n",
      "Epoch: 3607/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7169\n",
      "Epoch: 3608/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7169\n",
      "Epoch: 3609/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7170\n",
      "Epoch: 3610/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7171\n",
      "Epoch: 3611/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7171\n",
      "Epoch: 3612/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7172\n",
      "Epoch: 3613/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7173\n",
      "Epoch: 3614/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7173\n",
      "Epoch: 3615/8000, Train Loss: 0.2856\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7174\n",
      "Epoch: 3616/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7174\n",
      "Epoch: 3617/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7175\n",
      "Epoch: 3618/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7176\n",
      "Epoch: 3619/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7176\n",
      "Epoch: 3620/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7177\n",
      "Epoch: 3621/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7178\n",
      "Epoch: 3622/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7178\n",
      "Epoch: 3623/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7179\n",
      "Epoch: 3624/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7180\n",
      "Epoch: 3625/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7180\n",
      "Epoch: 3626/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7181\n",
      "Epoch: 3627/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7181\n",
      "Epoch: 3628/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7182\n",
      "Epoch: 3629/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7183\n",
      "Epoch: 3630/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7183\n",
      "Epoch: 3631/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7184\n",
      "Epoch: 3632/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7185\n",
      "Epoch: 3633/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7185\n",
      "Epoch: 3634/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7186\n",
      "Epoch: 3635/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7187\n",
      "Epoch: 3636/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7187\n",
      "Epoch: 3637/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7188\n",
      "Epoch: 3638/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7188\n",
      "Epoch: 3639/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7189\n",
      "Epoch: 3640/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7190\n",
      "Epoch: 3641/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7190\n",
      "Epoch: 3642/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7191\n",
      "Epoch: 3643/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7192\n",
      "Epoch: 3644/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7192\n",
      "Epoch: 3645/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7193\n",
      "Epoch: 3646/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7194\n",
      "Epoch: 3647/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7194\n",
      "Epoch: 3648/8000, Train Loss: 0.2855\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7195\n",
      "Epoch: 3649/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7195\n",
      "Epoch: 3650/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7196\n",
      "Epoch: 3651/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7197\n",
      "Epoch: 3652/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7197\n",
      "Epoch: 3653/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7198\n",
      "Epoch: 3654/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7199\n",
      "Epoch: 3655/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7199\n",
      "Epoch: 3656/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7200\n",
      "Epoch: 3657/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7201\n",
      "Epoch: 3658/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7201\n",
      "Epoch: 3659/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7202\n",
      "Epoch: 3660/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7202\n",
      "Epoch: 3661/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7203\n",
      "Epoch: 3662/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7204\n",
      "Epoch: 3663/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7204\n",
      "Epoch: 3664/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7205\n",
      "Epoch: 3665/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7206\n",
      "Epoch: 3666/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7206\n",
      "Epoch: 3667/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7207\n",
      "Epoch: 3668/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7208\n",
      "Epoch: 3669/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7208\n",
      "Epoch: 3670/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7209\n",
      "Epoch: 3671/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7209\n",
      "Epoch: 3672/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7210\n",
      "Epoch: 3673/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7211\n",
      "Epoch: 3674/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7211\n",
      "Epoch: 3675/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7212\n",
      "Epoch: 3676/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7213\n",
      "Epoch: 3677/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7213\n",
      "Epoch: 3678/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7214\n",
      "Epoch: 3679/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7214\n",
      "Epoch: 3680/8000, Train Loss: 0.2854\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7215\n",
      "Epoch: 3681/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7216\n",
      "Epoch: 3682/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7216\n",
      "Epoch: 3683/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7217\n",
      "Epoch: 3684/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7218\n",
      "Epoch: 3685/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7218\n",
      "Epoch: 3686/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7219\n",
      "Epoch: 3687/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7220\n",
      "Epoch: 3688/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7220\n",
      "Epoch: 3689/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7221\n",
      "Epoch: 3690/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7221\n",
      "Epoch: 3691/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7222\n",
      "Epoch: 3692/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7223\n",
      "Epoch: 3693/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7223\n",
      "Epoch: 3694/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7224\n",
      "Epoch: 3695/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7225\n",
      "Epoch: 3696/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7225\n",
      "Epoch: 3697/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7226\n",
      "Epoch: 3698/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7227\n",
      "Epoch: 3699/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7227\n",
      "Epoch: 3700/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7228\n",
      "Epoch: 3701/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7228\n",
      "Epoch: 3702/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7229\n",
      "Epoch: 3703/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7230\n",
      "Epoch: 3704/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7230\n",
      "Epoch: 3705/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7231\n",
      "Epoch: 3706/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7232\n",
      "Epoch: 3707/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7232\n",
      "Epoch: 3708/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7233\n",
      "Epoch: 3709/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7233\n",
      "Epoch: 3710/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7234\n",
      "Epoch: 3711/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7235\n",
      "Epoch: 3712/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7235\n",
      "Epoch: 3713/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7236\n",
      "Epoch: 3714/8000, Train Loss: 0.2853\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7237\n",
      "Epoch: 3715/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7237\n",
      "Epoch: 3716/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7238\n",
      "Epoch: 3717/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7239\n",
      "Epoch: 3718/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7239\n",
      "Epoch: 3719/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7240\n",
      "Epoch: 3720/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7240\n",
      "Epoch: 3721/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7241\n",
      "Epoch: 3722/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7242\n",
      "Epoch: 3723/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7242\n",
      "Epoch: 3724/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7243\n",
      "Epoch: 3725/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7244\n",
      "Epoch: 3726/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7244\n",
      "Epoch: 3727/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7245\n",
      "Epoch: 3728/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7245\n",
      "Epoch: 3729/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7246\n",
      "Epoch: 3730/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7247\n",
      "Epoch: 3731/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7247\n",
      "Epoch: 3732/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7248\n",
      "Epoch: 3733/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7249\n",
      "Epoch: 3734/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7249\n",
      "Epoch: 3735/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7250\n",
      "Epoch: 3736/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7251\n",
      "Epoch: 3737/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7251\n",
      "Epoch: 3738/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7252\n",
      "Epoch: 3739/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7252\n",
      "Epoch: 3740/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7253\n",
      "Epoch: 3741/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7254\n",
      "Epoch: 3742/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7254\n",
      "Epoch: 3743/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7255\n",
      "Epoch: 3744/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7256\n",
      "Epoch: 3745/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7256\n",
      "Epoch: 3746/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7257\n",
      "Epoch: 3747/8000, Train Loss: 0.2852\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7257\n",
      "Epoch: 3748/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7258\n",
      "Epoch: 3749/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7259\n",
      "Epoch: 3750/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7259\n",
      "Epoch: 3751/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7260\n",
      "Epoch: 3752/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7261\n",
      "Epoch: 3753/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7261\n",
      "Epoch: 3754/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7262\n",
      "Epoch: 3755/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7263\n",
      "Epoch: 3756/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7263\n",
      "Epoch: 3757/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7264\n",
      "Epoch: 3758/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7264\n",
      "Epoch: 3759/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7265\n",
      "Epoch: 3760/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7266\n",
      "Epoch: 3761/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7266\n",
      "Epoch: 3762/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7267\n",
      "Epoch: 3763/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7268\n",
      "Epoch: 3764/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7268\n",
      "Epoch: 3765/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7269\n",
      "Epoch: 3766/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7269\n",
      "Epoch: 3767/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7270\n",
      "Epoch: 3768/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7271\n",
      "Epoch: 3769/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7271\n",
      "Epoch: 3770/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7272\n",
      "Epoch: 3771/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7273\n",
      "Epoch: 3772/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7273\n",
      "Epoch: 3773/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7274\n",
      "Epoch: 3774/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7275\n",
      "Epoch: 3775/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7275\n",
      "Epoch: 3776/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7276\n",
      "Epoch: 3777/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7276\n",
      "Epoch: 3778/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7277\n",
      "Epoch: 3779/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7278\n",
      "Epoch: 3780/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7278\n",
      "Epoch: 3781/8000, Train Loss: 0.2851\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7279\n",
      "Epoch: 3782/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7280\n",
      "Epoch: 3783/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7280\n",
      "Epoch: 3784/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7281\n",
      "Epoch: 3785/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7281\n",
      "Epoch: 3786/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7282\n",
      "Epoch: 3787/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7283\n",
      "Epoch: 3788/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7283\n",
      "Epoch: 3789/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7284\n",
      "Epoch: 3790/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7285\n",
      "Epoch: 3791/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7285\n",
      "Epoch: 3792/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7286\n",
      "Epoch: 3793/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7286\n",
      "Epoch: 3794/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7287\n",
      "Epoch: 3795/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7288\n",
      "Epoch: 3796/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7288\n",
      "Epoch: 3797/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7289\n",
      "Epoch: 3798/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7290\n",
      "Epoch: 3799/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7290\n",
      "Epoch: 3800/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7291\n",
      "Epoch: 3801/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7292\n",
      "Epoch: 3802/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7292\n",
      "Epoch: 3803/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7293\n",
      "Epoch: 3804/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7293\n",
      "Epoch: 3805/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7294\n",
      "Epoch: 3806/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7295\n",
      "Epoch: 3807/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7295\n",
      "Epoch: 3808/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7296\n",
      "Epoch: 3809/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7297\n",
      "Epoch: 3810/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7297\n",
      "Epoch: 3811/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7298\n",
      "Epoch: 3812/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7298\n",
      "Epoch: 3813/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7299\n",
      "Epoch: 3814/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7300\n",
      "Epoch: 3815/8000, Train Loss: 0.2850\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7300\n",
      "Epoch: 3816/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7301\n",
      "Epoch: 3817/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7302\n",
      "Epoch: 3818/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7302\n",
      "Epoch: 3819/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7303\n",
      "Epoch: 3820/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7303\n",
      "Epoch: 3821/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7304\n",
      "Epoch: 3822/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7305\n",
      "Epoch: 3823/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7305\n",
      "Epoch: 3824/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7306\n",
      "Epoch: 3825/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7307\n",
      "Epoch: 3826/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7307\n",
      "Epoch: 3827/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7308\n",
      "Epoch: 3828/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7308\n",
      "Epoch: 3829/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7309\n",
      "Epoch: 3830/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7310\n",
      "Epoch: 3831/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7310\n",
      "Epoch: 3832/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7311\n",
      "Epoch: 3833/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7312\n",
      "Epoch: 3834/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7312\n",
      "Epoch: 3835/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7313\n",
      "Epoch: 3836/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7314\n",
      "Epoch: 3837/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7314\n",
      "Epoch: 3838/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7315\n",
      "Epoch: 3839/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7315\n",
      "Epoch: 3840/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7316\n",
      "Epoch: 3841/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7317\n",
      "Epoch: 3842/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7317\n",
      "Epoch: 3843/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7318\n",
      "Epoch: 3844/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7319\n",
      "Epoch: 3845/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7319\n",
      "Epoch: 3846/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7320\n",
      "Epoch: 3847/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7320\n",
      "Epoch: 3848/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7321\n",
      "Epoch: 3849/8000, Train Loss: 0.2849\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7322\n",
      "Epoch: 3850/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7322\n",
      "Epoch: 3851/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7323\n",
      "Epoch: 3852/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7324\n",
      "Epoch: 3853/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7324\n",
      "Epoch: 3854/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7325\n",
      "Epoch: 3855/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7325\n",
      "Epoch: 3856/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7326\n",
      "Epoch: 3857/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7327\n",
      "Epoch: 3858/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7327\n",
      "Epoch: 3859/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7328\n",
      "Epoch: 3860/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7329\n",
      "Epoch: 3861/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7329\n",
      "Epoch: 3862/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7330\n",
      "Epoch: 3863/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7330\n",
      "Epoch: 3864/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7331\n",
      "Epoch: 3865/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7332\n",
      "Epoch: 3866/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7332\n",
      "Epoch: 3867/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7333\n",
      "Epoch: 3868/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7334\n",
      "Epoch: 3869/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7334\n",
      "Epoch: 3870/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7335\n",
      "Epoch: 3871/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7335\n",
      "Epoch: 3872/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7336\n",
      "Epoch: 3873/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7337\n",
      "Epoch: 3874/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7337\n",
      "Epoch: 3875/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7338\n",
      "Epoch: 3876/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7339\n",
      "Epoch: 3877/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7339\n",
      "Epoch: 3878/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7340\n",
      "Epoch: 3879/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7340\n",
      "Epoch: 3880/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7341\n",
      "Epoch: 3881/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7342\n",
      "Epoch: 3882/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7342\n",
      "Epoch: 3883/8000, Train Loss: 0.2848\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7343\n",
      "Epoch: 3884/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7344\n",
      "Epoch: 3885/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7344\n",
      "Epoch: 3886/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7345\n",
      "Epoch: 3887/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7345\n",
      "Epoch: 3888/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7346\n",
      "Epoch: 3889/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7347\n",
      "Epoch: 3890/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7347\n",
      "Epoch: 3891/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7348\n",
      "Epoch: 3892/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7349\n",
      "Epoch: 3893/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7349\n",
      "Epoch: 3894/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7350\n",
      "Epoch: 3895/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7350\n",
      "Epoch: 3896/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7351\n",
      "Epoch: 3897/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7352\n",
      "Epoch: 3898/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7352\n",
      "Epoch: 3899/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7353\n",
      "Epoch: 3900/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7354\n",
      "Epoch: 3901/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7354\n",
      "Epoch: 3902/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7355\n",
      "Epoch: 3903/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7355\n",
      "Epoch: 3904/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7356\n",
      "Epoch: 3905/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7357\n",
      "Epoch: 3906/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7357\n",
      "Epoch: 3907/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7358\n",
      "Epoch: 3908/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7359\n",
      "Epoch: 3909/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7359\n",
      "Epoch: 3910/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7360\n",
      "Epoch: 3911/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7360\n",
      "Epoch: 3912/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7361\n",
      "Epoch: 3913/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7362\n",
      "Epoch: 3914/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7362\n",
      "Epoch: 3915/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7363\n",
      "Epoch: 3916/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7364\n",
      "Epoch: 3917/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7364\n",
      "Epoch: 3918/8000, Train Loss: 0.2847\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7365\n",
      "Epoch: 3919/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7365\n",
      "Epoch: 3920/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7366\n",
      "Epoch: 3921/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7367\n",
      "Epoch: 3922/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7367\n",
      "Epoch: 3923/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7368\n",
      "Epoch: 3924/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7369\n",
      "Epoch: 3925/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7369\n",
      "Epoch: 3926/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7370\n",
      "Epoch: 3927/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7370\n",
      "Epoch: 3928/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7371\n",
      "Epoch: 3929/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7372\n",
      "Epoch: 3930/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7372\n",
      "Epoch: 3931/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7373\n",
      "Epoch: 3932/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7374\n",
      "Epoch: 3933/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7374\n",
      "Epoch: 3934/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7375\n",
      "Epoch: 3935/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7375\n",
      "Epoch: 3936/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7376\n",
      "Epoch: 3937/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7377\n",
      "Epoch: 3938/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7377\n",
      "Epoch: 3939/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7378\n",
      "Epoch: 3940/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7379\n",
      "Epoch: 3941/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7379\n",
      "Epoch: 3942/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7380\n",
      "Epoch: 3943/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7380\n",
      "Epoch: 3944/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7381\n",
      "Epoch: 3945/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7382\n",
      "Epoch: 3946/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7382\n",
      "Epoch: 3947/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7383\n",
      "Epoch: 3948/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7384\n",
      "Epoch: 3949/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7384\n",
      "Epoch: 3950/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7385\n",
      "Epoch: 3951/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7385\n",
      "Epoch: 3952/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7386\n",
      "Epoch: 3953/8000, Train Loss: 0.2846\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7387\n",
      "Epoch: 3954/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7387\n",
      "Epoch: 3955/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7388\n",
      "Epoch: 3956/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7389\n",
      "Epoch: 3957/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7389\n",
      "Epoch: 3958/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7390\n",
      "Epoch: 3959/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7390\n",
      "Epoch: 3960/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7391\n",
      "Epoch: 3961/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7392\n",
      "Epoch: 3962/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7392\n",
      "Epoch: 3963/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7393\n",
      "Epoch: 3964/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7394\n",
      "Epoch: 3965/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7394\n",
      "Epoch: 3966/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7395\n",
      "Epoch: 3967/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7395\n",
      "Epoch: 3968/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7396\n",
      "Epoch: 3969/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7397\n",
      "Epoch: 3970/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7397\n",
      "Epoch: 3971/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7398\n",
      "Epoch: 3972/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7399\n",
      "Epoch: 3973/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7399\n",
      "Epoch: 3974/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7400\n",
      "Epoch: 3975/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7400\n",
      "Epoch: 3976/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7401\n",
      "Epoch: 3977/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7402\n",
      "Epoch: 3978/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7402\n",
      "Epoch: 3979/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7403\n",
      "Epoch: 3980/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7404\n",
      "Epoch: 3981/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7404\n",
      "Epoch: 3982/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7405\n",
      "Epoch: 3983/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7405\n",
      "Epoch: 3984/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7406\n",
      "Epoch: 3985/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7407\n",
      "Epoch: 3986/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7407\n",
      "Epoch: 3987/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7408\n",
      "Epoch: 3988/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7409\n",
      "Epoch: 3989/8000, Train Loss: 0.2845\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7409\n",
      "Epoch: 3990/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7410\n",
      "Epoch: 3991/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7410\n",
      "Epoch: 3992/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7411\n",
      "Epoch: 3993/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7412\n",
      "Epoch: 3994/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7412\n",
      "Epoch: 3995/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7413\n",
      "Epoch: 3996/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7413\n",
      "Epoch: 3997/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7414\n",
      "Epoch: 3998/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7415\n",
      "Epoch: 3999/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7415\n",
      "Epoch: 4000/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7416\n",
      "Epoch: 4001/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7417\n",
      "Epoch: 4002/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7417\n",
      "Epoch: 4003/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7418\n",
      "Epoch: 4004/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7418\n",
      "Epoch: 4005/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7419\n",
      "Epoch: 4006/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7420\n",
      "Epoch: 4007/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7420\n",
      "Epoch: 4008/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7421\n",
      "Epoch: 4009/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7422\n",
      "Epoch: 4010/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7422\n",
      "Epoch: 4011/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7423\n",
      "Epoch: 4012/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7423\n",
      "Epoch: 4013/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7424\n",
      "Epoch: 4014/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7425\n",
      "Epoch: 4015/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7425\n",
      "Epoch: 4016/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7426\n",
      "Epoch: 4017/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7427\n",
      "Epoch: 4018/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7427\n",
      "Epoch: 4019/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7428\n",
      "Epoch: 4020/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7428\n",
      "Epoch: 4021/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7429\n",
      "Epoch: 4022/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7430\n",
      "Epoch: 4023/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7430\n",
      "Epoch: 4024/8000, Train Loss: 0.2844\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7431\n",
      "Epoch: 4025/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7432\n",
      "Epoch: 4026/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7432\n",
      "Epoch: 4027/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7433\n",
      "Epoch: 4028/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7433\n",
      "Epoch: 4029/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7434\n",
      "Epoch: 4030/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7435\n",
      "Epoch: 4031/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7435\n",
      "Epoch: 4032/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7436\n",
      "Epoch: 4033/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7436\n",
      "Epoch: 4034/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7437\n",
      "Epoch: 4035/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7438\n",
      "Epoch: 4036/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7438\n",
      "Epoch: 4037/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7439\n",
      "Epoch: 4038/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7440\n",
      "Epoch: 4039/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7440\n",
      "Epoch: 4040/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7441\n",
      "Epoch: 4041/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7441\n",
      "Epoch: 4042/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7442\n",
      "Epoch: 4043/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7443\n",
      "Epoch: 4044/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7443\n",
      "Epoch: 4045/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7444\n",
      "Epoch: 4046/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7445\n",
      "Epoch: 4047/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7445\n",
      "Epoch: 4048/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7446\n",
      "Epoch: 4049/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7446\n",
      "Epoch: 4050/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7447\n",
      "Epoch: 4051/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7448\n",
      "Epoch: 4052/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7448\n",
      "Epoch: 4053/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7449\n",
      "Epoch: 4054/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7449\n",
      "Epoch: 4055/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7450\n",
      "Epoch: 4056/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7451\n",
      "Epoch: 4057/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7451\n",
      "Epoch: 4058/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7452\n",
      "Epoch: 4059/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7453\n",
      "Epoch: 4060/8000, Train Loss: 0.2843\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7453\n",
      "Epoch: 4061/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7454\n",
      "Epoch: 4062/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7454\n",
      "Epoch: 4063/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7455\n",
      "Epoch: 4064/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7456\n",
      "Epoch: 4065/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7456\n",
      "Epoch: 4066/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7457\n",
      "Epoch: 4067/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7458\n",
      "Epoch: 4068/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7458\n",
      "Epoch: 4069/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7459\n",
      "Epoch: 4070/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7459\n",
      "Epoch: 4071/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7460\n",
      "Epoch: 4072/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7461\n",
      "Epoch: 4073/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7461\n",
      "Epoch: 4074/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7462\n",
      "Epoch: 4075/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7463\n",
      "Epoch: 4076/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7463\n",
      "Epoch: 4077/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7464\n",
      "Epoch: 4078/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7464\n",
      "Epoch: 4079/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7465\n",
      "Epoch: 4080/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7466\n",
      "Epoch: 4081/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7466\n",
      "Epoch: 4082/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7467\n",
      "Epoch: 4083/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7467\n",
      "Epoch: 4084/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7468\n",
      "Epoch: 4085/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7469\n",
      "Epoch: 4086/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7469\n",
      "Epoch: 4087/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7470\n",
      "Epoch: 4088/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7471\n",
      "Epoch: 4089/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7471\n",
      "Epoch: 4090/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7472\n",
      "Epoch: 4091/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7472\n",
      "Epoch: 4092/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7473\n",
      "Epoch: 4093/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7474\n",
      "Epoch: 4094/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7474\n",
      "Epoch: 4095/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7475\n",
      "Epoch: 4096/8000, Train Loss: 0.2842\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7476\n",
      "Epoch: 4097/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7476\n",
      "Epoch: 4098/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7477\n",
      "Epoch: 4099/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7477\n",
      "Epoch: 4100/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7478\n",
      "Epoch: 4101/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7479\n",
      "Epoch: 4102/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7479\n",
      "Epoch: 4103/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7480\n",
      "Epoch: 4104/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7480\n",
      "Epoch: 4105/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7481\n",
      "Epoch: 4106/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7482\n",
      "Epoch: 4107/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7482\n",
      "Epoch: 4108/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7483\n",
      "Epoch: 4109/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7484\n",
      "Epoch: 4110/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7484\n",
      "Epoch: 4111/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7485\n",
      "Epoch: 4112/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7485\n",
      "Epoch: 4113/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7486\n",
      "Epoch: 4114/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7487\n",
      "Epoch: 4115/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7487\n",
      "Epoch: 4116/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7488\n",
      "Epoch: 4117/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7488\n",
      "Epoch: 4118/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7489\n",
      "Epoch: 4119/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7490\n",
      "Epoch: 4120/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7490\n",
      "Epoch: 4121/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7491\n",
      "Epoch: 4122/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7492\n",
      "Epoch: 4123/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7492\n",
      "Epoch: 4124/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7493\n",
      "Epoch: 4125/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7493\n",
      "Epoch: 4126/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7494\n",
      "Epoch: 4127/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7495\n",
      "Epoch: 4128/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7495\n",
      "Epoch: 4129/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7496\n",
      "Epoch: 4130/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7497\n",
      "Epoch: 4131/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7497\n",
      "Epoch: 4132/8000, Train Loss: 0.2841\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7498\n",
      "Epoch: 4133/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7498\n",
      "Epoch: 4134/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7499\n",
      "Epoch: 4135/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7500\n",
      "Epoch: 4136/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7500\n",
      "Epoch: 4137/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7501\n",
      "Epoch: 4138/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7501\n",
      "Epoch: 4139/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7502\n",
      "Epoch: 4140/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7503\n",
      "Epoch: 4141/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7503\n",
      "Epoch: 4142/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7504\n",
      "Epoch: 4143/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7505\n",
      "Epoch: 4144/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7505\n",
      "Epoch: 4145/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7506\n",
      "Epoch: 4146/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7506\n",
      "Epoch: 4147/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7507\n",
      "Epoch: 4148/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7508\n",
      "Epoch: 4149/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7508\n",
      "Epoch: 4150/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7509\n",
      "Epoch: 4151/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7509\n",
      "Epoch: 4152/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7510\n",
      "Epoch: 4153/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7511\n",
      "Epoch: 4154/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7511\n",
      "Epoch: 4155/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7512\n",
      "Epoch: 4156/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7513\n",
      "Epoch: 4157/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7513\n",
      "Epoch: 4158/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7514\n",
      "Epoch: 4159/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7514\n",
      "Epoch: 4160/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7515\n",
      "Epoch: 4161/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7516\n",
      "Epoch: 4162/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7516\n",
      "Epoch: 4163/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7517\n",
      "Epoch: 4164/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7517\n",
      "Epoch: 4165/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7518\n",
      "Epoch: 4166/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7519\n",
      "Epoch: 4167/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7519\n",
      "Epoch: 4168/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7520\n",
      "Epoch: 4169/8000, Train Loss: 0.2840\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7521\n",
      "Epoch: 4170/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7521\n",
      "Epoch: 4171/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7522\n",
      "Epoch: 4172/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7522\n",
      "Epoch: 4173/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7523\n",
      "Epoch: 4174/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7524\n",
      "Epoch: 4175/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7524\n",
      "Epoch: 4176/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7525\n",
      "Epoch: 4177/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7526\n",
      "Epoch: 4178/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7526\n",
      "Epoch: 4179/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7527\n",
      "Epoch: 4180/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7527\n",
      "Epoch: 4181/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7528\n",
      "Epoch: 4182/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7529\n",
      "Epoch: 4183/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7529\n",
      "Epoch: 4184/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7530\n",
      "Epoch: 4185/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7530\n",
      "Epoch: 4186/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7531\n",
      "Epoch: 4187/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7532\n",
      "Epoch: 4188/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7532\n",
      "Epoch: 4189/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7533\n",
      "Epoch: 4190/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7534\n",
      "Epoch: 4191/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7534\n",
      "Epoch: 4192/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7535\n",
      "Epoch: 4193/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7535\n",
      "Epoch: 4194/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7536\n",
      "Epoch: 4195/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7537\n",
      "Epoch: 4196/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7537\n",
      "Epoch: 4197/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7538\n",
      "Epoch: 4198/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7538\n",
      "Epoch: 4199/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7539\n",
      "Epoch: 4200/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7540\n",
      "Epoch: 4201/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7540\n",
      "Epoch: 4202/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7541\n",
      "Epoch: 4203/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7542\n",
      "Epoch: 4204/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7542\n",
      "Epoch: 4205/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7543\n",
      "Epoch: 4206/8000, Train Loss: 0.2839\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7543\n",
      "Epoch: 4207/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7544\n",
      "Epoch: 4208/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7545\n",
      "Epoch: 4209/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7545\n",
      "Epoch: 4210/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7546\n",
      "Epoch: 4211/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7546\n",
      "Epoch: 4212/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7547\n",
      "Epoch: 4213/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7548\n",
      "Epoch: 4214/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7548\n",
      "Epoch: 4215/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7549\n",
      "Epoch: 4216/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7550\n",
      "Epoch: 4217/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7550\n",
      "Epoch: 4218/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7551\n",
      "Epoch: 4219/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7551\n",
      "Epoch: 4220/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7552\n",
      "Epoch: 4221/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7553\n",
      "Epoch: 4222/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7553\n",
      "Epoch: 4223/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7554\n",
      "Epoch: 4224/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7554\n",
      "Epoch: 4225/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7555\n",
      "Epoch: 4226/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7556\n",
      "Epoch: 4227/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7556\n",
      "Epoch: 4228/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7557\n",
      "Epoch: 4229/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7557\n",
      "Epoch: 4230/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7558\n",
      "Epoch: 4231/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7559\n",
      "Epoch: 4232/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7559\n",
      "Epoch: 4233/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7560\n",
      "Epoch: 4234/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7561\n",
      "Epoch: 4235/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7561\n",
      "Epoch: 4236/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7562\n",
      "Epoch: 4237/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7562\n",
      "Epoch: 4238/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7563\n",
      "Epoch: 4239/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7564\n",
      "Epoch: 4240/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7564\n",
      "Epoch: 4241/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7565\n",
      "Epoch: 4242/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7565\n",
      "Epoch: 4243/8000, Train Loss: 0.2838\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7566\n",
      "Epoch: 4244/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7567\n",
      "Epoch: 4245/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7567\n",
      "Epoch: 4246/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7568\n",
      "Epoch: 4247/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7569\n",
      "Epoch: 4248/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7569\n",
      "Epoch: 4249/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7570\n",
      "Epoch: 4250/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7570\n",
      "Epoch: 4251/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7571\n",
      "Epoch: 4252/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7572\n",
      "Epoch: 4253/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7572\n",
      "Epoch: 4254/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7573\n",
      "Epoch: 4255/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7573\n",
      "Epoch: 4256/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7574\n",
      "Epoch: 4257/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7575\n",
      "Epoch: 4258/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7575\n",
      "Epoch: 4259/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7576\n",
      "Epoch: 4260/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7577\n",
      "Epoch: 4261/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7577\n",
      "Epoch: 4262/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7578\n",
      "Epoch: 4263/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7578\n",
      "Epoch: 4264/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7579\n",
      "Epoch: 4265/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7580\n",
      "Epoch: 4266/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7580\n",
      "Epoch: 4267/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7581\n",
      "Epoch: 4268/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7581\n",
      "Epoch: 4269/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7582\n",
      "Epoch: 4270/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7583\n",
      "Epoch: 4271/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7583\n",
      "Epoch: 4272/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7584\n",
      "Epoch: 4273/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7584\n",
      "Epoch: 4274/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7585\n",
      "Epoch: 4275/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7586\n",
      "Epoch: 4276/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7586\n",
      "Epoch: 4277/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7587\n",
      "Epoch: 4278/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7588\n",
      "Epoch: 4279/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7588\n",
      "Epoch: 4280/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7589\n",
      "Epoch: 4281/8000, Train Loss: 0.2837\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7589\n",
      "Epoch: 4282/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7590\n",
      "Epoch: 4283/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7591\n",
      "Epoch: 4284/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7591\n",
      "Epoch: 4285/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7592\n",
      "Epoch: 4286/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7592\n",
      "Epoch: 4287/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7593\n",
      "Epoch: 4288/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7594\n",
      "Epoch: 4289/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7594\n",
      "Epoch: 4290/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7595\n",
      "Epoch: 4291/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7596\n",
      "Epoch: 4292/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7596\n",
      "Epoch: 4293/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7597\n",
      "Epoch: 4294/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7597\n",
      "Epoch: 4295/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7598\n",
      "Epoch: 4296/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7599\n",
      "Epoch: 4297/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7599\n",
      "Epoch: 4298/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7600\n",
      "Epoch: 4299/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7600\n",
      "Epoch: 4300/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7601\n",
      "Epoch: 4301/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7602\n",
      "Epoch: 4302/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7602\n",
      "Epoch: 4303/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7603\n",
      "Epoch: 4304/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7603\n",
      "Epoch: 4305/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7604\n",
      "Epoch: 4306/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7605\n",
      "Epoch: 4307/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7605\n",
      "Epoch: 4308/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7606\n",
      "Epoch: 4309/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7607\n",
      "Epoch: 4310/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7607\n",
      "Epoch: 4311/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7608\n",
      "Epoch: 4312/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7608\n",
      "Epoch: 4313/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7609\n",
      "Epoch: 4314/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7610\n",
      "Epoch: 4315/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7610\n",
      "Epoch: 4316/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7611\n",
      "Epoch: 4317/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7611\n",
      "Epoch: 4318/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7612\n",
      "Epoch: 4319/8000, Train Loss: 0.2836\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7613\n",
      "Epoch: 4320/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7613\n",
      "Epoch: 4321/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7614\n",
      "Epoch: 4322/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7614\n",
      "Epoch: 4323/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7615\n",
      "Epoch: 4324/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7616\n",
      "Epoch: 4325/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7616\n",
      "Epoch: 4326/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7617\n",
      "Epoch: 4327/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7618\n",
      "Epoch: 4328/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7618\n",
      "Epoch: 4329/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7619\n",
      "Epoch: 4330/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7619\n",
      "Epoch: 4331/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7620\n",
      "Epoch: 4332/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7621\n",
      "Epoch: 4333/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7621\n",
      "Epoch: 4334/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7622\n",
      "Epoch: 4335/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7622\n",
      "Epoch: 4336/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7623\n",
      "Epoch: 4337/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7624\n",
      "Epoch: 4338/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7624\n",
      "Epoch: 4339/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7625\n",
      "Epoch: 4340/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7625\n",
      "Epoch: 4341/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7626\n",
      "Epoch: 4342/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7627\n",
      "Epoch: 4343/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7627\n",
      "Epoch: 4344/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7628\n",
      "Epoch: 4345/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7629\n",
      "Epoch: 4346/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7629\n",
      "Epoch: 4347/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7630\n",
      "Epoch: 4348/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7630\n",
      "Epoch: 4349/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7631\n",
      "Epoch: 4350/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7632\n",
      "Epoch: 4351/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7632\n",
      "Epoch: 4352/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7633\n",
      "Epoch: 4353/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7633\n",
      "Epoch: 4354/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7634\n",
      "Epoch: 4355/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7635\n",
      "Epoch: 4356/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7635\n",
      "Epoch: 4357/8000, Train Loss: 0.2835\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7636\n",
      "Epoch: 4358/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7636\n",
      "Epoch: 4359/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7637\n",
      "Epoch: 4360/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7638\n",
      "Epoch: 4361/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7638\n",
      "Epoch: 4362/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7639\n",
      "Epoch: 4363/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7640\n",
      "Epoch: 4364/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7640\n",
      "Epoch: 4365/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7641\n",
      "Epoch: 4366/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7641\n",
      "Epoch: 4367/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7642\n",
      "Epoch: 4368/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7643\n",
      "Epoch: 4369/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7643\n",
      "Epoch: 4370/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7644\n",
      "Epoch: 4371/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7644\n",
      "Epoch: 4372/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7645\n",
      "Epoch: 4373/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7646\n",
      "Epoch: 4374/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7646\n",
      "Epoch: 4375/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7647\n",
      "Epoch: 4376/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7647\n",
      "Epoch: 4377/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7648\n",
      "Epoch: 4378/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7649\n",
      "Epoch: 4379/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7649\n",
      "Epoch: 4380/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7650\n",
      "Epoch: 4381/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7651\n",
      "Epoch: 4382/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7651\n",
      "Epoch: 4383/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7652\n",
      "Epoch: 4384/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7652\n",
      "Epoch: 4385/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7653\n",
      "Epoch: 4386/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7654\n",
      "Epoch: 4387/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7654\n",
      "Epoch: 4388/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7655\n",
      "Epoch: 4389/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7655\n",
      "Epoch: 4390/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7656\n",
      "Epoch: 4391/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7657\n",
      "Epoch: 4392/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7657\n",
      "Epoch: 4393/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7658\n",
      "Epoch: 4394/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7658\n",
      "Epoch: 4395/8000, Train Loss: 0.2834\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7659\n",
      "Epoch: 4396/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7660\n",
      "Epoch: 4397/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7660\n",
      "Epoch: 4398/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7661\n",
      "Epoch: 4399/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7661\n",
      "Epoch: 4400/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7662\n",
      "Epoch: 4401/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7663\n",
      "Epoch: 4402/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7663\n",
      "Epoch: 4403/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7664\n",
      "Epoch: 4404/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7665\n",
      "Epoch: 4405/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7665\n",
      "Epoch: 4406/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7666\n",
      "Epoch: 4407/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7666\n",
      "Epoch: 4408/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7667\n",
      "Epoch: 4409/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7668\n",
      "Epoch: 4410/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7668\n",
      "Epoch: 4411/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7669\n",
      "Epoch: 4412/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7669\n",
      "Epoch: 4413/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7670\n",
      "Epoch: 4414/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7671\n",
      "Epoch: 4415/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7671\n",
      "Epoch: 4416/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7672\n",
      "Epoch: 4417/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7672\n",
      "Epoch: 4418/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7673\n",
      "Epoch: 4419/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7674\n",
      "Epoch: 4420/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7674\n",
      "Epoch: 4421/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7675\n",
      "Epoch: 4422/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7675\n",
      "Epoch: 4423/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7676\n",
      "Epoch: 4424/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7677\n",
      "Epoch: 4425/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7677\n",
      "Epoch: 4426/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7678\n",
      "Epoch: 4427/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7679\n",
      "Epoch: 4428/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7679\n",
      "Epoch: 4429/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7680\n",
      "Epoch: 4430/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7680\n",
      "Epoch: 4431/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7681\n",
      "Epoch: 4432/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7682\n",
      "Epoch: 4433/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7682\n",
      "Epoch: 4434/8000, Train Loss: 0.2833\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7683\n",
      "Epoch: 4435/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7683\n",
      "Epoch: 4436/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7684\n",
      "Epoch: 4437/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7685\n",
      "Epoch: 4438/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7685\n",
      "Epoch: 4439/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7686\n",
      "Epoch: 4440/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7686\n",
      "Epoch: 4441/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7687\n",
      "Epoch: 4442/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7688\n",
      "Epoch: 4443/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7688\n",
      "Epoch: 4444/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7689\n",
      "Epoch: 4445/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7689\n",
      "Epoch: 4446/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7690\n",
      "Epoch: 4447/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7691\n",
      "Epoch: 4448/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7691\n",
      "Epoch: 4449/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7692\n",
      "Epoch: 4450/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7693\n",
      "Epoch: 4451/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7693\n",
      "Epoch: 4452/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7694\n",
      "Epoch: 4453/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7694\n",
      "Epoch: 4454/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7695\n",
      "Epoch: 4455/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7696\n",
      "Epoch: 4456/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7696\n",
      "Epoch: 4457/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7697\n",
      "Epoch: 4458/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7697\n",
      "Epoch: 4459/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7698\n",
      "Epoch: 4460/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7699\n",
      "Epoch: 4461/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7699\n",
      "Epoch: 4462/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7700\n",
      "Epoch: 4463/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7700\n",
      "Epoch: 4464/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7701\n",
      "Epoch: 4465/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7702\n",
      "Epoch: 4466/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7702\n",
      "Epoch: 4467/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7703\n",
      "Epoch: 4468/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7703\n",
      "Epoch: 4469/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7704\n",
      "Epoch: 4470/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7705\n",
      "Epoch: 4471/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7705\n",
      "Epoch: 4472/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7706\n",
      "Epoch: 4473/8000, Train Loss: 0.2832\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7706\n",
      "Epoch: 4474/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7707\n",
      "Epoch: 4475/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7708\n",
      "Epoch: 4476/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7708\n",
      "Epoch: 4477/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7709\n",
      "Epoch: 4478/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7710\n",
      "Epoch: 4479/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7710\n",
      "Epoch: 4480/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7711\n",
      "Epoch: 4481/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7711\n",
      "Epoch: 4482/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7712\n",
      "Epoch: 4483/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7713\n",
      "Epoch: 4484/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7713\n",
      "Epoch: 4485/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7714\n",
      "Epoch: 4486/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7714\n",
      "Epoch: 4487/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7715\n",
      "Epoch: 4488/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7716\n",
      "Epoch: 4489/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7716\n",
      "Epoch: 4490/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7717\n",
      "Epoch: 4491/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7717\n",
      "Epoch: 4492/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7718\n",
      "Epoch: 4493/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7719\n",
      "Epoch: 4494/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7719\n",
      "Epoch: 4495/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7720\n",
      "Epoch: 4496/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7720\n",
      "Epoch: 4497/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7721\n",
      "Epoch: 4498/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7722\n",
      "Epoch: 4499/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7722\n",
      "Epoch: 4500/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7723\n",
      "Epoch: 4501/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7723\n",
      "Epoch: 4502/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7724\n",
      "Epoch: 4503/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7725\n",
      "Epoch: 4504/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7725\n",
      "Epoch: 4505/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7726\n",
      "Epoch: 4506/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7726\n",
      "Epoch: 4507/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7727\n",
      "Epoch: 4508/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7728\n",
      "Epoch: 4509/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7728\n",
      "Epoch: 4510/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7729\n",
      "Epoch: 4511/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7730\n",
      "Epoch: 4512/8000, Train Loss: 0.2831\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7730\n",
      "Epoch: 4513/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7731\n",
      "Epoch: 4514/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7731\n",
      "Epoch: 4515/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7732\n",
      "Epoch: 4516/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7733\n",
      "Epoch: 4517/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7733\n",
      "Epoch: 4518/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7734\n",
      "Epoch: 4519/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7734\n",
      "Epoch: 4520/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7735\n",
      "Epoch: 4521/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7736\n",
      "Epoch: 4522/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7736\n",
      "Epoch: 4523/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7737\n",
      "Epoch: 4524/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7737\n",
      "Epoch: 4525/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7738\n",
      "Epoch: 4526/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7739\n",
      "Epoch: 4527/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7739\n",
      "Epoch: 4528/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7740\n",
      "Epoch: 4529/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7740\n",
      "Epoch: 4530/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7741\n",
      "Epoch: 4531/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7742\n",
      "Epoch: 4532/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7742\n",
      "Epoch: 4533/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7743\n",
      "Epoch: 4534/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7743\n",
      "Epoch: 4535/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7744\n",
      "Epoch: 4536/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7745\n",
      "Epoch: 4537/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7745\n",
      "Epoch: 4538/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7746\n",
      "Epoch: 4539/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7746\n",
      "Epoch: 4540/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7747\n",
      "Epoch: 4541/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7748\n",
      "Epoch: 4542/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7748\n",
      "Epoch: 4543/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7749\n",
      "Epoch: 4544/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7749\n",
      "Epoch: 4545/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7750\n",
      "Epoch: 4546/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7751\n",
      "Epoch: 4547/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7751\n",
      "Epoch: 4548/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7752\n",
      "Epoch: 4549/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7753\n",
      "Epoch: 4550/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7753\n",
      "Epoch: 4551/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7754\n",
      "Epoch: 4552/8000, Train Loss: 0.2830\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7754\n",
      "Epoch: 4553/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7755\n",
      "Epoch: 4554/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7756\n",
      "Epoch: 4555/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7756\n",
      "Epoch: 4556/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7757\n",
      "Epoch: 4557/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7757\n",
      "Epoch: 4558/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7758\n",
      "Epoch: 4559/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7759\n",
      "Epoch: 4560/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7759\n",
      "Epoch: 4561/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7760\n",
      "Epoch: 4562/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7760\n",
      "Epoch: 4563/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7761\n",
      "Epoch: 4564/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7762\n",
      "Epoch: 4565/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7762\n",
      "Epoch: 4566/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7763\n",
      "Epoch: 4567/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7763\n",
      "Epoch: 4568/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7764\n",
      "Epoch: 4569/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7765\n",
      "Epoch: 4570/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7765\n",
      "Epoch: 4571/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7766\n",
      "Epoch: 4572/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7766\n",
      "Epoch: 4573/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7767\n",
      "Epoch: 4574/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7768\n",
      "Epoch: 4575/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7768\n",
      "Epoch: 4576/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7769\n",
      "Epoch: 4577/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7769\n",
      "Epoch: 4578/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7770\n",
      "Epoch: 4579/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7771\n",
      "Epoch: 4580/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7771\n",
      "Epoch: 4581/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7772\n",
      "Epoch: 4582/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7772\n",
      "Epoch: 4583/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7773\n",
      "Epoch: 4584/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7774\n",
      "Epoch: 4585/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7774\n",
      "Epoch: 4586/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7775\n",
      "Epoch: 4587/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7775\n",
      "Epoch: 4588/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7776\n",
      "Epoch: 4589/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7777\n",
      "Epoch: 4590/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7777\n",
      "Epoch: 4591/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7778\n",
      "Epoch: 4592/8000, Train Loss: 0.2829\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7778\n",
      "Epoch: 4593/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7779\n",
      "Epoch: 4594/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7780\n",
      "Epoch: 4595/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7780\n",
      "Epoch: 4596/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7781\n",
      "Epoch: 4597/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7781\n",
      "Epoch: 4598/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7782\n",
      "Epoch: 4599/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7783\n",
      "Epoch: 4600/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7783\n",
      "Epoch: 4601/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7784\n",
      "Epoch: 4602/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7785\n",
      "Epoch: 4603/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7785\n",
      "Epoch: 4604/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7786\n",
      "Epoch: 4605/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7786\n",
      "Epoch: 4606/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7787\n",
      "Epoch: 4607/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7788\n",
      "Epoch: 4608/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7788\n",
      "Epoch: 4609/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7789\n",
      "Epoch: 4610/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7789\n",
      "Epoch: 4611/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7790\n",
      "Epoch: 4612/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7791\n",
      "Epoch: 4613/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7791\n",
      "Epoch: 4614/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7792\n",
      "Epoch: 4615/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7792\n",
      "Epoch: 4616/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7793\n",
      "Epoch: 4617/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7794\n",
      "Epoch: 4618/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7794\n",
      "Epoch: 4619/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7795\n",
      "Epoch: 4620/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7795\n",
      "Epoch: 4621/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7796\n",
      "Epoch: 4622/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7797\n",
      "Epoch: 4623/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7797\n",
      "Epoch: 4624/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7798\n",
      "Epoch: 4625/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7798\n",
      "Epoch: 4626/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7799\n",
      "Epoch: 4627/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7800\n",
      "Epoch: 4628/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7800\n",
      "Epoch: 4629/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7801\n",
      "Epoch: 4630/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7801\n",
      "Epoch: 4631/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7802\n",
      "Epoch: 4632/8000, Train Loss: 0.2828\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7803\n",
      "Epoch: 4633/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7803\n",
      "Epoch: 4634/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7804\n",
      "Epoch: 4635/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7804\n",
      "Epoch: 4636/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7805\n",
      "Epoch: 4637/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7806\n",
      "Epoch: 4638/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7806\n",
      "Epoch: 4639/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7807\n",
      "Epoch: 4640/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7807\n",
      "Epoch: 4641/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7808\n",
      "Epoch: 4642/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7809\n",
      "Epoch: 4643/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7809\n",
      "Epoch: 4644/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7810\n",
      "Epoch: 4645/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7810\n",
      "Epoch: 4646/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7811\n",
      "Epoch: 4647/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7812\n",
      "Epoch: 4648/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7812\n",
      "Epoch: 4649/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7813\n",
      "Epoch: 4650/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7813\n",
      "Epoch: 4651/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7814\n",
      "Epoch: 4652/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7815\n",
      "Epoch: 4653/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7815\n",
      "Epoch: 4654/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7816\n",
      "Epoch: 4655/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7816\n",
      "Epoch: 4656/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7817\n",
      "Epoch: 4657/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7818\n",
      "Epoch: 4658/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7818\n",
      "Epoch: 4659/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7819\n",
      "Epoch: 4660/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7819\n",
      "Epoch: 4661/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7820\n",
      "Epoch: 4662/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7821\n",
      "Epoch: 4663/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7821\n",
      "Epoch: 4664/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7822\n",
      "Epoch: 4665/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7822\n",
      "Epoch: 4666/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7823\n",
      "Epoch: 4667/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7824\n",
      "Epoch: 4668/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7824\n",
      "Epoch: 4669/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7825\n",
      "Epoch: 4670/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7825\n",
      "Epoch: 4671/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7826\n",
      "Epoch: 4672/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7827\n",
      "Epoch: 4673/8000, Train Loss: 0.2827\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7827\n",
      "Epoch: 4674/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7828\n",
      "Epoch: 4675/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7828\n",
      "Epoch: 4676/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7829\n",
      "Epoch: 4677/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7830\n",
      "Epoch: 4678/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7830\n",
      "Epoch: 4679/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7831\n",
      "Epoch: 4680/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7831\n",
      "Epoch: 4681/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7832\n",
      "Epoch: 4682/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7833\n",
      "Epoch: 4683/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7833\n",
      "Epoch: 4684/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7834\n",
      "Epoch: 4685/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7834\n",
      "Epoch: 4686/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7835\n",
      "Epoch: 4687/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7836\n",
      "Epoch: 4688/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7836\n",
      "Epoch: 4689/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7837\n",
      "Epoch: 4690/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7837\n",
      "Epoch: 4691/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7838\n",
      "Epoch: 4692/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7839\n",
      "Epoch: 4693/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7839\n",
      "Epoch: 4694/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7840\n",
      "Epoch: 4695/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7840\n",
      "Epoch: 4696/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7841\n",
      "Epoch: 4697/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7842\n",
      "Epoch: 4698/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7842\n",
      "Epoch: 4699/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7843\n",
      "Epoch: 4700/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7843\n",
      "Epoch: 4701/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7844\n",
      "Epoch: 4702/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7845\n",
      "Epoch: 4703/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7845\n",
      "Epoch: 4704/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7846\n",
      "Epoch: 4705/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7846\n",
      "Epoch: 4706/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7847\n",
      "Epoch: 4707/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7848\n",
      "Epoch: 4708/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7848\n",
      "Epoch: 4709/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7849\n",
      "Epoch: 4710/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7849\n",
      "Epoch: 4711/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7850\n",
      "Epoch: 4712/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7851\n",
      "Epoch: 4713/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7851\n",
      "Epoch: 4714/8000, Train Loss: 0.2826\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7852\n",
      "Epoch: 4715/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7852\n",
      "Epoch: 4716/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7853\n",
      "Epoch: 4717/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7854\n",
      "Epoch: 4718/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7854\n",
      "Epoch: 4719/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7855\n",
      "Epoch: 4720/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7855\n",
      "Epoch: 4721/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7856\n",
      "Epoch: 4722/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7857\n",
      "Epoch: 4723/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7857\n",
      "Epoch: 4724/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7858\n",
      "Epoch: 4725/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7858\n",
      "Epoch: 4726/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7859\n",
      "Epoch: 4727/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7860\n",
      "Epoch: 4728/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7860\n",
      "Epoch: 4729/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7861\n",
      "Epoch: 4730/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7861\n",
      "Epoch: 4731/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7862\n",
      "Epoch: 4732/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7863\n",
      "Epoch: 4733/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7863\n",
      "Epoch: 4734/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7864\n",
      "Epoch: 4735/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7864\n",
      "Epoch: 4736/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7865\n",
      "Epoch: 4737/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7866\n",
      "Epoch: 4738/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7866\n",
      "Epoch: 4739/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7867\n",
      "Epoch: 4740/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7867\n",
      "Epoch: 4741/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7868\n",
      "Epoch: 4742/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7869\n",
      "Epoch: 4743/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7869\n",
      "Epoch: 4744/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7870\n",
      "Epoch: 4745/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7870\n",
      "Epoch: 4746/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7871\n",
      "Epoch: 4747/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7872\n",
      "Epoch: 4748/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7872\n",
      "Epoch: 4749/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7873\n",
      "Epoch: 4750/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7873\n",
      "Epoch: 4751/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7874\n",
      "Epoch: 4752/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7875\n",
      "Epoch: 4753/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7875\n",
      "Epoch: 4754/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7876\n",
      "Epoch: 4755/8000, Train Loss: 0.2825\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7876\n",
      "Epoch: 4756/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7877\n",
      "Epoch: 4757/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7878\n",
      "Epoch: 4758/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7878\n",
      "Epoch: 4759/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7879\n",
      "Epoch: 4760/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7879\n",
      "Epoch: 4761/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7880\n",
      "Epoch: 4762/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7881\n",
      "Epoch: 4763/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7881\n",
      "Epoch: 4764/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7882\n",
      "Epoch: 4765/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7882\n",
      "Epoch: 4766/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7883\n",
      "Epoch: 4767/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7884\n",
      "Epoch: 4768/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7884\n",
      "Epoch: 4769/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7885\n",
      "Epoch: 4770/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7885\n",
      "Epoch: 4771/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7886\n",
      "Epoch: 4772/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7887\n",
      "Epoch: 4773/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7887\n",
      "Epoch: 4774/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7888\n",
      "Epoch: 4775/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7888\n",
      "Epoch: 4776/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7889\n",
      "Epoch: 4777/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7890\n",
      "Epoch: 4778/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7890\n",
      "Epoch: 4779/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7891\n",
      "Epoch: 4780/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7891\n",
      "Epoch: 4781/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7892\n",
      "Epoch: 4782/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7893\n",
      "Epoch: 4783/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7893\n",
      "Epoch: 4784/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7894\n",
      "Epoch: 4785/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7894\n",
      "Epoch: 4786/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7895\n",
      "Epoch: 4787/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7896\n",
      "Epoch: 4788/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7896\n",
      "Epoch: 4789/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7897\n",
      "Epoch: 4790/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7897\n",
      "Epoch: 4791/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7898\n",
      "Epoch: 4792/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7899\n",
      "Epoch: 4793/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7899\n",
      "Epoch: 4794/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7900\n",
      "Epoch: 4795/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7900\n",
      "Epoch: 4796/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7901\n",
      "Epoch: 4797/8000, Train Loss: 0.2824\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7902\n",
      "Epoch: 4798/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7902\n",
      "Epoch: 4799/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7903\n",
      "Epoch: 4800/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7903\n",
      "Epoch: 4801/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7904\n",
      "Epoch: 4802/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7905\n",
      "Epoch: 4803/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7905\n",
      "Epoch: 4804/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7906\n",
      "Epoch: 4805/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7906\n",
      "Epoch: 4806/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7907\n",
      "Epoch: 4807/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7908\n",
      "Epoch: 4808/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7908\n",
      "Epoch: 4809/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7909\n",
      "Epoch: 4810/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7909\n",
      "Epoch: 4811/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7910\n",
      "Epoch: 4812/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7911\n",
      "Epoch: 4813/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7911\n",
      "Epoch: 4814/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7912\n",
      "Epoch: 4815/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7912\n",
      "Epoch: 4816/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7913\n",
      "Epoch: 4817/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7914\n",
      "Epoch: 4818/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7914\n",
      "Epoch: 4819/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7915\n",
      "Epoch: 4820/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7915\n",
      "Epoch: 4821/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7916\n",
      "Epoch: 4822/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7917\n",
      "Epoch: 4823/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7917\n",
      "Epoch: 4824/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7918\n",
      "Epoch: 4825/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7918\n",
      "Epoch: 4826/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7919\n",
      "Epoch: 4827/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7920\n",
      "Epoch: 4828/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7920\n",
      "Epoch: 4829/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7921\n",
      "Epoch: 4830/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7921\n",
      "Epoch: 4831/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7922\n",
      "Epoch: 4832/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7923\n",
      "Epoch: 4833/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7923\n",
      "Epoch: 4834/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7924\n",
      "Epoch: 4835/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7924\n",
      "Epoch: 4836/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7925\n",
      "Epoch: 4837/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7925\n",
      "Epoch: 4838/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7926\n",
      "Epoch: 4839/8000, Train Loss: 0.2823\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7927\n",
      "Epoch: 4840/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7927\n",
      "Epoch: 4841/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7928\n",
      "Epoch: 4842/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7928\n",
      "Epoch: 4843/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7929\n",
      "Epoch: 4844/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7930\n",
      "Epoch: 4845/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7930\n",
      "Epoch: 4846/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7931\n",
      "Epoch: 4847/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7931\n",
      "Epoch: 4848/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7932\n",
      "Epoch: 4849/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7933\n",
      "Epoch: 4850/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7933\n",
      "Epoch: 4851/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7934\n",
      "Epoch: 4852/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7934\n",
      "Epoch: 4853/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7935\n",
      "Epoch: 4854/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7936\n",
      "Epoch: 4855/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7936\n",
      "Epoch: 4856/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7937\n",
      "Epoch: 4857/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7937\n",
      "Epoch: 4858/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7938\n",
      "Epoch: 4859/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7939\n",
      "Epoch: 4860/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7939\n",
      "Epoch: 4861/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7940\n",
      "Epoch: 4862/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7940\n",
      "Epoch: 4863/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7941\n",
      "Epoch: 4864/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7942\n",
      "Epoch: 4865/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7942\n",
      "Epoch: 4866/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7943\n",
      "Epoch: 4867/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7943\n",
      "Epoch: 4868/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7944\n",
      "Epoch: 4869/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7945\n",
      "Epoch: 4870/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7945\n",
      "Epoch: 4871/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7946\n",
      "Epoch: 4872/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7946\n",
      "Epoch: 4873/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7947\n",
      "Epoch: 4874/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7948\n",
      "Epoch: 4875/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7948\n",
      "Epoch: 4876/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7949\n",
      "Epoch: 4877/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7949\n",
      "Epoch: 4878/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7950\n",
      "Epoch: 4879/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7951\n",
      "Epoch: 4880/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7951\n",
      "Epoch: 4881/8000, Train Loss: 0.2822\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7952\n",
      "Epoch: 4882/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7952\n",
      "Epoch: 4883/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7953\n",
      "Epoch: 4884/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7954\n",
      "Epoch: 4885/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7954\n",
      "Epoch: 4886/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7955\n",
      "Epoch: 4887/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7955\n",
      "Epoch: 4888/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7956\n",
      "Epoch: 4889/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7956\n",
      "Epoch: 4890/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7957\n",
      "Epoch: 4891/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7958\n",
      "Epoch: 4892/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7958\n",
      "Epoch: 4893/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7959\n",
      "Epoch: 4894/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7959\n",
      "Epoch: 4895/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7960\n",
      "Epoch: 4896/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7961\n",
      "Epoch: 4897/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7961\n",
      "Epoch: 4898/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7962\n",
      "Epoch: 4899/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7962\n",
      "Epoch: 4900/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7963\n",
      "Epoch: 4901/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7964\n",
      "Epoch: 4902/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7964\n",
      "Epoch: 4903/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7965\n",
      "Epoch: 4904/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7965\n",
      "Epoch: 4905/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7966\n",
      "Epoch: 4906/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7967\n",
      "Epoch: 4907/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7967\n",
      "Epoch: 4908/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7968\n",
      "Epoch: 4909/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7968\n",
      "Epoch: 4910/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7969\n",
      "Epoch: 4911/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7970\n",
      "Epoch: 4912/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7970\n",
      "Epoch: 4913/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7971\n",
      "Epoch: 4914/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7971\n",
      "Epoch: 4915/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7972\n",
      "Epoch: 4916/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7973\n",
      "Epoch: 4917/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7973\n",
      "Epoch: 4918/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7974\n",
      "Epoch: 4919/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7974\n",
      "Epoch: 4920/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7975\n",
      "Epoch: 4921/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7976\n",
      "Epoch: 4922/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7976\n",
      "Epoch: 4923/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7977\n",
      "Epoch: 4924/8000, Train Loss: 0.2821\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7977\n",
      "Epoch: 4925/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7978\n",
      "Epoch: 4926/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7978\n",
      "Epoch: 4927/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7979\n",
      "Epoch: 4928/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7980\n",
      "Epoch: 4929/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7980\n",
      "Epoch: 4930/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7981\n",
      "Epoch: 4931/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7981\n",
      "Epoch: 4932/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7982\n",
      "Epoch: 4933/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7983\n",
      "Epoch: 4934/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7983\n",
      "Epoch: 4935/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7984\n",
      "Epoch: 4936/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7984\n",
      "Epoch: 4937/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7985\n",
      "Epoch: 4938/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7986\n",
      "Epoch: 4939/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7986\n",
      "Epoch: 4940/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7987\n",
      "Epoch: 4941/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7987\n",
      "Epoch: 4942/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7988\n",
      "Epoch: 4943/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7989\n",
      "Epoch: 4944/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7989\n",
      "Epoch: 4945/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7990\n",
      "Epoch: 4946/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7990\n",
      "Epoch: 4947/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7991\n",
      "Epoch: 4948/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7992\n",
      "Epoch: 4949/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7992\n",
      "Epoch: 4950/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7993\n",
      "Epoch: 4951/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7993\n",
      "Epoch: 4952/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7994\n",
      "Epoch: 4953/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7995\n",
      "Epoch: 4954/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7995\n",
      "Epoch: 4955/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7996\n",
      "Epoch: 4956/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7996\n",
      "Epoch: 4957/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7997\n",
      "Epoch: 4958/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7998\n",
      "Epoch: 4959/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7998\n",
      "Epoch: 4960/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7999\n",
      "Epoch: 4961/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.7999\n",
      "Epoch: 4962/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8000\n",
      "Epoch: 4963/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8000\n",
      "Epoch: 4964/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8001\n",
      "Epoch: 4965/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8002\n",
      "Epoch: 4966/8000, Train Loss: 0.2820\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8002\n",
      "Epoch: 4967/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8003\n",
      "Epoch: 4968/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8003\n",
      "Epoch: 4969/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8004\n",
      "Epoch: 4970/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8005\n",
      "Epoch: 4971/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8005\n",
      "Epoch: 4972/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8006\n",
      "Epoch: 4973/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8006\n",
      "Epoch: 4974/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8007\n",
      "Epoch: 4975/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8008\n",
      "Epoch: 4976/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8008\n",
      "Epoch: 4977/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8009\n",
      "Epoch: 4978/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8009\n",
      "Epoch: 4979/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8010\n",
      "Epoch: 4980/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8011\n",
      "Epoch: 4981/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8011\n",
      "Epoch: 4982/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8012\n",
      "Epoch: 4983/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8012\n",
      "Epoch: 4984/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8013\n",
      "Epoch: 4985/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8014\n",
      "Epoch: 4986/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8014\n",
      "Epoch: 4987/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8015\n",
      "Epoch: 4988/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8015\n",
      "Epoch: 4989/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8016\n",
      "Epoch: 4990/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8016\n",
      "Epoch: 4991/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8017\n",
      "Epoch: 4992/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8018\n",
      "Epoch: 4993/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8018\n",
      "Epoch: 4994/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8019\n",
      "Epoch: 4995/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8019\n",
      "Epoch: 4996/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8020\n",
      "Epoch: 4997/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8021\n",
      "Epoch: 4998/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8021\n",
      "Epoch: 4999/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8022\n",
      "Epoch: 5000/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8022\n",
      "Epoch: 5001/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8023\n",
      "Epoch: 5002/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8024\n",
      "Epoch: 5003/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8024\n",
      "Epoch: 5004/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8025\n",
      "Epoch: 5005/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8025\n",
      "Epoch: 5006/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8026\n",
      "Epoch: 5007/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8027\n",
      "Epoch: 5008/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8027\n",
      "Epoch: 5009/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8028\n",
      "Epoch: 5010/8000, Train Loss: 0.2819\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8028\n",
      "Epoch: 5011/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8029\n",
      "Epoch: 5012/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8030\n",
      "Epoch: 5013/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8030\n",
      "Epoch: 5014/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8031\n",
      "Epoch: 5015/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8031\n",
      "Epoch: 5016/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8032\n",
      "Epoch: 5017/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8032\n",
      "Epoch: 5018/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8033\n",
      "Epoch: 5019/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8034\n",
      "Epoch: 5020/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8034\n",
      "Epoch: 5021/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8035\n",
      "Epoch: 5022/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8035\n",
      "Epoch: 5023/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8036\n",
      "Epoch: 5024/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8037\n",
      "Epoch: 5025/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8037\n",
      "Epoch: 5026/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8038\n",
      "Epoch: 5027/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8038\n",
      "Epoch: 5028/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8039\n",
      "Epoch: 5029/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8040\n",
      "Epoch: 5030/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8040\n",
      "Epoch: 5031/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8041\n",
      "Epoch: 5032/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8041\n",
      "Epoch: 5033/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8042\n",
      "Epoch: 5034/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8043\n",
      "Epoch: 5035/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8043\n",
      "Epoch: 5036/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8044\n",
      "Epoch: 5037/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8044\n",
      "Epoch: 5038/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8045\n",
      "Epoch: 5039/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8045\n",
      "Epoch: 5040/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8046\n",
      "Epoch: 5041/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8047\n",
      "Epoch: 5042/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8047\n",
      "Epoch: 5043/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8048\n",
      "Epoch: 5044/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8048\n",
      "Epoch: 5045/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8049\n",
      "Epoch: 5046/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8050\n",
      "Epoch: 5047/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8050\n",
      "Epoch: 5048/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8051\n",
      "Epoch: 5049/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8051\n",
      "Epoch: 5050/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8052\n",
      "Epoch: 5051/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8053\n",
      "Epoch: 5052/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8053\n",
      "Epoch: 5053/8000, Train Loss: 0.2818\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8054\n",
      "Epoch: 5054/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8054\n",
      "Epoch: 5055/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8055\n",
      "Epoch: 5056/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8056\n",
      "Epoch: 5057/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8056\n",
      "Epoch: 5058/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8057\n",
      "Epoch: 5059/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8057\n",
      "Epoch: 5060/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8058\n",
      "Epoch: 5061/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8059\n",
      "Epoch: 5062/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8059\n",
      "Epoch: 5063/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8060\n",
      "Epoch: 5064/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8060\n",
      "Epoch: 5065/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8061\n",
      "Epoch: 5066/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8061\n",
      "Epoch: 5067/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8062\n",
      "Epoch: 5068/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8063\n",
      "Epoch: 5069/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8063\n",
      "Epoch: 5070/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8064\n",
      "Epoch: 5071/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8064\n",
      "Epoch: 5072/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8065\n",
      "Epoch: 5073/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8066\n",
      "Epoch: 5074/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8066\n",
      "Epoch: 5075/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8067\n",
      "Epoch: 5076/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8067\n",
      "Epoch: 5077/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8068\n",
      "Epoch: 5078/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8069\n",
      "Epoch: 5079/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8069\n",
      "Epoch: 5080/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8070\n",
      "Epoch: 5081/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8070\n",
      "Epoch: 5082/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8071\n",
      "Epoch: 5083/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8071\n",
      "Epoch: 5084/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8072\n",
      "Epoch: 5085/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8073\n",
      "Epoch: 5086/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8073\n",
      "Epoch: 5087/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8074\n",
      "Epoch: 5088/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8074\n",
      "Epoch: 5089/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8075\n",
      "Epoch: 5090/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8076\n",
      "Epoch: 5091/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8076\n",
      "Epoch: 5092/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8077\n",
      "Epoch: 5093/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8077\n",
      "Epoch: 5094/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8078\n",
      "Epoch: 5095/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8079\n",
      "Epoch: 5096/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8079\n",
      "Epoch: 5097/8000, Train Loss: 0.2817\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8080\n",
      "Epoch: 5098/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8080\n",
      "Epoch: 5099/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8081\n",
      "Epoch: 5100/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8082\n",
      "Epoch: 5101/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8082\n",
      "Epoch: 5102/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8083\n",
      "Epoch: 5103/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8083\n",
      "Epoch: 5104/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8084\n",
      "Epoch: 5105/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8084\n",
      "Epoch: 5106/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8085\n",
      "Epoch: 5107/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8086\n",
      "Epoch: 5108/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8086\n",
      "Epoch: 5109/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8087\n",
      "Epoch: 5110/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8087\n",
      "Epoch: 5111/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8088\n",
      "Epoch: 5112/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8089\n",
      "Epoch: 5113/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8089\n",
      "Epoch: 5114/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8090\n",
      "Epoch: 5115/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8090\n",
      "Epoch: 5116/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8091\n",
      "Epoch: 5117/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8092\n",
      "Epoch: 5118/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8092\n",
      "Epoch: 5119/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8093\n",
      "Epoch: 5120/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8093\n",
      "Epoch: 5121/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8094\n",
      "Epoch: 5122/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8095\n",
      "Epoch: 5123/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8095\n",
      "Epoch: 5124/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8096\n",
      "Epoch: 5125/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8096\n",
      "Epoch: 5126/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8097\n",
      "Epoch: 5127/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8097\n",
      "Epoch: 5128/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8098\n",
      "Epoch: 5129/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8099\n",
      "Epoch: 5130/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8099\n",
      "Epoch: 5131/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8100\n",
      "Epoch: 5132/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8100\n",
      "Epoch: 5133/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8101\n",
      "Epoch: 5134/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8102\n",
      "Epoch: 5135/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8102\n",
      "Epoch: 5136/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8103\n",
      "Epoch: 5137/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8103\n",
      "Epoch: 5138/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8104\n",
      "Epoch: 5139/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8105\n",
      "Epoch: 5140/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8105\n",
      "Epoch: 5141/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8106\n",
      "Epoch: 5142/8000, Train Loss: 0.2816\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8106\n",
      "Epoch: 5143/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8107\n",
      "Epoch: 5144/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8107\n",
      "Epoch: 5145/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8108\n",
      "Epoch: 5146/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8109\n",
      "Epoch: 5147/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8109\n",
      "Epoch: 5148/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8110\n",
      "Epoch: 5149/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8110\n",
      "Epoch: 5150/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8111\n",
      "Epoch: 5151/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8112\n",
      "Epoch: 5152/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8112\n",
      "Epoch: 5153/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8113\n",
      "Epoch: 5154/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8113\n",
      "Epoch: 5155/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8114\n",
      "Epoch: 5156/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8115\n",
      "Epoch: 5157/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8115\n",
      "Epoch: 5158/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8116\n",
      "Epoch: 5159/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8116\n",
      "Epoch: 5160/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8117\n",
      "Epoch: 5161/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8117\n",
      "Epoch: 5162/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8118\n",
      "Epoch: 5163/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8119\n",
      "Epoch: 5164/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8119\n",
      "Epoch: 5165/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8120\n",
      "Epoch: 5166/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8120\n",
      "Epoch: 5167/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8121\n",
      "Epoch: 5168/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8122\n",
      "Epoch: 5169/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8122\n",
      "Epoch: 5170/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8123\n",
      "Epoch: 5171/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8123\n",
      "Epoch: 5172/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8124\n",
      "Epoch: 5173/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8125\n",
      "Epoch: 5174/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8125\n",
      "Epoch: 5175/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8126\n",
      "Epoch: 5176/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8126\n",
      "Epoch: 5177/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8127\n",
      "Epoch: 5178/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8127\n",
      "Epoch: 5179/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8128\n",
      "Epoch: 5180/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8129\n",
      "Epoch: 5181/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8129\n",
      "Epoch: 5182/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8130\n",
      "Epoch: 5183/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8130\n",
      "Epoch: 5184/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8131\n",
      "Epoch: 5185/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8132\n",
      "Epoch: 5186/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8132\n",
      "Epoch: 5187/8000, Train Loss: 0.2815\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8133\n",
      "Epoch: 5188/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8133\n",
      "Epoch: 5189/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8134\n",
      "Epoch: 5190/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8135\n",
      "Epoch: 5191/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8135\n",
      "Epoch: 5192/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8136\n",
      "Epoch: 5193/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8136\n",
      "Epoch: 5194/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8137\n",
      "Epoch: 5195/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8137\n",
      "Epoch: 5196/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8138\n",
      "Epoch: 5197/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8139\n",
      "Epoch: 5198/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8139\n",
      "Epoch: 5199/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8140\n",
      "Epoch: 5200/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8140\n",
      "Epoch: 5201/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8141\n",
      "Epoch: 5202/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8142\n",
      "Epoch: 5203/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8142\n",
      "Epoch: 5204/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8143\n",
      "Epoch: 5205/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8143\n",
      "Epoch: 5206/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8144\n",
      "Epoch: 5207/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8145\n",
      "Epoch: 5208/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8145\n",
      "Epoch: 5209/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8146\n",
      "Epoch: 5210/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8146\n",
      "Epoch: 5211/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8147\n",
      "Epoch: 5212/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8147\n",
      "Epoch: 5213/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8148\n",
      "Epoch: 5214/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8149\n",
      "Epoch: 5215/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8149\n",
      "Epoch: 5216/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8150\n",
      "Epoch: 5217/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8150\n",
      "Epoch: 5218/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8151\n",
      "Epoch: 5219/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8152\n",
      "Epoch: 5220/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8152\n",
      "Epoch: 5221/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8153\n",
      "Epoch: 5222/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8153\n",
      "Epoch: 5223/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8154\n",
      "Epoch: 5224/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8154\n",
      "Epoch: 5225/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8155\n",
      "Epoch: 5226/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8156\n",
      "Epoch: 5227/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8156\n",
      "Epoch: 5228/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8157\n",
      "Epoch: 5229/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8157\n",
      "Epoch: 5230/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8158\n",
      "Epoch: 5231/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8159\n",
      "Epoch: 5232/8000, Train Loss: 0.2814\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8159\n",
      "Epoch: 5233/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8160\n",
      "Epoch: 5234/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8160\n",
      "Epoch: 5235/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8161\n",
      "Epoch: 5236/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8162\n",
      "Epoch: 5237/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8162\n",
      "Epoch: 5238/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8163\n",
      "Epoch: 5239/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8163\n",
      "Epoch: 5240/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8164\n",
      "Epoch: 5241/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8164\n",
      "Epoch: 5242/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8165\n",
      "Epoch: 5243/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8166\n",
      "Epoch: 5244/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8166\n",
      "Epoch: 5245/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8167\n",
      "Epoch: 5246/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8167\n",
      "Epoch: 5247/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8168\n",
      "Epoch: 5248/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8169\n",
      "Epoch: 5249/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8169\n",
      "Epoch: 5250/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8170\n",
      "Epoch: 5251/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8170\n",
      "Epoch: 5252/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8171\n",
      "Epoch: 5253/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8171\n",
      "Epoch: 5254/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8172\n",
      "Epoch: 5255/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8173\n",
      "Epoch: 5256/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8173\n",
      "Epoch: 5257/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8174\n",
      "Epoch: 5258/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8174\n",
      "Epoch: 5259/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8175\n",
      "Epoch: 5260/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8176\n",
      "Epoch: 5261/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8176\n",
      "Epoch: 5262/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8177\n",
      "Epoch: 5263/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8177\n",
      "Epoch: 5264/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8178\n",
      "Epoch: 5265/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8179\n",
      "Epoch: 5266/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8179\n",
      "Epoch: 5267/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8180\n",
      "Epoch: 5268/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8180\n",
      "Epoch: 5269/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8181\n",
      "Epoch: 5270/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8181\n",
      "Epoch: 5271/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8182\n",
      "Epoch: 5272/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8183\n",
      "Epoch: 5273/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8183\n",
      "Epoch: 5274/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8184\n",
      "Epoch: 5275/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8184\n",
      "Epoch: 5276/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8185\n",
      "Epoch: 5277/8000, Train Loss: 0.2813\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8186\n",
      "Epoch: 5278/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8186\n",
      "Epoch: 5279/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8187\n",
      "Epoch: 5280/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8187\n",
      "Epoch: 5281/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8188\n",
      "Epoch: 5282/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8188\n",
      "Epoch: 5283/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8189\n",
      "Epoch: 5284/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8190\n",
      "Epoch: 5285/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8190\n",
      "Epoch: 5286/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8191\n",
      "Epoch: 5287/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8191\n",
      "Epoch: 5288/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8192\n",
      "Epoch: 5289/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8193\n",
      "Epoch: 5290/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8193\n",
      "Epoch: 5291/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8194\n",
      "Epoch: 5292/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8194\n",
      "Epoch: 5293/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8195\n",
      "Epoch: 5294/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8196\n",
      "Epoch: 5295/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8196\n",
      "Epoch: 5296/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8197\n",
      "Epoch: 5297/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8197\n",
      "Epoch: 5298/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8198\n",
      "Epoch: 5299/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8198\n",
      "Epoch: 5300/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8199\n",
      "Epoch: 5301/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8200\n",
      "Epoch: 5302/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8200\n",
      "Epoch: 5303/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8201\n",
      "Epoch: 5304/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8201\n",
      "Epoch: 5305/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8202\n",
      "Epoch: 5306/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8203\n",
      "Epoch: 5307/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8203\n",
      "Epoch: 5308/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8204\n",
      "Epoch: 5309/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8204\n",
      "Epoch: 5310/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8205\n",
      "Epoch: 5311/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8205\n",
      "Epoch: 5312/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8206\n",
      "Epoch: 5313/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8207\n",
      "Epoch: 5314/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8207\n",
      "Epoch: 5315/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8208\n",
      "Epoch: 5316/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8208\n",
      "Epoch: 5317/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8209\n",
      "Epoch: 5318/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8210\n",
      "Epoch: 5319/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8210\n",
      "Epoch: 5320/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8211\n",
      "Epoch: 5321/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8211\n",
      "Epoch: 5322/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8212\n",
      "Epoch: 5323/8000, Train Loss: 0.2812\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8212\n",
      "Epoch: 5324/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8213\n",
      "Epoch: 5325/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8214\n",
      "Epoch: 5326/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8214\n",
      "Epoch: 5327/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8215\n",
      "Epoch: 5328/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8215\n",
      "Epoch: 5329/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8216\n",
      "Epoch: 5330/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8217\n",
      "Epoch: 5331/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8217\n",
      "Epoch: 5332/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8218\n",
      "Epoch: 5333/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8218\n",
      "Epoch: 5334/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8219\n",
      "Epoch: 5335/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8219\n",
      "Epoch: 5336/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8220\n",
      "Epoch: 5337/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8221\n",
      "Epoch: 5338/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8221\n",
      "Epoch: 5339/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8222\n",
      "Epoch: 5340/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8222\n",
      "Epoch: 5341/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8223\n",
      "Epoch: 5342/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8224\n",
      "Epoch: 5343/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8224\n",
      "Epoch: 5344/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8225\n",
      "Epoch: 5345/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8225\n",
      "Epoch: 5346/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8226\n",
      "Epoch: 5347/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8226\n",
      "Epoch: 5348/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8227\n",
      "Epoch: 5349/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8228\n",
      "Epoch: 5350/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8228\n",
      "Epoch: 5351/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8229\n",
      "Epoch: 5352/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8229\n",
      "Epoch: 5353/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8230\n",
      "Epoch: 5354/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8231\n",
      "Epoch: 5355/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8231\n",
      "Epoch: 5356/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8232\n",
      "Epoch: 5357/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8232\n",
      "Epoch: 5358/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8233\n",
      "Epoch: 5359/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8233\n",
      "Epoch: 5360/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8234\n",
      "Epoch: 5361/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8235\n",
      "Epoch: 5362/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8235\n",
      "Epoch: 5363/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8236\n",
      "Epoch: 5364/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8236\n",
      "Epoch: 5365/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8237\n",
      "Epoch: 5366/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8238\n",
      "Epoch: 5367/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8238\n",
      "Epoch: 5368/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8239\n",
      "Epoch: 5369/8000, Train Loss: 0.2811\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8239\n",
      "Epoch: 5370/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8240\n",
      "Epoch: 5371/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8240\n",
      "Epoch: 5372/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8241\n",
      "Epoch: 5373/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8242\n",
      "Epoch: 5374/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8242\n",
      "Epoch: 5375/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8243\n",
      "Epoch: 5376/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8243\n",
      "Epoch: 5377/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8244\n",
      "Epoch: 5378/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8245\n",
      "Epoch: 5379/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8245\n",
      "Epoch: 5380/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8246\n",
      "Epoch: 5381/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8246\n",
      "Epoch: 5382/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8247\n",
      "Epoch: 5383/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8247\n",
      "Epoch: 5384/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8248\n",
      "Epoch: 5385/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8249\n",
      "Epoch: 5386/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8249\n",
      "Epoch: 5387/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8250\n",
      "Epoch: 5388/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8250\n",
      "Epoch: 5389/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8251\n",
      "Epoch: 5390/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8252\n",
      "Epoch: 5391/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8252\n",
      "Epoch: 5392/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8253\n",
      "Epoch: 5393/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8253\n",
      "Epoch: 5394/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8254\n",
      "Epoch: 5395/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8254\n",
      "Epoch: 5396/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8255\n",
      "Epoch: 5397/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8256\n",
      "Epoch: 5398/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8256\n",
      "Epoch: 5399/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8257\n",
      "Epoch: 5400/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8257\n",
      "Epoch: 5401/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8258\n",
      "Epoch: 5402/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8259\n",
      "Epoch: 5403/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8259\n",
      "Epoch: 5404/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8260\n",
      "Epoch: 5405/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8260\n",
      "Epoch: 5406/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8261\n",
      "Epoch: 5407/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8261\n",
      "Epoch: 5408/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8262\n",
      "Epoch: 5409/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8263\n",
      "Epoch: 5410/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8263\n",
      "Epoch: 5411/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8264\n",
      "Epoch: 5412/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8264\n",
      "Epoch: 5413/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8265\n",
      "Epoch: 5414/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8266\n",
      "Epoch: 5415/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8266\n",
      "Epoch: 5416/8000, Train Loss: 0.2810\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8267\n",
      "Epoch: 5417/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8267\n",
      "Epoch: 5418/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8268\n",
      "Epoch: 5419/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8268\n",
      "Epoch: 5420/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8269\n",
      "Epoch: 5421/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8270\n",
      "Epoch: 5422/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8270\n",
      "Epoch: 5423/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8271\n",
      "Epoch: 5424/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8271\n",
      "Epoch: 5425/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8272\n",
      "Epoch: 5426/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8273\n",
      "Epoch: 5427/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8273\n",
      "Epoch: 5428/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8274\n",
      "Epoch: 5429/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8274\n",
      "Epoch: 5430/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8275\n",
      "Epoch: 5431/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8275\n",
      "Epoch: 5432/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8276\n",
      "Epoch: 5433/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8277\n",
      "Epoch: 5434/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8277\n",
      "Epoch: 5435/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8278\n",
      "Epoch: 5436/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8278\n",
      "Epoch: 5437/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8279\n",
      "Epoch: 5438/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8280\n",
      "Epoch: 5439/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8280\n",
      "Epoch: 5440/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8281\n",
      "Epoch: 5441/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8281\n",
      "Epoch: 5442/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8282\n",
      "Epoch: 5443/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8282\n",
      "Epoch: 5444/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8283\n",
      "Epoch: 5445/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8284\n",
      "Epoch: 5446/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8284\n",
      "Epoch: 5447/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8285\n",
      "Epoch: 5448/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8285\n",
      "Epoch: 5449/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8286\n",
      "Epoch: 5450/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8287\n",
      "Epoch: 5451/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8287\n",
      "Epoch: 5452/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8288\n",
      "Epoch: 5453/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8288\n",
      "Epoch: 5454/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8289\n",
      "Epoch: 5455/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8289\n",
      "Epoch: 5456/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8290\n",
      "Epoch: 5457/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8291\n",
      "Epoch: 5458/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8291\n",
      "Epoch: 5459/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8292\n",
      "Epoch: 5460/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8292\n",
      "Epoch: 5461/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8293\n",
      "Epoch: 5462/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8293\n",
      "Epoch: 5463/8000, Train Loss: 0.2809\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8294\n",
      "Epoch: 5464/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8295\n",
      "Epoch: 5465/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8295\n",
      "Epoch: 5466/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8296\n",
      "Epoch: 5467/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8296\n",
      "Epoch: 5468/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8297\n",
      "Epoch: 5469/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8298\n",
      "Epoch: 5470/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8298\n",
      "Epoch: 5471/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8299\n",
      "Epoch: 5472/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8299\n",
      "Epoch: 5473/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8300\n",
      "Epoch: 5474/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8300\n",
      "Epoch: 5475/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8301\n",
      "Epoch: 5476/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8302\n",
      "Epoch: 5477/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8302\n",
      "Epoch: 5478/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8303\n",
      "Epoch: 5479/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8303\n",
      "Epoch: 5480/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8304\n",
      "Epoch: 5481/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8305\n",
      "Epoch: 5482/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8305\n",
      "Epoch: 5483/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8306\n",
      "Epoch: 5484/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8306\n",
      "Epoch: 5485/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8307\n",
      "Epoch: 5486/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8307\n",
      "Epoch: 5487/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8308\n",
      "Epoch: 5488/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8309\n",
      "Epoch: 5489/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8309\n",
      "Epoch: 5490/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8310\n",
      "Epoch: 5491/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8310\n",
      "Epoch: 5492/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8311\n",
      "Epoch: 5493/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8311\n",
      "Epoch: 5494/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8312\n",
      "Epoch: 5495/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8313\n",
      "Epoch: 5496/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8313\n",
      "Epoch: 5497/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8314\n",
      "Epoch: 5498/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8314\n",
      "Epoch: 5499/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8315\n",
      "Epoch: 5500/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8316\n",
      "Epoch: 5501/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8316\n",
      "Epoch: 5502/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8317\n",
      "Epoch: 5503/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8317\n",
      "Epoch: 5504/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8318\n",
      "Epoch: 5505/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8318\n",
      "Epoch: 5506/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8319\n",
      "Epoch: 5507/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8320\n",
      "Epoch: 5508/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8320\n",
      "Epoch: 5509/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8321\n",
      "Epoch: 5510/8000, Train Loss: 0.2808\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8321\n",
      "Epoch: 5511/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8322\n",
      "Epoch: 5512/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8323\n",
      "Epoch: 5513/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8323\n",
      "Epoch: 5514/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8324\n",
      "Epoch: 5515/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8324\n",
      "Epoch: 5516/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8325\n",
      "Epoch: 5517/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8325\n",
      "Epoch: 5518/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8326\n",
      "Epoch: 5519/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8327\n",
      "Epoch: 5520/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8327\n",
      "Epoch: 5521/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8328\n",
      "Epoch: 5522/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8328\n",
      "Epoch: 5523/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8329\n",
      "Epoch: 5524/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8329\n",
      "Epoch: 5525/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8330\n",
      "Epoch: 5526/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8331\n",
      "Epoch: 5527/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8331\n",
      "Epoch: 5528/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8332\n",
      "Epoch: 5529/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8332\n",
      "Epoch: 5530/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8333\n",
      "Epoch: 5531/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8334\n",
      "Epoch: 5532/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8334\n",
      "Epoch: 5533/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8335\n",
      "Epoch: 5534/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8335\n",
      "Epoch: 5535/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8336\n",
      "Epoch: 5536/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8336\n",
      "Epoch: 5537/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8337\n",
      "Epoch: 5538/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8338\n",
      "Epoch: 5539/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8338\n",
      "Epoch: 5540/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8339\n",
      "Epoch: 5541/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8339\n",
      "Epoch: 5542/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8340\n",
      "Epoch: 5543/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8340\n",
      "Epoch: 5544/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8341\n",
      "Epoch: 5545/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8342\n",
      "Epoch: 5546/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8342\n",
      "Epoch: 5547/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8343\n",
      "Epoch: 5548/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8343\n",
      "Epoch: 5549/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8344\n",
      "Epoch: 5550/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8345\n",
      "Epoch: 5551/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8345\n",
      "Epoch: 5552/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8346\n",
      "Epoch: 5553/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8346\n",
      "Epoch: 5554/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8347\n",
      "Epoch: 5555/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8347\n",
      "Epoch: 5556/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8348\n",
      "Epoch: 5557/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8349\n",
      "Epoch: 5558/8000, Train Loss: 0.2807\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8349\n",
      "Epoch: 5559/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8350\n",
      "Epoch: 5560/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8350\n",
      "Epoch: 5561/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8351\n",
      "Epoch: 5562/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8351\n",
      "Epoch: 5563/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8352\n",
      "Epoch: 5564/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8353\n",
      "Epoch: 5565/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8353\n",
      "Epoch: 5566/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8354\n",
      "Epoch: 5567/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8354\n",
      "Epoch: 5568/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8355\n",
      "Epoch: 5569/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8356\n",
      "Epoch: 5570/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8356\n",
      "Epoch: 5571/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8357\n",
      "Epoch: 5572/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8357\n",
      "Epoch: 5573/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8358\n",
      "Epoch: 5574/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8358\n",
      "Epoch: 5575/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8359\n",
      "Epoch: 5576/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8360\n",
      "Epoch: 5577/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8360\n",
      "Epoch: 5578/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8361\n",
      "Epoch: 5579/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8361\n",
      "Epoch: 5580/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8362\n",
      "Epoch: 5581/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8362\n",
      "Epoch: 5582/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8363\n",
      "Epoch: 5583/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8364\n",
      "Epoch: 5584/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8364\n",
      "Epoch: 5585/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8365\n",
      "Epoch: 5586/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8365\n",
      "Epoch: 5587/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8366\n",
      "Epoch: 5588/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8367\n",
      "Epoch: 5589/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8367\n",
      "Epoch: 5590/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8368\n",
      "Epoch: 5591/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8368\n",
      "Epoch: 5592/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8369\n",
      "Epoch: 5593/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8369\n",
      "Epoch: 5594/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8370\n",
      "Epoch: 5595/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8371\n",
      "Epoch: 5596/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8371\n",
      "Epoch: 5597/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8372\n",
      "Epoch: 5598/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8372\n",
      "Epoch: 5599/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8373\n",
      "Epoch: 5600/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8373\n",
      "Epoch: 5601/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8374\n",
      "Epoch: 5602/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8375\n",
      "Epoch: 5603/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8375\n",
      "Epoch: 5604/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8376\n",
      "Epoch: 5605/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8376\n",
      "Epoch: 5606/8000, Train Loss: 0.2806\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8377\n",
      "Epoch: 5607/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8378\n",
      "Epoch: 5608/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8378\n",
      "Epoch: 5609/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8379\n",
      "Epoch: 5610/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8379\n",
      "Epoch: 5611/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8380\n",
      "Epoch: 5612/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8380\n",
      "Epoch: 5613/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8381\n",
      "Epoch: 5614/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8382\n",
      "Epoch: 5615/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8382\n",
      "Epoch: 5616/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8383\n",
      "Epoch: 5617/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8383\n",
      "Epoch: 5618/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8384\n",
      "Epoch: 5619/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8384\n",
      "Epoch: 5620/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8385\n",
      "Epoch: 5621/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8386\n",
      "Epoch: 5622/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8386\n",
      "Epoch: 5623/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8387\n",
      "Epoch: 5624/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8387\n",
      "Epoch: 5625/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8388\n",
      "Epoch: 5626/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8388\n",
      "Epoch: 5627/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8389\n",
      "Epoch: 5628/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8390\n",
      "Epoch: 5629/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8390\n",
      "Epoch: 5630/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8391\n",
      "Epoch: 5631/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8391\n",
      "Epoch: 5632/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8392\n",
      "Epoch: 5633/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8393\n",
      "Epoch: 5634/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8393\n",
      "Epoch: 5635/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8394\n",
      "Epoch: 5636/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8394\n",
      "Epoch: 5637/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8395\n",
      "Epoch: 5638/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8395\n",
      "Epoch: 5639/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8396\n",
      "Epoch: 5640/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8397\n",
      "Epoch: 5641/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8397\n",
      "Epoch: 5642/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8398\n",
      "Epoch: 5643/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8398\n",
      "Epoch: 5644/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8399\n",
      "Epoch: 5645/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8399\n",
      "Epoch: 5646/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8400\n",
      "Epoch: 5647/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8401\n",
      "Epoch: 5648/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8401\n",
      "Epoch: 5649/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8402\n",
      "Epoch: 5650/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8402\n",
      "Epoch: 5651/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8403\n",
      "Epoch: 5652/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8403\n",
      "Epoch: 5653/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8404\n",
      "Epoch: 5654/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8405\n",
      "Epoch: 5655/8000, Train Loss: 0.2805\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8405\n",
      "Epoch: 5656/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8406\n",
      "Epoch: 5657/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8406\n",
      "Epoch: 5658/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8407\n",
      "Epoch: 5659/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8408\n",
      "Epoch: 5660/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8408\n",
      "Epoch: 5661/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8409\n",
      "Epoch: 5662/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8409\n",
      "Epoch: 5663/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8410\n",
      "Epoch: 5664/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8410\n",
      "Epoch: 5665/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8411\n",
      "Epoch: 5666/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8412\n",
      "Epoch: 5667/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8412\n",
      "Epoch: 5668/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8413\n",
      "Epoch: 5669/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8413\n",
      "Epoch: 5670/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8414\n",
      "Epoch: 5671/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8414\n",
      "Epoch: 5672/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8415\n",
      "Epoch: 5673/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8416\n",
      "Epoch: 5674/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8416\n",
      "Epoch: 5675/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8417\n",
      "Epoch: 5676/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8417\n",
      "Epoch: 5677/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8418\n",
      "Epoch: 5678/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8418\n",
      "Epoch: 5679/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8419\n",
      "Epoch: 5680/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8420\n",
      "Epoch: 5681/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8420\n",
      "Epoch: 5682/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8421\n",
      "Epoch: 5683/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8421\n",
      "Epoch: 5684/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8422\n",
      "Epoch: 5685/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8423\n",
      "Epoch: 5686/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8423\n",
      "Epoch: 5687/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8424\n",
      "Epoch: 5688/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8424\n",
      "Epoch: 5689/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8425\n",
      "Epoch: 5690/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8425\n",
      "Epoch: 5691/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8426\n",
      "Epoch: 5692/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8427\n",
      "Epoch: 5693/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8427\n",
      "Epoch: 5694/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8428\n",
      "Epoch: 5695/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8428\n",
      "Epoch: 5696/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8429\n",
      "Epoch: 5697/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8429\n",
      "Epoch: 5698/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8430\n",
      "Epoch: 5699/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8431\n",
      "Epoch: 5700/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8431\n",
      "Epoch: 5701/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8432\n",
      "Epoch: 5702/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8432\n",
      "Epoch: 5703/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8433\n",
      "Epoch: 5704/8000, Train Loss: 0.2804\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8433\n",
      "Epoch: 5705/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8434\n",
      "Epoch: 5706/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8435\n",
      "Epoch: 5707/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8435\n",
      "Epoch: 5708/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8436\n",
      "Epoch: 5709/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8436\n",
      "Epoch: 5710/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8437\n",
      "Epoch: 5711/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8437\n",
      "Epoch: 5712/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8438\n",
      "Epoch: 5713/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8439\n",
      "Epoch: 5714/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8439\n",
      "Epoch: 5715/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8440\n",
      "Epoch: 5716/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8440\n",
      "Epoch: 5717/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8441\n",
      "Epoch: 5718/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8441\n",
      "Epoch: 5719/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8442\n",
      "Epoch: 5720/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8443\n",
      "Epoch: 5721/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8443\n",
      "Epoch: 5722/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8444\n",
      "Epoch: 5723/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8444\n",
      "Epoch: 5724/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8445\n",
      "Epoch: 5725/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8446\n",
      "Epoch: 5726/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8446\n",
      "Epoch: 5727/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8447\n",
      "Epoch: 5728/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8447\n",
      "Epoch: 5729/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8448\n",
      "Epoch: 5730/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8448\n",
      "Epoch: 5731/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8449\n",
      "Epoch: 5732/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8450\n",
      "Epoch: 5733/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8450\n",
      "Epoch: 5734/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8451\n",
      "Epoch: 5735/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8451\n",
      "Epoch: 5736/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8452\n",
      "Epoch: 5737/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8452\n",
      "Epoch: 5738/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8453\n",
      "Epoch: 5739/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8454\n",
      "Epoch: 5740/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8454\n",
      "Epoch: 5741/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8455\n",
      "Epoch: 5742/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8455\n",
      "Epoch: 5743/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8456\n",
      "Epoch: 5744/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8456\n",
      "Epoch: 5745/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8457\n",
      "Epoch: 5746/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8458\n",
      "Epoch: 5747/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8458\n",
      "Epoch: 5748/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8459\n",
      "Epoch: 5749/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8459\n",
      "Epoch: 5750/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8460\n",
      "Epoch: 5751/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8460\n",
      "Epoch: 5752/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8461\n",
      "Epoch: 5753/8000, Train Loss: 0.2803\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8462\n",
      "Epoch: 5754/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8462\n",
      "Epoch: 5755/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8463\n",
      "Epoch: 5756/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8463\n",
      "Epoch: 5757/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8464\n",
      "Epoch: 5758/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8464\n",
      "Epoch: 5759/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8465\n",
      "Epoch: 5760/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8466\n",
      "Epoch: 5761/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8466\n",
      "Epoch: 5762/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8467\n",
      "Epoch: 5763/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8467\n",
      "Epoch: 5764/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8468\n",
      "Epoch: 5765/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8469\n",
      "Epoch: 5766/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8469\n",
      "Epoch: 5767/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8470\n",
      "Epoch: 5768/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8470\n",
      "Epoch: 5769/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8471\n",
      "Epoch: 5770/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8471\n",
      "Epoch: 5771/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8472\n",
      "Epoch: 5772/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8473\n",
      "Epoch: 5773/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8473\n",
      "Epoch: 5774/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8474\n",
      "Epoch: 5775/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8474\n",
      "Epoch: 5776/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8475\n",
      "Epoch: 5777/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8475\n",
      "Epoch: 5778/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8476\n",
      "Epoch: 5779/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8477\n",
      "Epoch: 5780/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8477\n",
      "Epoch: 5781/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8478\n",
      "Epoch: 5782/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8478\n",
      "Epoch: 5783/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8479\n",
      "Epoch: 5784/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8479\n",
      "Epoch: 5785/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8480\n",
      "Epoch: 5786/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8481\n",
      "Epoch: 5787/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8481\n",
      "Epoch: 5788/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8482\n",
      "Epoch: 5789/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8482\n",
      "Epoch: 5790/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8483\n",
      "Epoch: 5791/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8483\n",
      "Epoch: 5792/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8484\n",
      "Epoch: 5793/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8485\n",
      "Epoch: 5794/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8485\n",
      "Epoch: 5795/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8486\n",
      "Epoch: 5796/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8486\n",
      "Epoch: 5797/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8487\n",
      "Epoch: 5798/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8487\n",
      "Epoch: 5799/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8488\n",
      "Epoch: 5800/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8489\n",
      "Epoch: 5801/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8489\n",
      "Epoch: 5802/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8490\n",
      "Epoch: 5803/8000, Train Loss: 0.2802\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8490\n",
      "Epoch: 5804/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8491\n",
      "Epoch: 5805/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8491\n",
      "Epoch: 5806/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8492\n",
      "Epoch: 5807/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8493\n",
      "Epoch: 5808/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8493\n",
      "Epoch: 5809/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8494\n",
      "Epoch: 5810/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8494\n",
      "Epoch: 5811/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8495\n",
      "Epoch: 5812/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8495\n",
      "Epoch: 5813/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8496\n",
      "Epoch: 5814/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8497\n",
      "Epoch: 5815/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8497\n",
      "Epoch: 5816/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8498\n",
      "Epoch: 5817/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8498\n",
      "Epoch: 5818/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8499\n",
      "Epoch: 5819/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8499\n",
      "Epoch: 5820/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8500\n",
      "Epoch: 5821/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8501\n",
      "Epoch: 5822/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8501\n",
      "Epoch: 5823/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8502\n",
      "Epoch: 5824/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8502\n",
      "Epoch: 5825/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8503\n",
      "Epoch: 5826/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8503\n",
      "Epoch: 5827/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8504\n",
      "Epoch: 5828/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8505\n",
      "Epoch: 5829/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8505\n",
      "Epoch: 5830/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8506\n",
      "Epoch: 5831/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8506\n",
      "Epoch: 5832/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8507\n",
      "Epoch: 5833/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8508\n",
      "Epoch: 5834/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8508\n",
      "Epoch: 5835/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8509\n",
      "Epoch: 5836/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8509\n",
      "Epoch: 5837/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8510\n",
      "Epoch: 5838/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8510\n",
      "Epoch: 5839/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8511\n",
      "Epoch: 5840/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8512\n",
      "Epoch: 5841/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8512\n",
      "Epoch: 5842/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8513\n",
      "Epoch: 5843/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8513\n",
      "Epoch: 5844/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8514\n",
      "Epoch: 5845/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8514\n",
      "Epoch: 5846/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8515\n",
      "Epoch: 5847/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8516\n",
      "Epoch: 5848/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8516\n",
      "Epoch: 5849/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8517\n",
      "Epoch: 5850/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8517\n",
      "Epoch: 5851/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8518\n",
      "Epoch: 5852/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8518\n",
      "Epoch: 5853/8000, Train Loss: 0.2801\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8519\n",
      "Epoch: 5854/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8520\n",
      "Epoch: 5855/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8520\n",
      "Epoch: 5856/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8521\n",
      "Epoch: 5857/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8521\n",
      "Epoch: 5858/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8522\n",
      "Epoch: 5859/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8522\n",
      "Epoch: 5860/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8523\n",
      "Epoch: 5861/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8524\n",
      "Epoch: 5862/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8524\n",
      "Epoch: 5863/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8525\n",
      "Epoch: 5864/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8525\n",
      "Epoch: 5865/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8526\n",
      "Epoch: 5866/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8526\n",
      "Epoch: 5867/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8527\n",
      "Epoch: 5868/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8528\n",
      "Epoch: 5869/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8528\n",
      "Epoch: 5870/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8529\n",
      "Epoch: 5871/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8529\n",
      "Epoch: 5872/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8530\n",
      "Epoch: 5873/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8530\n",
      "Epoch: 5874/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8531\n",
      "Epoch: 5875/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8532\n",
      "Epoch: 5876/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8532\n",
      "Epoch: 5877/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8533\n",
      "Epoch: 5878/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8533\n",
      "Epoch: 5879/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8534\n",
      "Epoch: 5880/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8534\n",
      "Epoch: 5881/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8535\n",
      "Epoch: 5882/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8536\n",
      "Epoch: 5883/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8536\n",
      "Epoch: 5884/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8537\n",
      "Epoch: 5885/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8537\n",
      "Epoch: 5886/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8538\n",
      "Epoch: 5887/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8538\n",
      "Epoch: 5888/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8539\n",
      "Epoch: 5889/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8540\n",
      "Epoch: 5890/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8540\n",
      "Epoch: 5891/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8541\n",
      "Epoch: 5892/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8541\n",
      "Epoch: 5893/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8542\n",
      "Epoch: 5894/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8542\n",
      "Epoch: 5895/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8543\n",
      "Epoch: 5896/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8544\n",
      "Epoch: 5897/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8544\n",
      "Epoch: 5898/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8545\n",
      "Epoch: 5899/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8545\n",
      "Epoch: 5900/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8546\n",
      "Epoch: 5901/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8546\n",
      "Epoch: 5902/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8547\n",
      "Epoch: 5903/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8548\n",
      "Epoch: 5904/8000, Train Loss: 0.2800\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8548\n",
      "Epoch: 5905/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8549\n",
      "Epoch: 5906/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8549\n",
      "Epoch: 5907/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8550\n",
      "Epoch: 5908/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8550\n",
      "Epoch: 5909/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8551\n",
      "Epoch: 5910/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8552\n",
      "Epoch: 5911/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8552\n",
      "Epoch: 5912/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8553\n",
      "Epoch: 5913/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8553\n",
      "Epoch: 5914/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8554\n",
      "Epoch: 5915/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8554\n",
      "Epoch: 5916/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8555\n",
      "Epoch: 5917/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8556\n",
      "Epoch: 5918/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8556\n",
      "Epoch: 5919/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8557\n",
      "Epoch: 5920/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8557\n",
      "Epoch: 5921/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8558\n",
      "Epoch: 5922/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8558\n",
      "Epoch: 5923/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8559\n",
      "Epoch: 5924/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8560\n",
      "Epoch: 5925/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8560\n",
      "Epoch: 5926/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8561\n",
      "Epoch: 5927/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8561\n",
      "Epoch: 5928/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8562\n",
      "Epoch: 5929/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8562\n",
      "Epoch: 5930/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8563\n",
      "Epoch: 5931/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8564\n",
      "Epoch: 5932/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8564\n",
      "Epoch: 5933/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8565\n",
      "Epoch: 5934/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8565\n",
      "Epoch: 5935/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8566\n",
      "Epoch: 5936/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8566\n",
      "Epoch: 5937/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8567\n",
      "Epoch: 5938/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8568\n",
      "Epoch: 5939/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8568\n",
      "Epoch: 5940/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8569\n",
      "Epoch: 5941/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8569\n",
      "Epoch: 5942/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8570\n",
      "Epoch: 5943/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8570\n",
      "Epoch: 5944/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8571\n",
      "Epoch: 5945/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8572\n",
      "Epoch: 5946/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8572\n",
      "Epoch: 5947/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8573\n",
      "Epoch: 5948/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8573\n",
      "Epoch: 5949/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8574\n",
      "Epoch: 5950/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8574\n",
      "Epoch: 5951/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8575\n",
      "Epoch: 5952/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8576\n",
      "Epoch: 5953/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8576\n",
      "Epoch: 5954/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8577\n",
      "Epoch: 5955/8000, Train Loss: 0.2799\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8577\n",
      "Epoch: 5956/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8578\n",
      "Epoch: 5957/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8578\n",
      "Epoch: 5958/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8579\n",
      "Epoch: 5959/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8579\n",
      "Epoch: 5960/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8580\n",
      "Epoch: 5961/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8581\n",
      "Epoch: 5962/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8581\n",
      "Epoch: 5963/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8582\n",
      "Epoch: 5964/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8582\n",
      "Epoch: 5965/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8583\n",
      "Epoch: 5966/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8583\n",
      "Epoch: 5967/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8584\n",
      "Epoch: 5968/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8585\n",
      "Epoch: 5969/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8585\n",
      "Epoch: 5970/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8586\n",
      "Epoch: 5971/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8586\n",
      "Epoch: 5972/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8587\n",
      "Epoch: 5973/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8587\n",
      "Epoch: 5974/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8588\n",
      "Epoch: 5975/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8589\n",
      "Epoch: 5976/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8589\n",
      "Epoch: 5977/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8590\n",
      "Epoch: 5978/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8590\n",
      "Epoch: 5979/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8591\n",
      "Epoch: 5980/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8591\n",
      "Epoch: 5981/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8592\n",
      "Epoch: 5982/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8593\n",
      "Epoch: 5983/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8593\n",
      "Epoch: 5984/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8594\n",
      "Epoch: 5985/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8594\n",
      "Epoch: 5986/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8595\n",
      "Epoch: 5987/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8595\n",
      "Epoch: 5988/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8596\n",
      "Epoch: 5989/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8597\n",
      "Epoch: 5990/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8597\n",
      "Epoch: 5991/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8598\n",
      "Epoch: 5992/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8598\n",
      "Epoch: 5993/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8599\n",
      "Epoch: 5994/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8599\n",
      "Epoch: 5995/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8600\n",
      "Epoch: 5996/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8601\n",
      "Epoch: 5997/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8601\n",
      "Epoch: 5998/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8602\n",
      "Epoch: 5999/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8602\n",
      "Epoch: 6000/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8603\n",
      "Epoch: 6001/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8603\n",
      "Epoch: 6002/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8604\n",
      "Epoch: 6003/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8605\n",
      "Epoch: 6004/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8605\n",
      "Epoch: 6005/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8606\n",
      "Epoch: 6006/8000, Train Loss: 0.2798\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8606\n",
      "Epoch: 6007/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8607\n",
      "Epoch: 6008/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8607\n",
      "Epoch: 6009/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8608\n",
      "Epoch: 6010/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8609\n",
      "Epoch: 6011/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8609\n",
      "Epoch: 6012/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8610\n",
      "Epoch: 6013/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8610\n",
      "Epoch: 6014/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8611\n",
      "Epoch: 6015/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8611\n",
      "Epoch: 6016/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8612\n",
      "Epoch: 6017/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8613\n",
      "Epoch: 6018/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8613\n",
      "Epoch: 6019/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8614\n",
      "Epoch: 6020/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8614\n",
      "Epoch: 6021/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8615\n",
      "Epoch: 6022/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8615\n",
      "Epoch: 6023/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8616\n",
      "Epoch: 6024/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8616\n",
      "Epoch: 6025/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8617\n",
      "Epoch: 6026/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8618\n",
      "Epoch: 6027/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8618\n",
      "Epoch: 6028/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8619\n",
      "Epoch: 6029/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8619\n",
      "Epoch: 6030/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8620\n",
      "Epoch: 6031/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8620\n",
      "Epoch: 6032/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8621\n",
      "Epoch: 6033/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8622\n",
      "Epoch: 6034/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8622\n",
      "Epoch: 6035/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8623\n",
      "Epoch: 6036/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8623\n",
      "Epoch: 6037/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8624\n",
      "Epoch: 6038/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8624\n",
      "Epoch: 6039/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8625\n",
      "Epoch: 6040/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8626\n",
      "Epoch: 6041/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8626\n",
      "Epoch: 6042/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8627\n",
      "Epoch: 6043/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8627\n",
      "Epoch: 6044/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8628\n",
      "Epoch: 6045/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8628\n",
      "Epoch: 6046/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8629\n",
      "Epoch: 6047/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8630\n",
      "Epoch: 6048/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8630\n",
      "Epoch: 6049/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8631\n",
      "Epoch: 6050/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8631\n",
      "Epoch: 6051/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8632\n",
      "Epoch: 6052/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8632\n",
      "Epoch: 6053/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8633\n",
      "Epoch: 6054/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8634\n",
      "Epoch: 6055/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8634\n",
      "Epoch: 6056/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8635\n",
      "Epoch: 6057/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8635\n",
      "Epoch: 6058/8000, Train Loss: 0.2797\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8636\n",
      "Epoch: 6059/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8636\n",
      "Epoch: 6060/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8637\n",
      "Epoch: 6061/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8638\n",
      "Epoch: 6062/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8638\n",
      "Epoch: 6063/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8639\n",
      "Epoch: 6064/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8639\n",
      "Epoch: 6065/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8640\n",
      "Epoch: 6066/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8640\n",
      "Epoch: 6067/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8641\n",
      "Epoch: 6068/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8641\n",
      "Epoch: 6069/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8642\n",
      "Epoch: 6070/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8643\n",
      "Epoch: 6071/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8643\n",
      "Epoch: 6072/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8644\n",
      "Epoch: 6073/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8644\n",
      "Epoch: 6074/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8645\n",
      "Epoch: 6075/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8645\n",
      "Epoch: 6076/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8646\n",
      "Epoch: 6077/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8647\n",
      "Epoch: 6078/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8647\n",
      "Epoch: 6079/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8648\n",
      "Epoch: 6080/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8648\n",
      "Epoch: 6081/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8649\n",
      "Epoch: 6082/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8649\n",
      "Epoch: 6083/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8650\n",
      "Epoch: 6084/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8651\n",
      "Epoch: 6085/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8651\n",
      "Epoch: 6086/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8652\n",
      "Epoch: 6087/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8652\n",
      "Epoch: 6088/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8653\n",
      "Epoch: 6089/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8653\n",
      "Epoch: 6090/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8654\n",
      "Epoch: 6091/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8655\n",
      "Epoch: 6092/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8655\n",
      "Epoch: 6093/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8656\n",
      "Epoch: 6094/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8656\n",
      "Epoch: 6095/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8657\n",
      "Epoch: 6096/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8657\n",
      "Epoch: 6097/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8658\n",
      "Epoch: 6098/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8659\n",
      "Epoch: 6099/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8659\n",
      "Epoch: 6100/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8660\n",
      "Epoch: 6101/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8660\n",
      "Epoch: 6102/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8661\n",
      "Epoch: 6103/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8661\n",
      "Epoch: 6104/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8662\n",
      "Epoch: 6105/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8662\n",
      "Epoch: 6106/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8663\n",
      "Epoch: 6107/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8664\n",
      "Epoch: 6108/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8664\n",
      "Epoch: 6109/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8665\n",
      "Epoch: 6110/8000, Train Loss: 0.2796\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8665\n",
      "Epoch: 6111/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8666\n",
      "Epoch: 6112/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8666\n",
      "Epoch: 6113/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8667\n",
      "Epoch: 6114/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8668\n",
      "Epoch: 6115/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8668\n",
      "Epoch: 6116/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8669\n",
      "Epoch: 6117/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8669\n",
      "Epoch: 6118/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8670\n",
      "Epoch: 6119/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8670\n",
      "Epoch: 6120/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8671\n",
      "Epoch: 6121/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8672\n",
      "Epoch: 6122/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8672\n",
      "Epoch: 6123/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8673\n",
      "Epoch: 6124/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8673\n",
      "Epoch: 6125/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8674\n",
      "Epoch: 6126/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8674\n",
      "Epoch: 6127/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8675\n",
      "Epoch: 6128/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8676\n",
      "Epoch: 6129/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8676\n",
      "Epoch: 6130/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8677\n",
      "Epoch: 6131/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8677\n",
      "Epoch: 6132/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8678\n",
      "Epoch: 6133/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8678\n",
      "Epoch: 6134/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8679\n",
      "Epoch: 6135/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8679\n",
      "Epoch: 6136/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8680\n",
      "Epoch: 6137/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8681\n",
      "Epoch: 6138/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8681\n",
      "Epoch: 6139/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8682\n",
      "Epoch: 6140/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8682\n",
      "Epoch: 6141/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8683\n",
      "Epoch: 6142/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8683\n",
      "Epoch: 6143/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8684\n",
      "Epoch: 6144/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8685\n",
      "Epoch: 6145/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8685\n",
      "Epoch: 6146/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8686\n",
      "Epoch: 6147/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8686\n",
      "Epoch: 6148/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8687\n",
      "Epoch: 6149/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8687\n",
      "Epoch: 6150/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8688\n",
      "Epoch: 6151/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8689\n",
      "Epoch: 6152/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8689\n",
      "Epoch: 6153/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8690\n",
      "Epoch: 6154/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8690\n",
      "Epoch: 6155/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8691\n",
      "Epoch: 6156/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8691\n",
      "Epoch: 6157/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8692\n",
      "Epoch: 6158/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8692\n",
      "Epoch: 6159/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8693\n",
      "Epoch: 6160/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8694\n",
      "Epoch: 6161/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8694\n",
      "Epoch: 6162/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8695\n",
      "Epoch: 6163/8000, Train Loss: 0.2795\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8695\n",
      "Epoch: 6164/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8696\n",
      "Epoch: 6165/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8696\n",
      "Epoch: 6166/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8697\n",
      "Epoch: 6167/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8698\n",
      "Epoch: 6168/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8698\n",
      "Epoch: 6169/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8699\n",
      "Epoch: 6170/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8699\n",
      "Epoch: 6171/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8700\n",
      "Epoch: 6172/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8700\n",
      "Epoch: 6173/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8701\n",
      "Epoch: 6174/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8702\n",
      "Epoch: 6175/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8702\n",
      "Epoch: 6176/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8703\n",
      "Epoch: 6177/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8703\n",
      "Epoch: 6178/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8704\n",
      "Epoch: 6179/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8704\n",
      "Epoch: 6180/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8705\n",
      "Epoch: 6181/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8705\n",
      "Epoch: 6182/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8706\n",
      "Epoch: 6183/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8707\n",
      "Epoch: 6184/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8707\n",
      "Epoch: 6185/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8708\n",
      "Epoch: 6186/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8708\n",
      "Epoch: 6187/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8709\n",
      "Epoch: 6188/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8709\n",
      "Epoch: 6189/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8710\n",
      "Epoch: 6190/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8711\n",
      "Epoch: 6191/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8711\n",
      "Epoch: 6192/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8712\n",
      "Epoch: 6193/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8712\n",
      "Epoch: 6194/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8713\n",
      "Epoch: 6195/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8713\n",
      "Epoch: 6196/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8714\n",
      "Epoch: 6197/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8715\n",
      "Epoch: 6198/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8715\n",
      "Epoch: 6199/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8716\n",
      "Epoch: 6200/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8716\n",
      "Epoch: 6201/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8717\n",
      "Epoch: 6202/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8717\n",
      "Epoch: 6203/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8718\n",
      "Epoch: 6204/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8718\n",
      "Epoch: 6205/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8719\n",
      "Epoch: 6206/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8720\n",
      "Epoch: 6207/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8720\n",
      "Epoch: 6208/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8721\n",
      "Epoch: 6209/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8721\n",
      "Epoch: 6210/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8722\n",
      "Epoch: 6211/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8722\n",
      "Epoch: 6212/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8723\n",
      "Epoch: 6213/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8724\n",
      "Epoch: 6214/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8724\n",
      "Epoch: 6215/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8725\n",
      "Epoch: 6216/8000, Train Loss: 0.2794\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8725\n",
      "Epoch: 6217/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8726\n",
      "Epoch: 6218/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8726\n",
      "Epoch: 6219/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8727\n",
      "Epoch: 6220/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8728\n",
      "Epoch: 6221/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8728\n",
      "Epoch: 6222/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8729\n",
      "Epoch: 6223/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8729\n",
      "Epoch: 6224/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8730\n",
      "Epoch: 6225/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8730\n",
      "Epoch: 6226/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8731\n",
      "Epoch: 6227/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8731\n",
      "Epoch: 6228/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8732\n",
      "Epoch: 6229/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8733\n",
      "Epoch: 6230/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8733\n",
      "Epoch: 6231/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8734\n",
      "Epoch: 6232/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8734\n",
      "Epoch: 6233/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8735\n",
      "Epoch: 6234/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8735\n",
      "Epoch: 6235/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8736\n",
      "Epoch: 6236/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8737\n",
      "Epoch: 6237/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8737\n",
      "Epoch: 6238/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8738\n",
      "Epoch: 6239/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8738\n",
      "Epoch: 6240/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8739\n",
      "Epoch: 6241/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8739\n",
      "Epoch: 6242/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8740\n",
      "Epoch: 6243/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8740\n",
      "Epoch: 6244/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8741\n",
      "Epoch: 6245/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8742\n",
      "Epoch: 6246/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8742\n",
      "Epoch: 6247/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8743\n",
      "Epoch: 6248/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8743\n",
      "Epoch: 6249/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8744\n",
      "Epoch: 6250/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8744\n",
      "Epoch: 6251/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8745\n",
      "Epoch: 6252/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8746\n",
      "Epoch: 6253/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8746\n",
      "Epoch: 6254/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8747\n",
      "Epoch: 6255/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8747\n",
      "Epoch: 6256/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8748\n",
      "Epoch: 6257/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8748\n",
      "Epoch: 6258/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8749\n",
      "Epoch: 6259/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8750\n",
      "Epoch: 6260/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8750\n",
      "Epoch: 6261/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8751\n",
      "Epoch: 6262/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8751\n",
      "Epoch: 6263/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8752\n",
      "Epoch: 6264/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8752\n",
      "Epoch: 6265/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8753\n",
      "Epoch: 6266/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8753\n",
      "Epoch: 6267/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8754\n",
      "Epoch: 6268/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8755\n",
      "Epoch: 6269/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8755\n",
      "Epoch: 6270/8000, Train Loss: 0.2793\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8756\n",
      "Epoch: 6271/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8756\n",
      "Epoch: 6272/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8757\n",
      "Epoch: 6273/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8757\n",
      "Epoch: 6274/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8758\n",
      "Epoch: 6275/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8759\n",
      "Epoch: 6276/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8759\n",
      "Epoch: 6277/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8760\n",
      "Epoch: 6278/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8760\n",
      "Epoch: 6279/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8761\n",
      "Epoch: 6280/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8761\n",
      "Epoch: 6281/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8762\n",
      "Epoch: 6282/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8762\n",
      "Epoch: 6283/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8763\n",
      "Epoch: 6284/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8764\n",
      "Epoch: 6285/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8764\n",
      "Epoch: 6286/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8765\n",
      "Epoch: 6287/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8765\n",
      "Epoch: 6288/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8766\n",
      "Epoch: 6289/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8766\n",
      "Epoch: 6290/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8767\n",
      "Epoch: 6291/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8768\n",
      "Epoch: 6292/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8768\n",
      "Epoch: 6293/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8769\n",
      "Epoch: 6294/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8769\n",
      "Epoch: 6295/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8770\n",
      "Epoch: 6296/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8770\n",
      "Epoch: 6297/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8771\n",
      "Epoch: 6298/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8771\n",
      "Epoch: 6299/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8772\n",
      "Epoch: 6300/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8773\n",
      "Epoch: 6301/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8773\n",
      "Epoch: 6302/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8774\n",
      "Epoch: 6303/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8774\n",
      "Epoch: 6304/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8775\n",
      "Epoch: 6305/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8775\n",
      "Epoch: 6306/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8776\n",
      "Epoch: 6307/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8777\n",
      "Epoch: 6308/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8777\n",
      "Epoch: 6309/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8778\n",
      "Epoch: 6310/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8778\n",
      "Epoch: 6311/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8779\n",
      "Epoch: 6312/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8779\n",
      "Epoch: 6313/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8780\n",
      "Epoch: 6314/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8780\n",
      "Epoch: 6315/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8781\n",
      "Epoch: 6316/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8782\n",
      "Epoch: 6317/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8782\n",
      "Epoch: 6318/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8783\n",
      "Epoch: 6319/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8783\n",
      "Epoch: 6320/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8784\n",
      "Epoch: 6321/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8784\n",
      "Epoch: 6322/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8785\n",
      "Epoch: 6323/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8786\n",
      "Epoch: 6324/8000, Train Loss: 0.2792\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8786\n",
      "Epoch: 6325/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8787\n",
      "Epoch: 6326/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8787\n",
      "Epoch: 6327/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8788\n",
      "Epoch: 6328/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8788\n",
      "Epoch: 6329/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8789\n",
      "Epoch: 6330/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8789\n",
      "Epoch: 6331/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8790\n",
      "Epoch: 6332/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8791\n",
      "Epoch: 6333/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8791\n",
      "Epoch: 6334/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8792\n",
      "Epoch: 6335/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8792\n",
      "Epoch: 6336/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8793\n",
      "Epoch: 6337/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8793\n",
      "Epoch: 6338/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8794\n",
      "Epoch: 6339/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8795\n",
      "Epoch: 6340/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8795\n",
      "Epoch: 6341/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8796\n",
      "Epoch: 6342/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8796\n",
      "Epoch: 6343/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8797\n",
      "Epoch: 6344/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8797\n",
      "Epoch: 6345/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8798\n",
      "Epoch: 6346/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8798\n",
      "Epoch: 6347/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8799\n",
      "Epoch: 6348/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8800\n",
      "Epoch: 6349/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8800\n",
      "Epoch: 6350/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8801\n",
      "Epoch: 6351/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8801\n",
      "Epoch: 6352/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8802\n",
      "Epoch: 6353/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8802\n",
      "Epoch: 6354/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8803\n",
      "Epoch: 6355/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8804\n",
      "Epoch: 6356/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8804\n",
      "Epoch: 6357/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8805\n",
      "Epoch: 6358/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8805\n",
      "Epoch: 6359/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8806\n",
      "Epoch: 6360/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8806\n",
      "Epoch: 6361/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8807\n",
      "Epoch: 6362/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8807\n",
      "Epoch: 6363/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8808\n",
      "Epoch: 6364/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8809\n",
      "Epoch: 6365/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8809\n",
      "Epoch: 6366/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8810\n",
      "Epoch: 6367/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8810\n",
      "Epoch: 6368/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8811\n",
      "Epoch: 6369/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8811\n",
      "Epoch: 6370/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8812\n",
      "Epoch: 6371/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8812\n",
      "Epoch: 6372/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8813\n",
      "Epoch: 6373/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8814\n",
      "Epoch: 6374/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8814\n",
      "Epoch: 6375/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8815\n",
      "Epoch: 6376/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8815\n",
      "Epoch: 6377/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8816\n",
      "Epoch: 6378/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8816\n",
      "Epoch: 6379/8000, Train Loss: 0.2791\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8817\n",
      "Epoch: 6380/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8818\n",
      "Epoch: 6381/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8818\n",
      "Epoch: 6382/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8819\n",
      "Epoch: 6383/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8819\n",
      "Epoch: 6384/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8820\n",
      "Epoch: 6385/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8820\n",
      "Epoch: 6386/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8821\n",
      "Epoch: 6387/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8821\n",
      "Epoch: 6388/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8822\n",
      "Epoch: 6389/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8823\n",
      "Epoch: 6390/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8823\n",
      "Epoch: 6391/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8824\n",
      "Epoch: 6392/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8824\n",
      "Epoch: 6393/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8825\n",
      "Epoch: 6394/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8825\n",
      "Epoch: 6395/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8826\n",
      "Epoch: 6396/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8827\n",
      "Epoch: 6397/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8827\n",
      "Epoch: 6398/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8828\n",
      "Epoch: 6399/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8828\n",
      "Epoch: 6400/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8829\n",
      "Epoch: 6401/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8829\n",
      "Epoch: 6402/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8830\n",
      "Epoch: 6403/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8830\n",
      "Epoch: 6404/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8831\n",
      "Epoch: 6405/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8832\n",
      "Epoch: 6406/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8832\n",
      "Epoch: 6407/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8833\n",
      "Epoch: 6408/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8833\n",
      "Epoch: 6409/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8834\n",
      "Epoch: 6410/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8834\n",
      "Epoch: 6411/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8835\n",
      "Epoch: 6412/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8835\n",
      "Epoch: 6413/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8836\n",
      "Epoch: 6414/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8837\n",
      "Epoch: 6415/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8837\n",
      "Epoch: 6416/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8838\n",
      "Epoch: 6417/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8838\n",
      "Epoch: 6418/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8839\n",
      "Epoch: 6419/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8839\n",
      "Epoch: 6420/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8840\n",
      "Epoch: 6421/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8841\n",
      "Epoch: 6422/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8841\n",
      "Epoch: 6423/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8842\n",
      "Epoch: 6424/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8842\n",
      "Epoch: 6425/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8843\n",
      "Epoch: 6426/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8843\n",
      "Epoch: 6427/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8844\n",
      "Epoch: 6428/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8844\n",
      "Epoch: 6429/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8845\n",
      "Epoch: 6430/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8846\n",
      "Epoch: 6431/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8846\n",
      "Epoch: 6432/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8847\n",
      "Epoch: 6433/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8847\n",
      "Epoch: 6434/8000, Train Loss: 0.2790\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8848\n",
      "Epoch: 6435/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8848\n",
      "Epoch: 6436/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8849\n",
      "Epoch: 6437/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8849\n",
      "Epoch: 6438/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8850\n",
      "Epoch: 6439/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8851\n",
      "Epoch: 6440/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8851\n",
      "Epoch: 6441/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8852\n",
      "Epoch: 6442/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8852\n",
      "Epoch: 6443/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8853\n",
      "Epoch: 6444/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8853\n",
      "Epoch: 6445/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8854\n",
      "Epoch: 6446/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8855\n",
      "Epoch: 6447/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8855\n",
      "Epoch: 6448/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8856\n",
      "Epoch: 6449/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8856\n",
      "Epoch: 6450/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8857\n",
      "Epoch: 6451/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8857\n",
      "Epoch: 6452/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8858\n",
      "Epoch: 6453/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8858\n",
      "Epoch: 6454/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8859\n",
      "Epoch: 6455/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8860\n",
      "Epoch: 6456/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8860\n",
      "Epoch: 6457/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8861\n",
      "Epoch: 6458/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8861\n",
      "Epoch: 6459/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8862\n",
      "Epoch: 6460/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8862\n",
      "Epoch: 6461/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8863\n",
      "Epoch: 6462/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8863\n",
      "Epoch: 6463/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8864\n",
      "Epoch: 6464/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8865\n",
      "Epoch: 6465/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8865\n",
      "Epoch: 6466/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8866\n",
      "Epoch: 6467/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8866\n",
      "Epoch: 6468/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8867\n",
      "Epoch: 6469/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8867\n",
      "Epoch: 6470/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8868\n",
      "Epoch: 6471/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8869\n",
      "Epoch: 6472/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8869\n",
      "Epoch: 6473/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8870\n",
      "Epoch: 6474/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8870\n",
      "Epoch: 6475/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8871\n",
      "Epoch: 6476/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8871\n",
      "Epoch: 6477/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8872\n",
      "Epoch: 6478/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8872\n",
      "Epoch: 6479/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8873\n",
      "Epoch: 6480/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8874\n",
      "Epoch: 6481/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8874\n",
      "Epoch: 6482/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8875\n",
      "Epoch: 6483/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8875\n",
      "Epoch: 6484/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8876\n",
      "Epoch: 6485/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8876\n",
      "Epoch: 6486/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8877\n",
      "Epoch: 6487/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8877\n",
      "Epoch: 6488/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8878\n",
      "Epoch: 6489/8000, Train Loss: 0.2789\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8879\n",
      "Epoch: 6490/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8879\n",
      "Epoch: 6491/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8880\n",
      "Epoch: 6492/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8880\n",
      "Epoch: 6493/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8881\n",
      "Epoch: 6494/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8881\n",
      "Epoch: 6495/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8882\n",
      "Epoch: 6496/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8882\n",
      "Epoch: 6497/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8883\n",
      "Epoch: 6498/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8884\n",
      "Epoch: 6499/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8884\n",
      "Epoch: 6500/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8885\n",
      "Epoch: 6501/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8885\n",
      "Epoch: 6502/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8886\n",
      "Epoch: 6503/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8886\n",
      "Epoch: 6504/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8887\n",
      "Epoch: 6505/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8888\n",
      "Epoch: 6506/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8888\n",
      "Epoch: 6507/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8889\n",
      "Epoch: 6508/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8889\n",
      "Epoch: 6509/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8890\n",
      "Epoch: 6510/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8890\n",
      "Epoch: 6511/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8891\n",
      "Epoch: 6512/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8891\n",
      "Epoch: 6513/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8892\n",
      "Epoch: 6514/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8893\n",
      "Epoch: 6515/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8893\n",
      "Epoch: 6516/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8894\n",
      "Epoch: 6517/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8894\n",
      "Epoch: 6518/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8895\n",
      "Epoch: 6519/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8895\n",
      "Epoch: 6520/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8896\n",
      "Epoch: 6521/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8896\n",
      "Epoch: 6522/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8897\n",
      "Epoch: 6523/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8898\n",
      "Epoch: 6524/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8898\n",
      "Epoch: 6525/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8899\n",
      "Epoch: 6526/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8899\n",
      "Epoch: 6527/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8900\n",
      "Epoch: 6528/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8900\n",
      "Epoch: 6529/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8901\n",
      "Epoch: 6530/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8901\n",
      "Epoch: 6531/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8902\n",
      "Epoch: 6532/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8903\n",
      "Epoch: 6533/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8903\n",
      "Epoch: 6534/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8904\n",
      "Epoch: 6535/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8904\n",
      "Epoch: 6536/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8905\n",
      "Epoch: 6537/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8905\n",
      "Epoch: 6538/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8906\n",
      "Epoch: 6539/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8906\n",
      "Epoch: 6540/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8907\n",
      "Epoch: 6541/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8908\n",
      "Epoch: 6542/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8908\n",
      "Epoch: 6543/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8909\n",
      "Epoch: 6544/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8909\n",
      "Epoch: 6545/8000, Train Loss: 0.2788\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8910\n",
      "Epoch: 6546/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8910\n",
      "Epoch: 6547/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8911\n",
      "Epoch: 6548/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8912\n",
      "Epoch: 6549/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8912\n",
      "Epoch: 6550/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8913\n",
      "Epoch: 6551/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8913\n",
      "Epoch: 6552/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8914\n",
      "Epoch: 6553/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8914\n",
      "Epoch: 6554/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8915\n",
      "Epoch: 6555/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8915\n",
      "Epoch: 6556/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8916\n",
      "Epoch: 6557/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8917\n",
      "Epoch: 6558/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8917\n",
      "Epoch: 6559/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8918\n",
      "Epoch: 6560/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8918\n",
      "Epoch: 6561/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8919\n",
      "Epoch: 6562/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8919\n",
      "Epoch: 6563/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8920\n",
      "Epoch: 6564/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8920\n",
      "Epoch: 6565/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8921\n",
      "Epoch: 6566/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8922\n",
      "Epoch: 6567/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8922\n",
      "Epoch: 6568/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8923\n",
      "Epoch: 6569/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8923\n",
      "Epoch: 6570/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8924\n",
      "Epoch: 6571/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8924\n",
      "Epoch: 6572/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8925\n",
      "Epoch: 6573/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8925\n",
      "Epoch: 6574/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8926\n",
      "Epoch: 6575/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8927\n",
      "Epoch: 6576/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8927\n",
      "Epoch: 6577/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8928\n",
      "Epoch: 6578/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8928\n",
      "Epoch: 6579/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8929\n",
      "Epoch: 6580/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8929\n",
      "Epoch: 6581/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8930\n",
      "Epoch: 6582/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8930\n",
      "Epoch: 6583/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8931\n",
      "Epoch: 6584/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8932\n",
      "Epoch: 6585/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8932\n",
      "Epoch: 6586/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8933\n",
      "Epoch: 6587/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8933\n",
      "Epoch: 6588/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8934\n",
      "Epoch: 6589/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8934\n",
      "Epoch: 6590/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8935\n",
      "Epoch: 6591/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8935\n",
      "Epoch: 6592/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8936\n",
      "Epoch: 6593/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8937\n",
      "Epoch: 6594/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8937\n",
      "Epoch: 6595/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8938\n",
      "Epoch: 6596/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8938\n",
      "Epoch: 6597/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8939\n",
      "Epoch: 6598/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8939\n",
      "Epoch: 6599/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8940\n",
      "Epoch: 6600/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8940\n",
      "Epoch: 6601/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8941\n",
      "Epoch: 6602/8000, Train Loss: 0.2787\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8942\n",
      "Epoch: 6603/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8942\n",
      "Epoch: 6604/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8943\n",
      "Epoch: 6605/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8943\n",
      "Epoch: 6606/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8944\n",
      "Epoch: 6607/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8944\n",
      "Epoch: 6608/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8945\n",
      "Epoch: 6609/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8945\n",
      "Epoch: 6610/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8946\n",
      "Epoch: 6611/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8947\n",
      "Epoch: 6612/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8947\n",
      "Epoch: 6613/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8948\n",
      "Epoch: 6614/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8948\n",
      "Epoch: 6615/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8949\n",
      "Epoch: 6616/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8949\n",
      "Epoch: 6617/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8950\n",
      "Epoch: 6618/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8950\n",
      "Epoch: 6619/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8951\n",
      "Epoch: 6620/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8952\n",
      "Epoch: 6621/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8952\n",
      "Epoch: 6622/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8953\n",
      "Epoch: 6623/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8953\n",
      "Epoch: 6624/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8954\n",
      "Epoch: 6625/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8954\n",
      "Epoch: 6626/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8955\n",
      "Epoch: 6627/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8955\n",
      "Epoch: 6628/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8956\n",
      "Epoch: 6629/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8957\n",
      "Epoch: 6630/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8957\n",
      "Epoch: 6631/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8958\n",
      "Epoch: 6632/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8958\n",
      "Epoch: 6633/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8959\n",
      "Epoch: 6634/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8959\n",
      "Epoch: 6635/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8960\n",
      "Epoch: 6636/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8960\n",
      "Epoch: 6637/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8961\n",
      "Epoch: 6638/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8962\n",
      "Epoch: 6639/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8962\n",
      "Epoch: 6640/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8963\n",
      "Epoch: 6641/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8963\n",
      "Epoch: 6642/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8964\n",
      "Epoch: 6643/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8964\n",
      "Epoch: 6644/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8965\n",
      "Epoch: 6645/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8965\n",
      "Epoch: 6646/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8966\n",
      "Epoch: 6647/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8967\n",
      "Epoch: 6648/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8967\n",
      "Epoch: 6649/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8968\n",
      "Epoch: 6650/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8968\n",
      "Epoch: 6651/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8969\n",
      "Epoch: 6652/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8969\n",
      "Epoch: 6653/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8970\n",
      "Epoch: 6654/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8970\n",
      "Epoch: 6655/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8971\n",
      "Epoch: 6656/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8972\n",
      "Epoch: 6657/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8972\n",
      "Epoch: 6658/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8973\n",
      "Epoch: 6659/8000, Train Loss: 0.2786\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8973\n",
      "Epoch: 6660/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8974\n",
      "Epoch: 6661/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8974\n",
      "Epoch: 6662/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8975\n",
      "Epoch: 6663/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8975\n",
      "Epoch: 6664/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8976\n",
      "Epoch: 6665/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8977\n",
      "Epoch: 6666/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8977\n",
      "Epoch: 6667/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8978\n",
      "Epoch: 6668/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8978\n",
      "Epoch: 6669/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8979\n",
      "Epoch: 6670/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8979\n",
      "Epoch: 6671/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8980\n",
      "Epoch: 6672/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8980\n",
      "Epoch: 6673/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8981\n",
      "Epoch: 6674/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8982\n",
      "Epoch: 6675/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8982\n",
      "Epoch: 6676/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8983\n",
      "Epoch: 6677/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8983\n",
      "Epoch: 6678/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8984\n",
      "Epoch: 6679/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8984\n",
      "Epoch: 6680/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8985\n",
      "Epoch: 6681/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8985\n",
      "Epoch: 6682/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8986\n",
      "Epoch: 6683/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8987\n",
      "Epoch: 6684/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8987\n",
      "Epoch: 6685/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8988\n",
      "Epoch: 6686/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8988\n",
      "Epoch: 6687/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8989\n",
      "Epoch: 6688/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8989\n",
      "Epoch: 6689/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8990\n",
      "Epoch: 6690/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8990\n",
      "Epoch: 6691/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8991\n",
      "Epoch: 6692/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8992\n",
      "Epoch: 6693/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8992\n",
      "Epoch: 6694/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8993\n",
      "Epoch: 6695/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8993\n",
      "Epoch: 6696/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8994\n",
      "Epoch: 6697/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8994\n",
      "Epoch: 6698/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8995\n",
      "Epoch: 6699/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8995\n",
      "Epoch: 6700/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8996\n",
      "Epoch: 6701/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8997\n",
      "Epoch: 6702/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8997\n",
      "Epoch: 6703/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8998\n",
      "Epoch: 6704/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8998\n",
      "Epoch: 6705/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8999\n",
      "Epoch: 6706/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.8999\n",
      "Epoch: 6707/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9000\n",
      "Epoch: 6708/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9000\n",
      "Epoch: 6709/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9001\n",
      "Epoch: 6710/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9002\n",
      "Epoch: 6711/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9002\n",
      "Epoch: 6712/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9003\n",
      "Epoch: 6713/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9003\n",
      "Epoch: 6714/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9004\n",
      "Epoch: 6715/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9004\n",
      "Epoch: 6716/8000, Train Loss: 0.2785\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9005\n",
      "Epoch: 6717/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9005\n",
      "Epoch: 6718/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9006\n",
      "Epoch: 6719/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9007\n",
      "Epoch: 6720/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9007\n",
      "Epoch: 6721/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9008\n",
      "Epoch: 6722/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9008\n",
      "Epoch: 6723/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9009\n",
      "Epoch: 6724/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9009\n",
      "Epoch: 6725/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9010\n",
      "Epoch: 6726/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9010\n",
      "Epoch: 6727/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9011\n",
      "Epoch: 6728/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9012\n",
      "Epoch: 6729/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9012\n",
      "Epoch: 6730/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9013\n",
      "Epoch: 6731/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9013\n",
      "Epoch: 6732/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9014\n",
      "Epoch: 6733/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9014\n",
      "Epoch: 6734/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9015\n",
      "Epoch: 6735/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9015\n",
      "Epoch: 6736/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9016\n",
      "Epoch: 6737/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9017\n",
      "Epoch: 6738/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9017\n",
      "Epoch: 6739/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9018\n",
      "Epoch: 6740/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9018\n",
      "Epoch: 6741/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9019\n",
      "Epoch: 6742/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9019\n",
      "Epoch: 6743/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9020\n",
      "Epoch: 6744/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9020\n",
      "Epoch: 6745/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9021\n",
      "Epoch: 6746/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9022\n",
      "Epoch: 6747/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9022\n",
      "Epoch: 6748/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9023\n",
      "Epoch: 6749/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9023\n",
      "Epoch: 6750/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9024\n",
      "Epoch: 6751/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9024\n",
      "Epoch: 6752/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9025\n",
      "Epoch: 6753/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9025\n",
      "Epoch: 6754/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9026\n",
      "Epoch: 6755/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9026\n",
      "Epoch: 6756/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9027\n",
      "Epoch: 6757/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9028\n",
      "Epoch: 6758/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9028\n",
      "Epoch: 6759/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9029\n",
      "Epoch: 6760/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9029\n",
      "Epoch: 6761/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9030\n",
      "Epoch: 6762/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9030\n",
      "Epoch: 6763/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9031\n",
      "Epoch: 6764/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9031\n",
      "Epoch: 6765/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9032\n",
      "Epoch: 6766/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9033\n",
      "Epoch: 6767/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9033\n",
      "Epoch: 6768/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9034\n",
      "Epoch: 6769/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9034\n",
      "Epoch: 6770/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9035\n",
      "Epoch: 6771/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9035\n",
      "Epoch: 6772/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9036\n",
      "Epoch: 6773/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9036\n",
      "Epoch: 6774/8000, Train Loss: 0.2784\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9037\n",
      "Epoch: 6775/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9038\n",
      "Epoch: 6776/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9038\n",
      "Epoch: 6777/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9039\n",
      "Epoch: 6778/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9039\n",
      "Epoch: 6779/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9040\n",
      "Epoch: 6780/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9040\n",
      "Epoch: 6781/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9041\n",
      "Epoch: 6782/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9041\n",
      "Epoch: 6783/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9042\n",
      "Epoch: 6784/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9043\n",
      "Epoch: 6785/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9043\n",
      "Epoch: 6786/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9044\n",
      "Epoch: 6787/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9044\n",
      "Epoch: 6788/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9045\n",
      "Epoch: 6789/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9045\n",
      "Epoch: 6790/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9046\n",
      "Epoch: 6791/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9046\n",
      "Epoch: 6792/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9047\n",
      "Epoch: 6793/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9047\n",
      "Epoch: 6794/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9048\n",
      "Epoch: 6795/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9049\n",
      "Epoch: 6796/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9049\n",
      "Epoch: 6797/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9050\n",
      "Epoch: 6798/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9050\n",
      "Epoch: 6799/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9051\n",
      "Epoch: 6800/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9051\n",
      "Epoch: 6801/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9052\n",
      "Epoch: 6802/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9052\n",
      "Epoch: 6803/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9053\n",
      "Epoch: 6804/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9054\n",
      "Epoch: 6805/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9054\n",
      "Epoch: 6806/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9055\n",
      "Epoch: 6807/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9055\n",
      "Epoch: 6808/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9056\n",
      "Epoch: 6809/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9056\n",
      "Epoch: 6810/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9057\n",
      "Epoch: 6811/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9057\n",
      "Epoch: 6812/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9058\n",
      "Epoch: 6813/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9059\n",
      "Epoch: 6814/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9059\n",
      "Epoch: 6815/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9060\n",
      "Epoch: 6816/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9060\n",
      "Epoch: 6817/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9061\n",
      "Epoch: 6818/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9061\n",
      "Epoch: 6819/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9062\n",
      "Epoch: 6820/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9062\n",
      "Epoch: 6821/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9063\n",
      "Epoch: 6822/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9064\n",
      "Epoch: 6823/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9064\n",
      "Epoch: 6824/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9065\n",
      "Epoch: 6825/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9065\n",
      "Epoch: 6826/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9066\n",
      "Epoch: 6827/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9066\n",
      "Epoch: 6828/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9067\n",
      "Epoch: 6829/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9067\n",
      "Epoch: 6830/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9068\n",
      "Epoch: 6831/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9068\n",
      "Epoch: 6832/8000, Train Loss: 0.2783\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9069\n",
      "Epoch: 6833/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9070\n",
      "Epoch: 6834/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9070\n",
      "Epoch: 6835/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9071\n",
      "Epoch: 6836/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9071\n",
      "Epoch: 6837/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9072\n",
      "Epoch: 6838/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9072\n",
      "Epoch: 6839/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9073\n",
      "Epoch: 6840/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9073\n",
      "Epoch: 6841/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9074\n",
      "Epoch: 6842/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9075\n",
      "Epoch: 6843/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9075\n",
      "Epoch: 6844/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9076\n",
      "Epoch: 6845/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9076\n",
      "Epoch: 6846/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9077\n",
      "Epoch: 6847/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9077\n",
      "Epoch: 6848/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9078\n",
      "Epoch: 6849/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9078\n",
      "Epoch: 6850/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9079\n",
      "Epoch: 6851/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9080\n",
      "Epoch: 6852/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9080\n",
      "Epoch: 6853/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9081\n",
      "Epoch: 6854/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9081\n",
      "Epoch: 6855/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9082\n",
      "Epoch: 6856/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9082\n",
      "Epoch: 6857/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9083\n",
      "Epoch: 6858/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9083\n",
      "Epoch: 6859/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9084\n",
      "Epoch: 6860/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9084\n",
      "Epoch: 6861/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9085\n",
      "Epoch: 6862/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9086\n",
      "Epoch: 6863/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9086\n",
      "Epoch: 6864/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9087\n",
      "Epoch: 6865/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9087\n",
      "Epoch: 6866/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9088\n",
      "Epoch: 6867/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9088\n",
      "Epoch: 6868/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9089\n",
      "Epoch: 6869/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9089\n",
      "Epoch: 6870/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9090\n",
      "Epoch: 6871/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9091\n",
      "Epoch: 6872/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9091\n",
      "Epoch: 6873/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9092\n",
      "Epoch: 6874/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9092\n",
      "Epoch: 6875/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9093\n",
      "Epoch: 6876/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9093\n",
      "Epoch: 6877/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9094\n",
      "Epoch: 6878/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9094\n",
      "Epoch: 6879/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9095\n",
      "Epoch: 6880/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9096\n",
      "Epoch: 6881/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9096\n",
      "Epoch: 6882/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9097\n",
      "Epoch: 6883/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9097\n",
      "Epoch: 6884/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9098\n",
      "Epoch: 6885/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9098\n",
      "Epoch: 6886/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9099\n",
      "Epoch: 6887/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9099\n",
      "Epoch: 6888/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9100\n",
      "Epoch: 6889/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9100\n",
      "Epoch: 6890/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9101\n",
      "Epoch: 6891/8000, Train Loss: 0.2782\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9102\n",
      "Epoch: 6892/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9102\n",
      "Epoch: 6893/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9103\n",
      "Epoch: 6894/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9103\n",
      "Epoch: 6895/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9104\n",
      "Epoch: 6896/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9104\n",
      "Epoch: 6897/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9105\n",
      "Epoch: 6898/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9105\n",
      "Epoch: 6899/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9106\n",
      "Epoch: 6900/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9107\n",
      "Epoch: 6901/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9107\n",
      "Epoch: 6902/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9108\n",
      "Epoch: 6903/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9108\n",
      "Epoch: 6904/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9109\n",
      "Epoch: 6905/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9109\n",
      "Epoch: 6906/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9110\n",
      "Epoch: 6907/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9110\n",
      "Epoch: 6908/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9111\n",
      "Epoch: 6909/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9111\n",
      "Epoch: 6910/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9112\n",
      "Epoch: 6911/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9113\n",
      "Epoch: 6912/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9113\n",
      "Epoch: 6913/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9114\n",
      "Epoch: 6914/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9114\n",
      "Epoch: 6915/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9115\n",
      "Epoch: 6916/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9115\n",
      "Epoch: 6917/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9116\n",
      "Epoch: 6918/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9116\n",
      "Epoch: 6919/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9117\n",
      "Epoch: 6920/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9118\n",
      "Epoch: 6921/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9118\n",
      "Epoch: 6922/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9119\n",
      "Epoch: 6923/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9119\n",
      "Epoch: 6924/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9120\n",
      "Epoch: 6925/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9120\n",
      "Epoch: 6926/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9121\n",
      "Epoch: 6927/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9121\n",
      "Epoch: 6928/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9122\n",
      "Epoch: 6929/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9122\n",
      "Epoch: 6930/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9123\n",
      "Epoch: 6931/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9124\n",
      "Epoch: 6932/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9124\n",
      "Epoch: 6933/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9125\n",
      "Epoch: 6934/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9125\n",
      "Epoch: 6935/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9126\n",
      "Epoch: 6936/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9126\n",
      "Epoch: 6937/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9127\n",
      "Epoch: 6938/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9127\n",
      "Epoch: 6939/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9128\n",
      "Epoch: 6940/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9129\n",
      "Epoch: 6941/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9129\n",
      "Epoch: 6942/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9130\n",
      "Epoch: 6943/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9130\n",
      "Epoch: 6944/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9131\n",
      "Epoch: 6945/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9131\n",
      "Epoch: 6946/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9132\n",
      "Epoch: 6947/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9132\n",
      "Epoch: 6948/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9133\n",
      "Epoch: 6949/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9133\n",
      "Epoch: 6950/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9134\n",
      "Epoch: 6951/8000, Train Loss: 0.2781\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9135\n",
      "Epoch: 6952/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9135\n",
      "Epoch: 6953/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9136\n",
      "Epoch: 6954/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9136\n",
      "Epoch: 6955/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9137\n",
      "Epoch: 6956/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9137\n",
      "Epoch: 6957/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9138\n",
      "Epoch: 6958/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9138\n",
      "Epoch: 6959/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9139\n",
      "Epoch: 6960/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9140\n",
      "Epoch: 6961/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9140\n",
      "Epoch: 6962/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9141\n",
      "Epoch: 6963/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9141\n",
      "Epoch: 6964/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9142\n",
      "Epoch: 6965/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9142\n",
      "Epoch: 6966/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9143\n",
      "Epoch: 6967/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9143\n",
      "Epoch: 6968/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9144\n",
      "Epoch: 6969/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9144\n",
      "Epoch: 6970/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9145\n",
      "Epoch: 6971/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9146\n",
      "Epoch: 6972/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9146\n",
      "Epoch: 6973/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9147\n",
      "Epoch: 6974/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9147\n",
      "Epoch: 6975/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9148\n",
      "Epoch: 6976/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9148\n",
      "Epoch: 6977/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9149\n",
      "Epoch: 6978/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9149\n",
      "Epoch: 6979/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9150\n",
      "Epoch: 6980/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9150\n",
      "Epoch: 6981/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9151\n",
      "Epoch: 6982/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9152\n",
      "Epoch: 6983/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9152\n",
      "Epoch: 6984/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9153\n",
      "Epoch: 6985/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9153\n",
      "Epoch: 6986/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9154\n",
      "Epoch: 6987/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9154\n",
      "Epoch: 6988/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9155\n",
      "Epoch: 6989/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9155\n",
      "Epoch: 6990/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9156\n",
      "Epoch: 6991/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9157\n",
      "Epoch: 6992/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9157\n",
      "Epoch: 6993/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9158\n",
      "Epoch: 6994/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9158\n",
      "Epoch: 6995/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9159\n",
      "Epoch: 6996/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9159\n",
      "Epoch: 6997/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9160\n",
      "Epoch: 6998/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9160\n",
      "Epoch: 6999/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9161\n",
      "Epoch: 7000/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9161\n",
      "Epoch: 7001/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9162\n",
      "Epoch: 7002/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9163\n",
      "Epoch: 7003/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9163\n",
      "Epoch: 7004/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9164\n",
      "Epoch: 7005/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9164\n",
      "Epoch: 7006/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9165\n",
      "Epoch: 7007/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9165\n",
      "Epoch: 7008/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9166\n",
      "Epoch: 7009/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9166\n",
      "Epoch: 7010/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9167\n",
      "Epoch: 7011/8000, Train Loss: 0.2780\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9168\n",
      "Epoch: 7012/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9168\n",
      "Epoch: 7013/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9169\n",
      "Epoch: 7014/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9169\n",
      "Epoch: 7015/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9170\n",
      "Epoch: 7016/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9170\n",
      "Epoch: 7017/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9171\n",
      "Epoch: 7018/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9171\n",
      "Epoch: 7019/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9172\n",
      "Epoch: 7020/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9172\n",
      "Epoch: 7021/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9173\n",
      "Epoch: 7022/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9174\n",
      "Epoch: 7023/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9174\n",
      "Epoch: 7024/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9175\n",
      "Epoch: 7025/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9175\n",
      "Epoch: 7026/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9176\n",
      "Epoch: 7027/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9176\n",
      "Epoch: 7028/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9177\n",
      "Epoch: 7029/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9177\n",
      "Epoch: 7030/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9178\n",
      "Epoch: 7031/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9178\n",
      "Epoch: 7032/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9179\n",
      "Epoch: 7033/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9180\n",
      "Epoch: 7034/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9180\n",
      "Epoch: 7035/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9181\n",
      "Epoch: 7036/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9181\n",
      "Epoch: 7037/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9182\n",
      "Epoch: 7038/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9182\n",
      "Epoch: 7039/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9183\n",
      "Epoch: 7040/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9183\n",
      "Epoch: 7041/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9184\n",
      "Epoch: 7042/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9184\n",
      "Epoch: 7043/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9185\n",
      "Epoch: 7044/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9186\n",
      "Epoch: 7045/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9186\n",
      "Epoch: 7046/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9187\n",
      "Epoch: 7047/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9187\n",
      "Epoch: 7048/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9188\n",
      "Epoch: 7049/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9188\n",
      "Epoch: 7050/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9189\n",
      "Epoch: 7051/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9189\n",
      "Epoch: 7052/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9190\n",
      "Epoch: 7053/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9191\n",
      "Epoch: 7054/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9191\n",
      "Epoch: 7055/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9192\n",
      "Epoch: 7056/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9192\n",
      "Epoch: 7057/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9193\n",
      "Epoch: 7058/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9193\n",
      "Epoch: 7059/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9194\n",
      "Epoch: 7060/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9194\n",
      "Epoch: 7061/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9195\n",
      "Epoch: 7062/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9195\n",
      "Epoch: 7063/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9196\n",
      "Epoch: 7064/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9197\n",
      "Epoch: 7065/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9197\n",
      "Epoch: 7066/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9198\n",
      "Epoch: 7067/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9198\n",
      "Epoch: 7068/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9199\n",
      "Epoch: 7069/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9199\n",
      "Epoch: 7070/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9200\n",
      "Epoch: 7071/8000, Train Loss: 0.2779\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9200\n",
      "Epoch: 7072/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9201\n",
      "Epoch: 7073/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9201\n",
      "Epoch: 7074/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9202\n",
      "Epoch: 7075/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9203\n",
      "Epoch: 7076/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9203\n",
      "Epoch: 7077/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9204\n",
      "Epoch: 7078/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9204\n",
      "Epoch: 7079/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9205\n",
      "Epoch: 7080/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9205\n",
      "Epoch: 7081/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9206\n",
      "Epoch: 7082/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9206\n",
      "Epoch: 7083/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9207\n",
      "Epoch: 7084/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9207\n",
      "Epoch: 7085/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9208\n",
      "Epoch: 7086/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9209\n",
      "Epoch: 7087/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9209\n",
      "Epoch: 7088/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9210\n",
      "Epoch: 7089/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9210\n",
      "Epoch: 7090/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9211\n",
      "Epoch: 7091/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9211\n",
      "Epoch: 7092/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9212\n",
      "Epoch: 7093/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9212\n",
      "Epoch: 7094/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9213\n",
      "Epoch: 7095/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9213\n",
      "Epoch: 7096/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9214\n",
      "Epoch: 7097/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9215\n",
      "Epoch: 7098/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9215\n",
      "Epoch: 7099/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9216\n",
      "Epoch: 7100/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9216\n",
      "Epoch: 7101/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9217\n",
      "Epoch: 7102/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9217\n",
      "Epoch: 7103/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9218\n",
      "Epoch: 7104/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9218\n",
      "Epoch: 7105/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9219\n",
      "Epoch: 7106/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9220\n",
      "Epoch: 7107/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9220\n",
      "Epoch: 7108/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9221\n",
      "Epoch: 7109/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9221\n",
      "Epoch: 7110/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9222\n",
      "Epoch: 7111/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9222\n",
      "Epoch: 7112/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9223\n",
      "Epoch: 7113/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9223\n",
      "Epoch: 7114/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9224\n",
      "Epoch: 7115/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9224\n",
      "Epoch: 7116/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9225\n",
      "Epoch: 7117/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9226\n",
      "Epoch: 7118/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9226\n",
      "Epoch: 7119/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9227\n",
      "Epoch: 7120/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9227\n",
      "Epoch: 7121/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9228\n",
      "Epoch: 7122/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9228\n",
      "Epoch: 7123/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9229\n",
      "Epoch: 7124/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9229\n",
      "Epoch: 7125/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9230\n",
      "Epoch: 7126/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9230\n",
      "Epoch: 7127/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9231\n",
      "Epoch: 7128/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9232\n",
      "Epoch: 7129/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9232\n",
      "Epoch: 7130/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9233\n",
      "Epoch: 7131/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9233\n",
      "Epoch: 7132/8000, Train Loss: 0.2778\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9234\n",
      "Epoch: 7133/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9234\n",
      "Epoch: 7134/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9235\n",
      "Epoch: 7135/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9235\n",
      "Epoch: 7136/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9236\n",
      "Epoch: 7137/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9236\n",
      "Epoch: 7138/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9237\n",
      "Epoch: 7139/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9238\n",
      "Epoch: 7140/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9238\n",
      "Epoch: 7141/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9239\n",
      "Epoch: 7142/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9239\n",
      "Epoch: 7143/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9240\n",
      "Epoch: 7144/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9240\n",
      "Epoch: 7145/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9241\n",
      "Epoch: 7146/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9241\n",
      "Epoch: 7147/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9242\n",
      "Epoch: 7148/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9242\n",
      "Epoch: 7149/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9243\n",
      "Epoch: 7150/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9244\n",
      "Epoch: 7151/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9244\n",
      "Epoch: 7152/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9245\n",
      "Epoch: 7153/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9245\n",
      "Epoch: 7154/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9246\n",
      "Epoch: 7155/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9246\n",
      "Epoch: 7156/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9247\n",
      "Epoch: 7157/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9247\n",
      "Epoch: 7158/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9248\n",
      "Epoch: 7159/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9248\n",
      "Epoch: 7160/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9249\n",
      "Epoch: 7161/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9250\n",
      "Epoch: 7162/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9250\n",
      "Epoch: 7163/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9251\n",
      "Epoch: 7164/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9251\n",
      "Epoch: 7165/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9252\n",
      "Epoch: 7166/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9252\n",
      "Epoch: 7167/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9253\n",
      "Epoch: 7168/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9253\n",
      "Epoch: 7169/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9254\n",
      "Epoch: 7170/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9254\n",
      "Epoch: 7171/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9255\n",
      "Epoch: 7172/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9256\n",
      "Epoch: 7173/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9256\n",
      "Epoch: 7174/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9257\n",
      "Epoch: 7175/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9257\n",
      "Epoch: 7176/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9258\n",
      "Epoch: 7177/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9258\n",
      "Epoch: 7178/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9259\n",
      "Epoch: 7179/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9259\n",
      "Epoch: 7180/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9260\n",
      "Epoch: 7181/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9260\n",
      "Epoch: 7182/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9261\n",
      "Epoch: 7183/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9262\n",
      "Epoch: 7184/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9262\n",
      "Epoch: 7185/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9263\n",
      "Epoch: 7186/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9263\n",
      "Epoch: 7187/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9264\n",
      "Epoch: 7188/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9264\n",
      "Epoch: 7189/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9265\n",
      "Epoch: 7190/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9265\n",
      "Epoch: 7191/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9266\n",
      "Epoch: 7192/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9266\n",
      "Epoch: 7193/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9267\n",
      "Epoch: 7194/8000, Train Loss: 0.2777\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9268\n",
      "Epoch: 7195/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9268\n",
      "Epoch: 7196/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9269\n",
      "Epoch: 7197/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9269\n",
      "Epoch: 7198/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9270\n",
      "Epoch: 7199/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9270\n",
      "Epoch: 7200/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9271\n",
      "Epoch: 7201/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9271\n",
      "Epoch: 7202/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9272\n",
      "Epoch: 7203/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9272\n",
      "Epoch: 7204/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9273\n",
      "Epoch: 7205/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9274\n",
      "Epoch: 7206/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9274\n",
      "Epoch: 7207/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9275\n",
      "Epoch: 7208/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9275\n",
      "Epoch: 7209/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9276\n",
      "Epoch: 7210/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9276\n",
      "Epoch: 7211/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9277\n",
      "Epoch: 7212/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9277\n",
      "Epoch: 7213/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9278\n",
      "Epoch: 7214/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9278\n",
      "Epoch: 7215/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9279\n",
      "Epoch: 7216/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9280\n",
      "Epoch: 7217/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9280\n",
      "Epoch: 7218/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9281\n",
      "Epoch: 7219/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9281\n",
      "Epoch: 7220/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9282\n",
      "Epoch: 7221/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9282\n",
      "Epoch: 7222/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9283\n",
      "Epoch: 7223/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9283\n",
      "Epoch: 7224/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9284\n",
      "Epoch: 7225/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9284\n",
      "Epoch: 7226/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9285\n",
      "Epoch: 7227/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9285\n",
      "Epoch: 7228/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9286\n",
      "Epoch: 7229/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9287\n",
      "Epoch: 7230/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9287\n",
      "Epoch: 7231/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9288\n",
      "Epoch: 7232/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9288\n",
      "Epoch: 7233/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9289\n",
      "Epoch: 7234/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9289\n",
      "Epoch: 7235/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9290\n",
      "Epoch: 7236/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9290\n",
      "Epoch: 7237/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9291\n",
      "Epoch: 7238/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9291\n",
      "Epoch: 7239/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9292\n",
      "Epoch: 7240/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9293\n",
      "Epoch: 7241/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9293\n",
      "Epoch: 7242/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9294\n",
      "Epoch: 7243/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9294\n",
      "Epoch: 7244/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9295\n",
      "Epoch: 7245/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9295\n",
      "Epoch: 7246/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9296\n",
      "Epoch: 7247/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9296\n",
      "Epoch: 7248/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9297\n",
      "Epoch: 7249/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9297\n",
      "Epoch: 7250/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9298\n",
      "Epoch: 7251/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9299\n",
      "Epoch: 7252/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9299\n",
      "Epoch: 7253/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9300\n",
      "Epoch: 7254/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9300\n",
      "Epoch: 7255/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9301\n",
      "Epoch: 7256/8000, Train Loss: 0.2776\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9301\n",
      "Epoch: 7257/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9302\n",
      "Epoch: 7258/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9302\n",
      "Epoch: 7259/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9303\n",
      "Epoch: 7260/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9303\n",
      "Epoch: 7261/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9304\n",
      "Epoch: 7262/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9305\n",
      "Epoch: 7263/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9305\n",
      "Epoch: 7264/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9306\n",
      "Epoch: 7265/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9306\n",
      "Epoch: 7266/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9307\n",
      "Epoch: 7267/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9307\n",
      "Epoch: 7268/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9308\n",
      "Epoch: 7269/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9308\n",
      "Epoch: 7270/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9309\n",
      "Epoch: 7271/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9309\n",
      "Epoch: 7272/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9310\n",
      "Epoch: 7273/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9311\n",
      "Epoch: 7274/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9311\n",
      "Epoch: 7275/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9312\n",
      "Epoch: 7276/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9312\n",
      "Epoch: 7277/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9313\n",
      "Epoch: 7278/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9313\n",
      "Epoch: 7279/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9314\n",
      "Epoch: 7280/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9314\n",
      "Epoch: 7281/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9315\n",
      "Epoch: 7282/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9315\n",
      "Epoch: 7283/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9316\n",
      "Epoch: 7284/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9316\n",
      "Epoch: 7285/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9317\n",
      "Epoch: 7286/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9318\n",
      "Epoch: 7287/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9318\n",
      "Epoch: 7288/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9319\n",
      "Epoch: 7289/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9319\n",
      "Epoch: 7290/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9320\n",
      "Epoch: 7291/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9320\n",
      "Epoch: 7292/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9321\n",
      "Epoch: 7293/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9321\n",
      "Epoch: 7294/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9322\n",
      "Epoch: 7295/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9322\n",
      "Epoch: 7296/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9323\n",
      "Epoch: 7297/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9324\n",
      "Epoch: 7298/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9324\n",
      "Epoch: 7299/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9325\n",
      "Epoch: 7300/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9325\n",
      "Epoch: 7301/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9326\n",
      "Epoch: 7302/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9326\n",
      "Epoch: 7303/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9327\n",
      "Epoch: 7304/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9327\n",
      "Epoch: 7305/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9328\n",
      "Epoch: 7306/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9328\n",
      "Epoch: 7307/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9329\n",
      "Epoch: 7308/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9330\n",
      "Epoch: 7309/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9330\n",
      "Epoch: 7310/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9331\n",
      "Epoch: 7311/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9331\n",
      "Epoch: 7312/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9332\n",
      "Epoch: 7313/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9332\n",
      "Epoch: 7314/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9333\n",
      "Epoch: 7315/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9333\n",
      "Epoch: 7316/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9334\n",
      "Epoch: 7317/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9334\n",
      "Epoch: 7318/8000, Train Loss: 0.2775\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9335\n",
      "Epoch: 7319/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9335\n",
      "Epoch: 7320/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9336\n",
      "Epoch: 7321/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9337\n",
      "Epoch: 7322/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9337\n",
      "Epoch: 7323/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9338\n",
      "Epoch: 7324/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9338\n",
      "Epoch: 7325/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9339\n",
      "Epoch: 7326/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9339\n",
      "Epoch: 7327/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9340\n",
      "Epoch: 7328/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9340\n",
      "Epoch: 7329/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9341\n",
      "Epoch: 7330/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9341\n",
      "Epoch: 7331/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9342\n",
      "Epoch: 7332/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9343\n",
      "Epoch: 7333/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9343\n",
      "Epoch: 7334/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9344\n",
      "Epoch: 7335/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9344\n",
      "Epoch: 7336/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9345\n",
      "Epoch: 7337/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9345\n",
      "Epoch: 7338/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9346\n",
      "Epoch: 7339/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9346\n",
      "Epoch: 7340/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9347\n",
      "Epoch: 7341/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9347\n",
      "Epoch: 7342/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9348\n",
      "Epoch: 7343/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9348\n",
      "Epoch: 7344/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9349\n",
      "Epoch: 7345/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9350\n",
      "Epoch: 7346/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9350\n",
      "Epoch: 7347/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9351\n",
      "Epoch: 7348/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9351\n",
      "Epoch: 7349/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9352\n",
      "Epoch: 7350/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9352\n",
      "Epoch: 7351/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9353\n",
      "Epoch: 7352/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9353\n",
      "Epoch: 7353/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9354\n",
      "Epoch: 7354/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9354\n",
      "Epoch: 7355/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9355\n",
      "Epoch: 7356/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9356\n",
      "Epoch: 7357/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9356\n",
      "Epoch: 7358/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9357\n",
      "Epoch: 7359/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9357\n",
      "Epoch: 7360/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9358\n",
      "Epoch: 7361/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9358\n",
      "Epoch: 7362/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9359\n",
      "Epoch: 7363/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9359\n",
      "Epoch: 7364/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9360\n",
      "Epoch: 7365/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9360\n",
      "Epoch: 7366/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9361\n",
      "Epoch: 7367/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9361\n",
      "Epoch: 7368/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9362\n",
      "Epoch: 7369/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9363\n",
      "Epoch: 7370/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9363\n",
      "Epoch: 7371/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9364\n",
      "Epoch: 7372/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9364\n",
      "Epoch: 7373/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9365\n",
      "Epoch: 7374/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9365\n",
      "Epoch: 7375/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9366\n",
      "Epoch: 7376/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9366\n",
      "Epoch: 7377/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9367\n",
      "Epoch: 7378/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9367\n",
      "Epoch: 7379/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9368\n",
      "Epoch: 7380/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9369\n",
      "Epoch: 7381/8000, Train Loss: 0.2774\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9369\n",
      "Epoch: 7382/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9370\n",
      "Epoch: 7383/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9370\n",
      "Epoch: 7384/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9371\n",
      "Epoch: 7385/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9371\n",
      "Epoch: 7386/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9372\n",
      "Epoch: 7387/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9372\n",
      "Epoch: 7388/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9373\n",
      "Epoch: 7389/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9373\n",
      "Epoch: 7390/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9374\n",
      "Epoch: 7391/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9374\n",
      "Epoch: 7392/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9375\n",
      "Epoch: 7393/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9376\n",
      "Epoch: 7394/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9376\n",
      "Epoch: 7395/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9377\n",
      "Epoch: 7396/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9377\n",
      "Epoch: 7397/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9378\n",
      "Epoch: 7398/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9378\n",
      "Epoch: 7399/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9379\n",
      "Epoch: 7400/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9379\n",
      "Epoch: 7401/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9380\n",
      "Epoch: 7402/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9380\n",
      "Epoch: 7403/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9381\n",
      "Epoch: 7404/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9382\n",
      "Epoch: 7405/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9382\n",
      "Epoch: 7406/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9383\n",
      "Epoch: 7407/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9383\n",
      "Epoch: 7408/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9384\n",
      "Epoch: 7409/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9384\n",
      "Epoch: 7410/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9385\n",
      "Epoch: 7411/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9385\n",
      "Epoch: 7412/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9386\n",
      "Epoch: 7413/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9386\n",
      "Epoch: 7414/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9387\n",
      "Epoch: 7415/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9387\n",
      "Epoch: 7416/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9388\n",
      "Epoch: 7417/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9389\n",
      "Epoch: 7418/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9389\n",
      "Epoch: 7419/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9390\n",
      "Epoch: 7420/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9390\n",
      "Epoch: 7421/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9391\n",
      "Epoch: 7422/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9391\n",
      "Epoch: 7423/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9392\n",
      "Epoch: 7424/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9392\n",
      "Epoch: 7425/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9393\n",
      "Epoch: 7426/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9393\n",
      "Epoch: 7427/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9394\n",
      "Epoch: 7428/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9394\n",
      "Epoch: 7429/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9395\n",
      "Epoch: 7430/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9396\n",
      "Epoch: 7431/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9396\n",
      "Epoch: 7432/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9397\n",
      "Epoch: 7433/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9397\n",
      "Epoch: 7434/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9398\n",
      "Epoch: 7435/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9398\n",
      "Epoch: 7436/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9399\n",
      "Epoch: 7437/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9399\n",
      "Epoch: 7438/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9400\n",
      "Epoch: 7439/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9400\n",
      "Epoch: 7440/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9401\n",
      "Epoch: 7441/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9402\n",
      "Epoch: 7442/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9402\n",
      "Epoch: 7443/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9403\n",
      "Epoch: 7444/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9403\n",
      "Epoch: 7445/8000, Train Loss: 0.2773\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9404\n",
      "Epoch: 7446/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9404\n",
      "Epoch: 7447/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9405\n",
      "Epoch: 7448/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9405\n",
      "Epoch: 7449/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9406\n",
      "Epoch: 7450/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9406\n",
      "Epoch: 7451/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9407\n",
      "Epoch: 7452/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9407\n",
      "Epoch: 7453/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9408\n",
      "Epoch: 7454/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9409\n",
      "Epoch: 7455/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9409\n",
      "Epoch: 7456/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9410\n",
      "Epoch: 7457/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9410\n",
      "Epoch: 7458/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9411\n",
      "Epoch: 7459/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9411\n",
      "Epoch: 7460/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9412\n",
      "Epoch: 7461/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9412\n",
      "Epoch: 7462/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9413\n",
      "Epoch: 7463/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9413\n",
      "Epoch: 7464/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9414\n",
      "Epoch: 7465/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9414\n",
      "Epoch: 7466/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9415\n",
      "Epoch: 7467/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9416\n",
      "Epoch: 7468/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9416\n",
      "Epoch: 7469/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9417\n",
      "Epoch: 7470/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9417\n",
      "Epoch: 7471/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9418\n",
      "Epoch: 7472/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9418\n",
      "Epoch: 7473/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9419\n",
      "Epoch: 7474/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9419\n",
      "Epoch: 7475/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9420\n",
      "Epoch: 7476/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9420\n",
      "Epoch: 7477/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9421\n",
      "Epoch: 7478/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9421\n",
      "Epoch: 7479/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9422\n",
      "Epoch: 7480/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9423\n",
      "Epoch: 7481/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9423\n",
      "Epoch: 7482/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9424\n",
      "Epoch: 7483/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9424\n",
      "Epoch: 7484/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9425\n",
      "Epoch: 7485/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9425\n",
      "Epoch: 7486/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9426\n",
      "Epoch: 7487/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9426\n",
      "Epoch: 7488/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9427\n",
      "Epoch: 7489/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9427\n",
      "Epoch: 7490/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9428\n",
      "Epoch: 7491/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9428\n",
      "Epoch: 7492/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9429\n",
      "Epoch: 7493/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9430\n",
      "Epoch: 7494/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9430\n",
      "Epoch: 7495/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9431\n",
      "Epoch: 7496/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9431\n",
      "Epoch: 7497/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9432\n",
      "Epoch: 7498/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9432\n",
      "Epoch: 7499/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9433\n",
      "Epoch: 7500/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9433\n",
      "Epoch: 7501/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9434\n",
      "Epoch: 7502/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9434\n",
      "Epoch: 7503/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9435\n",
      "Epoch: 7504/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9436\n",
      "Epoch: 7505/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9436\n",
      "Epoch: 7506/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9437\n",
      "Epoch: 7507/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9437\n",
      "Epoch: 7508/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9438\n",
      "Epoch: 7509/8000, Train Loss: 0.2772\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9438\n",
      "Epoch: 7510/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9439\n",
      "Epoch: 7511/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9439\n",
      "Epoch: 7512/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9440\n",
      "Epoch: 7513/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9440\n",
      "Epoch: 7514/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9441\n",
      "Epoch: 7515/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9441\n",
      "Epoch: 7516/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9442\n",
      "Epoch: 7517/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9443\n",
      "Epoch: 7518/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9443\n",
      "Epoch: 7519/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9444\n",
      "Epoch: 7520/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9444\n",
      "Epoch: 7521/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9445\n",
      "Epoch: 7522/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9445\n",
      "Epoch: 7523/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9446\n",
      "Epoch: 7524/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9446\n",
      "Epoch: 7525/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9447\n",
      "Epoch: 7526/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9447\n",
      "Epoch: 7527/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9448\n",
      "Epoch: 7528/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9448\n",
      "Epoch: 7529/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9449\n",
      "Epoch: 7530/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9450\n",
      "Epoch: 7531/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9450\n",
      "Epoch: 7532/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9451\n",
      "Epoch: 7533/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9451\n",
      "Epoch: 7534/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9452\n",
      "Epoch: 7535/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9452\n",
      "Epoch: 7536/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9453\n",
      "Epoch: 7537/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9453\n",
      "Epoch: 7538/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9454\n",
      "Epoch: 7539/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9454\n",
      "Epoch: 7540/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9455\n",
      "Epoch: 7541/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9455\n",
      "Epoch: 7542/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9456\n",
      "Epoch: 7543/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9457\n",
      "Epoch: 7544/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9457\n",
      "Epoch: 7545/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9458\n",
      "Epoch: 7546/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9458\n",
      "Epoch: 7547/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9459\n",
      "Epoch: 7548/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9459\n",
      "Epoch: 7549/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9460\n",
      "Epoch: 7550/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9460\n",
      "Epoch: 7551/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9461\n",
      "Epoch: 7552/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9461\n",
      "Epoch: 7553/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9462\n",
      "Epoch: 7554/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9462\n",
      "Epoch: 7555/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9463\n",
      "Epoch: 7556/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9464\n",
      "Epoch: 7557/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9464\n",
      "Epoch: 7558/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9465\n",
      "Epoch: 7559/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9465\n",
      "Epoch: 7560/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9466\n",
      "Epoch: 7561/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9466\n",
      "Epoch: 7562/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9467\n",
      "Epoch: 7563/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9467\n",
      "Epoch: 7564/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9468\n",
      "Epoch: 7565/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9468\n",
      "Epoch: 7566/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9469\n",
      "Epoch: 7567/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9469\n",
      "Epoch: 7568/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9470\n",
      "Epoch: 7569/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9470\n",
      "Epoch: 7570/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9471\n",
      "Epoch: 7571/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9472\n",
      "Epoch: 7572/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9472\n",
      "Epoch: 7573/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9473\n",
      "Epoch: 7574/8000, Train Loss: 0.2771\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9473\n",
      "Epoch: 7575/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9474\n",
      "Epoch: 7576/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9474\n",
      "Epoch: 7577/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9475\n",
      "Epoch: 7578/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9475\n",
      "Epoch: 7579/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9476\n",
      "Epoch: 7580/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9476\n",
      "Epoch: 7581/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9477\n",
      "Epoch: 7582/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9477\n",
      "Epoch: 7583/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9478\n",
      "Epoch: 7584/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9479\n",
      "Epoch: 7585/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9479\n",
      "Epoch: 7586/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9480\n",
      "Epoch: 7587/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9480\n",
      "Epoch: 7588/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9481\n",
      "Epoch: 7589/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9481\n",
      "Epoch: 7590/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9482\n",
      "Epoch: 7591/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9482\n",
      "Epoch: 7592/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9483\n",
      "Epoch: 7593/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9483\n",
      "Epoch: 7594/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9484\n",
      "Epoch: 7595/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9484\n",
      "Epoch: 7596/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9485\n",
      "Epoch: 7597/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9486\n",
      "Epoch: 7598/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9486\n",
      "Epoch: 7599/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9487\n",
      "Epoch: 7600/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9487\n",
      "Epoch: 7601/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9488\n",
      "Epoch: 7602/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9488\n",
      "Epoch: 7603/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9489\n",
      "Epoch: 7604/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9489\n",
      "Epoch: 7605/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9490\n",
      "Epoch: 7606/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9490\n",
      "Epoch: 7607/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9491\n",
      "Epoch: 7608/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9491\n",
      "Epoch: 7609/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9492\n",
      "Epoch: 7610/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9493\n",
      "Epoch: 7611/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9493\n",
      "Epoch: 7612/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9494\n",
      "Epoch: 7613/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9494\n",
      "Epoch: 7614/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9495\n",
      "Epoch: 7615/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9495\n",
      "Epoch: 7616/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9496\n",
      "Epoch: 7617/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9496\n",
      "Epoch: 7618/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9497\n",
      "Epoch: 7619/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9497\n",
      "Epoch: 7620/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9498\n",
      "Epoch: 7621/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9498\n",
      "Epoch: 7622/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9499\n",
      "Epoch: 7623/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9500\n",
      "Epoch: 7624/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9500\n",
      "Epoch: 7625/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9501\n",
      "Epoch: 7626/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9501\n",
      "Epoch: 7627/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9502\n",
      "Epoch: 7628/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9502\n",
      "Epoch: 7629/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9503\n",
      "Epoch: 7630/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9503\n",
      "Epoch: 7631/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9504\n",
      "Epoch: 7632/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9504\n",
      "Epoch: 7633/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9505\n",
      "Epoch: 7634/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9505\n",
      "Epoch: 7635/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9506\n",
      "Epoch: 7636/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9506\n",
      "Epoch: 7637/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9507\n",
      "Epoch: 7638/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9508\n",
      "Epoch: 7639/8000, Train Loss: 0.2770\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9508\n",
      "Epoch: 7640/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9509\n",
      "Epoch: 7641/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9509\n",
      "Epoch: 7642/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9510\n",
      "Epoch: 7643/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9510\n",
      "Epoch: 7644/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9511\n",
      "Epoch: 7645/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9511\n",
      "Epoch: 7646/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9512\n",
      "Epoch: 7647/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9512\n",
      "Epoch: 7648/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9513\n",
      "Epoch: 7649/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9513\n",
      "Epoch: 7650/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9514\n",
      "Epoch: 7651/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9515\n",
      "Epoch: 7652/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9515\n",
      "Epoch: 7653/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9516\n",
      "Epoch: 7654/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9516\n",
      "Epoch: 7655/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9517\n",
      "Epoch: 7656/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9517\n",
      "Epoch: 7657/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9518\n",
      "Epoch: 7658/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9518\n",
      "Epoch: 7659/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9519\n",
      "Epoch: 7660/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9519\n",
      "Epoch: 7661/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9520\n",
      "Epoch: 7662/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9520\n",
      "Epoch: 7663/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9521\n",
      "Epoch: 7664/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9522\n",
      "Epoch: 7665/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9522\n",
      "Epoch: 7666/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9523\n",
      "Epoch: 7667/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9523\n",
      "Epoch: 7668/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9524\n",
      "Epoch: 7669/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9524\n",
      "Epoch: 7670/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9525\n",
      "Epoch: 7671/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9525\n",
      "Epoch: 7672/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9526\n",
      "Epoch: 7673/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9526\n",
      "Epoch: 7674/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9527\n",
      "Epoch: 7675/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9527\n",
      "Epoch: 7676/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9528\n",
      "Epoch: 7677/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9528\n",
      "Epoch: 7678/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9529\n",
      "Epoch: 7679/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9530\n",
      "Epoch: 7680/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9530\n",
      "Epoch: 7681/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9531\n",
      "Epoch: 7682/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9531\n",
      "Epoch: 7683/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9532\n",
      "Epoch: 7684/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9532\n",
      "Epoch: 7685/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9533\n",
      "Epoch: 7686/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9533\n",
      "Epoch: 7687/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9534\n",
      "Epoch: 7688/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9534\n",
      "Epoch: 7689/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9535\n",
      "Epoch: 7690/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9535\n",
      "Epoch: 7691/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9536\n",
      "Epoch: 7692/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9537\n",
      "Epoch: 7693/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9537\n",
      "Epoch: 7694/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9538\n",
      "Epoch: 7695/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9538\n",
      "Epoch: 7696/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9539\n",
      "Epoch: 7697/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9539\n",
      "Epoch: 7698/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9540\n",
      "Epoch: 7699/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9540\n",
      "Epoch: 7700/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9541\n",
      "Epoch: 7701/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9541\n",
      "Epoch: 7702/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9542\n",
      "Epoch: 7703/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9542\n",
      "Epoch: 7704/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9543\n",
      "Epoch: 7705/8000, Train Loss: 0.2769\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9543\n",
      "Epoch: 7706/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9544\n",
      "Epoch: 7707/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9545\n",
      "Epoch: 7708/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9545\n",
      "Epoch: 7709/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9546\n",
      "Epoch: 7710/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9546\n",
      "Epoch: 7711/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9547\n",
      "Epoch: 7712/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9547\n",
      "Epoch: 7713/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9548\n",
      "Epoch: 7714/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9548\n",
      "Epoch: 7715/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9549\n",
      "Epoch: 7716/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9549\n",
      "Epoch: 7717/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9550\n",
      "Epoch: 7718/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9550\n",
      "Epoch: 7719/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9551\n",
      "Epoch: 7720/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9551\n",
      "Epoch: 7721/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9552\n",
      "Epoch: 7722/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9553\n",
      "Epoch: 7723/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9553\n",
      "Epoch: 7724/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9554\n",
      "Epoch: 7725/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9554\n",
      "Epoch: 7726/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9555\n",
      "Epoch: 7727/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9555\n",
      "Epoch: 7728/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9556\n",
      "Epoch: 7729/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9556\n",
      "Epoch: 7730/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9557\n",
      "Epoch: 7731/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9557\n",
      "Epoch: 7732/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9558\n",
      "Epoch: 7733/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9558\n",
      "Epoch: 7734/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9559\n",
      "Epoch: 7735/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9560\n",
      "Epoch: 7736/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9560\n",
      "Epoch: 7737/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9561\n",
      "Epoch: 7738/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9561\n",
      "Epoch: 7739/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9562\n",
      "Epoch: 7740/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9562\n",
      "Epoch: 7741/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9563\n",
      "Epoch: 7742/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9563\n",
      "Epoch: 7743/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9564\n",
      "Epoch: 7744/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9564\n",
      "Epoch: 7745/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9565\n",
      "Epoch: 7746/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9565\n",
      "Epoch: 7747/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9566\n",
      "Epoch: 7748/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9566\n",
      "Epoch: 7749/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9567\n",
      "Epoch: 7750/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9568\n",
      "Epoch: 7751/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9568\n",
      "Epoch: 7752/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9569\n",
      "Epoch: 7753/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9569\n",
      "Epoch: 7754/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9570\n",
      "Epoch: 7755/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9570\n",
      "Epoch: 7756/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9571\n",
      "Epoch: 7757/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9571\n",
      "Epoch: 7758/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9572\n",
      "Epoch: 7759/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9572\n",
      "Epoch: 7760/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9573\n",
      "Epoch: 7761/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9573\n",
      "Epoch: 7762/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9574\n",
      "Epoch: 7763/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9574\n",
      "Epoch: 7764/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9575\n",
      "Epoch: 7765/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9576\n",
      "Epoch: 7766/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9576\n",
      "Epoch: 7767/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9577\n",
      "Epoch: 7768/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9577\n",
      "Epoch: 7769/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9578\n",
      "Epoch: 7770/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9578\n",
      "Epoch: 7771/8000, Train Loss: 0.2768\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9579\n",
      "Epoch: 7772/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9579\n",
      "Epoch: 7773/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9580\n",
      "Epoch: 7774/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9580\n",
      "Epoch: 7775/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9581\n",
      "Epoch: 7776/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9581\n",
      "Epoch: 7777/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9582\n",
      "Epoch: 7778/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9582\n",
      "Epoch: 7779/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9583\n",
      "Epoch: 7780/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9584\n",
      "Epoch: 7781/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9584\n",
      "Epoch: 7782/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9585\n",
      "Epoch: 7783/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9585\n",
      "Epoch: 7784/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9586\n",
      "Epoch: 7785/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9586\n",
      "Epoch: 7786/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9587\n",
      "Epoch: 7787/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9587\n",
      "Epoch: 7788/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9588\n",
      "Epoch: 7789/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9588\n",
      "Epoch: 7790/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9589\n",
      "Epoch: 7791/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9589\n",
      "Epoch: 7792/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9590\n",
      "Epoch: 7793/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9590\n",
      "Epoch: 7794/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9591\n",
      "Epoch: 7795/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9592\n",
      "Epoch: 7796/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9592\n",
      "Epoch: 7797/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9593\n",
      "Epoch: 7798/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9593\n",
      "Epoch: 7799/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9594\n",
      "Epoch: 7800/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9594\n",
      "Epoch: 7801/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9595\n",
      "Epoch: 7802/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9595\n",
      "Epoch: 7803/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9596\n",
      "Epoch: 7804/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9596\n",
      "Epoch: 7805/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9597\n",
      "Epoch: 7806/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9597\n",
      "Epoch: 7807/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9598\n",
      "Epoch: 7808/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9598\n",
      "Epoch: 7809/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9599\n",
      "Epoch: 7810/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9600\n",
      "Epoch: 7811/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9600\n",
      "Epoch: 7812/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9601\n",
      "Epoch: 7813/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9601\n",
      "Epoch: 7814/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9602\n",
      "Epoch: 7815/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9602\n",
      "Epoch: 7816/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9603\n",
      "Epoch: 7817/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9603\n",
      "Epoch: 7818/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9604\n",
      "Epoch: 7819/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9604\n",
      "Epoch: 7820/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9605\n",
      "Epoch: 7821/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9605\n",
      "Epoch: 7822/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9606\n",
      "Epoch: 7823/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9606\n",
      "Epoch: 7824/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9607\n",
      "Epoch: 7825/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9608\n",
      "Epoch: 7826/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9608\n",
      "Epoch: 7827/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9609\n",
      "Epoch: 7828/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9609\n",
      "Epoch: 7829/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9610\n",
      "Epoch: 7830/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9610\n",
      "Epoch: 7831/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9611\n",
      "Epoch: 7832/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9611\n",
      "Epoch: 7833/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9612\n",
      "Epoch: 7834/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9612\n",
      "Epoch: 7835/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9613\n",
      "Epoch: 7836/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9613\n",
      "Epoch: 7837/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9614\n",
      "Epoch: 7838/8000, Train Loss: 0.2767\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9614\n",
      "Epoch: 7839/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9615\n",
      "Epoch: 7840/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9616\n",
      "Epoch: 7841/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9616\n",
      "Epoch: 7842/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9617\n",
      "Epoch: 7843/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9617\n",
      "Epoch: 7844/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9618\n",
      "Epoch: 7845/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9618\n",
      "Epoch: 7846/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9619\n",
      "Epoch: 7847/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9619\n",
      "Epoch: 7848/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9620\n",
      "Epoch: 7849/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9620\n",
      "Epoch: 7850/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9621\n",
      "Epoch: 7851/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9621\n",
      "Epoch: 7852/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9622\n",
      "Epoch: 7853/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9622\n",
      "Epoch: 7854/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9623\n",
      "Epoch: 7855/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9624\n",
      "Epoch: 7856/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9624\n",
      "Epoch: 7857/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9625\n",
      "Epoch: 7858/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9625\n",
      "Epoch: 7859/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9626\n",
      "Epoch: 7860/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9626\n",
      "Epoch: 7861/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9627\n",
      "Epoch: 7862/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9627\n",
      "Epoch: 7863/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9628\n",
      "Epoch: 7864/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9628\n",
      "Epoch: 7865/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9629\n",
      "Epoch: 7866/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9629\n",
      "Epoch: 7867/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9630\n",
      "Epoch: 7868/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9630\n",
      "Epoch: 7869/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9631\n",
      "Epoch: 7870/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9632\n",
      "Epoch: 7871/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9632\n",
      "Epoch: 7872/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9633\n",
      "Epoch: 7873/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9633\n",
      "Epoch: 7874/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9634\n",
      "Epoch: 7875/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9634\n",
      "Epoch: 7876/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9635\n",
      "Epoch: 7877/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9635\n",
      "Epoch: 7878/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9636\n",
      "Epoch: 7879/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9636\n",
      "Epoch: 7880/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9637\n",
      "Epoch: 7881/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9637\n",
      "Epoch: 7882/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9638\n",
      "Epoch: 7883/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9638\n",
      "Epoch: 7884/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9639\n",
      "Epoch: 7885/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9640\n",
      "Epoch: 7886/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9640\n",
      "Epoch: 7887/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9641\n",
      "Epoch: 7888/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9641\n",
      "Epoch: 7889/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9642\n",
      "Epoch: 7890/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9642\n",
      "Epoch: 7891/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9643\n",
      "Epoch: 7892/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9643\n",
      "Epoch: 7893/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9644\n",
      "Epoch: 7894/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9644\n",
      "Epoch: 7895/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9645\n",
      "Epoch: 7896/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9645\n",
      "Epoch: 7897/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9646\n",
      "Epoch: 7898/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9646\n",
      "Epoch: 7899/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9647\n",
      "Epoch: 7900/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9647\n",
      "Epoch: 7901/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9648\n",
      "Epoch: 7902/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9649\n",
      "Epoch: 7903/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9649\n",
      "Epoch: 7904/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9650\n",
      "Epoch: 7905/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9650\n",
      "Epoch: 7906/8000, Train Loss: 0.2766\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9651\n",
      "Epoch: 7907/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9651\n",
      "Epoch: 7908/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9652\n",
      "Epoch: 7909/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9652\n",
      "Epoch: 7910/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9653\n",
      "Epoch: 7911/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9653\n",
      "Epoch: 7912/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9654\n",
      "Epoch: 7913/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9654\n",
      "Epoch: 7914/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9655\n",
      "Epoch: 7915/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9655\n",
      "Epoch: 7916/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9656\n",
      "Epoch: 7917/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9657\n",
      "Epoch: 7918/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9657\n",
      "Epoch: 7919/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9658\n",
      "Epoch: 7920/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9658\n",
      "Epoch: 7921/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9659\n",
      "Epoch: 7922/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9659\n",
      "Epoch: 7923/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9660\n",
      "Epoch: 7924/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9660\n",
      "Epoch: 7925/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9661\n",
      "Epoch: 7926/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9661\n",
      "Epoch: 7927/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9662\n",
      "Epoch: 7928/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9662\n",
      "Epoch: 7929/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9663\n",
      "Epoch: 7930/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9663\n",
      "Epoch: 7931/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9664\n",
      "Epoch: 7932/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9664\n",
      "Epoch: 7933/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9665\n",
      "Epoch: 7934/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9666\n",
      "Epoch: 7935/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9666\n",
      "Epoch: 7936/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9667\n",
      "Epoch: 7937/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9667\n",
      "Epoch: 7938/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9668\n",
      "Epoch: 7939/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9668\n",
      "Epoch: 7940/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9669\n",
      "Epoch: 7941/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9669\n",
      "Epoch: 7942/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9670\n",
      "Epoch: 7943/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9670\n",
      "Epoch: 7944/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9671\n",
      "Epoch: 7945/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9671\n",
      "Epoch: 7946/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9672\n",
      "Epoch: 7947/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9672\n",
      "Epoch: 7948/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9673\n",
      "Epoch: 7949/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9674\n",
      "Epoch: 7950/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9674\n",
      "Epoch: 7951/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9675\n",
      "Epoch: 7952/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9675\n",
      "Epoch: 7953/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9676\n",
      "Epoch: 7954/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9676\n",
      "Epoch: 7955/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9677\n",
      "Epoch: 7956/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9677\n",
      "Epoch: 7957/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9678\n",
      "Epoch: 7958/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9678\n",
      "Epoch: 7959/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9679\n",
      "Epoch: 7960/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9679\n",
      "Epoch: 7961/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9680\n",
      "Epoch: 7962/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9680\n",
      "Epoch: 7963/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9681\n",
      "Epoch: 7964/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9681\n",
      "Epoch: 7965/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9682\n",
      "Epoch: 7966/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9683\n",
      "Epoch: 7967/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9683\n",
      "Epoch: 7968/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9684\n",
      "Epoch: 7969/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9684\n",
      "Epoch: 7970/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9685\n",
      "Epoch: 7971/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9685\n",
      "Epoch: 7972/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9686\n",
      "Epoch: 7973/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9686\n",
      "Epoch: 7974/8000, Train Loss: 0.2765\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9687\n",
      "Epoch: 7975/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9687\n",
      "Epoch: 7976/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9688\n",
      "Epoch: 7977/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9688\n",
      "Epoch: 7978/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9689\n",
      "Epoch: 7979/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9689\n",
      "Epoch: 7980/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9690\n",
      "Epoch: 7981/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9690\n",
      "Epoch: 7982/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9691\n",
      "Epoch: 7983/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9692\n",
      "Epoch: 7984/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9692\n",
      "Epoch: 7985/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9693\n",
      "Epoch: 7986/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9693\n",
      "Epoch: 7987/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9694\n",
      "Epoch: 7988/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9694\n",
      "Epoch: 7989/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9695\n",
      "Epoch: 7990/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9695\n",
      "Epoch: 7991/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9696\n",
      "Epoch: 7992/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9696\n",
      "Epoch: 7993/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9697\n",
      "Epoch: 7994/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9697\n",
      "Epoch: 7995/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9698\n",
      "Epoch: 7996/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9698\n",
      "Epoch: 7997/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9699\n",
      "Epoch: 7998/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9700\n",
      "Epoch: 7999/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9700\n",
      "Epoch: 8000/8000, Train Loss: 0.2764\n",
      "Accuracy on Val set: 87.50%\tLoss on Val set: 0.9701\n"
     ]
    }
   ],
   "source": [
    "from LogisticRegression import LogisticRegression\n",
    "\n",
    "epochs = 8000\n",
    "alpha = 0.5\n",
    "logistic_reg2 = LogisticRegression(x=train_x_map,y=train_y_ex,val_x=val_x_map,val_y=val_y_ex,epoch=epochs,lr=alpha,scale=0,regularize=\"L2\")\n",
    "theta, loss, val_loss = logistic_reg2.train()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "查看精度，损失和F1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Set: 79.17%\n",
      "My F1 Score: 0.8148\n"
     ]
    }
   ],
   "source": [
    "acc = logistic_reg2.test(val_x_map,val_y_ex)\n",
    "print(\"Accuracy on Test Set: {:.2f}%\".format(acc * 100))\n",
    "from sklearn.metrics import f1_score\n",
    "f1 = f1_score(y_true=val_y_ex,y_pred=logistic_reg2.predict(val_x_map))\n",
    "print(\"My F1 Score: {:.4f}\".format(f1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用库函数验证"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Accuracy: 79.17%\n",
      "Sklearn Val Loss: 0.7970\n",
      "Sklearn F1 Score: 0.8000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sk_lr2 = LogisticRegression()\n",
    "sk_lr2.fit(train_x_map,train_y)\n",
    "sk_pred2 = sk_lr2.predict(val_x_map)\n",
    "count2 = np.sum(np.equal(sk_pred2,val_y))\n",
    "sk_acc2 = count2/val_y.shape[0]\n",
    "sk_prob2 = sk_lr2.predict_proba(val_x_map)\n",
    "\n",
    "from LogisticRegression import bce_loss\n",
    "sk_loss2 = bce_loss(sk_prob2[:,1], val_y_ex)\n",
    "sk_f12 = f1_score(y_true=val_y_ex,y_pred=sk_pred2)\n",
    "print(\"Sklearn Accuracy: {:.2f}%\".format(sk_acc2 * 100))\n",
    "print(\"Sklearn Val Loss: {:.4f}\".format(sk_loss2))\n",
    "print(\"Sklearn F1 Score: {:.4f}\".format(sk_f12))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "可视化决策边界"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x800 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = np.linspace(-1, 1.5, 700)\n",
    "t2 = np.linspace(-1, 1.5, 700)\n",
    "\n",
    "coordinates = np.array([[x, y] for x in t1 for y in t2])\n",
    "\n",
    "mapped_cord_x = feature_mapping(np.array(coordinates), degree=6)  # this is a dataframe\n",
    "prob = logistic_reg2.get_inner_product(mapped_cord_x)\n",
    "sk_prob_coor = sk_lr2.predict_proba(mapped_cord_x)\n",
    "idx1 = np.where(abs(prob[0,:])<5e-3)\n",
    "idx2 = np.where(np.logical_and(sk_prob_coor[:,0] >= 0.495, sk_prob_coor[:,0] <= 0.505))\n",
    "my_bd = coordinates[idx1]\n",
    "sk_bd = coordinates[idx2]\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.scatter(x=my_bd[:, 0], y=my_bd[:, 1], s=10, color=\"yellow\", label=\"My Decision Boundary\")\n",
    "ax.scatter(x=sk_bd[:, 0], y=sk_bd[:, 1], s=10, color=\"gray\", label=\"Sklearn Decision Boundary\")\n",
    "ax.scatter(x=positive_data[:, 0], y=positive_data[:, 1], s=10, color=\"red\",label=\"positive\")\n",
    "ax.scatter(x=negative_data[:, 0], y=negative_data[:, 1], s=10, label=\"negative\")\n",
    "ax.set_title('Decision Boundary')\n",
    "ax.legend(loc=2)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}